{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11709306,"sourceType":"datasetVersion","datasetId":6711261}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"ver 8 (6), v10","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n# Keras được tích hợp trong TensorFlow dưới dạng tf.keras\nkeras_version_from_tf = tf.keras.__version__\nprint(f\"Phiên bản Keras API (thông qua tf.keras): {keras_version_from_tf}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:05:09.857798Z","iopub.execute_input":"2025-05-22T19:05:09.858222Z","iopub.status.idle":"2025-05-22T19:05:21.492621Z","shell.execute_reply.started":"2025-05-22T19:05:09.858182Z","shell.execute_reply":"2025-05-22T19:05:21.491905Z"}},"outputs":[{"name":"stdout","text":"Phiên bản Keras API (thông qua tf.keras): 3.5.0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!cat /proc/cpuinfo | grep \"model name\" | uniq \n# Hoặc để xem số core\n!nproc ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:59:33.535913Z","iopub.execute_input":"2025-05-22T18:59:33.536271Z","iopub.status.idle":"2025-05-22T18:59:33.773679Z","shell.execute_reply.started":"2025-05-22T18:59:33.536241Z","shell.execute_reply":"2025-05-22T18:59:33.772865Z"}},"outputs":[{"name":"stdout","text":"model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n4\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!free -h \n# Hoặc chi tiết hơn\n!cat /proc/meminfo | grep MemTotal","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:00:22.805424Z","iopub.execute_input":"2025-05-22T19:00:22.805756Z","iopub.status.idle":"2025-05-22T19:00:23.085306Z","shell.execute_reply.started":"2025-05-22T19:00:22.805729Z","shell.execute_reply":"2025-05-22T19:00:23.084541Z"}},"outputs":[{"name":"stdout","text":"               total        used        free      shared  buff/cache   available\nMem:            31Gi       836Mi        23Gi       1.0Mi       6.9Gi        30Gi\nSwap:             0B          0B          0B\nMemTotal:       32873392 kB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:58:04.760970Z","iopub.execute_input":"2025-05-22T18:58:04.761387Z","iopub.status.idle":"2025-05-22T18:58:04.933902Z","shell.execute_reply.started":"2025-05-22T18:58:04.761350Z","shell.execute_reply":"2025-05-22T18:58:04.932229Z"}},"outputs":[{"name":"stdout","text":"Thu May 22 18:58:04 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   31C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport json\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw\nfrom typing import Tuple\n\nimport cv2\nimport json\nfrom tqdm.notebook import tqdm\n\n\nimport pandas as pd\nimport glob\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\nimport shutil \n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom typing import List, Tuple, Optional","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T04:57:51.281364Z","iopub.execute_input":"2025-05-30T04:57:51.281650Z","iopub.status.idle":"2025-05-30T04:58:04.402530Z","shell.execute_reply.started":"2025-05-30T04:57:51.281629Z","shell.execute_reply":"2025-05-30T04:58:04.401793Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"base_input_dir = \"/kaggle/input/btxrd-data/BTXRD/BTXRD\" \nimage_dir = os.path.join(base_input_dir, \"images\")\nannotation_dir = os.path.join(base_input_dir, \"Annotations\")\nexcel_path = \"/kaggle/input/btxrd-data/classification.xlsx\"\n\n\n# output_dir = \"/kaggle/working/btxrd-v2.2\"\n# output_image_dir = os.path.join(output_dir, \"images\")\n# output_anno_dir = os.path.join(output_dir, \"Annotations\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.430179Z","iopub.status.idle":"2025-05-13T01:54:09.431135Z","shell.execute_reply.started":"2025-05-13T01:54:09.430368Z","shell.execute_reply":"2025-05-13T01:54:09.430415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Đọc file Excel\n# file_path = '/kaggle/input/btxrd-data/classification.xlsx'\ndf = pd.read_excel(excel_path)\n\n# Hiển thị 10 dòng đầu tiên\ndf.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.432391Z","iopub.status.idle":"2025-05-13T01:54:09.433268Z","shell.execute_reply.started":"2025-05-13T01:54:09.432557Z","shell.execute_reply":"2025-05-13T01:54:09.432619Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Xử lý ảnh**","metadata":{}},{"cell_type":"code","source":"# in 30 ảnh trước xử lý\nnum_images_to_show = 30\nimages_per_row = 5  # Số ảnh mỗi hàng\nmask_color = [255, 0, 0]  # Red\n\ndef create_mask(img_size: Tuple[int, int], ann_path: str) -> np.ndarray:\n    mask = Image.new('L', img_size, 0)\n    if os.path.exists(ann_path):\n        try:\n            with open(ann_path, 'r') as f:\n                data = json.load(f)\n                for shape in data.get('shapes', []):\n                    points = shape.get('points', [])\n                    polygon_points = [(int(x), int(y)) for x, y in points]\n                    if polygon_points:\n                        ImageDraw.Draw(mask).polygon(polygon_points, outline=1, fill=1)\n        except Exception as e:\n            print(f\"Lỗi annotation {ann_path}: {e}\")\n    return np.array(mask)\n\n# Lấy danh sách tất cả ảnh trong thư mục\nall_filenames = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# Chọn ngẫu nhiên 30 ảnh\nselected_filenames = random.sample(all_filenames, min(num_images_to_show, len(all_filenames)))\n\n# Plot ảnh với mask\nplt.figure(figsize=(18, 18))  # Tăng kích thước ảnh\nfor i, fname in enumerate(selected_filenames):\n    img_path = os.path.join(image_dir, fname)\n    ann_fname = os.path.splitext(fname)[0] + '.json'\n    ann_path = os.path.join(annotation_dir, ann_fname)\n\n    try:\n        img_pil = Image.open(img_path).convert('L')\n        img_np = np.array(img_pil)\n\n        mask_np = create_mask(img_pil.size, ann_path)\n        color_img = np.stack([img_np] * 3, axis=-1)\n        color_img[mask_np == 1] = mask_color\n\n        # Chia bố cục thành 6 hàng và 5 cột (số ảnh mỗi hàng là 5)\n        plt.subplot(6, 5, i + 1)\n        plt.imshow(color_img)\n        plt.axis('off')  # Tắt trục\n    except Exception as e:\n        print(f\"Lỗi khi xử lý {fname}: {e}\")\n        continue\n\n# Loại bỏ khoảng trống giữa các ảnh\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.434296Z","iopub.status.idle":"2025-05-13T01:54:09.435136Z","shell.execute_reply.started":"2025-05-13T01:54:09.434455Z","shell.execute_reply":"2025-05-13T01:54:09.434496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nTARGET_SIZE = 512\n\n# base_input_dir = \"/kaggle/input/btxrd-data/BTXRD/BTXRD\" # Đường dẫn gốc chứa ảnh và annotation\n# image_dir = os.path.join(base_input_dir, \"images\")      # Thư mục chứa ảnh gốc\n# annotation_dir = os.path.join(base_input_dir, \"Annotations\") # Thư mục chứa annotation gốc\n\noutput_dir = \"/kaggle/working/btxrd-v2.2\"\noutput_image_dir = os.path.join(output_dir, \"images\")\noutput_anno_dir = os.path.join(output_dir, \"annotations\")\n\nos.makedirs(output_image_dir, exist_ok=True)\nos.makedirs(output_anno_dir, exist_ok=True)\n\nMAX_VISUALIZATIONS = 5 # Số lượng ảnh tối đa để trực quan hóa\nvisualized_count = 0\n\n\ndef get_bounding_box(points):\n    if not points:\n        return None\n    points_array = np.array(points)\n    xmin = int(np.min(points_array[:, 0]))\n    ymin = int(np.min(points_array[:, 1]))\n    xmax = int(np.max(points_array[:, 0]))\n    ymax = int(np.max(points_array[:, 1]))\n    # Đảm bảo tọa độ không âm\n    xmin = max(0, xmin)\n    ymin = max(0, ymin)\n    return (xmin, ymin, xmax, ymax)\n\ntry:\n    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg'))]\n    total_images = len(image_files)\n    if total_images == 0:\n        print(f\"Không tìm thấy file ảnh nào trong: {image_dir}\")\n        exit()\n    print(f\"Tìm thấy {total_images} ảnh để xử lý.\")\nexcept FileNotFoundError:\n    print(f\"Không tìm thấy thư mục ảnh: {image_dir}\")\n    exit()\n\nprint(f\"Bắt đầu xử lý ảnh và lưu vào: {output_dir}\")\n# Sử dụng tqdm để hiển thị thanh tiến trình\nfor file in tqdm(image_files, desc=\"Processing Images\"):\n    img_path = os.path.join(image_dir, file)\n    anno_filename = file.rsplit('.', 1)[0] + '.json'\n    anno_path = os.path.join(annotation_dir, anno_filename)\n\n    # Đọc ảnh gốc\n    img_orig = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    if img_orig is None:\n        # print(f\"Không thể đọc ảnh: {file}\"\n        continue\n    orig_height, orig_width = img_orig.shape[:2]\n\n    # Đọc annotation gốc \n    annotation_orig = None\n    has_annotation = os.path.exists(anno_path)\n    if has_annotation:\n        try:\n            with open(anno_path, \"r\", encoding=\"utf-8\") as f:\n                annotation_orig = json.load(f)\n        except Exception as e:\n            # print(f\"Lỗi khi đọc annotation {anno_filename}: {e}\")\n            has_annotation = False # Coi như không có nếu đọc lỗi\n\n    img_to_draw_orig = None\n    img_to_draw_padded = None\n    original_bboxes = []\n    transformed_bboxes = []\n\n    should_visualize = has_annotation and (visualized_count < MAX_VISUALIZATIONS)\n\n    if should_visualize:\n        img_to_draw_orig = cv2.cvtColor(img_orig, cv2.COLOR_GRAY2BGR) # Chuyển sang BGR để vẽ màu\n        if annotation_orig and \"shapes\" in annotation_orig:\n             for shape in annotation_orig[\"shapes\"]:\n                if shape.get(\"shape_type\") == \"rectangle\" and \"points\" in shape and len(shape[\"points\"]) == 2:\n                     # LabelMe rectangle format uses [top-left, bottom-right]\n                     p1 = shape[\"points\"][0]\n                     p2 = shape[\"points\"][1]\n                     xmin = int(min(p1[0], p2[0]))\n                     ymin = int(min(p1[1], p2[1]))\n                     xmax = int(max(p1[0], p2[0]))\n                     ymax = int(max(p1[1], p2[1]))\n                     bbox = (max(0, xmin), max(0, ymin), xmax, ymax)\n                     original_bboxes.append(bbox)\n                     cv2.rectangle(img_to_draw_orig, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 2) # Vẽ màu đỏ (BGR)\n                elif shape.get(\"shape_type\") in [\"polygon\", \"linestrip\", \"point\"] and \"points\" in shape and shape[\"points\"]:\n                     # Lấy bounding box bao quanh các loại shape khác\n                     bbox = get_bounding_box(shape[\"points\"])\n                     if bbox:\n                        original_bboxes.append(bbox)\n                        cv2.rectangle(img_to_draw_orig, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 2) # Red\n\n    # Resize ảnh với padding để giữ tỉ lệ\n    # Tính tỉ lệ resize để cạnh dài nhất bằng TARGET_SIZE\n    scale = TARGET_SIZE / max(orig_height, orig_width)\n    new_width = int(orig_width * scale)\n    new_height = int(orig_height * scale)\n\n    # Đảm bảo kích thước mới không lớn hơn TARGET_SIZE\n    new_width = min(new_width, TARGET_SIZE)\n    new_height = min(new_height, TARGET_SIZE)\n\n    # Resize ảnh\n    img_resized = cv2.resize(img_orig, (new_width, new_height), interpolation=cv2.INTER_AREA)\n\n    # Tính toán padding\n    pad_h = TARGET_SIZE - new_height\n    pad_w = TARGET_SIZE - new_width\n    top = pad_h // 2\n    bottom = pad_h - top\n    left = pad_w // 2\n    right = pad_w - left\n\n    # Thêm padding\n    # Sử dụng giá trị 0 (màu đen) cho padding vì ảnh là grayscale\n    padded_img = cv2.copyMakeBorder(img_resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n\n    # Lưu ảnh đã xử lý\n    output_img_path = os.path.join(output_image_dir, file)\n    try:\n        # Đảm bảo kích thước cuối cùng đúng là TARGET_SIZE x TARGET_SIZE\n        if padded_img.shape[0] != TARGET_SIZE or padded_img.shape[1] != TARGET_SIZE:\n             # Nếu có sai lệch nhỏ do làm tròn, resize lại lần cuối\n             padded_img = cv2.resize(padded_img, (TARGET_SIZE, TARGET_SIZE), interpolation=cv2.INTER_AREA)\n             # print(f\"Final resize needed for {file}. Original: ({orig_width}x{orig_height}), Resized: ({new_width}x{new_height}), Padded: {padded_img.shape[:2]}\")\n\n\n        cv2.imwrite(output_img_path, padded_img)\n    except Exception as e:\n        # print(f\"Lỗi khi lưu ảnh {output_img_path}: {e}\") # Bỏ comment nếu cần debug\n        continue # Bỏ qua ảnh này nếu không lưu được\n\n    # Xử lý và lưu annotation\n    if has_annotation and annotation_orig:\n        # Tạo bản sao sâu để không ảnh hưởng annotation gốc\n        annotation_new = json.loads(json.dumps(annotation_orig))\n\n        if \"shapes\" in annotation_new:\n            new_shapes = [] # Tạo list mới để chứa các shape đã chuyển đổi\n            for shape in annotation_new[\"shapes\"]:\n                if \"points\" in shape and shape[\"points\"]:\n                    original_points = shape[\"points\"]\n                    new_points_transformed = []\n                    valid_shape = True\n                    for x, y in original_points:\n                        # Áp dụng tỉ lệ resize\n                        new_x = x * scale\n                        new_y = y * scale\n                        # Áp dụng padding offset\n                        new_x += left\n                        new_y += top\n\n                        # Kiểm tra xem điểm có nằm trong ảnh mới không\n                        # new_x = max(0, min(TARGET_SIZE - 1, new_x))\n                        # new_y = max(0, min(TARGET_SIZE - 1, new_y))\n                        new_points_transformed.append([new_x, new_y])\n\n                    # Cập nhật điểm trong shape\n                    shape[\"points\"] = new_points_transformed\n                    new_shapes.append(shape) # Thêm shape đã chuyển đổi vào list mới\n\n                    # Tính bbox mới để trực quan hóa\n                    if should_visualize:\n                        new_bbox = get_bounding_box(new_points_transformed)\n                        if new_bbox:\n                            # Đảm bảo bbox không vượt ra ngoài TARGET_SIZE\n                            xmin = max(0, min(TARGET_SIZE - 1, new_bbox[0]))\n                            ymin = max(0, min(TARGET_SIZE - 1, new_bbox[1]))\n                            xmax = max(0, min(TARGET_SIZE - 1, new_bbox[2]))\n                            ymax = max(0, min(TARGET_SIZE - 1, new_bbox[3]))\n                            # Chỉ thêm vào nếu bbox hợp lệ\n                            if xmax > xmin and ymax > ymin:\n                                transformed_bboxes.append((xmin, ymin, xmax, ymax))\n\n            # Cập nhật lại danh sách shapes và kích thước ảnh trong annotation\n            annotation_new[\"shapes\"] = new_shapes\n            annotation_new[\"imagePath\"] = file # Cập nhật tên file ảnh mới\n            annotation_new[\"imageWidth\"] = TARGET_SIZE\n            annotation_new[\"imageHeight\"] = TARGET_SIZE\n            \n            if \"imageData\" in annotation_new:\n                annotation_new[\"imageData\"] = None\n\n            # Lưu file annotation mới\n            output_annotation_path = os.path.join(output_anno_dir, anno_filename)\n            try:\n                with open(output_annotation_path, \"w\", encoding=\"utf-8\") as f:\n                    json.dump(annotation_new, f, indent=4, ensure_ascii=False)\n            except Exception as e:\n                # print(f\"Lỗi khi lưu annotation {anno_filename}: {e}\") # Bỏ comment nếu cần debug\n                pass # Bỏ qua nếu lưu lỗi\n\n            if should_visualize and img_to_draw_orig is not None:\n                # Chuyển ảnh đã padding sang BGR để vẽ màu\n                img_to_draw_padded = cv2.cvtColor(padded_img, cv2.COLOR_GRAY2BGR)\n                # Vẽ các bounding box đã biến đổi\n                for bbox in transformed_bboxes:\n                     # Đảm bảo tọa độ là số nguyên để vẽ\n                     pt1 = (int(bbox[0]), int(bbox[1]))\n                     pt2 = (int(bbox[2]), int(bbox[3]))\n                     cv2.rectangle(img_to_draw_padded, pt1, pt2, (0, 255, 0), 2) # Vẽ màu xanh lá (BGR)\n\n                # Hiển thị ảnh gốc và ảnh đã xử lý\n                fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\n                # Ảnh gốc với bbox gốc (màu đỏ)\n                axes[0].imshow(cv2.cvtColor(img_to_draw_orig, cv2.COLOR_BGR2RGB)) # Chuyển BGR sang RGB cho matplotlib\n                axes[0].set_title(f'Original: {file}\\nSize: {orig_width}x{orig_height}')\n                axes[0].axis('off')\n\n                # Ảnh đã xử lý với bbox mới (màu xanh)\n                axes[1].imshow(cv2.cvtColor(img_to_draw_padded, cv2.COLOR_BGR2RGB)) # Chuyển BGR sang RGB\n                axes[1].set_title(f'Processed (Resized & Padded)\\nSize: {TARGET_SIZE}x{TARGET_SIZE}')\n                axes[1].axis('off')\n\n                plt.suptitle(f\"Visualization {visualized_count + 1}/{MAX_VISUALIZATIONS}\")\n                plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Điều chỉnh layout để tiêu đề không bị che\n                plt.show()\n\n                visualized_count += 1\n\nprint(f\"Xử lý {total_images} ảnh.\")\nif visualized_count > 0:\n    print(f\"Hiển thị {visualized_count} ảnh trực quan hóa.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.436168Z","iopub.status.idle":"2025-05-13T01:54:09.436694Z","shell.execute_reply.started":"2025-05-13T01:54:09.436347Z","shell.execute_reply":"2025-05-13T01:54:09.436393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hiển thị random 30 hình sau khi xử lý ảnh\n\n\n# Cấu hình\nimage_dir_test = '/kaggle/working/btxrd-v2.2/images'\nannotation_dir_test = '/kaggle/working/btxrd-v2.2/annotations'\n# Cấu hình\nnum_images_to_show = 30\nimages_per_row = 5  # Số ảnh mỗi hàng\nmask_color = [255, 0, 0]  # Red\n\ndef create_mask(img_size: Tuple[int, int], ann_path: str) -> np.ndarray:\n    mask = Image.new('L', img_size, 0)\n    if os.path.exists(ann_path):\n        try:\n            with open(ann_path, 'r') as f:\n                data = json.load(f)\n                for shape in data.get('shapes', []):\n                    points = shape.get('points', [])\n                    polygon_points = [(int(x), int(y)) for x, y in points]\n                    if polygon_points:\n                        ImageDraw.Draw(mask).polygon(polygon_points, outline=1, fill=1)\n        except Exception as e:\n            print(f\"Lỗi annotation {ann_path}: {e}\")\n    return np.array(mask)\n\n# Lấy danh sách tất cả ảnh trong thư mục\nall_filenames = [f for f in os.listdir(image_dir_test) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# Chọn ngẫu nhiên 30 ảnh\nselected_filenames = random.sample(all_filenames, min(num_images_to_show, len(all_filenames)))\n\n# Plot ảnh với mask\nplt.figure(figsize=(18, 18))  # Tăng kích thước ảnh\nfor i, fname in enumerate(selected_filenames):\n    img_path = os.path.join(image_dir_test, fname)\n    ann_fname = os.path.splitext(fname)[0] + '.json'\n    ann_path = os.path.join(annotation_dir_test, ann_fname)\n\n    try:\n        img_pil = Image.open(img_path).convert('L')\n        img_np = np.array(img_pil)\n\n        mask_np = create_mask(img_pil.size, ann_path)\n        color_img = np.stack([img_np] * 3, axis=-1)\n        color_img[mask_np == 1] = mask_color\n\n        # Chia bố cục thành 6 hàng và 5 cột (số ảnh mỗi hàng là 5)\n        plt.subplot(6, 5, i + 1)\n        plt.imshow(color_img)\n        plt.axis('off')  # Tắt trục\n    except Exception as e:\n        print(f\"Lỗi khi xử lý {fname}: {e}\")\n        continue\n\n# Loại bỏ khoảng trống giữa các ảnh\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.437653Z","iopub.status.idle":"2025-05-13T01:54:09.438769Z","shell.execute_reply.started":"2025-05-13T01:54:09.437797Z","shell.execute_reply":"2025-05-13T01:54:09.437838Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Chia tập dữ liệu**","metadata":{}},{"cell_type":"code","source":"output_split_dir = \"/kaggle/working/btxrd-v2.1\"\n\nANNOTATION_EXTENSION = \".json\"\n\nVAL_SIZE = 0.20   # 20% cho tập validation\nTRAIN_SIZE = 0.70 # 70% cho tập train\nTEST_SIZE = 1.0 - VAL_SIZE - TRAIN_SIZE\n\nRANDOM_STATE = 42","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.439717Z","iopub.status.idle":"2025-05-13T01:54:09.440264Z","shell.execute_reply.started":"2025-05-13T01:54:09.439865Z","shell.execute_reply":"2025-05-13T01:54:09.439927Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Đọc Dữ liệu Phân loại từ Excel\ntry:\n    df_classification = pd.read_excel(excel_path)\n    required_columns = ['image_id', 'tumor_type', 'image_filename']\n    if not all(col in df_classification.columns for col in required_columns):\n        missing = [col for col in required_columns if col not in df_classification.columns]\n        raise ValueError(f\"File Excel thiếu các cột bắt buộc: {missing}\")\n\n    df_classification['image_id'] = df_classification['image_id'].astype(str).str.strip()\n    df_classification['image_filename'] = df_classification['image_filename'].astype(str).str.strip()\n\n    print(f\"Đọc thành công {len(df_classification)} dòng\")\n    print(df_classification['tumor_type'].value_counts())\nexcept FileNotFoundError:\n    print(f\"Không tìm thấy file Excel tại {excel_path}\")\n    exit()\nexcept ValueError as ve:\n    print(f\"Lỗi dữ liệu trong file Excel: {ve}\")\n    exit()\nexcept Exception as e:\n    print(f\"không xác định khi đọc file Excel: {e}\")\n    exit()\n\ntry:\n    all_image_files = glob.glob(os.path.join(image_dir_test, \"*.*\"))\n    annotation_files = glob.glob(os.path.join(annotation_dir_test, f\"*{ANNOTATION_EXTENSION}\"))\n\n    image_basenames_actual = set(os.path.splitext(os.path.basename(f))[0] for f in all_image_files)\n    annotation_basenames_actual = set(os.path.splitext(os.path.basename(f))[0] for f in annotation_files)\n\n    print(f\"Tìm thấy {len(all_image_files)} tệp\")\n    print(f\"Tìm thấy {len(annotation_files)} tệp annotation\")\nexcept Exception as e:\n    print(f\"Lỗi khi quét thư mục ảnh hoặc annotation: {e}\")\n    exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.441610Z","iopub.status.idle":"2025-05-13T01:54:09.442492Z","shell.execute_reply.started":"2025-05-13T01:54:09.442254Z","shell.execute_reply":"2025-05-13T01:54:09.442305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"excel_image_ids = set(df_classification['image_id'])\nvalid_ids = list(excel_image_ids.intersection(image_basenames_actual).intersection(annotation_basenames_actual))\n\nif not valid_ids:\n    print(\"Không tìm thấy dữ liệu hợp lệ nào.\")\n    exit()\ndf_filtered = df_classification[df_classification['image_id'].isin(valid_ids)].copy()\ndf_filtered = df_filtered.drop_duplicates(subset=['image_id'])\nfilename_map = pd.Series(df_filtered.image_filename.values, index=df_filtered.image_id).to_dict()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.443533Z","iopub.status.idle":"2025-05-13T01:54:09.444176Z","shell.execute_reply.started":"2025-05-13T01:54:09.443693Z","shell.execute_reply":"2025-05-13T01:54:09.443733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Chuẩn bị dữ liệu (X=IDs, y=Labels) cho việc chia\nX = df_filtered['image_id'].tolist() # Danh sách ID ảnh \ny = df_filtered['tumor_type'].tolist() # Danh sách nhãn tương ứng\n\n# Chia Lần 1 (Train+Val / Test)\nX_train_val, X_test, y_train_val, y_test = [], [], [], []\nif len(X) < 2:\n    print(\"Không đủ mẫu dữ liệu (< 2) để thực hiện chia.\")\n    exit()\nif TEST_SIZE <= 0 or TEST_SIZE >= 1:\n     print(f\"Tỷ lệ Test ({TEST_SIZE:.2f}) không hợp lệ. Toàn bộ dữ liệu sẽ là Train+Val.\")\n     X_train_val, y_train_val = X, y\nelse:\n    try:\n        unique_classes_total, counts_total = np.unique(y, return_counts=True)\n        stratify_option_1 = y\n        if len(unique_classes_total) < 2:\n            print(\"Chỉ có 1 lớp. Chia ngẫu nhiên cho Test.\")\n            stratify_option_1 = None\n        elif np.any(counts_total < 2):\n             print(f\"Có lớp < 2 mẫu. Chia ngẫu nhiên cho Test.\")\n             stratify_option_1 = None\n\n        X_train_val, X_test, y_train_val, y_test = train_test_split(\n            X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=stratify_option_1\n        )\n        print(f\"Chia lần 1: {len(X_train_val)} Train+Val, {len(X_test)} Test.\")\n        print(\"Phân phối 'tumor_type' trong Test:\", sorted(Counter(y_test).items()))\n    except ValueError as e:\n         print(f\"Lỗi khi chia lần 1 (Test): {e}. Thoát.\")\n         exit()\n\n\n# Chia lần 2 (Train / Validation)\nX_train, X_val, y_train, y_val = [], [], [], []\nif not X_train_val:\n     print(\"Tập Train+Val rỗng.\")\nelif len(X_train_val) == 1:\n     print(\"Tập Train+Val chỉ có 1 mẫu -> vào Train.\")\n     X_train, y_train = X_train_val, y_train_val\nelif VAL_SIZE <= 0 or VAL_SIZE >= 1:\n     print(f\"Tỷ lệ Val ({VAL_SIZE:.4f}) không hợp lệ. Toàn bộ Train+Val -> Train.\")\n     X_train, y_train = X_train_val, y_train_val\nelse:\n    try:\n        unique_classes_tv, counts_tv = np.unique(y_train_val, return_counts=True)\n        stratify_option_2 = y_train_val\n        if len(unique_classes_tv) < 2:\n            print(\"Train+Val chỉ còn 1 lớp. Chia ngẫu nhiên cho Val.\")\n            stratify_option_2 = None\n        elif np.any(counts_tv < 2):\n             print(f\"Có lớp < 2 mẫu trong Train+Val. Chia ngẫu nhiên cho Val.\")\n             stratify_option_2 = None\n\n        X_train, X_val, y_train, y_val = train_test_split(\n            X_train_val, y_train_val, test_size=VAL_SIZE,\n            random_state=RANDOM_STATE, stratify=stratify_option_2\n        )\n        print(f\"Chia lần 2: {len(X_train)} Train, {len(X_val)} Validation.\")\n        print(\"Phân phối 'tumor_type' trong Train:\", sorted(Counter(y_train).items()))\n        print(\"Phân phối 'tumor_type' trong Validation:\", sorted(Counter(y_val).items()))\n    except ValueError as e:\n        print(f\"Lỗi khi chia lần 2 (Validation): {e}. Toàn bộ Train+Val -> Train.\")\n        X_train, y_train = X_train_val, y_train_val # Gán lại vào Train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.445355Z","iopub.status.idle":"2025-05-13T01:54:09.445873Z","shell.execute_reply.started":"2025-05-13T01:54:09.445521Z","shell.execute_reply":"2025-05-13T01:54:09.445564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# kết quả sau khi chia\ntotal_ids_split = len(X_train) + len(X_val) + len(X_test)\noriginal_valid_count = len(df_filtered)\n\nprint(f\"Tổng số mẫu hợp lệ ban đầu: {original_valid_count}\")\nprint(f\"Tổng số IDs được chia vào các tập: {total_ids_split}\")\nif total_ids_split != original_valid_count:\n     print(f\"Số ID được chia ({total_ids_split}) không khớp số ID hợp lệ ({original_valid_count}). Kiểm tra logic chia.\")\n\nprint(f\"Train set IDs:      {len(X_train):>5}\")\nprint(f\"Validation set IDs: {len(X_val):>5}\")\nprint(f\"Test set IDs:       {len(X_test):>5}\")\n\nif total_ids_split > 0:\n    print(f\"\\nTỷ lệ thực tế (dựa trên IDs):\")\n    print(f\"  Train: {len(X_train) / total_ids_split * 100:>6.1f}%\")\n    print(f\"  Val:   {len(X_val) / total_ids_split * 100:>6.1f}%\")\n    print(f\"  Test:  {len(X_test) / total_ids_split * 100:>6.1f}%\")\n\nprint(\"\\nPhân phối 'tumor_type' cuối cùng (dựa trên IDs đã chia):\")\nprint(f\"Train:      {sorted(Counter(y_train).items())}\")\nprint(f\"Validation: {sorted(Counter(y_val).items())}\")\nprint(f\"Test:       {sorted(Counter(y_test).items())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.447098Z","iopub.status.idle":"2025-05-13T01:54:09.447781Z","shell.execute_reply.started":"2025-05-13T01:54:09.447359Z","shell.execute_reply":"2025-05-13T01:54:09.447402Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Huấn luyện mô hình**","metadata":{}},{"cell_type":"code","source":"!pip install wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T00:26:42.422684Z","iopub.execute_input":"2025-05-22T00:26:42.422966Z","iopub.status.idle":"2025-05-22T00:26:49.207863Z","shell.execute_reply.started":"2025-05-22T00:26:42.422940Z","shell.execute_reply":"2025-05-22T00:26:49.206145Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.11.0a2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.29.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# --- Cấu hình ---\nimport os # Thêm import os nếu chưa có\nimport numpy as np # Thêm import numpy nếu dùng trong tính mean/std\nimport pandas as pd # Thêm import pandas nếu dùng trong tải metadata\nfrom tqdm import tqdm # Thêm import tqdm\nimport tensorflow as tf # Thêm import tensorflow\nfrom PIL import Image, ImageDraw # Thêm import PIL\nimport json # Thêm import json\nimport matplotlib.pyplot as plt # Thêm import matplotlib nếu dùng plot_image\n\nINPUT_DATA_ROOT = '/kaggle/input/btxrd-data' # THAY ĐỔI NẾU MÔI TRƯỜNG CỦA BẠN KHÁC\nBASE_DATA_DIR = os.path.join(INPUT_DATA_ROOT, 'btxrd-v2.1')\nCLASSIFICATION_FILE = os.path.join(INPUT_DATA_ROOT, 'classification.xlsx')\nIMAGE_SUBDIR_NAME = 'images'\nANNOTATION_SUBDIR_NAME = 'annotations'\n\n# Tham số Model & Huấn luyện\nTARGET_SIZE = 512\nN_CLASSES = 2 # 2 lớp: 0 (nền), 1 (khối u)\nBATCH_SIZE = 4 # Sẽ được dùng trong config wandb\nBUFFER_SIZE = 100 # Dùng cho dataset.shuffle\nEPOCHS = 300 # Sẽ được dùng trong config wandb và vòng lặp for\nLEARNING_RATE = 1e-4 # Sẽ được dùng trong config wandb\nL2_REG_FACTOR = 1e-5\nDROPOUT_RATE = 0.3\n\n# --- Cải tiến để tăng IoU ---\nUSE_COMBINED_LOSS = True\nDICE_LOSS_WEIGHT = 0.6\nUSE_FOCAL_LOSS_IN_COMBINED = True\nFOCAL_LOSS_ALPHA = 0.25\nFOCAL_LOSS_GAMMA = 2.0\n\nUSE_ATTENTION_UNET = False\n\n# APPLY_POST_PROCESSING, POST_PROCESSING_KERNEL_SIZE, MIN_AREA_POST_PROCESSING\n# thường dùng sau huấn luyện, không trực tiếp ảnh hưởng đến vòng lặp huấn luyện này\n\nMODEL_CHECKPOINT_BASENAME = \"unet_model\"\nTENSORBOARD_LOG_DIR = \"./logs_unet_iou_focused\"\n\n# --- Các hằng số cho callback Keras tiêu chuẩn ---\nPATIENCE_EARLY_STOPPING = 35\nPATIENCE_REDUCE_LR = 12\nMONITOR_METRIC_CB = 'val_dice_coef_metric_tumor' # QUAN TRỌNG: Phải khớp với key trong history.history\n\n# --- Cấu hình WandB ---\nWANDB_PROJECT_NAME = \"btxrd-project\" # Đặt tên project của bạn trên WandB\nWANDB_ENTITY = \"nganltt2333\" # Đặt entity của bạn\nWANDB_API_KEY = \"2b7e633df37247dd52582a893eecab6314151a62\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T04:58:07.703028Z","iopub.execute_input":"2025-05-30T04:58:07.703393Z","iopub.status.idle":"2025-05-30T04:58:07.709730Z","shell.execute_reply.started":"2025-05-30T04:58:07.703361Z","shell.execute_reply":"2025-05-30T04:58:07.708814Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def get_valid_paths(base_dir: str, split_type: str, img_filename_with_ext: str) -> Optional[Tuple[str, str]]:\n    split_dir = os.path.join(base_dir, split_type); image_dir_path = os.path.join(split_dir, IMAGE_SUBDIR_NAME); annotation_dir_path = os.path.join(split_dir, ANNOTATION_SUBDIR_NAME)\n    img_path = os.path.join(image_dir_path, img_filename_with_ext); base_name = os.path.splitext(img_filename_with_ext)[0]; json_filename = base_name + '.json'\n    json_path = os.path.join(annotation_dir_path, json_filename)\n    if os.path.exists(img_path) and os.path.exists(json_path): return img_path, json_path\n    return None\n\ndef create_mask_pil(mask_size: Tuple[int, int], json_path: str) -> Image.Image:\n    if not os.path.exists(json_path): return Image.new('L', (mask_size[1], mask_size[0]), 0)\n    mask = Image.new('L', (mask_size[1], mask_size[0]), 0)\n    try:\n        with open(json_path, 'r') as f: data = json.load(f)\n        if 'shapes' not in data or not isinstance(data['shapes'], list) or not data['shapes']: return mask\n        for shape in data['shapes']:\n             if 'points' in shape and isinstance(shape['points'], list):\n                  polygon = [tuple(point) for point in shape['points']]\n                  if len(polygon) >= 3: ImageDraw.Draw(mask).polygon(polygon, outline=255, fill=255)\n    except (json.JSONDecodeError, Exception): return Image.new('L', (mask_size[1], mask_size[0]), 0)\n    return mask\n\ndef plot_image(ax: plt.Axes, image_data: np.ndarray, title: str, cmap='gray'):\n    if image_data.ndim == 2 or (image_data.ndim == 3 and image_data.shape[2] == 1): ax.imshow(image_data.squeeze(), cmap=cmap)\n    else: ax.imshow(image_data)\n    ax.set_title(title, fontsize=10); ax.axis('off')\n\nall_image_paths = []; all_mask_paths = []; all_types = []\ntry:\n    if not os.path.exists(CLASSIFICATION_FILE): raise FileNotFoundError(f\"Không tìm thấy file phân loại tại {CLASSIFICATION_FILE}\")\n    if not os.path.isdir(BASE_DATA_DIR): raise FileNotFoundError(f\"Không tìm thấy thư mục dữ liệu cơ sở: {BASE_DATA_DIR}\")\n    df_classification = pd.read_excel(CLASSIFICATION_FILE)\n    required_cols = ['image_filename', 'type']\n    if not all(col in df_classification.columns for col in required_cols): raise ValueError(f\"File Excel phải chứa các cột: {required_cols}\")\n    for index, row in tqdm(df_classification.iterrows(), total=len(df_classification), desc=\"Kiểm tra file\"):\n        img_filename_with_ext = row['image_filename']; file_type = row['type']\n        if pd.isna(img_filename_with_ext) or pd.isna(file_type) or file_type not in ['train', 'val', 'test']: continue\n        paths = get_valid_paths(BASE_DATA_DIR, str(file_type).lower(), str(img_filename_with_ext))\n        if paths: img_path, json_path = paths; all_image_paths.append(img_path); all_mask_paths.append(json_path); all_types.append(str(file_type).lower())\n    if not all_image_paths: print(\"\\nLỗi: Không tìm thấy cặp ảnh-chú thích hợp lệ nào.\"); exit()\n    df_paths = pd.DataFrame({'image_path': all_image_paths, 'mask_path': all_mask_paths, 'type': all_types})\n    df_train = df_paths[df_paths['type'] == 'train'].reset_index(drop=True); df_val = df_paths[df_paths['type'] == 'val'].reset_index(drop=True); df_test = df_paths[df_paths['type'] == 'test'].reset_index(drop=True)\n    train_image_paths = df_train['image_path'].tolist(); train_mask_paths = df_train['mask_path'].tolist()\n    val_image_paths = df_val['image_path'].tolist(); val_mask_paths = df_val['mask_path'].tolist()\n    test_image_paths = df_test['image_path'].tolist(); test_mask_paths = df_test['mask_path'].tolist()\n    print(f\"\\nPhân chia dữ liệu: Train({len(train_image_paths)}), Val({len(val_image_paths)}), Test({len(test_image_paths)})\")\n    if not train_image_paths: print(\"Cảnh báo: Tập huấn luyện rỗng!\"); exit()\nexcept Exception as e: print(f\"Lỗi khi tải siêu dữ liệu: {e}\"); import traceback; traceback.print_exc(); exit()\n\n# Tính toán Mean/Std\nmean_pixel = 0.5; std_pixel = 0.1\nnum_train_images = len(train_image_paths)\nif num_train_images > 0:\n    print(\"Đang tính toán Mean/Std...\")\n    pixel_sum = 0.0; pixel_sum_sq = 0.0; total_pixels_calculated = 0; processed_count = 0\n    sample_size_for_stats = min(num_train_images, 250) # Tăng nhẹ sample size\n    sampled_train_paths = np.random.choice(train_image_paths, size=sample_size_for_stats, replace=False)\n    for img_path in tqdm(sampled_train_paths, desc=\"Tính Mean/Std\"):\n        try:\n            img_bytes = tf.io.read_file(img_path); img = tf.io.decode_image(img_bytes, channels=1, expand_animations=False, dtype=tf.float32)\n            img = tf.image.resize(img, [TARGET_SIZE, TARGET_SIZE])\n            pixel_sum += tf.reduce_sum(img).numpy(); pixel_sum_sq += tf.reduce_sum(tf.square(img)).numpy()\n            total_pixels_calculated += (TARGET_SIZE * TARGET_SIZE); processed_count += 1\n        except Exception: pass\n    if processed_count > 0 and total_pixels_calculated > 0:\n        mean_pixel = pixel_sum / total_pixels_calculated; variance = (pixel_sum_sq / total_pixels_calculated) - (mean_pixel ** 2)\n        std_pixel = np.sqrt(max(variance, 1e-7)); print(f\"Mean: {mean_pixel:.4f}, Std Dev: {std_pixel:.4f}\")\n        if std_pixel < 1e-4: std_pixel = 0.1; print(\"Std Dev quá thấp, dùng mặc định 0.1.\")\n    else: print(f\"Cảnh báo: Không tính được mean/std, dùng mặc định.\")\nstd_pixel = max(std_pixel, 1e-7)\n\n# Pipeline Dữ liệu TensorFlow\ndef load_mask_from_json_py(json_path_bytes):\n    json_path = json_path_bytes.numpy().decode('utf-8'); pil_mask = create_mask_pil((TARGET_SIZE, TARGET_SIZE), json_path)\n    mask_np = np.array(pil_mask, dtype=np.uint8); mask_np = (mask_np > 128).astype(np.uint8)\n    return mask_np\n\n@tf.function\ndef load_and_preprocess(image_path, mask_json_path):\n    img_bytes = tf.io.read_file(image_path)\n    try: img = tf.io.decode_image(img_bytes, channels=1, expand_animations=False, dtype=tf.float32)\n    except tf.errors.InvalidArgumentError:\n        try: img = tf.image.decode_png(img_bytes, channels=1, dtype=tf.uint8); img = tf.cast(img, tf.float32) / 255.0\n        except tf.errors.InvalidArgumentError: img = tf.image.decode_jpeg(img_bytes, channels=1); img = tf.cast(img, tf.float32) / 255.0\n    img = tf.image.resize(img, [TARGET_SIZE, TARGET_SIZE]); img.set_shape([TARGET_SIZE, TARGET_SIZE, 1])\n    mask_np_binary = tf.py_function(func=load_mask_from_json_py, inp=[mask_json_path], Tout=tf.uint8)\n    mask_np_binary.set_shape([TARGET_SIZE, TARGET_SIZE])\n    mask_onehot = tf.one_hot(tf.cast(mask_np_binary, tf.int32), depth=N_CLASSES, dtype=tf.float32)\n    mask_onehot.set_shape([TARGET_SIZE, TARGET_SIZE, N_CLASSES])\n    img = (img - mean_pixel) / std_pixel\n    return img, mask_onehot\n\n@tf.function\ndef augment_data_tf(image, mask_onehot):\n    combined = tf.concat([image, tf.cast(mask_onehot, image.dtype)], axis=-1) # Nối image và mask (đã cast về dtype của image)\n    if tf.random.uniform(()) > 0.5: combined = tf.image.flip_left_right(combined)\n    if tf.random.uniform(()) > 0.5: combined = tf.image.flip_up_down(combined)\n    k_rot = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n    combined = tf.image.rot90(combined, k=k_rot)\n    img_aug = combined[..., :1]\n    mask_aug = tf.cast(combined[..., 1:], tf.float32)\n    img_aug = tf.image.random_brightness(img_aug, max_delta=0.25)\n    img_aug = tf.image.random_contrast(img_aug, lower=0.7, upper=1.3)\n    if tf.random.uniform(()) > 0.3:\n        scale = tf.random.uniform((), 0.8, 1.2)\n        new_height = tf.cast(TARGET_SIZE * scale, tf.int32)\n        new_width = tf.cast(TARGET_SIZE * scale, tf.int32)\n        img_scaled = tf.image.resize(img_aug, [new_height, new_width], method=tf.image.ResizeMethod.BILINEAR)\n        mask_scaled = tf.image.resize(mask_aug, [new_height, new_width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        img_aug = tf.image.resize_with_crop_or_pad(img_scaled, TARGET_SIZE, TARGET_SIZE)\n        mask_aug = tf.image.resize_with_crop_or_pad(mask_scaled, TARGET_SIZE, TARGET_SIZE)\n    img_aug = tf.clip_by_value(img_aug, -3.0, 3.0)\n    img_aug.set_shape([TARGET_SIZE, TARGET_SIZE, 1])\n    mask_aug.set_shape([TARGET_SIZE, TARGET_SIZE, N_CLASSES])\n    return img_aug, mask_aug\n\ndef create_dataset(image_paths, mask_paths, is_training=True):\n    if not image_paths or not mask_paths: return tf.data.Dataset.from_tensor_slices(([], [])).batch(BATCH_SIZE)\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n    if is_training: dataset = dataset.shuffle(buffer_size=min(BUFFER_SIZE, len(image_paths)), reshuffle_each_iteration=True)\n    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n    if is_training: dataset = dataset.map(augment_data_tf, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=(is_training if len(image_paths) >= BATCH_SIZE else False))\n    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return dataset\n\ntrain_ds = create_dataset(train_image_paths, train_mask_paths, is_training=True)\nval_ds = create_dataset(val_image_paths, val_mask_paths, is_training=False)\ntest_ds = create_dataset(test_image_paths, test_mask_paths, is_training=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T04:58:10.439301Z","iopub.execute_input":"2025-05-30T04:58:10.439640Z","iopub.status.idle":"2025-05-30T04:58:28.309943Z","shell.execute_reply.started":"2025-05-30T04:58:10.439616Z","shell.execute_reply":"2025-05-30T04:58:28.309238Z"}},"outputs":[{"name":"stderr","text":"Kiểm tra file: 100%|██████████| 3746/3746 [00:12<00:00, 303.51it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nPhân chia dữ liệu: Train(1344), Val(336), Test(187)\nĐang tính toán Mean/Std...\n","output_type":"stream"},{"name":"stderr","text":"Tính Mean/Std: 100%|██████████| 250/250 [00:03<00:00, 70.33it/s] \n","output_type":"stream"},{"name":"stdout","text":"Mean: 0.1943, Std Dev: 0.2352\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# UNET\nclass AttentionGate(layers.Layer):\n    def __init__(self, F_g, F_l, F_int, **kwargs): super(AttentionGate, self).__init__(**kwargs); self.W_g = layers.Conv2D(F_int, 1, padding='same', kernel_initializer='he_normal'); self.W_x = layers.Conv2D(F_int, 1, padding='same', kernel_initializer='he_normal'); self.psi = layers.Conv2D(1, 1, padding='same', kernel_initializer='he_normal', activation='sigmoid'); self.relu = layers.Activation('relu')\n    def call(self, g, x): g1 = self.W_g(g); x1 = self.W_x(x); psi_input = self.relu(g1 + x1); alpha = self.psi(psi_input); return x * alpha\ndef conv_block(inputs, num_filters, l2_reg, dropout):\n    x = layers.Conv2D(num_filters, 3, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(inputs); x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n    if dropout > 0: x = layers.Dropout(dropout)(x)\n    x = layers.Conv2D(num_filters, 3, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x); x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n    return x\ndef encoder_block(inputs, num_filters, l2_reg, dropout, pool=True): c = conv_block(inputs, num_filters, l2_reg, dropout); p = layers.MaxPooling2D(2)(c) if pool else None; return c, p\ndef decoder_block(inputs, skip_features, num_filters, l2_reg, dropout, use_attention):\n    x = layers.Conv2DTranspose(num_filters, 2, strides=2, padding='same')(inputs)\n    if use_attention and skip_features is not None: att_gate = AttentionGate(num_filters, skip_features.shape[-1], max(1, skip_features.shape[-1] // 2) ); skip_features = att_gate(g=x, x=skip_features)\n    if skip_features is not None: x = layers.Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters, l2_reg, dropout); return x\ndef build_unet(input_shape, n_classes=N_CLASSES, l2_reg=L2_REG_FACTOR, dropout=DROPOUT_RATE, use_attention=USE_ATTENTION_UNET):\n    filters = [64, 128, 256, 512, 1024]\n    inputs = keras.Input(shape=input_shape); skips = []; x = inputs\n    for f in filters[:-1]: s, p = encoder_block(x, f, l2_reg, dropout, pool=True); skips.append(s); x = p\n    x, _ = encoder_block(x, filters[-1], l2_reg, dropout*1.3, pool=False)\n    for i, f in reversed(list(enumerate(filters[:-1]))): x = decoder_block(x, skips[i], f, l2_reg, dropout, use_attention)\n    outputs = layers.Conv2D(n_classes, 1, padding='same', activation='softmax')(x)\n    return keras.Model(inputs, outputs, name=f\"{'Attention' if use_attention else ''}UNet_filters{filters[0]}\")\n\n# --- HÀM MẤT MÁT (LOSS FUNCTIONS) ---\nSMOOTH = 1e-6\ndef dice_coef(y_true_one_hot, y_pred_softmax):\n    y_true_f = tf.keras.backend.flatten(y_true_one_hot)\n    y_pred_f = tf.keras.backend.flatten(y_pred_softmax)\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    return (2. * intersection + SMOOTH) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + SMOOTH)\n\ndef dice_coef_metric_tumor(y_true, y_pred):\n    # y_true: (batch, H, W, N_CLASSES), y_pred: (batch, H, W, N_CLASSES)\n    return dice_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\ndice_coef_metric_tumor.__name__ = 'dice_coef_metric_tumor' # Khớp với `metrics_to_plot`\n\ndef dice_loss_tumor(y_true, y_pred):\n    return 1.0 - dice_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\n\ndef iou_coef(y_true_one_hot, y_pred_softmax):\n    y_true_f = tf.keras.backend.flatten(y_true_one_hot)\n    y_pred_f = tf.keras.backend.flatten(y_pred_softmax)\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n    return (intersection + SMOOTH) / (union + SMOOTH)\n\ndef iou_metric_tumor(y_true, y_pred):\n    return iou_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\niou_metric_tumor.__name__ = 'tumor_iou' # Khớp với `metrics_to_plot`\n\n# --- CÁC METRICS MỚI CHO LỚP TUMOR ---\ndef precision_recall_tumor_base(y_true, y_pred, metric_type):\n    if N_CLASSES < 2:\n        return tf.constant(0.0, dtype=tf.float32)\n\n    # Lấy kênh của lớp tumor (giả sử lớp 1 là tumor)\n    y_true_tumor = y_true[..., 1] # Ground truth cho lớp tumor (0 hoặc 1)\n    \n    # Chuyển đổi y_pred (softmax probabilities) thành dự đoán nhãn cứng (0 hoặc 1) cho lớp tumor\n    # Cách 1: Dựa trên xác suất cao nhất (argmax)\n    y_pred_labels = tf.argmax(y_pred, axis=-1) # Shape: (batch, H, W)\n    y_pred_tumor_binary = tf.cast(tf.equal(y_pred_labels, 1), tf.float32) # 1 nếu dự đoán là tumor (lớp 1), 0 nếu khác\n\n    # Cách 2: (Nếu chỉ có 2 lớp, có thể dùng ngưỡng 0.5 cho xác suất lớp tumor)\n    # y_pred_tumor_binary = tf.cast(y_pred[..., 1] > 0.5, tf.float32) # Chỉ phù hợp nếu N_CLASSES=2 và lớp 1 là tumor\n\n    # Flatten để tính toán\n    y_true_tumor_flat = tf.keras.backend.flatten(y_true_tumor)\n    y_pred_tumor_binary_flat = tf.keras.backend.flatten(y_pred_tumor_binary)\n\n    true_positives = tf.keras.backend.sum(y_true_tumor_flat * y_pred_tumor_binary_flat)\n    \n    if metric_type == 'precision':\n        predicted_positives = tf.keras.backend.sum(y_pred_tumor_binary_flat)\n        value = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n    elif metric_type == 'recall':\n        possible_positives = tf.keras.backend.sum(y_true_tumor_flat)\n        value = true_positives / (possible_positives + tf.keras.backend.epsilon())\n    else:\n        value = tf.constant(0.0, dtype=tf.float32)\n        \n    return value\n\ndef precision_tumor_metric(y_true, y_pred):\n    return precision_recall_tumor_base(y_true, y_pred, 'precision')\nprecision_tumor_metric.__name__ = 'precision_tumor' # Khớp với `metrics_to_plot`\n\ndef recall_tumor_metric(y_true, y_pred):\n    return precision_recall_tumor_base(y_true, y_pred, 'recall')\nrecall_tumor_metric.__name__ = 'recall_tumor' # Khớp với `metrics_to_plot`\n# --- KẾT THÚC METRICS MỚI ---\n\ndef categorical_focal_loss_wrapper(alpha=FOCAL_LOSS_ALPHA, gamma=FOCAL_LOSS_GAMMA):\n    def focal_loss_fn(y_true, y_pred):\n        epsilon = tf.keras.backend.epsilon(); y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n        cross_entropy = -y_true * tf.math.log(y_pred)\n        loss = alpha * tf.pow(1 - y_pred, gamma) * cross_entropy\n        return tf.reduce_mean(tf.reduce_sum(loss, axis=-1))\n    focal_loss_fn.__name__ = f'focal_loss_alpha{alpha}_gamma{gamma}'\n    return focal_loss_fn\n\ndef combined_loss_fn(y_true, y_pred, dice_w=DICE_LOSS_WEIGHT):\n    d_loss = dice_loss_tumor(y_true, y_pred)\n    if USE_FOCAL_LOSS_IN_COMBINED: ce_or_focal_loss = categorical_focal_loss_wrapper()(y_true, y_pred)\n    else: ce_or_focal_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true, y_pred))\n    return (dice_w * d_loss) + ((1.0 - dice_w) * ce_or_focal_loss)\ncombined_loss_fn.__name__ = f'combined_dice{DICE_LOSS_WEIGHT}_{\"focal\" if USE_FOCAL_LOSS_IN_COMBINED else \"cce\"}'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T04:58:33.016817Z","iopub.execute_input":"2025-05-30T04:58:33.017153Z","iopub.status.idle":"2025-05-30T04:58:33.036876Z","shell.execute_reply.started":"2025-05-30T04:58:33.017124Z","shell.execute_reply":"2025-05-30T04:58:33.036064Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import wandb # Đảm bảo wandb đã được import\nfrom datetime import datetime, timedelta # Để tạo tên run\n\n# --- Build và Compile Model ---\nmodel = build_unet((TARGET_SIZE, TARGET_SIZE, 1), N_CLASSES, L2_REG_FACTOR, DROPOUT_RATE, USE_ATTENTION_UNET)\noptimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n\nif USE_COMBINED_LOSS:\n    loss_to_use = combined_loss_fn\nelse:\n    if USE_FOCAL_LOSS_IN_COMBINED:\n        loss_to_use = categorical_focal_loss_wrapper(alpha=FOCAL_LOSS_ALPHA, gamma=FOCAL_LOSS_GAMMA)\n    else:\n        loss_to_use = tf.keras.losses.CategoricalCrossentropy()\n        loss_to_use.__name__ = \"categorical_crossentropy\" # Đặt tên nếu là object\n\nloss_name_str = loss_to_use.__name__ if hasattr(loss_to_use, '__name__') else \"custom_loss\"\n\n# --- Định nghĩa danh sách metrics cho model.compile() ---\n# Đảm bảo các tên này sẽ xuất hiện trong history.history\nmetrics_to_compile = [ # Đổi tên biến để tránh nhầm lẫn với list dùng để log\n    dice_coef_metric_tumor,\n    iou_metric_tumor,\n    precision_tumor_metric,\n    recall_tumor_metric,\n    tf.keras.metrics.MeanIoU(num_classes=N_CLASSES, name='mean_iou_all'),\n    tf.keras.metrics.CategoricalAccuracy(name='acc') # Keras có thể trả về 'acc' hoặc 'categorical_accuracy'\n]\n# Tạo list các tên metric thực tế sẽ dùng để log (từ history.history)\n# Điều này quan trọng để đảm bảo key khớp khi log thủ công\n# Keras trả về tên của hàm/object metric, hoặc tên bạn đặt trong tf.keras.metrics.Metric(name='...')\n# Nếu metric là một hàm, history.history sẽ dùng tên hàm.\n# Nếu là một object tf.keras.metrics.Metric, nó sẽ dùng thuộc tính .name\n# Đối với CategoricalAccuracy, Keras có thể dùng 'acc' hoặc 'categorical_accuracy'.\n# Chúng ta sẽ xử lý điều này linh hoạt hơn trong vòng lặp log.\n\n# Các tên metric cơ bản mà chúng ta muốn log, không bao gồm 'loss' và 'val_loss' (vì chúng luôn có)\n# và 'acc'/'val_acc' (sẽ xử lý riêng)\nmetric_names_to_log_manually = []\nfor m in metrics_to_compile:\n    if hasattr(m, 'name'):\n        metric_names_to_log_manually.append(m.name)\n    elif hasattr(m, '__name__'):\n        metric_names_to_log_manually.append(m.__name__)\n# Loại bỏ 'acc' nếu có, vì sẽ xử lý riêng\nif 'acc' in metric_names_to_log_manually:\n    metric_names_to_log_manually.remove('acc')\nif 'categorical_accuracy' in metric_names_to_log_manually:\n     metric_names_to_log_manually.remove('categorical_accuracy')\n\n\nmodel.compile(optimizer=optimizer, loss=loss_to_use, metrics=metrics_to_compile)\nmodel.summary()\n\n# --- KHỞI TẠO WEIGHTS & BIASES ---\nif WANDB_API_KEY:\n    wandb.login(key=WANDB_API_KEY)\nelse:\n    try:\n        wandb.login() # Thử đăng nhập tương tác nếu không có key\n    except Exception as e:\n        print(f\"Lỗi khi đăng nhập WandB: {e}. Vui lòng đảm bảo bạn đã đăng nhập WandB.\")\n        # Có thể exit() ở đây nếu WandB là bắt buộc\n\n# Lấy giờ VN cho tên run\nnow_vn = datetime.utcnow() + timedelta(hours=7)\n# Chỉnh sửa format tên run để không có ký tự '/' không hợp lệ cho tên file/directory\nrun_name_wandb = f\"{MODEL_CHECKPOINT_BASENAME}_{loss_name_str}_attn{USE_ATTENTION_UNET}_\" + now_vn.strftime(\"%d%m%Y_%H%M%S\")\n\nwandb_config = {\n    \"epochs\": EPOCHS,\n    \"batch_size\": BATCH_SIZE,\n    \"learning_rate\": LEARNING_RATE,\n    \"target_size\": TARGET_SIZE,\n    \"n_classes\": N_CLASSES,\n    \"l2_reg_factor\": L2_REG_FACTOR,\n    \"dropout_rate\": DROPOUT_RATE,\n    \"use_combined_loss\": USE_COMBINED_LOSS,\n    \"dice_loss_weight\": DICE_LOSS_WEIGHT,\n    \"use_focal_loss_in_combined\": USE_FOCAL_LOSS_IN_COMBINED,\n    \"focal_loss_alpha\": FOCAL_LOSS_ALPHA,\n    \"focal_loss_gamma\": FOCAL_LOSS_GAMMA,\n    \"use_attention_unet\": USE_ATTENTION_UNET,\n    \"architecture\": model.name,\n    \"optimizer\": type(optimizer).__name__,\n    \"loss_function\": loss_name_str,\n    \"mean_pixel_train\": mean_pixel, # Giả sử mean_pixel, std_pixel đã được tính\n    \"std_pixel_train\": std_pixel,\n    \"monitor_metric_callbacks\": MONITOR_METRIC_CB # Metric cho các Keras callback\n}\n\nwandb.init(\n    project=WANDB_PROJECT_NAME,\n    entity=WANDB_ENTITY,\n    name=run_name_wandb,\n    config=wandb_config\n    # sync_tensorboard=True # Vẫn có thể dùng nếu bạn có TensorBoard callback\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T04:58:36.620775Z","iopub.execute_input":"2025-05-30T04:58:36.621085Z","iopub.status.idle":"2025-05-30T04:58:53.836196Z","shell.execute_reply.started":"2025-05-30T04:58:36.621063Z","shell.execute_reply":"2025-05-30T04:58:53.835262Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"UNet_filters64\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"UNet_filters64\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m640\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_2 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_3 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_4 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m590,080\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_5 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_6 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_7 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │      \u001b[38;5;34m4,719,616\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_8 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │      \u001b[38;5;34m9,438,208\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_9 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,097,664\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                           │                        │                │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m4,719,104\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m524,544\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │      \u001b[38;5;34m1,179,904\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_12             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m590,080\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_13             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m131,200\u001b[0m │ activation_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_2[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m295,040\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_14             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_15             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m32,832\u001b[0m │ activation_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_3[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m73,792\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_16             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_17             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m2\u001b[0m)    │            \u001b[38;5;34m130\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                           │                        │                │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_12             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_13             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_14             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_15             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_16             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_17             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,054,210\u001b[0m (118.46 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,054,210</span> (118.46 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,042,434\u001b[0m (118.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,042,434</span> (118.42 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m11,776\u001b[0m (46.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,776</span> (46.00 KB)\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnganltt23\u001b[0m (\u001b[33mnganltt2333\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250530_045846-fhkoptyr</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nganltt2333/btxrd-project/runs/fhkoptyr' target=\"_blank\">unet_model_combined_dice0.6_focal_attnFalse_30052025_115846</a></strong> to <a href='https://wandb.ai/nganltt2333/btxrd-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nganltt2333/btxrd-project' target=\"_blank\">https://wandb.ai/nganltt2333/btxrd-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nganltt2333/btxrd-project/runs/fhkoptyr' target=\"_blank\">https://wandb.ai/nganltt2333/btxrd-project/runs/fhkoptyr</a>"},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nganltt2333/btxrd-project/runs/fhkoptyr?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7d716d51d510>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Callbacks Keras tiêu chuẩn (KHÔNG BAO GỒM WandbCallback)\n\n# Đường dẫn lưu checkpoint\ncheckpoint_path = f\"{MODEL_CHECKPOINT_BASENAME}_{run_name_wandb}.keras\" # Dùng run_name_wandb để duy nhất\n\n# MONITOR_METRIC_CB ('val_dice_coef_metric_tumor') phải là một key có trong history.history khi val_ds được dùng\nkeras_callbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_path, # Đổi tên tham số cho rõ ràng\n        save_best_only=True,\n        monitor=MONITOR_METRIC_CB,\n        mode='max',\n        verbose=1\n    ),\n    tf.keras.callbacks.EarlyStopping(\n        monitor=MONITOR_METRIC_CB,\n        patience=PATIENCE_EARLY_STOPPING,\n        mode='max',\n        restore_best_weights=True,\n        verbose=1\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor=MONITOR_METRIC_CB,\n        factor=0.3,\n        patience=PATIENCE_REDUCE_LR,\n        mode='max',\n        min_lr=1e-7,\n        verbose=1\n    ),\n    tf.keras.callbacks.TensorBoard(\n        log_dir=TENSORBOARD_LOG_DIR, # WandB có thể sync từ đây nếu sync_tensorboard=True trong init\n        histogram_freq=1 # Có thể gây chậm, cân nhắc\n    )\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T04:59:04.789573Z","iopub.execute_input":"2025-05-30T04:59:04.789890Z","iopub.status.idle":"2025-05-30T04:59:04.795650Z","shell.execute_reply.started":"2025-05-30T04:59:04.789867Z","shell.execute_reply":"2025-05-30T04:59:04.794813Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Class Weights\npix_cls0 = 0; pix_cls1 = 0\n# Giả sử train_mask_paths đã được tạo ở Đoạn 2\nif 'train_mask_paths' in locals() and train_mask_paths: # Kiểm tra biến tồn tại\n    for mask_p in tqdm(train_mask_paths, desc=\"Đếm pixels cho class weights\"):\n        try:\n            m = create_mask_pil((TARGET_SIZE, TARGET_SIZE), mask_p)\n            m_np = (np.array(m) > 128).astype(np.uint8)\n            pix_cls0 += np.sum(m_np == 0)\n            pix_cls1 += np.sum(m_np == 1)\n        except Exception as e:\n            print(f\"Lỗi khi xử lý mask {mask_p} cho class weights: {e}\")\n            continue\nelse:\n    print(\"Cảnh báo: train_mask_paths không tồn tại hoặc rỗng, không thể tính class weights.\")\n\nclass_weights = None # Khởi tạo class_weights\nif pix_cls1 > 0 and pix_cls0 > 0:\n    total_pix = float(pix_cls0 + pix_cls1)\n    w0 = (total_pix / (N_CLASSES * float(pix_cls0)))\n    w1 = (total_pix / (N_CLASSES * float(pix_cls1)))\n    class_weights = {0: w0, 1: w1} # Gán giá trị cho class_weights\n    print(f\"Class weights đã tính: Lớp 0: {w0:.4f}, Lớp 1: {w1:.4f}\")\n    if w1 < w0 :\n        print(\"Cảnh báo: Trọng số lớp khối u (1) nhỏ hơn lớp nền (0). Kiểm tra lại số lượng pixel hoặc dữ liệu.\")\n    if wandb.run:\n        wandb.config.update({\"class_weight_0\": w0, \"class_weight_1\": w1, \"calculated_class_weights\": True})\nelse:\n    print(\"Không tính được class weights (số pixel lớp 0 hoặc 1 bằng 0 hoặc train_mask_paths rỗng). Sử dụng None.\")\n    if wandb.run:\n        wandb.config.update({\"calculated_class_weights\": False})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T04:59:09.213461Z","iopub.execute_input":"2025-05-30T04:59:09.213761Z","iopub.status.idle":"2025-05-30T04:59:18.955665Z","shell.execute_reply.started":"2025-05-30T04:59:09.213738Z","shell.execute_reply":"2025-05-30T04:59:18.954840Z"}},"outputs":[{"name":"stderr","text":"Đếm pixels cho class weights: 100%|██████████| 1344/1344 [00:09<00:00, 138.15it/s]","output_type":"stream"},{"name":"stdout","text":"Class weights đã tính: Lớp 0: 0.5089, Lớp 1: 28.6592\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Huấn luyện Model với vòng lặp thủ công và log thủ công lên WandB\n\n# Kiểm tra sự tồn tại của train_ds và val_ds (nếu val_image_paths có)\nif 'train_ds' not in locals() or not train_ds:\n    print(\"Lỗi: Tập huấn luyện (train_ds) chưa được tạo hoặc rỗng.\")\n    if wandb.run: wandb.finish(exit_code=1)\n    exit()\n\nuse_validation = 'val_image_paths' in locals() and val_image_paths and 'val_ds' in locals() and val_ds\nif 'val_image_paths' in locals() and val_image_paths and ('val_ds' not in locals() or not val_ds):\n    print(\"Lỗi: Có val_image_paths nhưng tập validation (val_ds) chưa được tạo hoặc rỗng.\")\n    if wandb.run: wandb.finish(exit_code=1)\n    exit()\n\nprint(f\"\\nBắt đầu huấn luyện cho {EPOCHS} epochs...\")\n\nfor epoch in range(EPOCHS):\n    print(f\"\\n--- Epoch {epoch + 1}/{EPOCHS} ---\")\n\n    history = model.fit(\n        train_ds,\n        validation_data=val_ds if use_validation else None,\n        epochs=1, # CHỈ HUẤN LUYỆN 1 EPOCH MỖI LẦN GỌI FIT\n        class_weight=class_weights, # Từ Đoạn 6\n        callbacks=keras_callbacks, # Callbacks Keras tiêu chuẩn từ Đoạn 5\n        verbose=1\n    )\n\n    current_logs = history.history\n    if not current_logs:\n        print(f\"Cảnh báo: Không có logs nào được trả về từ model.fit() ở epoch {epoch + 1}.\")\n        continue\n\n    # --- Ghi log thủ công cho W&B ---\n    log_data_to_wandb = {\"epoch\": epoch + 1}\n\n    # Metrics huấn luyện\n    log_data_to_wandb[\"loss\"] = current_logs.get(\"loss\", [None])[0]\n    # Xử lý 'acc' hoặc 'categorical_accuracy' cho training\n    train_acc_key = None\n    if \"acc\" in current_logs:\n        train_acc_key = \"acc\"\n    elif \"categorical_accuracy\" in current_logs:\n        train_acc_key = \"categorical_accuracy\"\n    if train_acc_key:\n        log_data_to_wandb[train_acc_key] = current_logs.get(train_acc_key, [None])[0]\n\n    # Log các metrics tùy chỉnh khác cho training\n    for metric_name in metric_names_to_log_manually: # Từ Đoạn 4\n        if metric_name in current_logs:\n            log_data_to_wandb[metric_name] = current_logs.get(metric_name, [None])[0]\n\n\n    # Metrics validation (nếu có)\n    if use_validation:\n        log_data_to_wandb[\"val_loss\"] = current_logs.get(\"val_loss\", [None])[0]\n        # Xử lý 'val_acc' hoặc 'val_categorical_accuracy'\n        val_acc_key = None\n        if \"val_acc\" in current_logs:\n            val_acc_key = \"val_acc\"\n        elif \"val_categorical_accuracy\" in current_logs:\n            val_acc_key = \"val_categorical_accuracy\"\n        if val_acc_key:\n            log_data_to_wandb[val_acc_key] = current_logs.get(val_acc_key, [None])[0]\n\n        # Log các metrics tùy chỉnh khác cho validation\n        for metric_name in metric_names_to_log_manually: # Từ Đoạn 4\n            val_metric_key = f\"val_{metric_name}\"\n            if val_metric_key in current_logs:\n                log_data_to_wandb[val_metric_key] = current_logs.get(val_metric_key, [None])[0]\n\n    wandb.log(log_data_to_wandb)\n    print(f\"Đã log metrics cho epoch {epoch + 1} lên WandB.\")\n\n    # Kiểm tra điều kiện dừng sớm từ EarlyStopping callback\n    if model.stop_training:\n        print(f\"Huấn luyện dừng sớm bởi EarlyStopping callback sau epoch {epoch + 1}.\")\n        break\n\nprint(\"\\nHuấn luyện hoàn tất (hoặc dừng sớm)!\")\n\n# Kết thúc run WandB\nif wandb.run:\n    # (Tùy chọn) Log model tốt nhất như một artifact\n    # Giả sử ModelCheckpoint đã lưu model tốt nhất vào checkpoint_path\n    if os.path.exists(checkpoint_path):\n        print(f\"Đang log model tốt nhất từ: {checkpoint_path}\")\n        best_model_artifact = wandb.Artifact(\n            f'{MODEL_CHECKPOINT_BASENAME}-best_model',\n            type='model',\n            description=f'Best model based on {MONITOR_METRIC_CB} from run {run_name_wandb}',\n            metadata=dict(wandb.config) # Lưu config của run vào metadata artifact\n        )\n        best_model_artifact.add_file(checkpoint_path)\n        wandb.log_artifact(best_model_artifact)\n        print(\"Đã log model tốt nhất lên WandB Artifacts.\")\n    else:\n        print(f\"Không tìm thấy model checkpoint tại: {checkpoint_path} để log artifact.\")\n\n    wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T04:59:22.170568Z","iopub.execute_input":"2025-05-30T04:59:22.170865Z","execution_failed":"2025-05-30T16:57:43.567Z"}},"outputs":[{"name":"stdout","text":"\nBắt đầu huấn luyện cho 300 epochs...\n\n--- Epoch 1/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - acc: 0.6206 - dice_coef_metric_tumor: 0.0504 - loss: 0.7092 - mean_iou_all: 0.2512 - precision_tumor: 0.0401 - recall_tumor: 0.7161 - tumor_iou: 0.0264\nEpoch 1: val_dice_coef_metric_tumor improved from -inf to 0.07215, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 480ms/step - acc: 0.6211 - dice_coef_metric_tumor: 0.0505 - loss: 0.7090 - mean_iou_all: 0.2512 - precision_tumor: 0.0401 - recall_tumor: 0.7159 - tumor_iou: 0.0264 - val_acc: 0.8763 - val_dice_coef_metric_tumor: 0.0721 - val_loss: 0.6217 - val_mean_iou_all: 0.2495 - val_precision_tumor: 0.0586 - val_recall_tumor: 0.4248 - val_tumor_iou: 0.0384 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 1 lên WandB.\n\n--- Epoch 2/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.8574 - dice_coef_metric_tumor: 0.0961 - loss: 0.5996 - mean_iou_all: 0.2520 - precision_tumor: 0.0810 - recall_tumor: 0.6594 - tumor_iou: 0.0522\nEpoch 1: val_dice_coef_metric_tumor improved from 0.07215 to 0.08671, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.8574 - dice_coef_metric_tumor: 0.0961 - loss: 0.5995 - mean_iou_all: 0.2520 - precision_tumor: 0.0810 - recall_tumor: 0.6592 - tumor_iou: 0.0522 - val_acc: 0.8727 - val_dice_coef_metric_tumor: 0.0867 - val_loss: 0.6080 - val_mean_iou_all: 0.2486 - val_precision_tumor: 0.0661 - val_recall_tumor: 0.4691 - val_tumor_iou: 0.0470 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 2 lên WandB.\n\n--- Epoch 3/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9011 - dice_coef_metric_tumor: 0.1213 - loss: 0.5669 - mean_iou_all: 0.2518 - precision_tumor: 0.1017 - recall_tumor: 0.5415 - tumor_iou: 0.0676\nEpoch 1: val_dice_coef_metric_tumor improved from 0.08671 to 0.10848, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9011 - dice_coef_metric_tumor: 0.1213 - loss: 0.5669 - mean_iou_all: 0.2518 - precision_tumor: 0.1017 - recall_tumor: 0.5415 - tumor_iou: 0.0676 - val_acc: 0.8840 - val_dice_coef_metric_tumor: 0.1085 - val_loss: 0.5858 - val_mean_iou_all: 0.2497 - val_precision_tumor: 0.0793 - val_recall_tumor: 0.5374 - val_tumor_iou: 0.0599 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 3 lên WandB.\n\n--- Epoch 4/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9231 - dice_coef_metric_tumor: 0.1480 - loss: 0.5641 - mean_iou_all: 0.2518 - precision_tumor: 0.1188 - recall_tumor: 0.4668 - tumor_iou: 0.0842\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.10848\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 462ms/step - acc: 0.9231 - dice_coef_metric_tumor: 0.1480 - loss: 0.5641 - mean_iou_all: 0.2518 - precision_tumor: 0.1188 - recall_tumor: 0.4668 - tumor_iou: 0.0842 - val_acc: 0.6803 - val_dice_coef_metric_tumor: 0.0598 - val_loss: 0.6292 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0489 - val_recall_tumor: 0.9676 - val_tumor_iou: 0.0315 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 4 lên WandB.\n\n--- Epoch 5/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9097 - dice_coef_metric_tumor: 0.1539 - loss: 0.5515 - mean_iou_all: 0.2521 - precision_tumor: 0.1156 - recall_tumor: 0.5335 - tumor_iou: 0.0881\nEpoch 1: val_dice_coef_metric_tumor improved from 0.10848 to 0.12666, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9097 - dice_coef_metric_tumor: 0.1538 - loss: 0.5514 - mean_iou_all: 0.2521 - precision_tumor: 0.1156 - recall_tumor: 0.5335 - tumor_iou: 0.0881 - val_acc: 0.8933 - val_dice_coef_metric_tumor: 0.1267 - val_loss: 0.5669 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0866 - val_recall_tumor: 0.5498 - val_tumor_iou: 0.0710 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 5 lên WandB.\n\n--- Epoch 6/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9271 - dice_coef_metric_tumor: 0.1711 - loss: 0.5329 - mean_iou_all: 0.2529 - precision_tumor: 0.1340 - recall_tumor: 0.5042 - tumor_iou: 0.0995\nEpoch 1: val_dice_coef_metric_tumor improved from 0.12666 to 0.14334, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 470ms/step - acc: 0.9271 - dice_coef_metric_tumor: 0.1711 - loss: 0.5329 - mean_iou_all: 0.2529 - precision_tumor: 0.1340 - recall_tumor: 0.5042 - tumor_iou: 0.0995 - val_acc: 0.9136 - val_dice_coef_metric_tumor: 0.1433 - val_loss: 0.5590 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0998 - val_recall_tumor: 0.5211 - val_tumor_iou: 0.0820 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 6 lên WandB.\n\n--- Epoch 7/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9345 - dice_coef_metric_tumor: 0.1876 - loss: 0.5157 - mean_iou_all: 0.2523 - precision_tumor: 0.1474 - recall_tumor: 0.4738 - tumor_iou: 0.1117\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.14334\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9345 - dice_coef_metric_tumor: 0.1876 - loss: 0.5157 - mean_iou_all: 0.2523 - precision_tumor: 0.1474 - recall_tumor: 0.4739 - tumor_iou: 0.1116 - val_acc: 0.9392 - val_dice_coef_metric_tumor: 0.1388 - val_loss: 0.5541 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1135 - val_recall_tumor: 0.3714 - val_tumor_iou: 0.0797 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 7 lên WandB.\n\n--- Epoch 8/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9406 - dice_coef_metric_tumor: 0.1872 - loss: 0.5191 - mean_iou_all: 0.2527 - precision_tumor: 0.1466 - recall_tumor: 0.4422 - tumor_iou: 0.1106\nEpoch 1: val_dice_coef_metric_tumor improved from 0.14334 to 0.14755, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9406 - dice_coef_metric_tumor: 0.1871 - loss: 0.5191 - mean_iou_all: 0.2527 - precision_tumor: 0.1465 - recall_tumor: 0.4422 - tumor_iou: 0.1105 - val_acc: 0.9447 - val_dice_coef_metric_tumor: 0.1476 - val_loss: 0.5487 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1218 - val_recall_tumor: 0.3576 - val_tumor_iou: 0.0857 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 8 lên WandB.\n\n--- Epoch 9/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9387 - dice_coef_metric_tumor: 0.1865 - loss: 0.5041 - mean_iou_all: 0.2536 - precision_tumor: 0.1422 - recall_tumor: 0.4479 - tumor_iou: 0.1109\nEpoch 1: val_dice_coef_metric_tumor improved from 0.14755 to 0.15709, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9387 - dice_coef_metric_tumor: 0.1865 - loss: 0.5040 - mean_iou_all: 0.2536 - precision_tumor: 0.1422 - recall_tumor: 0.4479 - tumor_iou: 0.1109 - val_acc: 0.9451 - val_dice_coef_metric_tumor: 0.1571 - val_loss: 0.5419 - val_mean_iou_all: 0.2502 - val_precision_tumor: 0.1268 - val_recall_tumor: 0.3832 - val_tumor_iou: 0.0918 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 9 lên WandB.\n\n--- Epoch 10/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9447 - dice_coef_metric_tumor: 0.1999 - loss: 0.5043 - mean_iou_all: 0.2540 - precision_tumor: 0.1543 - recall_tumor: 0.4315 - tumor_iou: 0.1183\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.15709\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9447 - dice_coef_metric_tumor: 0.1999 - loss: 0.5043 - mean_iou_all: 0.2540 - precision_tumor: 0.1543 - recall_tumor: 0.4315 - tumor_iou: 0.1183 - val_acc: 0.8662 - val_dice_coef_metric_tumor: 0.1486 - val_loss: 0.5579 - val_mean_iou_all: 0.2538 - val_precision_tumor: 0.0909 - val_recall_tumor: 0.7941 - val_tumor_iou: 0.0846 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 10 lên WandB.\n\n--- Epoch 11/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9388 - dice_coef_metric_tumor: 0.1919 - loss: 0.5052 - mean_iou_all: 0.2555 - precision_tumor: 0.1453 - recall_tumor: 0.4666 - tumor_iou: 0.1137\nEpoch 1: val_dice_coef_metric_tumor improved from 0.15709 to 0.16165, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9388 - dice_coef_metric_tumor: 0.1919 - loss: 0.5052 - mean_iou_all: 0.2555 - precision_tumor: 0.1452 - recall_tumor: 0.4665 - tumor_iou: 0.1137 - val_acc: 0.8988 - val_dice_coef_metric_tumor: 0.1617 - val_loss: 0.5450 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1035 - val_recall_tumor: 0.6704 - val_tumor_iou: 0.0934 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 11 lên WandB.\n\n--- Epoch 12/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9434 - dice_coef_metric_tumor: 0.2050 - loss: 0.4951 - mean_iou_all: 0.2550 - precision_tumor: 0.1573 - recall_tumor: 0.4710 - tumor_iou: 0.1237\nEpoch 1: val_dice_coef_metric_tumor improved from 0.16165 to 0.17480, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9434 - dice_coef_metric_tumor: 0.2049 - loss: 0.4951 - mean_iou_all: 0.2550 - precision_tumor: 0.1573 - recall_tumor: 0.4709 - tumor_iou: 0.1236 - val_acc: 0.9411 - val_dice_coef_metric_tumor: 0.1748 - val_loss: 0.5303 - val_mean_iou_all: 0.2558 - val_precision_tumor: 0.1307 - val_recall_tumor: 0.4643 - val_tumor_iou: 0.1030 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 12 lên WandB.\n\n--- Epoch 13/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9473 - dice_coef_metric_tumor: 0.2040 - loss: 0.5006 - mean_iou_all: 0.2568 - precision_tumor: 0.1614 - recall_tumor: 0.4080 - tumor_iou: 0.1231\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.17480\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9473 - dice_coef_metric_tumor: 0.2040 - loss: 0.5005 - mean_iou_all: 0.2569 - precision_tumor: 0.1614 - recall_tumor: 0.4080 - tumor_iou: 0.1231 - val_acc: 0.9369 - val_dice_coef_metric_tumor: 0.1660 - val_loss: 0.5364 - val_mean_iou_all: 0.2522 - val_precision_tumor: 0.1208 - val_recall_tumor: 0.4518 - val_tumor_iou: 0.0974 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 13 lên WandB.\n\n--- Epoch 14/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9477 - dice_coef_metric_tumor: 0.2022 - loss: 0.4999 - mean_iou_all: 0.2561 - precision_tumor: 0.1615 - recall_tumor: 0.4052 - tumor_iou: 0.1226\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.17480\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9477 - dice_coef_metric_tumor: 0.2022 - loss: 0.4998 - mean_iou_all: 0.2561 - precision_tumor: 0.1615 - recall_tumor: 0.4052 - tumor_iou: 0.1226 - val_acc: 0.9310 - val_dice_coef_metric_tumor: 0.1663 - val_loss: 0.5364 - val_mean_iou_all: 0.2502 - val_precision_tumor: 0.1206 - val_recall_tumor: 0.4876 - val_tumor_iou: 0.0977 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 14 lên WandB.\n\n--- Epoch 15/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9535 - dice_coef_metric_tumor: 0.2291 - loss: 0.4792 - mean_iou_all: 0.2544 - precision_tumor: 0.1861 - recall_tumor: 0.4313 - tumor_iou: 0.1416\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.17480\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9535 - dice_coef_metric_tumor: 0.2291 - loss: 0.4792 - mean_iou_all: 0.2544 - precision_tumor: 0.1860 - recall_tumor: 0.4313 - tumor_iou: 0.1416 - val_acc: 0.9373 - val_dice_coef_metric_tumor: 0.1690 - val_loss: 0.5351 - val_mean_iou_all: 0.2509 - val_precision_tumor: 0.1228 - val_recall_tumor: 0.4388 - val_tumor_iou: 0.1002 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 15 lên WandB.\n\n--- Epoch 16/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9510 - dice_coef_metric_tumor: 0.2193 - loss: 0.4858 - mean_iou_all: 0.2607 - precision_tumor: 0.1813 - recall_tumor: 0.4297 - tumor_iou: 0.1342\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.17480\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9510 - dice_coef_metric_tumor: 0.2193 - loss: 0.4858 - mean_iou_all: 0.2607 - precision_tumor: 0.1812 - recall_tumor: 0.4298 - tumor_iou: 0.1341 - val_acc: 0.9354 - val_dice_coef_metric_tumor: 0.1697 - val_loss: 0.5311 - val_mean_iou_all: 0.2677 - val_precision_tumor: 0.1240 - val_recall_tumor: 0.4694 - val_tumor_iou: 0.0998 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 16 lên WandB.\n\n--- Epoch 17/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9505 - dice_coef_metric_tumor: 0.2304 - loss: 0.4860 - mean_iou_all: 0.2600 - precision_tumor: 0.1869 - recall_tumor: 0.4574 - tumor_iou: 0.1411\nEpoch 1: val_dice_coef_metric_tumor improved from 0.17480 to 0.18723, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9504 - dice_coef_metric_tumor: 0.2304 - loss: 0.4859 - mean_iou_all: 0.2601 - precision_tumor: 0.1869 - recall_tumor: 0.4574 - tumor_iou: 0.1411 - val_acc: 0.9499 - val_dice_coef_metric_tumor: 0.1872 - val_loss: 0.5192 - val_mean_iou_all: 0.2501 - val_precision_tumor: 0.1488 - val_recall_tumor: 0.4317 - val_tumor_iou: 0.1114 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 17 lên WandB.\n\n--- Epoch 18/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9490 - dice_coef_metric_tumor: 0.2321 - loss: 0.4795 - mean_iou_all: 0.2562 - precision_tumor: 0.1830 - recall_tumor: 0.4875 - tumor_iou: 0.1435\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18723\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9490 - dice_coef_metric_tumor: 0.2320 - loss: 0.4795 - mean_iou_all: 0.2563 - precision_tumor: 0.1830 - recall_tumor: 0.4875 - tumor_iou: 0.1435 - val_acc: 0.9260 - val_dice_coef_metric_tumor: 0.1754 - val_loss: 0.5301 - val_mean_iou_all: 0.2502 - val_precision_tumor: 0.1228 - val_recall_tumor: 0.5707 - val_tumor_iou: 0.1026 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 18 lên WandB.\n\n--- Epoch 19/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9545 - dice_coef_metric_tumor: 0.2376 - loss: 0.4740 - mean_iou_all: 0.2607 - precision_tumor: 0.1951 - recall_tumor: 0.4425 - tumor_iou: 0.1469\nEpoch 1: val_dice_coef_metric_tumor improved from 0.18723 to 0.19705, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9545 - dice_coef_metric_tumor: 0.2376 - loss: 0.4740 - mean_iou_all: 0.2607 - precision_tumor: 0.1950 - recall_tumor: 0.4424 - tumor_iou: 0.1468 - val_acc: 0.9464 - val_dice_coef_metric_tumor: 0.1970 - val_loss: 0.5148 - val_mean_iou_all: 0.2530 - val_precision_tumor: 0.1494 - val_recall_tumor: 0.4729 - val_tumor_iou: 0.1187 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 19 lên WandB.\n\n--- Epoch 20/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9598 - dice_coef_metric_tumor: 0.2459 - loss: 0.4716 - mean_iou_all: 0.2630 - precision_tumor: 0.2093 - recall_tumor: 0.4187 - tumor_iou: 0.1525\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.19705\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9598 - dice_coef_metric_tumor: 0.2459 - loss: 0.4716 - mean_iou_all: 0.2631 - precision_tumor: 0.2093 - recall_tumor: 0.4186 - tumor_iou: 0.1525 - val_acc: 0.9645 - val_dice_coef_metric_tumor: 0.1879 - val_loss: 0.5170 - val_mean_iou_all: 0.2549 - val_precision_tumor: 0.1763 - val_recall_tumor: 0.3077 - val_tumor_iou: 0.1145 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 20 lên WandB.\n\n--- Epoch 21/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9625 - dice_coef_metric_tumor: 0.2681 - loss: 0.4592 - mean_iou_all: 0.2602 - precision_tumor: 0.2308 - recall_tumor: 0.4368 - tumor_iou: 0.1675\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.19705\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9625 - dice_coef_metric_tumor: 0.2680 - loss: 0.4593 - mean_iou_all: 0.2602 - precision_tumor: 0.2308 - recall_tumor: 0.4367 - tumor_iou: 0.1675 - val_acc: 0.9811 - val_dice_coef_metric_tumor: 0.0544 - val_loss: 0.5992 - val_mean_iou_all: 0.2519 - val_precision_tumor: 0.1774 - val_recall_tumor: 0.0364 - val_tumor_iou: 0.0305 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 21 lên WandB.\n\n--- Epoch 22/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9599 - dice_coef_metric_tumor: 0.2539 - loss: 0.4694 - mean_iou_all: 0.2631 - precision_tumor: 0.2120 - recall_tumor: 0.4336 - tumor_iou: 0.1583\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.19705\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9599 - dice_coef_metric_tumor: 0.2539 - loss: 0.4694 - mean_iou_all: 0.2631 - precision_tumor: 0.2120 - recall_tumor: 0.4336 - tumor_iou: 0.1583 - val_acc: 0.9757 - val_dice_coef_metric_tumor: 0.1616 - val_loss: 0.5324 - val_mean_iou_all: 0.2556 - val_precision_tumor: 0.2151 - val_recall_tumor: 0.1743 - val_tumor_iou: 0.0994 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 22 lên WandB.\n\n--- Epoch 23/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9591 - dice_coef_metric_tumor: 0.2650 - loss: 0.4532 - mean_iou_all: 0.2613 - precision_tumor: 0.2328 - recall_tumor: 0.4506 - tumor_iou: 0.1694\nEpoch 1: val_dice_coef_metric_tumor improved from 0.19705 to 0.20366, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9591 - dice_coef_metric_tumor: 0.2650 - loss: 0.4532 - mean_iou_all: 0.2613 - precision_tumor: 0.2328 - recall_tumor: 0.4505 - tumor_iou: 0.1694 - val_acc: 0.9646 - val_dice_coef_metric_tumor: 0.2037 - val_loss: 0.5094 - val_mean_iou_all: 0.2554 - val_precision_tumor: 0.1911 - val_recall_tumor: 0.3234 - val_tumor_iou: 0.1275 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 23 lên WandB.\n\n--- Epoch 24/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9639 - dice_coef_metric_tumor: 0.2634 - loss: 0.4497 - mean_iou_all: 0.2596 - precision_tumor: 0.2319 - recall_tumor: 0.4195 - tumor_iou: 0.1667\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.20366\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9639 - dice_coef_metric_tumor: 0.2634 - loss: 0.4497 - mean_iou_all: 0.2596 - precision_tumor: 0.2319 - recall_tumor: 0.4195 - tumor_iou: 0.1666 - val_acc: 0.9277 - val_dice_coef_metric_tumor: 0.2036 - val_loss: 0.5181 - val_mean_iou_all: 0.2661 - val_precision_tumor: 0.1403 - val_recall_tumor: 0.6005 - val_tumor_iou: 0.1239 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 24 lên WandB.\n\n--- Epoch 25/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9622 - dice_coef_metric_tumor: 0.2692 - loss: 0.4558 - mean_iou_all: 0.2722 - precision_tumor: 0.2398 - recall_tumor: 0.4380 - tumor_iou: 0.1719\nEpoch 1: val_dice_coef_metric_tumor improved from 0.20366 to 0.22153, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 472ms/step - acc: 0.9622 - dice_coef_metric_tumor: 0.2692 - loss: 0.4558 - mean_iou_all: 0.2722 - precision_tumor: 0.2397 - recall_tumor: 0.4380 - tumor_iou: 0.1719 - val_acc: 0.9646 - val_dice_coef_metric_tumor: 0.2215 - val_loss: 0.4982 - val_mean_iou_all: 0.2647 - val_precision_tumor: 0.2045 - val_recall_tumor: 0.3455 - val_tumor_iou: 0.1386 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 25 lên WandB.\n\n--- Epoch 26/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9675 - dice_coef_metric_tumor: 0.3037 - loss: 0.4340 - mean_iou_all: 0.2613 - precision_tumor: 0.2713 - recall_tumor: 0.4456 - tumor_iou: 0.1969\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.22153\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9675 - dice_coef_metric_tumor: 0.3037 - loss: 0.4340 - mean_iou_all: 0.2614 - precision_tumor: 0.2712 - recall_tumor: 0.4457 - tumor_iou: 0.1969 - val_acc: 0.9808 - val_dice_coef_metric_tumor: 0.1662 - val_loss: 0.5302 - val_mean_iou_all: 0.2562 - val_precision_tumor: 0.2857 - val_recall_tumor: 0.1444 - val_tumor_iou: 0.1021 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 26 lên WandB.\n\n--- Epoch 27/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9683 - dice_coef_metric_tumor: 0.3049 - loss: 0.4238 - mean_iou_all: 0.2611 - precision_tumor: 0.2729 - recall_tumor: 0.4570 - tumor_iou: 0.1966\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.22153\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9683 - dice_coef_metric_tumor: 0.3049 - loss: 0.4238 - mean_iou_all: 0.2612 - precision_tumor: 0.2729 - recall_tumor: 0.4569 - tumor_iou: 0.1965 - val_acc: 0.8973 - val_dice_coef_metric_tumor: 0.1794 - val_loss: 0.5425 - val_mean_iou_all: 0.2651 - val_precision_tumor: 0.1125 - val_recall_tumor: 0.7472 - val_tumor_iou: 0.1053 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 27 lên WandB.\n\n--- Epoch 28/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9657 - dice_coef_metric_tumor: 0.3010 - loss: 0.4340 - mean_iou_all: 0.2648 - precision_tumor: 0.2671 - recall_tumor: 0.4607 - tumor_iou: 0.1963\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.22153\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9657 - dice_coef_metric_tumor: 0.3009 - loss: 0.4340 - mean_iou_all: 0.2649 - precision_tumor: 0.2670 - recall_tumor: 0.4606 - tumor_iou: 0.1963 - val_acc: 0.9685 - val_dice_coef_metric_tumor: 0.1892 - val_loss: 0.5183 - val_mean_iou_all: 0.2579 - val_precision_tumor: 0.2207 - val_recall_tumor: 0.2522 - val_tumor_iou: 0.1170 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 28 lên WandB.\n\n--- Epoch 29/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9686 - dice_coef_metric_tumor: 0.3049 - loss: 0.4267 - mean_iou_all: 0.2623 - precision_tumor: 0.2778 - recall_tumor: 0.4573 - tumor_iou: 0.1981\nEpoch 1: val_dice_coef_metric_tumor improved from 0.22153 to 0.23964, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9686 - dice_coef_metric_tumor: 0.3048 - loss: 0.4267 - mean_iou_all: 0.2623 - precision_tumor: 0.2778 - recall_tumor: 0.4573 - tumor_iou: 0.1981 - val_acc: 0.9727 - val_dice_coef_metric_tumor: 0.2396 - val_loss: 0.4859 - val_mean_iou_all: 0.2539 - val_precision_tumor: 0.2520 - val_recall_tumor: 0.3193 - val_tumor_iou: 0.1516 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 29 lên WandB.\n\n--- Epoch 30/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9691 - dice_coef_metric_tumor: 0.3147 - loss: 0.4249 - mean_iou_all: 0.2591 - precision_tumor: 0.2907 - recall_tumor: 0.4539 - tumor_iou: 0.2059\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.23964\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9691 - dice_coef_metric_tumor: 0.3147 - loss: 0.4249 - mean_iou_all: 0.2591 - precision_tumor: 0.2906 - recall_tumor: 0.4539 - tumor_iou: 0.2059 - val_acc: 0.9736 - val_dice_coef_metric_tumor: 0.2249 - val_loss: 0.4946 - val_mean_iou_all: 0.2563 - val_precision_tumor: 0.2314 - val_recall_tumor: 0.2914 - val_tumor_iou: 0.1411 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 30 lên WandB.\n\n--- Epoch 31/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9684 - dice_coef_metric_tumor: 0.3136 - loss: 0.4197 - mean_iou_all: 0.2640 - precision_tumor: 0.2836 - recall_tumor: 0.4694 - tumor_iou: 0.2062\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.23964\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9684 - dice_coef_metric_tumor: 0.3135 - loss: 0.4197 - mean_iou_all: 0.2640 - precision_tumor: 0.2835 - recall_tumor: 0.4694 - tumor_iou: 0.2062 - val_acc: 0.9750 - val_dice_coef_metric_tumor: 0.2243 - val_loss: 0.4954 - val_mean_iou_all: 0.2585 - val_precision_tumor: 0.2675 - val_recall_tumor: 0.2691 - val_tumor_iou: 0.1421 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 31 lên WandB.\n\n--- Epoch 32/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9715 - dice_coef_metric_tumor: 0.3268 - loss: 0.4148 - mean_iou_all: 0.2598 - precision_tumor: 0.3019 - recall_tumor: 0.4589 - tumor_iou: 0.2149\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.23964\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9715 - dice_coef_metric_tumor: 0.3267 - loss: 0.4149 - mean_iou_all: 0.2599 - precision_tumor: 0.3018 - recall_tumor: 0.4589 - tumor_iou: 0.2149 - val_acc: 0.9563 - val_dice_coef_metric_tumor: 0.2344 - val_loss: 0.4956 - val_mean_iou_all: 0.2734 - val_precision_tumor: 0.1953 - val_recall_tumor: 0.4480 - val_tumor_iou: 0.1472 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 32 lên WandB.\n\n--- Epoch 33/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9699 - dice_coef_metric_tumor: 0.3214 - loss: 0.4122 - mean_iou_all: 0.2813 - precision_tumor: 0.2889 - recall_tumor: 0.4793 - tumor_iou: 0.2111\nEpoch 1: val_dice_coef_metric_tumor improved from 0.23964 to 0.27057, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9699 - dice_coef_metric_tumor: 0.3214 - loss: 0.4122 - mean_iou_all: 0.2813 - precision_tumor: 0.2889 - recall_tumor: 0.4792 - tumor_iou: 0.2111 - val_acc: 0.9587 - val_dice_coef_metric_tumor: 0.2706 - val_loss: 0.4733 - val_mean_iou_all: 0.2609 - val_precision_tumor: 0.2149 - val_recall_tumor: 0.5315 - val_tumor_iou: 0.1714 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 33 lên WandB.\n\n--- Epoch 34/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9664 - dice_coef_metric_tumor: 0.3228 - loss: 0.4198 - mean_iou_all: 0.2651 - precision_tumor: 0.2892 - recall_tumor: 0.4905 - tumor_iou: 0.2130\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.27057\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9664 - dice_coef_metric_tumor: 0.3228 - loss: 0.4198 - mean_iou_all: 0.2652 - precision_tumor: 0.2891 - recall_tumor: 0.4904 - tumor_iou: 0.2130 - val_acc: 0.9665 - val_dice_coef_metric_tumor: 0.2498 - val_loss: 0.4831 - val_mean_iou_all: 0.2609 - val_precision_tumor: 0.2318 - val_recall_tumor: 0.3960 - val_tumor_iou: 0.1597 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 34 lên WandB.\n\n--- Epoch 35/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9688 - dice_coef_metric_tumor: 0.3187 - loss: 0.4226 - mean_iou_all: 0.2636 - precision_tumor: 0.2949 - recall_tumor: 0.4715 - tumor_iou: 0.2109\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.27057\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9688 - dice_coef_metric_tumor: 0.3187 - loss: 0.4225 - mean_iou_all: 0.2637 - precision_tumor: 0.2949 - recall_tumor: 0.4715 - tumor_iou: 0.2108 - val_acc: 0.9556 - val_dice_coef_metric_tumor: 0.2684 - val_loss: 0.4740 - val_mean_iou_all: 0.2608 - val_precision_tumor: 0.2162 - val_recall_tumor: 0.5234 - val_tumor_iou: 0.1701 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 35 lên WandB.\n\n--- Epoch 36/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9689 - dice_coef_metric_tumor: 0.3315 - loss: 0.4149 - mean_iou_all: 0.2718 - precision_tumor: 0.3039 - recall_tumor: 0.4971 - tumor_iou: 0.2216\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.27057\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9689 - dice_coef_metric_tumor: 0.3314 - loss: 0.4148 - mean_iou_all: 0.2719 - precision_tumor: 0.3039 - recall_tumor: 0.4970 - tumor_iou: 0.2215 - val_acc: 0.9539 - val_dice_coef_metric_tumor: 0.2312 - val_loss: 0.4977 - val_mean_iou_all: 0.2577 - val_precision_tumor: 0.1867 - val_recall_tumor: 0.4781 - val_tumor_iou: 0.1451 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 36 lên WandB.\n\n--- Epoch 37/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9713 - dice_coef_metric_tumor: 0.3434 - loss: 0.4131 - mean_iou_all: 0.2695 - precision_tumor: 0.3149 - recall_tumor: 0.4859 - tumor_iou: 0.2278\nEpoch 1: val_dice_coef_metric_tumor improved from 0.27057 to 0.30090, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9713 - dice_coef_metric_tumor: 0.3434 - loss: 0.4131 - mean_iou_all: 0.2695 - precision_tumor: 0.3149 - recall_tumor: 0.4858 - tumor_iou: 0.2278 - val_acc: 0.9774 - val_dice_coef_metric_tumor: 0.3009 - val_loss: 0.4501 - val_mean_iou_all: 0.2565 - val_precision_tumor: 0.3294 - val_recall_tumor: 0.3610 - val_tumor_iou: 0.1975 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 37 lên WandB.\n\n--- Epoch 38/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9716 - dice_coef_metric_tumor: 0.3522 - loss: 0.4014 - mean_iou_all: 0.2611 - precision_tumor: 0.3224 - recall_tumor: 0.4968 - tumor_iou: 0.2365\nEpoch 1: val_dice_coef_metric_tumor improved from 0.30090 to 0.31294, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9716 - dice_coef_metric_tumor: 0.3522 - loss: 0.4013 - mean_iou_all: 0.2612 - precision_tumor: 0.3223 - recall_tumor: 0.4968 - tumor_iou: 0.2365 - val_acc: 0.9727 - val_dice_coef_metric_tumor: 0.3129 - val_loss: 0.4434 - val_mean_iou_all: 0.2604 - val_precision_tumor: 0.2942 - val_recall_tumor: 0.4488 - val_tumor_iou: 0.2045 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 38 lên WandB.\n\n--- Epoch 39/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9746 - dice_coef_metric_tumor: 0.3625 - loss: 0.3843 - mean_iou_all: 0.2621 - precision_tumor: 0.3433 - recall_tumor: 0.4858 - tumor_iou: 0.2452\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31294\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9746 - dice_coef_metric_tumor: 0.3624 - loss: 0.3843 - mean_iou_all: 0.2622 - precision_tumor: 0.3432 - recall_tumor: 0.4858 - tumor_iou: 0.2451 - val_acc: 0.9841 - val_dice_coef_metric_tumor: 0.1986 - val_loss: 0.5108 - val_mean_iou_all: 0.2565 - val_precision_tumor: 0.4454 - val_recall_tumor: 0.1502 - val_tumor_iou: 0.1242 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 39 lên WandB.\n\n--- Epoch 40/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9754 - dice_coef_metric_tumor: 0.3659 - loss: 0.3850 - mean_iou_all: 0.2609 - precision_tumor: 0.3557 - recall_tumor: 0.4883 - tumor_iou: 0.2472\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31294\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9754 - dice_coef_metric_tumor: 0.3659 - loss: 0.3850 - mean_iou_all: 0.2610 - precision_tumor: 0.3556 - recall_tumor: 0.4883 - tumor_iou: 0.2472 - val_acc: 0.9612 - val_dice_coef_metric_tumor: 0.2884 - val_loss: 0.4627 - val_mean_iou_all: 0.2602 - val_precision_tumor: 0.2244 - val_recall_tumor: 0.5530 - val_tumor_iou: 0.1832 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 40 lên WandB.\n\n--- Epoch 41/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9740 - dice_coef_metric_tumor: 0.3712 - loss: 0.3859 - mean_iou_all: 0.2670 - precision_tumor: 0.3459 - recall_tumor: 0.4977 - tumor_iou: 0.2535\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31294\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9740 - dice_coef_metric_tumor: 0.3711 - loss: 0.3859 - mean_iou_all: 0.2671 - precision_tumor: 0.3458 - recall_tumor: 0.4977 - tumor_iou: 0.2534 - val_acc: 0.9725 - val_dice_coef_metric_tumor: 0.3052 - val_loss: 0.4492 - val_mean_iou_all: 0.2677 - val_precision_tumor: 0.2938 - val_recall_tumor: 0.4376 - val_tumor_iou: 0.1991 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 41 lên WandB.\n\n--- Epoch 42/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9761 - dice_coef_metric_tumor: 0.3857 - loss: 0.3765 - mean_iou_all: 0.2802 - precision_tumor: 0.3693 - recall_tumor: 0.5097 - tumor_iou: 0.2640\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31294\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 466ms/step - acc: 0.9761 - dice_coef_metric_tumor: 0.3856 - loss: 0.3765 - mean_iou_all: 0.2802 - precision_tumor: 0.3692 - recall_tumor: 0.5097 - tumor_iou: 0.2639 - val_acc: 0.9721 - val_dice_coef_metric_tumor: 0.3095 - val_loss: 0.4474 - val_mean_iou_all: 0.2585 - val_precision_tumor: 0.2963 - val_recall_tumor: 0.4251 - val_tumor_iou: 0.2043 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 42 lên WandB.\n\n--- Epoch 43/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9763 - dice_coef_metric_tumor: 0.3754 - loss: 0.3807 - mean_iou_all: 0.2649 - precision_tumor: 0.3539 - recall_tumor: 0.5018 - tumor_iou: 0.2543\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31294\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9763 - dice_coef_metric_tumor: 0.3754 - loss: 0.3807 - mean_iou_all: 0.2649 - precision_tumor: 0.3538 - recall_tumor: 0.5018 - tumor_iou: 0.2542 - val_acc: 0.9792 - val_dice_coef_metric_tumor: 0.2978 - val_loss: 0.4515 - val_mean_iou_all: 0.2555 - val_precision_tumor: 0.3269 - val_recall_tumor: 0.3562 - val_tumor_iou: 0.1976 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 43 lên WandB.\n\n--- Epoch 44/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9737 - dice_coef_metric_tumor: 0.3657 - loss: 0.3936 - mean_iou_all: 0.2706 - precision_tumor: 0.3487 - recall_tumor: 0.5069 - tumor_iou: 0.2459\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31294\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9737 - dice_coef_metric_tumor: 0.3657 - loss: 0.3936 - mean_iou_all: 0.2707 - precision_tumor: 0.3487 - recall_tumor: 0.5069 - tumor_iou: 0.2459 - val_acc: 0.9464 - val_dice_coef_metric_tumor: 0.2634 - val_loss: 0.4828 - val_mean_iou_all: 0.2757 - val_precision_tumor: 0.1880 - val_recall_tumor: 0.6483 - val_tumor_iou: 0.1643 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 44 lên WandB.\n\n--- Epoch 45/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9760 - dice_coef_metric_tumor: 0.3792 - loss: 0.3854 - mean_iou_all: 0.2725 - precision_tumor: 0.3615 - recall_tumor: 0.5019 - tumor_iou: 0.2568\nEpoch 1: val_dice_coef_metric_tumor improved from 0.31294 to 0.32114, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9760 - dice_coef_metric_tumor: 0.3791 - loss: 0.3854 - mean_iou_all: 0.2726 - precision_tumor: 0.3614 - recall_tumor: 0.5019 - tumor_iou: 0.2568 - val_acc: 0.9743 - val_dice_coef_metric_tumor: 0.3211 - val_loss: 0.4395 - val_mean_iou_all: 0.2624 - val_precision_tumor: 0.3170 - val_recall_tumor: 0.4288 - val_tumor_iou: 0.2140 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 45 lên WandB.\n\n--- Epoch 46/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9748 - dice_coef_metric_tumor: 0.3631 - loss: 0.3903 - mean_iou_all: 0.2754 - precision_tumor: 0.3421 - recall_tumor: 0.4905 - tumor_iou: 0.2431\nEpoch 1: val_dice_coef_metric_tumor improved from 0.32114 to 0.33595, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9748 - dice_coef_metric_tumor: 0.3631 - loss: 0.3903 - mean_iou_all: 0.2755 - precision_tumor: 0.3421 - recall_tumor: 0.4906 - tumor_iou: 0.2430 - val_acc: 0.9746 - val_dice_coef_metric_tumor: 0.3360 - val_loss: 0.4308 - val_mean_iou_all: 0.2638 - val_precision_tumor: 0.3371 - val_recall_tumor: 0.4522 - val_tumor_iou: 0.2243 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 46 lên WandB.\n\n--- Epoch 47/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9783 - dice_coef_metric_tumor: 0.3962 - loss: 0.3714 - mean_iou_all: 0.2901 - precision_tumor: 0.3935 - recall_tumor: 0.4913 - tumor_iou: 0.2719\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.33595\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9783 - dice_coef_metric_tumor: 0.3961 - loss: 0.3714 - mean_iou_all: 0.2903 - precision_tumor: 0.3934 - recall_tumor: 0.4913 - tumor_iou: 0.2718 - val_acc: 0.9729 - val_dice_coef_metric_tumor: 0.3247 - val_loss: 0.4382 - val_mean_iou_all: 0.2681 - val_precision_tumor: 0.2954 - val_recall_tumor: 0.4676 - val_tumor_iou: 0.2136 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 47 lên WandB.\n\n--- Epoch 48/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9767 - dice_coef_metric_tumor: 0.3955 - loss: 0.3696 - mean_iou_all: 0.2996 - precision_tumor: 0.3883 - recall_tumor: 0.5181 - tumor_iou: 0.2709\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.33595\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9766 - dice_coef_metric_tumor: 0.3954 - loss: 0.3696 - mean_iou_all: 0.2997 - precision_tumor: 0.3881 - recall_tumor: 0.5181 - tumor_iou: 0.2708 - val_acc: 0.9723 - val_dice_coef_metric_tumor: 0.2865 - val_loss: 0.4616 - val_mean_iou_all: 0.2626 - val_precision_tumor: 0.3321 - val_recall_tumor: 0.3810 - val_tumor_iou: 0.1864 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 48 lên WandB.\n\n--- Epoch 49/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9735 - dice_coef_metric_tumor: 0.3647 - loss: 0.3852 - mean_iou_all: 0.3025 - precision_tumor: 0.3469 - recall_tumor: 0.5073 - tumor_iou: 0.2466\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.33595\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9735 - dice_coef_metric_tumor: 0.3647 - loss: 0.3852 - mean_iou_all: 0.3026 - precision_tumor: 0.3469 - recall_tumor: 0.5073 - tumor_iou: 0.2466 - val_acc: 0.9829 - val_dice_coef_metric_tumor: 0.2904 - val_loss: 0.4558 - val_mean_iou_all: 0.2763 - val_precision_tumor: 0.4307 - val_recall_tumor: 0.2700 - val_tumor_iou: 0.1917 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 49 lên WandB.\n\n--- Epoch 50/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9759 - dice_coef_metric_tumor: 0.3860 - loss: 0.3838 - mean_iou_all: 0.3015 - precision_tumor: 0.3688 - recall_tumor: 0.5007 - tumor_iou: 0.2636\nEpoch 1: val_dice_coef_metric_tumor improved from 0.33595 to 0.34411, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9759 - dice_coef_metric_tumor: 0.3860 - loss: 0.3838 - mean_iou_all: 0.3017 - precision_tumor: 0.3687 - recall_tumor: 0.5007 - tumor_iou: 0.2635 - val_acc: 0.9767 - val_dice_coef_metric_tumor: 0.3441 - val_loss: 0.4245 - val_mean_iou_all: 0.2703 - val_precision_tumor: 0.3232 - val_recall_tumor: 0.4685 - val_tumor_iou: 0.2287 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 50 lên WandB.\n\n--- Epoch 51/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9780 - dice_coef_metric_tumor: 0.4083 - loss: 0.3625 - mean_iou_all: 0.2976 - precision_tumor: 0.3953 - recall_tumor: 0.5212 - tumor_iou: 0.2821\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34411\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9780 - dice_coef_metric_tumor: 0.4083 - loss: 0.3625 - mean_iou_all: 0.2977 - precision_tumor: 0.3952 - recall_tumor: 0.5212 - tumor_iou: 0.2820 - val_acc: 0.9842 - val_dice_coef_metric_tumor: 0.2989 - val_loss: 0.4507 - val_mean_iou_all: 0.2742 - val_precision_tumor: 0.4664 - val_recall_tumor: 0.2622 - val_tumor_iou: 0.1984 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 51 lên WandB.\n\n--- Epoch 52/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9777 - dice_coef_metric_tumor: 0.3965 - loss: 0.3673 - mean_iou_all: 0.2945 - precision_tumor: 0.3802 - recall_tumor: 0.5163 - tumor_iou: 0.2741\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34411\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9777 - dice_coef_metric_tumor: 0.3965 - loss: 0.3673 - mean_iou_all: 0.2946 - precision_tumor: 0.3801 - recall_tumor: 0.5163 - tumor_iou: 0.2741 - val_acc: 0.9582 - val_dice_coef_metric_tumor: 0.2639 - val_loss: 0.4811 - val_mean_iou_all: 0.4342 - val_precision_tumor: 0.2083 - val_recall_tumor: 0.4997 - val_tumor_iou: 0.1680 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 52 lên WandB.\n\n--- Epoch 53/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9751 - dice_coef_metric_tumor: 0.3921 - loss: 0.3762 - mean_iou_all: 0.3162 - precision_tumor: 0.3615 - recall_tumor: 0.5369 - tumor_iou: 0.2690\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34411\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9751 - dice_coef_metric_tumor: 0.3921 - loss: 0.3762 - mean_iou_all: 0.3164 - precision_tumor: 0.3614 - recall_tumor: 0.5368 - tumor_iou: 0.2690 - val_acc: 0.9626 - val_dice_coef_metric_tumor: 0.3176 - val_loss: 0.4456 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.2424 - val_recall_tumor: 0.6138 - val_tumor_iou: 0.2051 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 53 lên WandB.\n\n--- Epoch 54/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9768 - dice_coef_metric_tumor: 0.3933 - loss: 0.3714 - mean_iou_all: 0.3233 - precision_tumor: 0.3656 - recall_tumor: 0.5241 - tumor_iou: 0.2697\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34411\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9768 - dice_coef_metric_tumor: 0.3933 - loss: 0.3715 - mean_iou_all: 0.3234 - precision_tumor: 0.3655 - recall_tumor: 0.5241 - tumor_iou: 0.2696 - val_acc: 0.9602 - val_dice_coef_metric_tumor: 0.3170 - val_loss: 0.4476 - val_mean_iou_all: 0.2662 - val_precision_tumor: 0.2524 - val_recall_tumor: 0.6147 - val_tumor_iou: 0.2064 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 54 lên WandB.\n\n--- Epoch 55/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9774 - dice_coef_metric_tumor: 0.4031 - loss: 0.3718 - mean_iou_all: 0.3306 - precision_tumor: 0.3832 - recall_tumor: 0.5125 - tumor_iou: 0.2752\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34411\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9774 - dice_coef_metric_tumor: 0.4031 - loss: 0.3718 - mean_iou_all: 0.3307 - precision_tumor: 0.3831 - recall_tumor: 0.5125 - tumor_iou: 0.2752 - val_acc: 0.9789 - val_dice_coef_metric_tumor: 0.3322 - val_loss: 0.4328 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4105 - val_recall_tumor: 0.3689 - val_tumor_iou: 0.2225 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 55 lên WandB.\n\n--- Epoch 56/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9774 - dice_coef_metric_tumor: 0.4022 - loss: 0.3756 - mean_iou_all: 0.3222 - precision_tumor: 0.3863 - recall_tumor: 0.5248 - tumor_iou: 0.2766\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34411\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9774 - dice_coef_metric_tumor: 0.4021 - loss: 0.3756 - mean_iou_all: 0.3223 - precision_tumor: 0.3862 - recall_tumor: 0.5248 - tumor_iou: 0.2765 - val_acc: 0.9446 - val_dice_coef_metric_tumor: 0.2883 - val_loss: 0.4715 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.2003 - val_recall_tumor: 0.7335 - val_tumor_iou: 0.1825 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 56 lên WandB.\n\n--- Epoch 57/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9786 - dice_coef_metric_tumor: 0.4250 - loss: 0.3489 - mean_iou_all: 0.3374 - precision_tumor: 0.4057 - recall_tumor: 0.5465 - tumor_iou: 0.2975\nEpoch 1: val_dice_coef_metric_tumor improved from 0.34411 to 0.34481, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9786 - dice_coef_metric_tumor: 0.4249 - loss: 0.3489 - mean_iou_all: 0.3377 - precision_tumor: 0.4056 - recall_tumor: 0.5465 - tumor_iou: 0.2975 - val_acc: 0.9650 - val_dice_coef_metric_tumor: 0.3448 - val_loss: 0.4292 - val_mean_iou_all: 0.3070 - val_precision_tumor: 0.2819 - val_recall_tumor: 0.6163 - val_tumor_iou: 0.2268 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 57 lên WandB.\n\n--- Epoch 58/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9768 - dice_coef_metric_tumor: 0.4014 - loss: 0.3635 - mean_iou_all: 0.3372 - precision_tumor: 0.3811 - recall_tumor: 0.5340 - tumor_iou: 0.2780\nEpoch 1: val_dice_coef_metric_tumor improved from 0.34481 to 0.38889, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9768 - dice_coef_metric_tumor: 0.4014 - loss: 0.3635 - mean_iou_all: 0.3374 - precision_tumor: 0.3811 - recall_tumor: 0.5340 - tumor_iou: 0.2780 - val_acc: 0.9820 - val_dice_coef_metric_tumor: 0.3889 - val_loss: 0.3975 - val_mean_iou_all: 0.3092 - val_precision_tumor: 0.4129 - val_recall_tumor: 0.4478 - val_tumor_iou: 0.2661 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 58 lên WandB.\n\n--- Epoch 59/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9790 - dice_coef_metric_tumor: 0.4308 - loss: 0.3564 - mean_iou_all: 0.3494 - precision_tumor: 0.4164 - recall_tumor: 0.5334 - tumor_iou: 0.3006\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.38889\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9790 - dice_coef_metric_tumor: 0.4307 - loss: 0.3564 - mean_iou_all: 0.3496 - precision_tumor: 0.4163 - recall_tumor: 0.5333 - tumor_iou: 0.3005 - val_acc: 0.9636 - val_dice_coef_metric_tumor: 0.3386 - val_loss: 0.4345 - val_mean_iou_all: 0.2884 - val_precision_tumor: 0.2718 - val_recall_tumor: 0.6267 - val_tumor_iou: 0.2227 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 59 lên WandB.\n\n--- Epoch 60/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9790 - dice_coef_metric_tumor: 0.4218 - loss: 0.3547 - mean_iou_all: 0.3417 - precision_tumor: 0.4092 - recall_tumor: 0.5412 - tumor_iou: 0.2976\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.38889\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9790 - dice_coef_metric_tumor: 0.4217 - loss: 0.3547 - mean_iou_all: 0.3419 - precision_tumor: 0.4091 - recall_tumor: 0.5412 - tumor_iou: 0.2975 - val_acc: 0.9692 - val_dice_coef_metric_tumor: 0.3186 - val_loss: 0.4450 - val_mean_iou_all: 0.2717 - val_precision_tumor: 0.2898 - val_recall_tumor: 0.5013 - val_tumor_iou: 0.2099 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 60 lên WandB.\n\n--- Epoch 61/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9778 - dice_coef_metric_tumor: 0.4156 - loss: 0.3608 - mean_iou_all: 0.3702 - precision_tumor: 0.3997 - recall_tumor: 0.5444 - tumor_iou: 0.2879\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.38889\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9778 - dice_coef_metric_tumor: 0.4155 - loss: 0.3608 - mean_iou_all: 0.3704 - precision_tumor: 0.3996 - recall_tumor: 0.5444 - tumor_iou: 0.2879 - val_acc: 0.9724 - val_dice_coef_metric_tumor: 0.3732 - val_loss: 0.4093 - val_mean_iou_all: 0.2616 - val_precision_tumor: 0.3137 - val_recall_tumor: 0.6182 - val_tumor_iou: 0.2502 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 61 lên WandB.\n\n--- Epoch 62/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9791 - dice_coef_metric_tumor: 0.4383 - loss: 0.3471 - mean_iou_all: 0.3628 - precision_tumor: 0.4156 - recall_tumor: 0.5550 - tumor_iou: 0.3058\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.38889\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9791 - dice_coef_metric_tumor: 0.4383 - loss: 0.3471 - mean_iou_all: 0.3631 - precision_tumor: 0.4155 - recall_tumor: 0.5550 - tumor_iou: 0.3058 - val_acc: 0.9825 - val_dice_coef_metric_tumor: 0.3717 - val_loss: 0.4085 - val_mean_iou_all: 0.3745 - val_precision_tumor: 0.4220 - val_recall_tumor: 0.4124 - val_tumor_iou: 0.2544 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 62 lên WandB.\n\n--- Epoch 63/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9789 - dice_coef_metric_tumor: 0.4153 - loss: 0.3608 - mean_iou_all: 0.3683 - precision_tumor: 0.4076 - recall_tumor: 0.5244 - tumor_iou: 0.2872\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.38889\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9789 - dice_coef_metric_tumor: 0.4153 - loss: 0.3608 - mean_iou_all: 0.3685 - precision_tumor: 0.4075 - recall_tumor: 0.5244 - tumor_iou: 0.2872 - val_acc: 0.9793 - val_dice_coef_metric_tumor: 0.3652 - val_loss: 0.4136 - val_mean_iou_all: 0.2997 - val_precision_tumor: 0.3945 - val_recall_tumor: 0.4250 - val_tumor_iou: 0.2479 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 63 lên WandB.\n\n--- Epoch 64/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9776 - dice_coef_metric_tumor: 0.4309 - loss: 0.3567 - mean_iou_all: 0.3778 - precision_tumor: 0.4085 - recall_tumor: 0.5406 - tumor_iou: 0.3039\nEpoch 1: val_dice_coef_metric_tumor improved from 0.38889 to 0.41736, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9776 - dice_coef_metric_tumor: 0.4309 - loss: 0.3567 - mean_iou_all: 0.3781 - precision_tumor: 0.4085 - recall_tumor: 0.5406 - tumor_iou: 0.3039 - val_acc: 0.9833 - val_dice_coef_metric_tumor: 0.4174 - val_loss: 0.3804 - val_mean_iou_all: 0.3027 - val_precision_tumor: 0.4835 - val_recall_tumor: 0.4477 - val_tumor_iou: 0.2914 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 64 lên WandB.\n\n--- Epoch 65/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9789 - dice_coef_metric_tumor: 0.4263 - loss: 0.3561 - mean_iou_all: 0.3887 - precision_tumor: 0.4104 - recall_tumor: 0.5444 - tumor_iou: 0.2979\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41736\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9789 - dice_coef_metric_tumor: 0.4262 - loss: 0.3561 - mean_iou_all: 0.3890 - precision_tumor: 0.4103 - recall_tumor: 0.5444 - tumor_iou: 0.2978 - val_acc: 0.9545 - val_dice_coef_metric_tumor: 0.3177 - val_loss: 0.4536 - val_mean_iou_all: 0.3219 - val_precision_tumor: 0.2385 - val_recall_tumor: 0.6875 - val_tumor_iou: 0.2075 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 65 lên WandB.\n\n--- Epoch 66/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9791 - dice_coef_metric_tumor: 0.4292 - loss: 0.3531 - mean_iou_all: 0.3864 - precision_tumor: 0.4168 - recall_tumor: 0.5462 - tumor_iou: 0.3002\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41736\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9791 - dice_coef_metric_tumor: 0.4291 - loss: 0.3531 - mean_iou_all: 0.3867 - precision_tumor: 0.4167 - recall_tumor: 0.5462 - tumor_iou: 0.3001 - val_acc: 0.9637 - val_dice_coef_metric_tumor: 0.3426 - val_loss: 0.4333 - val_mean_iou_all: 0.2973 - val_precision_tumor: 0.2677 - val_recall_tumor: 0.6222 - val_tumor_iou: 0.2264 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 66 lên WandB.\n\n--- Epoch 67/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9807 - dice_coef_metric_tumor: 0.4407 - loss: 0.3332 - mean_iou_all: 0.3922 - precision_tumor: 0.4217 - recall_tumor: 0.5598 - tumor_iou: 0.3123\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41736\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9807 - dice_coef_metric_tumor: 0.4406 - loss: 0.3332 - mean_iou_all: 0.3925 - precision_tumor: 0.4216 - recall_tumor: 0.5597 - tumor_iou: 0.3123 - val_acc: 0.9760 - val_dice_coef_metric_tumor: 0.3490 - val_loss: 0.4252 - val_mean_iou_all: 0.3310 - val_precision_tumor: 0.3222 - val_recall_tumor: 0.4799 - val_tumor_iou: 0.2346 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 67 lên WandB.\n\n--- Epoch 68/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9790 - dice_coef_metric_tumor: 0.4259 - loss: 0.3560 - mean_iou_all: 0.4123 - precision_tumor: 0.4094 - recall_tumor: 0.5392 - tumor_iou: 0.2959\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41736\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9790 - dice_coef_metric_tumor: 0.4258 - loss: 0.3560 - mean_iou_all: 0.4125 - precision_tumor: 0.4094 - recall_tumor: 0.5392 - tumor_iou: 0.2959 - val_acc: 0.9717 - val_dice_coef_metric_tumor: 0.3833 - val_loss: 0.4058 - val_mean_iou_all: 0.2699 - val_precision_tumor: 0.3124 - val_recall_tumor: 0.6146 - val_tumor_iou: 0.2586 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 68 lên WandB.\n\n--- Epoch 69/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9790 - dice_coef_metric_tumor: 0.4400 - loss: 0.3449 - mean_iou_all: 0.4220 - precision_tumor: 0.4223 - recall_tumor: 0.5706 - tumor_iou: 0.3121\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41736\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9790 - dice_coef_metric_tumor: 0.4399 - loss: 0.3449 - mean_iou_all: 0.4222 - precision_tumor: 0.4223 - recall_tumor: 0.5706 - tumor_iou: 0.3121 - val_acc: 0.9704 - val_dice_coef_metric_tumor: 0.3394 - val_loss: 0.4331 - val_mean_iou_all: 0.2861 - val_precision_tumor: 0.3025 - val_recall_tumor: 0.5132 - val_tumor_iou: 0.2276 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 69 lên WandB.\n\n--- Epoch 70/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9788 - dice_coef_metric_tumor: 0.4304 - loss: 0.3489 - mean_iou_all: 0.3958 - precision_tumor: 0.4107 - recall_tumor: 0.5409 - tumor_iou: 0.3032\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41736\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9789 - dice_coef_metric_tumor: 0.4304 - loss: 0.3489 - mean_iou_all: 0.3960 - precision_tumor: 0.4107 - recall_tumor: 0.5409 - tumor_iou: 0.3031 - val_acc: 0.9723 - val_dice_coef_metric_tumor: 0.3780 - val_loss: 0.4086 - val_mean_iou_all: 0.2791 - val_precision_tumor: 0.3231 - val_recall_tumor: 0.5923 - val_tumor_iou: 0.2561 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 70 lên WandB.\n\n--- Epoch 71/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9800 - dice_coef_metric_tumor: 0.4436 - loss: 0.3509 - mean_iou_all: 0.4013 - precision_tumor: 0.4290 - recall_tumor: 0.5437 - tumor_iou: 0.3130\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41736\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9800 - dice_coef_metric_tumor: 0.4435 - loss: 0.3509 - mean_iou_all: 0.4015 - precision_tumor: 0.4290 - recall_tumor: 0.5437 - tumor_iou: 0.3129 - val_acc: 0.9833 - val_dice_coef_metric_tumor: 0.3828 - val_loss: 0.4019 - val_mean_iou_all: 0.3288 - val_precision_tumor: 0.4551 - val_recall_tumor: 0.4150 - val_tumor_iou: 0.2646 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 71 lên WandB.\n\n--- Epoch 72/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9771 - dice_coef_metric_tumor: 0.4210 - loss: 0.3499 - mean_iou_all: 0.4026 - precision_tumor: 0.4124 - recall_tumor: 0.5783 - tumor_iou: 0.2967\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41736\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9771 - dice_coef_metric_tumor: 0.4209 - loss: 0.3499 - mean_iou_all: 0.4029 - precision_tumor: 0.4124 - recall_tumor: 0.5782 - tumor_iou: 0.2966 - val_acc: 0.9808 - val_dice_coef_metric_tumor: 0.3907 - val_loss: 0.3982 - val_mean_iou_all: 0.3152 - val_precision_tumor: 0.4145 - val_recall_tumor: 0.4656 - val_tumor_iou: 0.2699 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 72 lên WandB.\n\n--- Epoch 73/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9803 - dice_coef_metric_tumor: 0.4423 - loss: 0.3421 - mean_iou_all: 0.3920 - precision_tumor: 0.4302 - recall_tumor: 0.5573 - tumor_iou: 0.3106\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41736\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9803 - dice_coef_metric_tumor: 0.4423 - loss: 0.3421 - mean_iou_all: 0.3922 - precision_tumor: 0.4302 - recall_tumor: 0.5573 - tumor_iou: 0.3106 - val_acc: 0.9785 - val_dice_coef_metric_tumor: 0.3911 - val_loss: 0.3986 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3748 - val_recall_tumor: 0.5136 - val_tumor_iou: 0.2668 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 73 lên WandB.\n\n--- Epoch 74/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9805 - dice_coef_metric_tumor: 0.4513 - loss: 0.3382 - mean_iou_all: 0.3780 - precision_tumor: 0.4357 - recall_tumor: 0.5772 - tumor_iou: 0.3199\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41736\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9805 - dice_coef_metric_tumor: 0.4512 - loss: 0.3382 - mean_iou_all: 0.3782 - precision_tumor: 0.4357 - recall_tumor: 0.5771 - tumor_iou: 0.3198 - val_acc: 0.9801 - val_dice_coef_metric_tumor: 0.3865 - val_loss: 0.4015 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4338 - val_recall_tumor: 0.4651 - val_tumor_iou: 0.2673 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 74 lên WandB.\n\n--- Epoch 75/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9793 - dice_coef_metric_tumor: 0.4412 - loss: 0.3457 - mean_iou_all: 0.4195 - precision_tumor: 0.4366 - recall_tumor: 0.5586 - tumor_iou: 0.3121\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41736\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9793 - dice_coef_metric_tumor: 0.4412 - loss: 0.3456 - mean_iou_all: 0.4197 - precision_tumor: 0.4365 - recall_tumor: 0.5586 - tumor_iou: 0.3120 - val_acc: 0.9813 - val_dice_coef_metric_tumor: 0.3989 - val_loss: 0.3939 - val_mean_iou_all: 0.3461 - val_precision_tumor: 0.3996 - val_recall_tumor: 0.4780 - val_tumor_iou: 0.2741 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 75 lên WandB.\n\n--- Epoch 76/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9804 - dice_coef_metric_tumor: 0.4535 - loss: 0.3421 - mean_iou_all: 0.4052 - precision_tumor: 0.4486 - recall_tumor: 0.5690 - tumor_iou: 0.3175\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41736\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9804 - dice_coef_metric_tumor: 0.4535 - loss: 0.3420 - mean_iou_all: 0.4055 - precision_tumor: 0.4485 - recall_tumor: 0.5690 - tumor_iou: 0.3175 - val_acc: 0.9762 - val_dice_coef_metric_tumor: 0.3868 - val_loss: 0.4027 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3750 - val_recall_tumor: 0.5153 - val_tumor_iou: 0.2642 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 76 lên WandB.\n\n--- Epoch 77/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9812 - dice_coef_metric_tumor: 0.4505 - loss: 0.3415 - mean_iou_all: 0.4179 - precision_tumor: 0.4400 - recall_tumor: 0.5605 - tumor_iou: 0.3168\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41736\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9812 - dice_coef_metric_tumor: 0.4505 - loss: 0.3415 - mean_iou_all: 0.4181 - precision_tumor: 0.4400 - recall_tumor: 0.5605 - tumor_iou: 0.3168 - val_acc: 0.9817 - val_dice_coef_metric_tumor: 0.4009 - val_loss: 0.3922 - val_mean_iou_all: 0.3157 - val_precision_tumor: 0.4260 - val_recall_tumor: 0.4757 - val_tumor_iou: 0.2763 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 77 lên WandB.\n\n--- Epoch 78/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9826 - dice_coef_metric_tumor: 0.4617 - loss: 0.3289 - mean_iou_all: 0.3806 - precision_tumor: 0.4622 - recall_tumor: 0.5487 - tumor_iou: 0.3319\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41736\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 466ms/step - acc: 0.9826 - dice_coef_metric_tumor: 0.4617 - loss: 0.3289 - mean_iou_all: 0.3809 - precision_tumor: 0.4622 - recall_tumor: 0.5487 - tumor_iou: 0.3318 - val_acc: 0.9840 - val_dice_coef_metric_tumor: 0.4000 - val_loss: 0.3926 - val_mean_iou_all: 0.3349 - val_precision_tumor: 0.4889 - val_recall_tumor: 0.4133 - val_tumor_iou: 0.2783 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 78 lên WandB.\n\n--- Epoch 79/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4447 - loss: 0.3410 - mean_iou_all: 0.4200 - precision_tumor: 0.4302 - recall_tumor: 0.5801 - tumor_iou: 0.3119\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41736\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4446 - loss: 0.3410 - mean_iou_all: 0.4202 - precision_tumor: 0.4301 - recall_tumor: 0.5801 - tumor_iou: 0.3118 - val_acc: 0.9684 - val_dice_coef_metric_tumor: 0.3750 - val_loss: 0.4130 - val_mean_iou_all: 0.3393 - val_precision_tumor: 0.2997 - val_recall_tumor: 0.6615 - val_tumor_iou: 0.2524 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 79 lên WandB.\n\n--- Epoch 80/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9804 - dice_coef_metric_tumor: 0.4525 - loss: 0.3437 - mean_iou_all: 0.4353 - precision_tumor: 0.4459 - recall_tumor: 0.5551 - tumor_iou: 0.3220\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41736\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9804 - dice_coef_metric_tumor: 0.4524 - loss: 0.3437 - mean_iou_all: 0.4354 - precision_tumor: 0.4459 - recall_tumor: 0.5551 - tumor_iou: 0.3219 - val_acc: 0.9772 - val_dice_coef_metric_tumor: 0.4097 - val_loss: 0.3890 - val_mean_iou_all: 0.3677 - val_precision_tumor: 0.3657 - val_recall_tumor: 0.5912 - val_tumor_iou: 0.2833 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 80 lên WandB.\n\n--- Epoch 81/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9801 - dice_coef_metric_tumor: 0.4591 - loss: 0.3379 - mean_iou_all: 0.4304 - precision_tumor: 0.4299 - recall_tumor: 0.5818 - tumor_iou: 0.3243\nEpoch 1: val_dice_coef_metric_tumor improved from 0.41736 to 0.45507, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9801 - dice_coef_metric_tumor: 0.4591 - loss: 0.3378 - mean_iou_all: 0.4306 - precision_tumor: 0.4299 - recall_tumor: 0.5818 - tumor_iou: 0.3243 - val_acc: 0.9833 - val_dice_coef_metric_tumor: 0.4551 - val_loss: 0.3598 - val_mean_iou_all: 0.3285 - val_precision_tumor: 0.4487 - val_recall_tumor: 0.5489 - val_tumor_iou: 0.3226 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 81 lên WandB.\n\n--- Epoch 82/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9829 - dice_coef_metric_tumor: 0.4751 - loss: 0.3234 - mean_iou_all: 0.4252 - precision_tumor: 0.4745 - recall_tumor: 0.5602 - tumor_iou: 0.3412\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45507\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9829 - dice_coef_metric_tumor: 0.4750 - loss: 0.3234 - mean_iou_all: 0.4254 - precision_tumor: 0.4744 - recall_tumor: 0.5602 - tumor_iou: 0.3411 - val_acc: 0.9810 - val_dice_coef_metric_tumor: 0.4102 - val_loss: 0.3880 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4202 - val_recall_tumor: 0.5114 - val_tumor_iou: 0.2873 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 82 lên WandB.\n\n--- Epoch 83/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9824 - dice_coef_metric_tumor: 0.4709 - loss: 0.3243 - mean_iou_all: 0.4500 - precision_tumor: 0.4590 - recall_tumor: 0.5785 - tumor_iou: 0.3362\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45507\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9824 - dice_coef_metric_tumor: 0.4709 - loss: 0.3243 - mean_iou_all: 0.4501 - precision_tumor: 0.4589 - recall_tumor: 0.5785 - tumor_iou: 0.3362 - val_acc: 0.9843 - val_dice_coef_metric_tumor: 0.4385 - val_loss: 0.3701 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4874 - val_recall_tumor: 0.4614 - val_tumor_iou: 0.3111 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 83 lên WandB.\n\n--- Epoch 84/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9829 - dice_coef_metric_tumor: 0.4903 - loss: 0.3238 - mean_iou_all: 0.4497 - precision_tumor: 0.4954 - recall_tumor: 0.5667 - tumor_iou: 0.3506\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45507\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9829 - dice_coef_metric_tumor: 0.4902 - loss: 0.3238 - mean_iou_all: 0.4498 - precision_tumor: 0.4953 - recall_tumor: 0.5667 - tumor_iou: 0.3505 - val_acc: 0.9808 - val_dice_coef_metric_tumor: 0.4441 - val_loss: 0.3674 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4071 - val_recall_tumor: 0.5898 - val_tumor_iou: 0.3130 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 84 lên WandB.\n\n--- Epoch 85/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9820 - dice_coef_metric_tumor: 0.4759 - loss: 0.3288 - mean_iou_all: 0.4292 - precision_tumor: 0.4678 - recall_tumor: 0.5819 - tumor_iou: 0.3402\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45507\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9820 - dice_coef_metric_tumor: 0.4759 - loss: 0.3288 - mean_iou_all: 0.4293 - precision_tumor: 0.4677 - recall_tumor: 0.5818 - tumor_iou: 0.3402 - val_acc: 0.9757 - val_dice_coef_metric_tumor: 0.3912 - val_loss: 0.4029 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4077 - val_recall_tumor: 0.4978 - val_tumor_iou: 0.2686 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 85 lên WandB.\n\n--- Epoch 86/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9816 - dice_coef_metric_tumor: 0.4616 - loss: 0.3252 - mean_iou_all: 0.4526 - precision_tumor: 0.4404 - recall_tumor: 0.5725 - tumor_iou: 0.3311\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45507\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9816 - dice_coef_metric_tumor: 0.4616 - loss: 0.3251 - mean_iou_all: 0.4527 - precision_tumor: 0.4404 - recall_tumor: 0.5725 - tumor_iou: 0.3311 - val_acc: 0.9861 - val_dice_coef_metric_tumor: 0.4276 - val_loss: 0.3764 - val_mean_iou_all: 0.3614 - val_precision_tumor: 0.5642 - val_recall_tumor: 0.4111 - val_tumor_iou: 0.2985 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 86 lên WandB.\n\n--- Epoch 87/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.4864 - loss: 0.3128 - mean_iou_all: 0.4233 - precision_tumor: 0.4885 - recall_tumor: 0.5676 - tumor_iou: 0.3531\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45507\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.4863 - loss: 0.3129 - mean_iou_all: 0.4235 - precision_tumor: 0.4884 - recall_tumor: 0.5676 - tumor_iou: 0.3530 - val_acc: 0.9817 - val_dice_coef_metric_tumor: 0.4241 - val_loss: 0.3799 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4263 - val_recall_tumor: 0.5189 - val_tumor_iou: 0.2960 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 87 lên WandB.\n\n--- Epoch 88/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9823 - dice_coef_metric_tumor: 0.4876 - loss: 0.3188 - mean_iou_all: 0.4367 - precision_tumor: 0.4828 - recall_tumor: 0.5841 - tumor_iou: 0.3535\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45507\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9823 - dice_coef_metric_tumor: 0.4875 - loss: 0.3188 - mean_iou_all: 0.4368 - precision_tumor: 0.4827 - recall_tumor: 0.5841 - tumor_iou: 0.3534 - val_acc: 0.9865 - val_dice_coef_metric_tumor: 0.4148 - val_loss: 0.3840 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5597 - val_recall_tumor: 0.3875 - val_tumor_iou: 0.2866 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 88 lên WandB.\n\n--- Epoch 89/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9829 - dice_coef_metric_tumor: 0.4810 - loss: 0.3196 - mean_iou_all: 0.4591 - precision_tumor: 0.4744 - recall_tumor: 0.5762 - tumor_iou: 0.3486\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45507\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9829 - dice_coef_metric_tumor: 0.4809 - loss: 0.3196 - mean_iou_all: 0.4592 - precision_tumor: 0.4744 - recall_tumor: 0.5762 - tumor_iou: 0.3485 - val_acc: 0.9865 - val_dice_coef_metric_tumor: 0.4519 - val_loss: 0.3621 - val_mean_iou_all: 0.4518 - val_precision_tumor: 0.5668 - val_recall_tumor: 0.4356 - val_tumor_iou: 0.3217 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 89 lên WandB.\n\n--- Epoch 90/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9819 - dice_coef_metric_tumor: 0.4824 - loss: 0.3263 - mean_iou_all: 0.4582 - precision_tumor: 0.4767 - recall_tumor: 0.5737 - tumor_iou: 0.3482\nEpoch 1: val_dice_coef_metric_tumor improved from 0.45507 to 0.45765, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9819 - dice_coef_metric_tumor: 0.4824 - loss: 0.3263 - mean_iou_all: 0.4582 - precision_tumor: 0.4767 - recall_tumor: 0.5737 - tumor_iou: 0.3482 - val_acc: 0.9834 - val_dice_coef_metric_tumor: 0.4577 - val_loss: 0.3595 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4844 - val_recall_tumor: 0.5006 - val_tumor_iou: 0.3287 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 90 lên WandB.\n\n--- Epoch 91/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9816 - dice_coef_metric_tumor: 0.4808 - loss: 0.3197 - mean_iou_all: 0.4632 - precision_tumor: 0.4698 - recall_tumor: 0.5920 - tumor_iou: 0.3467\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9816 - dice_coef_metric_tumor: 0.4808 - loss: 0.3197 - mean_iou_all: 0.4632 - precision_tumor: 0.4698 - recall_tumor: 0.5920 - tumor_iou: 0.3467 - val_acc: 0.9810 - val_dice_coef_metric_tumor: 0.4123 - val_loss: 0.3880 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4222 - val_recall_tumor: 0.5200 - val_tumor_iou: 0.2850 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 91 lên WandB.\n\n--- Epoch 92/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9807 - dice_coef_metric_tumor: 0.4777 - loss: 0.3297 - mean_iou_all: 0.4568 - precision_tumor: 0.4563 - recall_tumor: 0.6025 - tumor_iou: 0.3426\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9807 - dice_coef_metric_tumor: 0.4776 - loss: 0.3297 - mean_iou_all: 0.4569 - precision_tumor: 0.4562 - recall_tumor: 0.6024 - tumor_iou: 0.3425 - val_acc: 0.9648 - val_dice_coef_metric_tumor: 0.3517 - val_loss: 0.4302 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.2697 - val_recall_tumor: 0.6798 - val_tumor_iou: 0.2325 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 92 lên WandB.\n\n--- Epoch 93/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9818 - dice_coef_metric_tumor: 0.4763 - loss: 0.3246 - mean_iou_all: 0.4546 - precision_tumor: 0.4586 - recall_tumor: 0.6063 - tumor_iou: 0.3400\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9818 - dice_coef_metric_tumor: 0.4763 - loss: 0.3246 - mean_iou_all: 0.4547 - precision_tumor: 0.4586 - recall_tumor: 0.6062 - tumor_iou: 0.3400 - val_acc: 0.9767 - val_dice_coef_metric_tumor: 0.4050 - val_loss: 0.3937 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3671 - val_recall_tumor: 0.5712 - val_tumor_iou: 0.2824 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 93 lên WandB.\n\n--- Epoch 94/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9819 - dice_coef_metric_tumor: 0.4777 - loss: 0.3199 - mean_iou_all: 0.4547 - precision_tumor: 0.4581 - recall_tumor: 0.5906 - tumor_iou: 0.3441\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9819 - dice_coef_metric_tumor: 0.4777 - loss: 0.3199 - mean_iou_all: 0.4547 - precision_tumor: 0.4581 - recall_tumor: 0.5906 - tumor_iou: 0.3440 - val_acc: 0.9847 - val_dice_coef_metric_tumor: 0.4564 - val_loss: 0.3601 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4868 - val_recall_tumor: 0.5183 - val_tumor_iou: 0.3254 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 94 lên WandB.\n\n--- Epoch 95/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9825 - dice_coef_metric_tumor: 0.4871 - loss: 0.3229 - mean_iou_all: 0.4453 - precision_tumor: 0.4759 - recall_tumor: 0.5874 - tumor_iou: 0.3498\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9825 - dice_coef_metric_tumor: 0.4871 - loss: 0.3228 - mean_iou_all: 0.4453 - precision_tumor: 0.4759 - recall_tumor: 0.5874 - tumor_iou: 0.3498 - val_acc: 0.9871 - val_dice_coef_metric_tumor: 0.4548 - val_loss: 0.3609 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6037 - val_recall_tumor: 0.4286 - val_tumor_iou: 0.3238 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 95 lên WandB.\n\n--- Epoch 96/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9823 - dice_coef_metric_tumor: 0.4939 - loss: 0.3181 - mean_iou_all: 0.4534 - precision_tumor: 0.4833 - recall_tumor: 0.5948 - tumor_iou: 0.3591\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9823 - dice_coef_metric_tumor: 0.4938 - loss: 0.3181 - mean_iou_all: 0.4534 - precision_tumor: 0.4833 - recall_tumor: 0.5947 - tumor_iou: 0.3590 - val_acc: 0.9858 - val_dice_coef_metric_tumor: 0.3752 - val_loss: 0.4100 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5207 - val_recall_tumor: 0.3626 - val_tumor_iou: 0.2609 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 96 lên WandB.\n\n--- Epoch 97/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9822 - dice_coef_metric_tumor: 0.4849 - loss: 0.3187 - mean_iou_all: 0.4572 - precision_tumor: 0.4792 - recall_tumor: 0.5864 - tumor_iou: 0.3519\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9822 - dice_coef_metric_tumor: 0.4848 - loss: 0.3187 - mean_iou_all: 0.4573 - precision_tumor: 0.4792 - recall_tumor: 0.5864 - tumor_iou: 0.3519 - val_acc: 0.9833 - val_dice_coef_metric_tumor: 0.4412 - val_loss: 0.3698 - val_mean_iou_all: 0.4352 - val_precision_tumor: 0.4333 - val_recall_tumor: 0.5391 - val_tumor_iou: 0.3109 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 97 lên WandB.\n\n--- Epoch 98/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9823 - dice_coef_metric_tumor: 0.4731 - loss: 0.3272 - mean_iou_all: 0.4590 - precision_tumor: 0.4674 - recall_tumor: 0.5765 - tumor_iou: 0.3370\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9823 - dice_coef_metric_tumor: 0.4731 - loss: 0.3272 - mean_iou_all: 0.4590 - precision_tumor: 0.4675 - recall_tumor: 0.5765 - tumor_iou: 0.3370 - val_acc: 0.9863 - val_dice_coef_metric_tumor: 0.4230 - val_loss: 0.3811 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5194 - val_recall_tumor: 0.4148 - val_tumor_iou: 0.3024 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 98 lên WandB.\n\n--- Epoch 99/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9820 - dice_coef_metric_tumor: 0.4788 - loss: 0.3242 - mean_iou_all: 0.4669 - precision_tumor: 0.4796 - recall_tumor: 0.5866 - tumor_iou: 0.3445\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9820 - dice_coef_metric_tumor: 0.4787 - loss: 0.3241 - mean_iou_all: 0.4670 - precision_tumor: 0.4796 - recall_tumor: 0.5866 - tumor_iou: 0.3445 - val_acc: 0.9786 - val_dice_coef_metric_tumor: 0.4233 - val_loss: 0.3824 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3778 - val_recall_tumor: 0.6086 - val_tumor_iou: 0.2933 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 99 lên WandB.\n\n--- Epoch 100/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9826 - dice_coef_metric_tumor: 0.4909 - loss: 0.3201 - mean_iou_all: 0.4589 - precision_tumor: 0.4794 - recall_tumor: 0.5959 - tumor_iou: 0.3530\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9826 - dice_coef_metric_tumor: 0.4909 - loss: 0.3201 - mean_iou_all: 0.4590 - precision_tumor: 0.4794 - recall_tumor: 0.5959 - tumor_iou: 0.3530 - val_acc: 0.9864 - val_dice_coef_metric_tumor: 0.4492 - val_loss: 0.3647 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5522 - val_recall_tumor: 0.4523 - val_tumor_iou: 0.3243 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 100 lên WandB.\n\n--- Epoch 101/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9817 - dice_coef_metric_tumor: 0.4853 - loss: 0.3282 - mean_iou_all: 0.4666 - precision_tumor: 0.4745 - recall_tumor: 0.5852 - tumor_iou: 0.3481\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9817 - dice_coef_metric_tumor: 0.4853 - loss: 0.3282 - mean_iou_all: 0.4667 - precision_tumor: 0.4745 - recall_tumor: 0.5852 - tumor_iou: 0.3481 - val_acc: 0.9865 - val_dice_coef_metric_tumor: 0.4335 - val_loss: 0.3752 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5539 - val_recall_tumor: 0.4238 - val_tumor_iou: 0.3051 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 101 lên WandB.\n\n--- Epoch 102/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.5034 - loss: 0.3089 - mean_iou_all: 0.4459 - precision_tumor: 0.4942 - recall_tumor: 0.5946 - tumor_iou: 0.3651\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.5033 - loss: 0.3089 - mean_iou_all: 0.4460 - precision_tumor: 0.4942 - recall_tumor: 0.5945 - tumor_iou: 0.3651 - val_acc: 0.9862 - val_dice_coef_metric_tumor: 0.4478 - val_loss: 0.3656 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5527 - val_recall_tumor: 0.4490 - val_tumor_iou: 0.3217 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 102 lên WandB.\n\n--- Epoch 103/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9833 - dice_coef_metric_tumor: 0.4995 - loss: 0.3190 - mean_iou_all: 0.4689 - precision_tumor: 0.5028 - recall_tumor: 0.5914 - tumor_iou: 0.3617\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9833 - dice_coef_metric_tumor: 0.4995 - loss: 0.3190 - mean_iou_all: 0.4689 - precision_tumor: 0.5027 - recall_tumor: 0.5914 - tumor_iou: 0.3616 - val_acc: 0.9833 - val_dice_coef_metric_tumor: 0.4376 - val_loss: 0.3732 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4530 - val_recall_tumor: 0.5077 - val_tumor_iou: 0.3052 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 103 lên WandB.\n\n--- Epoch 104/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9830 - dice_coef_metric_tumor: 0.4955 - loss: 0.3197 - mean_iou_all: 0.4592 - precision_tumor: 0.4943 - recall_tumor: 0.5760 - tumor_iou: 0.3610\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9830 - dice_coef_metric_tumor: 0.4955 - loss: 0.3197 - mean_iou_all: 0.4592 - precision_tumor: 0.4942 - recall_tumor: 0.5760 - tumor_iou: 0.3609 - val_acc: 0.9751 - val_dice_coef_metric_tumor: 0.4290 - val_loss: 0.3816 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3420 - val_recall_tumor: 0.7028 - val_tumor_iou: 0.3000 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 104 lên WandB.\n\n--- Epoch 105/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9846 - dice_coef_metric_tumor: 0.5233 - loss: 0.2991 - mean_iou_all: 0.4635 - precision_tumor: 0.5209 - recall_tumor: 0.6018 - tumor_iou: 0.3864\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9846 - dice_coef_metric_tumor: 0.5232 - loss: 0.2991 - mean_iou_all: 0.4635 - precision_tumor: 0.5208 - recall_tumor: 0.6018 - tumor_iou: 0.3863 - val_acc: 0.9863 - val_dice_coef_metric_tumor: 0.4566 - val_loss: 0.3607 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5255 - val_recall_tumor: 0.4760 - val_tumor_iou: 0.3280 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 105 lên WandB.\n\n--- Epoch 106/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.4989 - loss: 0.3199 - mean_iou_all: 0.4586 - precision_tumor: 0.4862 - recall_tumor: 0.5996 - tumor_iou: 0.3605\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.4989 - loss: 0.3199 - mean_iou_all: 0.4586 - precision_tumor: 0.4862 - recall_tumor: 0.5996 - tumor_iou: 0.3605 - val_acc: 0.9874 - val_dice_coef_metric_tumor: 0.3968 - val_loss: 0.3969 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6049 - val_recall_tumor: 0.3469 - val_tumor_iou: 0.2770 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 106 lên WandB.\n\n--- Epoch 107/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9829 - dice_coef_metric_tumor: 0.4909 - loss: 0.3188 - mean_iou_all: 0.4566 - precision_tumor: 0.4901 - recall_tumor: 0.5909 - tumor_iou: 0.3525\nEpoch 1: val_dice_coef_metric_tumor improved from 0.45765 to 0.45963, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9829 - dice_coef_metric_tumor: 0.4909 - loss: 0.3187 - mean_iou_all: 0.4566 - precision_tumor: 0.4901 - recall_tumor: 0.5909 - tumor_iou: 0.3524 - val_acc: 0.9836 - val_dice_coef_metric_tumor: 0.4596 - val_loss: 0.3600 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4820 - val_recall_tumor: 0.5322 - val_tumor_iou: 0.3317 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 107 lên WandB.\n\n--- Epoch 108/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9828 - dice_coef_metric_tumor: 0.4942 - loss: 0.3204 - mean_iou_all: 0.4694 - precision_tumor: 0.4900 - recall_tumor: 0.5865 - tumor_iou: 0.3569\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45963\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9828 - dice_coef_metric_tumor: 0.4942 - loss: 0.3204 - mean_iou_all: 0.4694 - precision_tumor: 0.4900 - recall_tumor: 0.5865 - tumor_iou: 0.3569 - val_acc: 0.9784 - val_dice_coef_metric_tumor: 0.4318 - val_loss: 0.3789 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3865 - val_recall_tumor: 0.6130 - val_tumor_iou: 0.3027 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 108 lên WandB.\n\n--- Epoch 109/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9841 - dice_coef_metric_tumor: 0.5209 - loss: 0.3036 - mean_iou_all: 0.4621 - precision_tumor: 0.5194 - recall_tumor: 0.6127 - tumor_iou: 0.3826\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45963\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9841 - dice_coef_metric_tumor: 0.5209 - loss: 0.3036 - mean_iou_all: 0.4621 - precision_tumor: 0.5193 - recall_tumor: 0.6126 - tumor_iou: 0.3826 - val_acc: 0.9874 - val_dice_coef_metric_tumor: 0.3764 - val_loss: 0.4105 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6635 - val_recall_tumor: 0.3101 - val_tumor_iou: 0.2612 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 109 lên WandB.\n\n--- Epoch 110/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9845 - dice_coef_metric_tumor: 0.5169 - loss: 0.3064 - mean_iou_all: 0.4692 - precision_tumor: 0.5192 - recall_tumor: 0.5938 - tumor_iou: 0.3775\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45963\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9845 - dice_coef_metric_tumor: 0.5169 - loss: 0.3063 - mean_iou_all: 0.4692 - precision_tumor: 0.5192 - recall_tumor: 0.5938 - tumor_iou: 0.3774 - val_acc: 0.9863 - val_dice_coef_metric_tumor: 0.4585 - val_loss: 0.3618 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5373 - val_recall_tumor: 0.4639 - val_tumor_iou: 0.3288 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 110 lên WandB.\n\n--- Epoch 111/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5298 - loss: 0.3022 - mean_iou_all: 0.4614 - precision_tumor: 0.5341 - recall_tumor: 0.6014 - tumor_iou: 0.3883\nEpoch 1: val_dice_coef_metric_tumor improved from 0.45963 to 0.48528, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5298 - loss: 0.3021 - mean_iou_all: 0.4614 - precision_tumor: 0.5340 - recall_tumor: 0.6014 - tumor_iou: 0.3883 - val_acc: 0.9844 - val_dice_coef_metric_tumor: 0.4853 - val_loss: 0.3449 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4662 - val_recall_tumor: 0.5971 - val_tumor_iou: 0.3489 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 111 lên WandB.\n\n--- Epoch 112/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5274 - loss: 0.2991 - mean_iou_all: 0.4621 - precision_tumor: 0.5287 - recall_tumor: 0.6122 - tumor_iou: 0.3867\nEpoch 1: val_dice_coef_metric_tumor improved from 0.48528 to 0.49971, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5274 - loss: 0.2991 - mean_iou_all: 0.4621 - precision_tumor: 0.5287 - recall_tumor: 0.6123 - tumor_iou: 0.3867 - val_acc: 0.9875 - val_dice_coef_metric_tumor: 0.4997 - val_loss: 0.3356 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5942 - val_recall_tumor: 0.4944 - val_tumor_iou: 0.3686 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 112 lên WandB.\n\n--- Epoch 113/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5283 - loss: 0.2921 - mean_iou_all: 0.4524 - precision_tumor: 0.5245 - recall_tumor: 0.6133 - tumor_iou: 0.3924\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.49971\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5283 - loss: 0.2921 - mean_iou_all: 0.4523 - precision_tumor: 0.5245 - recall_tumor: 0.6132 - tumor_iou: 0.3924 - val_acc: 0.9865 - val_dice_coef_metric_tumor: 0.4983 - val_loss: 0.3367 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5619 - val_recall_tumor: 0.5182 - val_tumor_iou: 0.3645 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 113 lên WandB.\n\n--- Epoch 114/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9844 - dice_coef_metric_tumor: 0.5331 - loss: 0.2949 - mean_iou_all: 0.4411 - precision_tumor: 0.5268 - recall_tumor: 0.6178 - tumor_iou: 0.3924\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.49971\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9844 - dice_coef_metric_tumor: 0.5331 - loss: 0.2949 - mean_iou_all: 0.4411 - precision_tumor: 0.5267 - recall_tumor: 0.6177 - tumor_iou: 0.3924 - val_acc: 0.9869 - val_dice_coef_metric_tumor: 0.4712 - val_loss: 0.3530 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5356 - val_recall_tumor: 0.4848 - val_tumor_iou: 0.3398 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 114 lên WandB.\n\n--- Epoch 115/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9855 - dice_coef_metric_tumor: 0.5436 - loss: 0.2981 - mean_iou_all: 0.4565 - precision_tumor: 0.5624 - recall_tumor: 0.6101 - tumor_iou: 0.4014\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.49971\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9855 - dice_coef_metric_tumor: 0.5436 - loss: 0.2981 - mean_iou_all: 0.4565 - precision_tumor: 0.5624 - recall_tumor: 0.6101 - tumor_iou: 0.4014 - val_acc: 0.9856 - val_dice_coef_metric_tumor: 0.4984 - val_loss: 0.3370 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5037 - val_recall_tumor: 0.5740 - val_tumor_iou: 0.3614 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 115 lên WandB.\n\n--- Epoch 116/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.5161 - loss: 0.3087 - mean_iou_all: 0.4563 - precision_tumor: 0.5079 - recall_tumor: 0.6266 - tumor_iou: 0.3772\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.49971\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.5160 - loss: 0.3087 - mean_iou_all: 0.4562 - precision_tumor: 0.5079 - recall_tumor: 0.6266 - tumor_iou: 0.3772 - val_acc: 0.9859 - val_dice_coef_metric_tumor: 0.4833 - val_loss: 0.3468 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5048 - val_recall_tumor: 0.5604 - val_tumor_iou: 0.3481 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 116 lên WandB.\n\n--- Epoch 117/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9848 - dice_coef_metric_tumor: 0.5392 - loss: 0.3021 - mean_iou_all: 0.4478 - precision_tumor: 0.5362 - recall_tumor: 0.6126 - tumor_iou: 0.3969\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.49971\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9848 - dice_coef_metric_tumor: 0.5392 - loss: 0.3021 - mean_iou_all: 0.4478 - precision_tumor: 0.5362 - recall_tumor: 0.6126 - tumor_iou: 0.3969 - val_acc: 0.9850 - val_dice_coef_metric_tumor: 0.4246 - val_loss: 0.3826 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5838 - val_recall_tumor: 0.4104 - val_tumor_iou: 0.3000 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 117 lên WandB.\n\n--- Epoch 118/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9844 - dice_coef_metric_tumor: 0.5271 - loss: 0.3004 - mean_iou_all: 0.4643 - precision_tumor: 0.5209 - recall_tumor: 0.6210 - tumor_iou: 0.3868\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.49971\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9844 - dice_coef_metric_tumor: 0.5270 - loss: 0.3004 - mean_iou_all: 0.4643 - precision_tumor: 0.5209 - recall_tumor: 0.6210 - tumor_iou: 0.3867 - val_acc: 0.9840 - val_dice_coef_metric_tumor: 0.4639 - val_loss: 0.3592 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4997 - val_recall_tumor: 0.5160 - val_tumor_iou: 0.3353 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 118 lên WandB.\n\n--- Epoch 119/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5366 - loss: 0.2916 - mean_iou_all: 0.4732 - precision_tumor: 0.5367 - recall_tumor: 0.6101 - tumor_iou: 0.3972\nEpoch 1: val_dice_coef_metric_tumor improved from 0.49971 to 0.51091, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5366 - loss: 0.2916 - mean_iou_all: 0.4732 - precision_tumor: 0.5366 - recall_tumor: 0.6101 - tumor_iou: 0.3972 - val_acc: 0.9846 - val_dice_coef_metric_tumor: 0.5109 - val_loss: 0.3303 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4850 - val_recall_tumor: 0.6205 - val_tumor_iou: 0.3755 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 119 lên WandB.\n\n--- Epoch 120/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9852 - dice_coef_metric_tumor: 0.5434 - loss: 0.2943 - mean_iou_all: 0.4316 - precision_tumor: 0.5430 - recall_tumor: 0.6140 - tumor_iou: 0.4044\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51091\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9852 - dice_coef_metric_tumor: 0.5433 - loss: 0.2944 - mean_iou_all: 0.4316 - precision_tumor: 0.5429 - recall_tumor: 0.6139 - tumor_iou: 0.4043 - val_acc: 0.9863 - val_dice_coef_metric_tumor: 0.4331 - val_loss: 0.3778 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6248 - val_recall_tumor: 0.3921 - val_tumor_iou: 0.3045 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 120 lên WandB.\n\n--- Epoch 121/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9840 - dice_coef_metric_tumor: 0.5184 - loss: 0.3059 - mean_iou_all: 0.4728 - precision_tumor: 0.5209 - recall_tumor: 0.6019 - tumor_iou: 0.3813\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51091\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9840 - dice_coef_metric_tumor: 0.5183 - loss: 0.3059 - mean_iou_all: 0.4727 - precision_tumor: 0.5209 - recall_tumor: 0.6020 - tumor_iou: 0.3813 - val_acc: 0.9831 - val_dice_coef_metric_tumor: 0.4865 - val_loss: 0.3458 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4549 - val_recall_tumor: 0.6231 - val_tumor_iou: 0.3535 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 121 lên WandB.\n\n--- Epoch 122/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5397 - loss: 0.2972 - mean_iou_all: 0.4543 - precision_tumor: 0.5365 - recall_tumor: 0.6144 - tumor_iou: 0.3984\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51091\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5396 - loss: 0.2972 - mean_iou_all: 0.4543 - precision_tumor: 0.5364 - recall_tumor: 0.6143 - tumor_iou: 0.3984 - val_acc: 0.9833 - val_dice_coef_metric_tumor: 0.4806 - val_loss: 0.3498 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4467 - val_recall_tumor: 0.6003 - val_tumor_iou: 0.3496 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 122 lên WandB.\n\n--- Epoch 123/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5239 - loss: 0.3009 - mean_iou_all: 0.4587 - precision_tumor: 0.5324 - recall_tumor: 0.6013 - tumor_iou: 0.3821\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51091\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5239 - loss: 0.3008 - mean_iou_all: 0.4587 - precision_tumor: 0.5325 - recall_tumor: 0.6013 - tumor_iou: 0.3821 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.4808 - val_loss: 0.3487 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5991 - val_recall_tumor: 0.4683 - val_tumor_iou: 0.3494 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 123 lên WandB.\n\n--- Epoch 124/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5612 - loss: 0.2807 - mean_iou_all: 0.4442 - precision_tumor: 0.5637 - recall_tumor: 0.6306 - tumor_iou: 0.4171\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51091\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5611 - loss: 0.2808 - mean_iou_all: 0.4442 - precision_tumor: 0.5636 - recall_tumor: 0.6306 - tumor_iou: 0.4170 - val_acc: 0.9847 - val_dice_coef_metric_tumor: 0.4650 - val_loss: 0.3587 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4721 - val_recall_tumor: 0.5341 - val_tumor_iou: 0.3327 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 124 lên WandB.\n\n--- Epoch 125/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5485 - loss: 0.2864 - mean_iou_all: 0.4623 - precision_tumor: 0.5368 - recall_tumor: 0.6491 - tumor_iou: 0.4073\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51091\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5484 - loss: 0.2864 - mean_iou_all: 0.4622 - precision_tumor: 0.5368 - recall_tumor: 0.6491 - tumor_iou: 0.4073 - val_acc: 0.9874 - val_dice_coef_metric_tumor: 0.4914 - val_loss: 0.3420 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5930 - val_recall_tumor: 0.4894 - val_tumor_iou: 0.3589 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 125 lên WandB.\n\n--- Epoch 126/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5478 - loss: 0.2837 - mean_iou_all: 0.4540 - precision_tumor: 0.5419 - recall_tumor: 0.6286 - tumor_iou: 0.4089\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51091\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5477 - loss: 0.2837 - mean_iou_all: 0.4540 - precision_tumor: 0.5419 - recall_tumor: 0.6285 - tumor_iou: 0.4088 - val_acc: 0.9870 - val_dice_coef_metric_tumor: 0.4821 - val_loss: 0.3478 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5805 - val_recall_tumor: 0.4812 - val_tumor_iou: 0.3466 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 126 lên WandB.\n\n--- Epoch 127/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9855 - dice_coef_metric_tumor: 0.5544 - loss: 0.2834 - mean_iou_all: 0.4573 - precision_tumor: 0.5428 - recall_tumor: 0.6459 - tumor_iou: 0.4132\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51091\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9855 - dice_coef_metric_tumor: 0.5544 - loss: 0.2834 - mean_iou_all: 0.4573 - precision_tumor: 0.5427 - recall_tumor: 0.6459 - tumor_iou: 0.4131 - val_acc: 0.9810 - val_dice_coef_metric_tumor: 0.4759 - val_loss: 0.3534 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4022 - val_recall_tumor: 0.7093 - val_tumor_iou: 0.3420 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 127 lên WandB.\n\n--- Epoch 128/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5421 - loss: 0.2895 - mean_iou_all: 0.4353 - precision_tumor: 0.5370 - recall_tumor: 0.6328 - tumor_iou: 0.4020\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51091\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5420 - loss: 0.2895 - mean_iou_all: 0.4353 - precision_tumor: 0.5370 - recall_tumor: 0.6328 - tumor_iou: 0.4020 - val_acc: 0.9870 - val_dice_coef_metric_tumor: 0.5041 - val_loss: 0.3347 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5660 - val_recall_tumor: 0.5253 - val_tumor_iou: 0.3665 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 128 lên WandB.\n\n--- Epoch 129/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5559 - loss: 0.2884 - mean_iou_all: 0.4637 - precision_tumor: 0.5538 - recall_tumor: 0.6404 - tumor_iou: 0.4133\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51091\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5558 - loss: 0.2884 - mean_iou_all: 0.4636 - precision_tumor: 0.5538 - recall_tumor: 0.6403 - tumor_iou: 0.4133 - val_acc: 0.9878 - val_dice_coef_metric_tumor: 0.4448 - val_loss: 0.3711 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6530 - val_recall_tumor: 0.3933 - val_tumor_iou: 0.3165 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 129 lên WandB.\n\n--- Epoch 130/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5491 - loss: 0.2878 - mean_iou_all: 0.4527 - precision_tumor: 0.5492 - recall_tumor: 0.6200 - tumor_iou: 0.4090\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51091\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5491 - loss: 0.2878 - mean_iou_all: 0.4526 - precision_tumor: 0.5492 - recall_tumor: 0.6200 - tumor_iou: 0.4089 - val_acc: 0.9853 - val_dice_coef_metric_tumor: 0.5021 - val_loss: 0.3366 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4868 - val_recall_tumor: 0.6034 - val_tumor_iou: 0.3687 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 130 lên WandB.\n\n--- Epoch 131/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5569 - loss: 0.2847 - mean_iou_all: 0.4549 - precision_tumor: 0.5636 - recall_tumor: 0.6276 - tumor_iou: 0.4144\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51091\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5569 - loss: 0.2847 - mean_iou_all: 0.4549 - precision_tumor: 0.5635 - recall_tumor: 0.6275 - tumor_iou: 0.4144 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.5061 - val_loss: 0.3342 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6063 - val_recall_tumor: 0.5014 - val_tumor_iou: 0.3743 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 131 lên WandB.\n\n--- Epoch 132/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5478 - loss: 0.2900 - mean_iou_all: 0.4424 - precision_tumor: 0.5516 - recall_tumor: 0.6261 - tumor_iou: 0.4058\nEpoch 1: val_dice_coef_metric_tumor improved from 0.51091 to 0.51111, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5477 - loss: 0.2900 - mean_iou_all: 0.4423 - precision_tumor: 0.5515 - recall_tumor: 0.6261 - tumor_iou: 0.4058 - val_acc: 0.9879 - val_dice_coef_metric_tumor: 0.5111 - val_loss: 0.3310 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5909 - val_recall_tumor: 0.5128 - val_tumor_iou: 0.3765 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 132 lên WandB.\n\n--- Epoch 133/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9865 - dice_coef_metric_tumor: 0.5658 - loss: 0.2822 - mean_iou_all: 0.4441 - precision_tumor: 0.5691 - recall_tumor: 0.6259 - tumor_iou: 0.4246\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51111\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9865 - dice_coef_metric_tumor: 0.5657 - loss: 0.2823 - mean_iou_all: 0.4440 - precision_tumor: 0.5691 - recall_tumor: 0.6258 - tumor_iou: 0.4245 - val_acc: 0.9879 - val_dice_coef_metric_tumor: 0.3840 - val_loss: 0.4079 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7048 - val_recall_tumor: 0.3052 - val_tumor_iou: 0.2670 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 133 lên WandB.\n\n--- Epoch 134/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5570 - loss: 0.2861 - mean_iou_all: 0.4690 - precision_tumor: 0.5679 - recall_tumor: 0.6188 - tumor_iou: 0.4168\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51111\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5570 - loss: 0.2861 - mean_iou_all: 0.4689 - precision_tumor: 0.5679 - recall_tumor: 0.6187 - tumor_iou: 0.4168 - val_acc: 0.9835 - val_dice_coef_metric_tumor: 0.4963 - val_loss: 0.3418 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5186 - val_recall_tumor: 0.5744 - val_tumor_iou: 0.3611 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 134 lên WandB.\n\n--- Epoch 135/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5521 - loss: 0.2877 - mean_iou_all: 0.4611 - precision_tumor: 0.5498 - recall_tumor: 0.6332 - tumor_iou: 0.4106\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51111\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9857 - dice_coef_metric_tumor: 0.5521 - loss: 0.2877 - mean_iou_all: 0.4611 - precision_tumor: 0.5498 - recall_tumor: 0.6331 - tumor_iou: 0.4105 - val_acc: 0.9820 - val_dice_coef_metric_tumor: 0.4662 - val_loss: 0.3600 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4336 - val_recall_tumor: 0.6064 - val_tumor_iou: 0.3350 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 135 lên WandB.\n\n--- Epoch 136/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5633 - loss: 0.2849 - mean_iou_all: 0.4687 - precision_tumor: 0.5579 - recall_tumor: 0.6335 - tumor_iou: 0.4219\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51111\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5632 - loss: 0.2849 - mean_iou_all: 0.4686 - precision_tumor: 0.5579 - recall_tumor: 0.6335 - tumor_iou: 0.4218 - val_acc: 0.9879 - val_dice_coef_metric_tumor: 0.4926 - val_loss: 0.3430 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5942 - val_recall_tumor: 0.4755 - val_tumor_iou: 0.3608 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 136 lên WandB.\n\n--- Epoch 137/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5632 - loss: 0.2787 - mean_iou_all: 0.4559 - precision_tumor: 0.5697 - recall_tumor: 0.6361 - tumor_iou: 0.4232\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51111\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5631 - loss: 0.2787 - mean_iou_all: 0.4558 - precision_tumor: 0.5697 - recall_tumor: 0.6361 - tumor_iou: 0.4231 - val_acc: 0.9818 - val_dice_coef_metric_tumor: 0.4798 - val_loss: 0.3525 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4361 - val_recall_tumor: 0.6388 - val_tumor_iou: 0.3479 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 137 lên WandB.\n\n--- Epoch 138/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5621 - loss: 0.2837 - mean_iou_all: 0.4539 - precision_tumor: 0.5608 - recall_tumor: 0.6415 - tumor_iou: 0.4223\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51111\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5620 - loss: 0.2837 - mean_iou_all: 0.4538 - precision_tumor: 0.5608 - recall_tumor: 0.6415 - tumor_iou: 0.4223 - val_acc: 0.9840 - val_dice_coef_metric_tumor: 0.5048 - val_loss: 0.3365 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4592 - val_recall_tumor: 0.6477 - val_tumor_iou: 0.3712 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 138 lên WandB.\n\n--- Epoch 139/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9849 - dice_coef_metric_tumor: 0.5468 - loss: 0.2933 - mean_iou_all: 0.4743 - precision_tumor: 0.5352 - recall_tumor: 0.6248 - tumor_iou: 0.4091\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51111\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9849 - dice_coef_metric_tumor: 0.5468 - loss: 0.2933 - mean_iou_all: 0.4742 - precision_tumor: 0.5352 - recall_tumor: 0.6247 - tumor_iou: 0.4091 - val_acc: 0.9880 - val_dice_coef_metric_tumor: 0.4991 - val_loss: 0.3390 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5970 - val_recall_tumor: 0.4830 - val_tumor_iou: 0.3623 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 139 lên WandB.\n\n--- Epoch 140/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5562 - loss: 0.2849 - mean_iou_all: 0.4671 - precision_tumor: 0.5634 - recall_tumor: 0.6168 - tumor_iou: 0.4118\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51111\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5561 - loss: 0.2849 - mean_iou_all: 0.4671 - precision_tumor: 0.5633 - recall_tumor: 0.6168 - tumor_iou: 0.4117 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.4686 - val_loss: 0.3572 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6683 - val_recall_tumor: 0.4160 - val_tumor_iou: 0.3384 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 140 lên WandB.\n\n--- Epoch 141/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5682 - loss: 0.2755 - mean_iou_all: 0.4673 - precision_tumor: 0.5633 - recall_tumor: 0.6486 - tumor_iou: 0.4283\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51111\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5681 - loss: 0.2755 - mean_iou_all: 0.4673 - precision_tumor: 0.5632 - recall_tumor: 0.6485 - tumor_iou: 0.4282 - val_acc: 0.9860 - val_dice_coef_metric_tumor: 0.5054 - val_loss: 0.3359 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5631 - val_recall_tumor: 0.5371 - val_tumor_iou: 0.3700 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 141 lên WandB.\n\n--- Epoch 142/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5625 - loss: 0.2769 - mean_iou_all: 0.4567 - precision_tumor: 0.5614 - recall_tumor: 0.6488 - tumor_iou: 0.4258\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51111\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5625 - loss: 0.2769 - mean_iou_all: 0.4566 - precision_tumor: 0.5614 - recall_tumor: 0.6487 - tumor_iou: 0.4257 - val_acc: 0.9830 - val_dice_coef_metric_tumor: 0.4891 - val_loss: 0.3472 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5056 - val_recall_tumor: 0.5709 - val_tumor_iou: 0.3556 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 142 lên WandB.\n\n--- Epoch 143/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5832 - loss: 0.2686 - mean_iou_all: 0.4373 - precision_tumor: 0.5871 - recall_tumor: 0.6485 - tumor_iou: 0.4402\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51111\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5831 - loss: 0.2686 - mean_iou_all: 0.4372 - precision_tumor: 0.5870 - recall_tumor: 0.6485 - tumor_iou: 0.4402 - val_acc: 0.9763 - val_dice_coef_metric_tumor: 0.4590 - val_loss: 0.3675 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3762 - val_recall_tumor: 0.7161 - val_tumor_iou: 0.3287 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 143 lên WandB.\n\n--- Epoch 144/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5626 - loss: 0.2864 - mean_iou_all: 0.4588 - precision_tumor: 0.5600 - recall_tumor: 0.6491 - tumor_iou: 0.4198\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51111\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5626 - loss: 0.2864 - mean_iou_all: 0.4587 - precision_tumor: 0.5600 - recall_tumor: 0.6491 - tumor_iou: 0.4198 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.4651 - val_loss: 0.3603 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6648 - val_recall_tumor: 0.4032 - val_tumor_iou: 0.3308 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 144 lên WandB.\n\n--- Epoch 145/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5799 - loss: 0.2765 - mean_iou_all: 0.4549 - precision_tumor: 0.5909 - recall_tumor: 0.6486 - tumor_iou: 0.4360\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51111\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5799 - loss: 0.2765 - mean_iou_all: 0.4548 - precision_tumor: 0.5909 - recall_tumor: 0.6486 - tumor_iou: 0.4359 - val_acc: 0.9839 - val_dice_coef_metric_tumor: 0.5049 - val_loss: 0.3372 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4558 - val_recall_tumor: 0.6514 - val_tumor_iou: 0.3692 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 145 lên WandB.\n\n--- Epoch 146/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5695 - loss: 0.2804 - mean_iou_all: 0.4470 - precision_tumor: 0.5643 - recall_tumor: 0.6551 - tumor_iou: 0.4268\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51111\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 463ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5694 - loss: 0.2804 - mean_iou_all: 0.4469 - precision_tumor: 0.5643 - recall_tumor: 0.6551 - tumor_iou: 0.4268 - val_acc: 0.9797 - val_dice_coef_metric_tumor: 0.4541 - val_loss: 0.3700 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4486 - val_recall_tumor: 0.5624 - val_tumor_iou: 0.3276 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 146 lên WandB.\n\n--- Epoch 147/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9846 - dice_coef_metric_tumor: 0.5510 - loss: 0.2877 - mean_iou_all: 0.4584 - precision_tumor: 0.5370 - recall_tumor: 0.6391 - tumor_iou: 0.4115\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51111\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9846 - dice_coef_metric_tumor: 0.5510 - loss: 0.2877 - mean_iou_all: 0.4583 - precision_tumor: 0.5370 - recall_tumor: 0.6391 - tumor_iou: 0.4115 - val_acc: 0.9877 - val_dice_coef_metric_tumor: 0.4669 - val_loss: 0.3596 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6088 - val_recall_tumor: 0.4419 - val_tumor_iou: 0.3400 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 147 lên WandB.\n\n--- Epoch 148/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5755 - loss: 0.2743 - mean_iou_all: 0.4706 - precision_tumor: 0.5680 - recall_tumor: 0.6604 - tumor_iou: 0.4339\nEpoch 1: val_dice_coef_metric_tumor improved from 0.51111 to 0.53546, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5754 - loss: 0.2743 - mean_iou_all: 0.4705 - precision_tumor: 0.5680 - recall_tumor: 0.6604 - tumor_iou: 0.4339 - val_acc: 0.9868 - val_dice_coef_metric_tumor: 0.5355 - val_loss: 0.3183 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5301 - val_recall_tumor: 0.6068 - val_tumor_iou: 0.3981 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 148 lên WandB.\n\n--- Epoch 149/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5638 - loss: 0.2832 - mean_iou_all: 0.4558 - precision_tumor: 0.5749 - recall_tumor: 0.6274 - tumor_iou: 0.4223\nEpoch 1: val_dice_coef_metric_tumor improved from 0.53546 to 0.54027, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5638 - loss: 0.2832 - mean_iou_all: 0.4557 - precision_tumor: 0.5749 - recall_tumor: 0.6274 - tumor_iou: 0.4223 - val_acc: 0.9881 - val_dice_coef_metric_tumor: 0.5403 - val_loss: 0.3149 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5832 - val_recall_tumor: 0.5659 - val_tumor_iou: 0.4057 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 149 lên WandB.\n\n--- Epoch 150/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5643 - loss: 0.2845 - mean_iou_all: 0.4696 - precision_tumor: 0.5578 - recall_tumor: 0.6522 - tumor_iou: 0.4228\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54027\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5643 - loss: 0.2845 - mean_iou_all: 0.4695 - precision_tumor: 0.5578 - recall_tumor: 0.6521 - tumor_iou: 0.4228 - val_acc: 0.9879 - val_dice_coef_metric_tumor: 0.5194 - val_loss: 0.3275 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6021 - val_recall_tumor: 0.5251 - val_tumor_iou: 0.3863 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 150 lên WandB.\n\n--- Epoch 151/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5482 - loss: 0.2924 - mean_iou_all: 0.4652 - precision_tumor: 0.5410 - recall_tumor: 0.6314 - tumor_iou: 0.4062\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54027\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5482 - loss: 0.2923 - mean_iou_all: 0.4651 - precision_tumor: 0.5411 - recall_tumor: 0.6314 - tumor_iou: 0.4062 - val_acc: 0.9858 - val_dice_coef_metric_tumor: 0.5052 - val_loss: 0.3370 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5146 - val_recall_tumor: 0.5820 - val_tumor_iou: 0.3678 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 151 lên WandB.\n\n--- Epoch 152/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5499 - loss: 0.2848 - mean_iou_all: 0.4417 - precision_tumor: 0.5447 - recall_tumor: 0.6375 - tumor_iou: 0.4115\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54027\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5499 - loss: 0.2848 - mean_iou_all: 0.4415 - precision_tumor: 0.5447 - recall_tumor: 0.6375 - tumor_iou: 0.4115 - val_acc: 0.9873 - val_dice_coef_metric_tumor: 0.5229 - val_loss: 0.3256 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5178 - val_recall_tumor: 0.5951 - val_tumor_iou: 0.3894 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 152 lên WandB.\n\n--- Epoch 153/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.5862 - loss: 0.2665 - mean_iou_all: 0.4448 - precision_tumor: 0.5853 - recall_tumor: 0.6575 - tumor_iou: 0.4465\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54027\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.5861 - loss: 0.2665 - mean_iou_all: 0.4448 - precision_tumor: 0.5852 - recall_tumor: 0.6574 - tumor_iou: 0.4465 - val_acc: 0.9882 - val_dice_coef_metric_tumor: 0.5127 - val_loss: 0.3321 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6011 - val_recall_tumor: 0.5051 - val_tumor_iou: 0.3779 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 153 lên WandB.\n\n--- Epoch 154/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9857 - dice_coef_metric_tumor: 0.5653 - loss: 0.2828 - mean_iou_all: 0.4470 - precision_tumor: 0.5694 - recall_tumor: 0.6432 - tumor_iou: 0.4254\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54027\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9857 - dice_coef_metric_tumor: 0.5653 - loss: 0.2828 - mean_iou_all: 0.4468 - precision_tumor: 0.5694 - recall_tumor: 0.6431 - tumor_iou: 0.4254 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.4873 - val_loss: 0.3475 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6425 - val_recall_tumor: 0.4374 - val_tumor_iou: 0.3565 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 154 lên WandB.\n\n--- Epoch 155/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5738 - loss: 0.2781 - mean_iou_all: 0.4172 - precision_tumor: 0.5796 - recall_tumor: 0.6358 - tumor_iou: 0.4318\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54027\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5738 - loss: 0.2781 - mean_iou_all: 0.4170 - precision_tumor: 0.5796 - recall_tumor: 0.6358 - tumor_iou: 0.4318 - val_acc: 0.9880 - val_dice_coef_metric_tumor: 0.4888 - val_loss: 0.3468 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6075 - val_recall_tumor: 0.4562 - val_tumor_iou: 0.3539 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 155 lên WandB.\n\n--- Epoch 156/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5749 - loss: 0.2757 - mean_iou_all: 0.4441 - precision_tumor: 0.5767 - recall_tumor: 0.6511 - tumor_iou: 0.4338\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54027\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5749 - loss: 0.2757 - mean_iou_all: 0.4439 - precision_tumor: 0.5767 - recall_tumor: 0.6511 - tumor_iou: 0.4338 - val_acc: 0.9861 - val_dice_coef_metric_tumor: 0.5110 - val_loss: 0.3335 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5008 - val_recall_tumor: 0.5955 - val_tumor_iou: 0.3771 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 156 lên WandB.\n\n--- Epoch 157/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5754 - loss: 0.2778 - mean_iou_all: 0.4485 - precision_tumor: 0.5805 - recall_tumor: 0.6395 - tumor_iou: 0.4321\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54027\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5753 - loss: 0.2778 - mean_iou_all: 0.4484 - precision_tumor: 0.5804 - recall_tumor: 0.6394 - tumor_iou: 0.4321 - val_acc: 0.9862 - val_dice_coef_metric_tumor: 0.5334 - val_loss: 0.3201 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5164 - val_recall_tumor: 0.6193 - val_tumor_iou: 0.3944 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 157 lên WandB.\n\n--- Epoch 158/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5836 - loss: 0.2763 - mean_iou_all: 0.4503 - precision_tumor: 0.5850 - recall_tumor: 0.6456 - tumor_iou: 0.4378\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54027\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5836 - loss: 0.2763 - mean_iou_all: 0.4502 - precision_tumor: 0.5850 - recall_tumor: 0.6455 - tumor_iou: 0.4377 - val_acc: 0.9878 - val_dice_coef_metric_tumor: 0.5359 - val_loss: 0.3184 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5468 - val_recall_tumor: 0.5842 - val_tumor_iou: 0.3988 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 158 lên WandB.\n\n--- Epoch 159/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5722 - loss: 0.2754 - mean_iou_all: 0.4364 - precision_tumor: 0.5694 - recall_tumor: 0.6599 - tumor_iou: 0.4333\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54027\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5722 - loss: 0.2754 - mean_iou_all: 0.4363 - precision_tumor: 0.5693 - recall_tumor: 0.6598 - tumor_iou: 0.4333 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5051 - val_loss: 0.3371 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6243 - val_recall_tumor: 0.4764 - val_tumor_iou: 0.3676 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 159 lên WandB.\n\n--- Epoch 160/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.5658 - loss: 0.2790 - mean_iou_all: 0.4513 - precision_tumor: 0.5640 - recall_tumor: 0.6375 - tumor_iou: 0.4247\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54027\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5658 - loss: 0.2789 - mean_iou_all: 0.4513 - precision_tumor: 0.5640 - recall_tumor: 0.6374 - tumor_iou: 0.4247 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.4979 - val_loss: 0.3418 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6169 - val_recall_tumor: 0.4771 - val_tumor_iou: 0.3679 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 160 lên WandB.\n\n--- Epoch 161/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5505 - loss: 0.2834 - mean_iou_all: 0.4709 - precision_tumor: 0.5415 - recall_tumor: 0.6441 - tumor_iou: 0.4151\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54027\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5505 - loss: 0.2834 - mean_iou_all: 0.4708 - precision_tumor: 0.5415 - recall_tumor: 0.6441 - tumor_iou: 0.4151 - val_acc: 0.9851 - val_dice_coef_metric_tumor: 0.5328 - val_loss: 0.3212 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4901 - val_recall_tumor: 0.6759 - val_tumor_iou: 0.3947 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 161 lên WandB.\n\n--- Epoch 162/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5737 - loss: 0.2733 - mean_iou_all: 0.4638 - precision_tumor: 0.5760 - recall_tumor: 0.6397 - tumor_iou: 0.4358\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54027\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5736 - loss: 0.2733 - mean_iou_all: 0.4638 - precision_tumor: 0.5760 - recall_tumor: 0.6396 - tumor_iou: 0.4358 - val_acc: 0.9855 - val_dice_coef_metric_tumor: 0.5068 - val_loss: 0.3376 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4755 - val_recall_tumor: 0.6389 - val_tumor_iou: 0.3677 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 162 lên WandB.\n\n--- Epoch 163/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5690 - loss: 0.2764 - mean_iou_all: 0.4621 - precision_tumor: 0.5583 - recall_tumor: 0.6658 - tumor_iou: 0.4285\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54027\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5690 - loss: 0.2764 - mean_iou_all: 0.4620 - precision_tumor: 0.5583 - recall_tumor: 0.6658 - tumor_iou: 0.4285 - val_acc: 0.9848 - val_dice_coef_metric_tumor: 0.5216 - val_loss: 0.3288 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5434 - val_recall_tumor: 0.5801 - val_tumor_iou: 0.3865 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 163 lên WandB.\n\n--- Epoch 164/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5809 - loss: 0.2730 - mean_iou_all: 0.4620 - precision_tumor: 0.5891 - recall_tumor: 0.6464 - tumor_iou: 0.4404\nEpoch 1: val_dice_coef_metric_tumor improved from 0.54027 to 0.55241, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5809 - loss: 0.2730 - mean_iou_all: 0.4619 - precision_tumor: 0.5890 - recall_tumor: 0.6464 - tumor_iou: 0.4404 - val_acc: 0.9895 - val_dice_coef_metric_tumor: 0.5524 - val_loss: 0.3091 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6345 - val_recall_tumor: 0.5382 - val_tumor_iou: 0.4166 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 164 lên WandB.\n\n--- Epoch 165/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5750 - loss: 0.2764 - mean_iou_all: 0.4674 - precision_tumor: 0.5796 - recall_tumor: 0.6433 - tumor_iou: 0.4343\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5749 - loss: 0.2764 - mean_iou_all: 0.4673 - precision_tumor: 0.5795 - recall_tumor: 0.6433 - tumor_iou: 0.4343 - val_acc: 0.9872 - val_dice_coef_metric_tumor: 0.5169 - val_loss: 0.3307 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5545 - val_recall_tumor: 0.5649 - val_tumor_iou: 0.3792 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 165 lên WandB.\n\n--- Epoch 166/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5777 - loss: 0.2787 - mean_iou_all: 0.4767 - precision_tumor: 0.5894 - recall_tumor: 0.6355 - tumor_iou: 0.4346\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5777 - loss: 0.2787 - mean_iou_all: 0.4766 - precision_tumor: 0.5894 - recall_tumor: 0.6355 - tumor_iou: 0.4346 - val_acc: 0.9878 - val_dice_coef_metric_tumor: 0.5321 - val_loss: 0.3214 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5675 - val_recall_tumor: 0.5750 - val_tumor_iou: 0.3961 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 166 lên WandB.\n\n--- Epoch 167/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.5852 - loss: 0.2735 - mean_iou_all: 0.4699 - precision_tumor: 0.5890 - recall_tumor: 0.6416 - tumor_iou: 0.4436\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.5852 - loss: 0.2735 - mean_iou_all: 0.4699 - precision_tumor: 0.5890 - recall_tumor: 0.6416 - tumor_iou: 0.4436 - val_acc: 0.9877 - val_dice_coef_metric_tumor: 0.5111 - val_loss: 0.3347 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5860 - val_recall_tumor: 0.5115 - val_tumor_iou: 0.3749 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 167 lên WandB.\n\n--- Epoch 168/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5681 - loss: 0.2808 - mean_iou_all: 0.4483 - precision_tumor: 0.5652 - recall_tumor: 0.6563 - tumor_iou: 0.4288\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5681 - loss: 0.2808 - mean_iou_all: 0.4482 - precision_tumor: 0.5652 - recall_tumor: 0.6563 - tumor_iou: 0.4288 - val_acc: 0.9880 - val_dice_coef_metric_tumor: 0.4993 - val_loss: 0.3417 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6317 - val_recall_tumor: 0.4834 - val_tumor_iou: 0.3685 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 168 lên WandB.\n\n--- Epoch 169/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5812 - loss: 0.2683 - mean_iou_all: 0.4555 - precision_tumor: 0.5774 - recall_tumor: 0.6722 - tumor_iou: 0.4405\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5812 - loss: 0.2683 - mean_iou_all: 0.4554 - precision_tumor: 0.5774 - recall_tumor: 0.6721 - tumor_iou: 0.4404 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.5484 - val_loss: 0.3115 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6434 - val_recall_tumor: 0.5237 - val_tumor_iou: 0.4113 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 169 lên WandB.\n\n--- Epoch 170/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9865 - dice_coef_metric_tumor: 0.5852 - loss: 0.2754 - mean_iou_all: 0.4603 - precision_tumor: 0.5773 - recall_tumor: 0.6612 - tumor_iou: 0.4413\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9865 - dice_coef_metric_tumor: 0.5852 - loss: 0.2754 - mean_iou_all: 0.4602 - precision_tumor: 0.5773 - recall_tumor: 0.6612 - tumor_iou: 0.4413 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.5173 - val_loss: 0.3305 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6963 - val_recall_tumor: 0.4623 - val_tumor_iou: 0.3849 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 170 lên WandB.\n\n--- Epoch 171/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.5853 - loss: 0.2669 - mean_iou_all: 0.4469 - precision_tumor: 0.5877 - recall_tumor: 0.6527 - tumor_iou: 0.4448\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.5852 - loss: 0.2669 - mean_iou_all: 0.4468 - precision_tumor: 0.5877 - recall_tumor: 0.6527 - tumor_iou: 0.4448 - val_acc: 0.9877 - val_dice_coef_metric_tumor: 0.5251 - val_loss: 0.3264 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5849 - val_recall_tumor: 0.5423 - val_tumor_iou: 0.3866 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 171 lên WandB.\n\n--- Epoch 172/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.5912 - loss: 0.2664 - mean_iou_all: 0.4334 - precision_tumor: 0.5972 - recall_tumor: 0.6514 - tumor_iou: 0.4489\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.5912 - loss: 0.2664 - mean_iou_all: 0.4333 - precision_tumor: 0.5972 - recall_tumor: 0.6514 - tumor_iou: 0.4489 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.4945 - val_loss: 0.3450 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6982 - val_recall_tumor: 0.4305 - val_tumor_iou: 0.3640 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 172 lên WandB.\n\n--- Epoch 173/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.5922 - loss: 0.2707 - mean_iou_all: 0.4339 - precision_tumor: 0.6087 - recall_tumor: 0.6418 - tumor_iou: 0.4472\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.5921 - loss: 0.2707 - mean_iou_all: 0.4338 - precision_tumor: 0.6086 - recall_tumor: 0.6418 - tumor_iou: 0.4472 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.5479 - val_loss: 0.3125 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5801 - val_recall_tumor: 0.5824 - val_tumor_iou: 0.4120 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 173 lên WandB.\n\n--- Epoch 174/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.5997 - loss: 0.2682 - mean_iou_all: 0.4533 - precision_tumor: 0.6192 - recall_tumor: 0.6439 - tumor_iou: 0.4558\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.5997 - loss: 0.2682 - mean_iou_all: 0.4531 - precision_tumor: 0.6192 - recall_tumor: 0.6439 - tumor_iou: 0.4558 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5134 - val_loss: 0.3333 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6288 - val_recall_tumor: 0.4860 - val_tumor_iou: 0.3795 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 174 lên WandB.\n\n--- Epoch 175/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.5990 - loss: 0.2686 - mean_iou_all: 0.4467 - precision_tumor: 0.6165 - recall_tumor: 0.6504 - tumor_iou: 0.4561\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.5990 - loss: 0.2686 - mean_iou_all: 0.4466 - precision_tumor: 0.6165 - recall_tumor: 0.6504 - tumor_iou: 0.4561 - val_acc: 0.9858 - val_dice_coef_metric_tumor: 0.5147 - val_loss: 0.3332 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5049 - val_recall_tumor: 0.6041 - val_tumor_iou: 0.3783 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 175 lên WandB.\n\n--- Epoch 176/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5958 - loss: 0.2694 - mean_iou_all: 0.4502 - precision_tumor: 0.5945 - recall_tumor: 0.6537 - tumor_iou: 0.4541\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5958 - loss: 0.2694 - mean_iou_all: 0.4501 - precision_tumor: 0.5946 - recall_tumor: 0.6537 - tumor_iou: 0.4541 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.5519 - val_loss: 0.3097 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6033 - val_recall_tumor: 0.5637 - val_tumor_iou: 0.4149 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 176 lên WandB.\n\n--- Epoch 177/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9873 - dice_coef_metric_tumor: 0.5937 - loss: 0.2688 - mean_iou_all: 0.4543 - precision_tumor: 0.5938 - recall_tumor: 0.6617 - tumor_iou: 0.4529\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 463ms/step - acc: 0.9873 - dice_coef_metric_tumor: 0.5937 - loss: 0.2688 - mean_iou_all: 0.4542 - precision_tumor: 0.5938 - recall_tumor: 0.6617 - tumor_iou: 0.4528 - val_acc: 0.9865 - val_dice_coef_metric_tumor: 0.5309 - val_loss: 0.3233 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5293 - val_recall_tumor: 0.6161 - val_tumor_iou: 0.3950 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 177 lên WandB.\n\n--- Epoch 178/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.6098 - loss: 0.2612 - mean_iou_all: 0.4497 - precision_tumor: 0.6034 - recall_tumor: 0.6756 - tumor_iou: 0.4668\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.6098 - loss: 0.2612 - mean_iou_all: 0.4496 - precision_tumor: 0.6034 - recall_tumor: 0.6755 - tumor_iou: 0.4668 - val_acc: 0.9882 - val_dice_coef_metric_tumor: 0.5461 - val_loss: 0.3137 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5481 - val_recall_tumor: 0.5972 - val_tumor_iou: 0.4113 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 178 lên WandB.\n\n--- Epoch 179/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5934 - loss: 0.2667 - mean_iou_all: 0.4386 - precision_tumor: 0.5833 - recall_tumor: 0.6803 - tumor_iou: 0.4479\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5934 - loss: 0.2667 - mean_iou_all: 0.4385 - precision_tumor: 0.5834 - recall_tumor: 0.6802 - tumor_iou: 0.4479 - val_acc: 0.9859 - val_dice_coef_metric_tumor: 0.5182 - val_loss: 0.3316 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5005 - val_recall_tumor: 0.6012 - val_tumor_iou: 0.3871 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 179 lên WandB.\n\n--- Epoch 180/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.5840 - loss: 0.2705 - mean_iou_all: 0.4400 - precision_tumor: 0.5952 - recall_tumor: 0.6342 - tumor_iou: 0.4440\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.5840 - loss: 0.2705 - mean_iou_all: 0.4398 - precision_tumor: 0.5952 - recall_tumor: 0.6342 - tumor_iou: 0.4440 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.5078 - val_loss: 0.3374 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6309 - val_recall_tumor: 0.4845 - val_tumor_iou: 0.3781 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 180 lên WandB.\n\n--- Epoch 181/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.5927 - loss: 0.2660 - mean_iou_all: 0.4662 - precision_tumor: 0.6035 - recall_tumor: 0.6540 - tumor_iou: 0.4509\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.5926 - loss: 0.2660 - mean_iou_all: 0.4661 - precision_tumor: 0.6035 - recall_tumor: 0.6540 - tumor_iou: 0.4508 - val_acc: 0.9898 - val_dice_coef_metric_tumor: 0.5146 - val_loss: 0.3328 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7032 - val_recall_tumor: 0.4596 - val_tumor_iou: 0.3852 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 181 lên WandB.\n\n--- Epoch 182/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.6046 - loss: 0.2630 - mean_iou_all: 0.4648 - precision_tumor: 0.6108 - recall_tumor: 0.6558 - tumor_iou: 0.4613\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.6046 - loss: 0.2631 - mean_iou_all: 0.4647 - precision_tumor: 0.6107 - recall_tumor: 0.6558 - tumor_iou: 0.4613 - val_acc: 0.9853 - val_dice_coef_metric_tumor: 0.5275 - val_loss: 0.3263 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4821 - val_recall_tumor: 0.6582 - val_tumor_iou: 0.3906 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 182 lên WandB.\n\n--- Epoch 183/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.5918 - loss: 0.2669 - mean_iou_all: 0.4619 - precision_tumor: 0.5958 - recall_tumor: 0.6581 - tumor_iou: 0.4512\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.5917 - loss: 0.2669 - mean_iou_all: 0.4618 - precision_tumor: 0.5957 - recall_tumor: 0.6581 - tumor_iou: 0.4512 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5237 - val_loss: 0.3277 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6257 - val_recall_tumor: 0.5205 - val_tumor_iou: 0.3840 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 183 lên WandB.\n\n--- Epoch 184/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5895 - loss: 0.2816 - mean_iou_all: 0.4538 - precision_tumor: 0.5998 - recall_tumor: 0.6461 - tumor_iou: 0.4451\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5895 - loss: 0.2815 - mean_iou_all: 0.4536 - precision_tumor: 0.5998 - recall_tumor: 0.6462 - tumor_iou: 0.4452 - val_acc: 0.9897 - val_dice_coef_metric_tumor: 0.5349 - val_loss: 0.3206 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6744 - val_recall_tumor: 0.4938 - val_tumor_iou: 0.4036 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 184 lên WandB.\n\n--- Epoch 185/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9873 - dice_coef_metric_tumor: 0.5949 - loss: 0.2694 - mean_iou_all: 0.4386 - precision_tumor: 0.6041 - recall_tumor: 0.6626 - tumor_iou: 0.4521\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9873 - dice_coef_metric_tumor: 0.5949 - loss: 0.2694 - mean_iou_all: 0.4384 - precision_tumor: 0.6041 - recall_tumor: 0.6626 - tumor_iou: 0.4521 - val_acc: 0.9888 - val_dice_coef_metric_tumor: 0.4988 - val_loss: 0.3434 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6605 - val_recall_tumor: 0.4388 - val_tumor_iou: 0.3637 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 185 lên WandB.\n\n--- Epoch 186/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.6126 - loss: 0.2550 - mean_iou_all: 0.4617 - precision_tumor: 0.6223 - recall_tumor: 0.6660 - tumor_iou: 0.4700\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.6126 - loss: 0.2550 - mean_iou_all: 0.4616 - precision_tumor: 0.6223 - recall_tumor: 0.6660 - tumor_iou: 0.4700 - val_acc: 0.9867 - val_dice_coef_metric_tumor: 0.5503 - val_loss: 0.3124 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5445 - val_recall_tumor: 0.6241 - val_tumor_iou: 0.4100 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 186 lên WandB.\n\n--- Epoch 187/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6010 - loss: 0.2641 - mean_iou_all: 0.4593 - precision_tumor: 0.6024 - recall_tumor: 0.6635 - tumor_iou: 0.4632\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6010 - loss: 0.2641 - mean_iou_all: 0.4592 - precision_tumor: 0.6024 - recall_tumor: 0.6635 - tumor_iou: 0.4632 - val_acc: 0.9862 - val_dice_coef_metric_tumor: 0.5226 - val_loss: 0.3293 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5251 - val_recall_tumor: 0.5941 - val_tumor_iou: 0.3885 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 187 lên WandB.\n\n--- Epoch 188/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5943 - loss: 0.2701 - mean_iou_all: 0.4665 - precision_tumor: 0.5850 - recall_tumor: 0.6698 - tumor_iou: 0.4533\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5943 - loss: 0.2701 - mean_iou_all: 0.4664 - precision_tumor: 0.5850 - recall_tumor: 0.6698 - tumor_iou: 0.4533 - val_acc: 0.9882 - val_dice_coef_metric_tumor: 0.5502 - val_loss: 0.3120 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5813 - val_recall_tumor: 0.5793 - val_tumor_iou: 0.4150 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 188 lên WandB.\n\n--- Epoch 189/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.6035 - loss: 0.2670 - mean_iou_all: 0.4702 - precision_tumor: 0.6103 - recall_tumor: 0.6579 - tumor_iou: 0.4608\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55241\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.6034 - loss: 0.2669 - mean_iou_all: 0.4701 - precision_tumor: 0.6103 - recall_tumor: 0.6579 - tumor_iou: 0.4608 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.5329 - val_loss: 0.3230 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6490 - val_recall_tumor: 0.5083 - val_tumor_iou: 0.3930 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 189 lên WandB.\n\n--- Epoch 190/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6031 - loss: 0.2625 - mean_iou_all: 0.4732 - precision_tumor: 0.6108 - recall_tumor: 0.6584 - tumor_iou: 0.4620\nEpoch 1: val_dice_coef_metric_tumor improved from 0.55241 to 0.55370, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6031 - loss: 0.2625 - mean_iou_all: 0.4731 - precision_tumor: 0.6108 - recall_tumor: 0.6584 - tumor_iou: 0.4620 - val_acc: 0.9887 - val_dice_coef_metric_tumor: 0.5537 - val_loss: 0.3106 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6313 - val_recall_tumor: 0.5455 - val_tumor_iou: 0.4183 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 190 lên WandB.\n\n--- Epoch 191/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6065 - loss: 0.2575 - mean_iou_all: 0.4304 - precision_tumor: 0.6118 - recall_tumor: 0.6683 - tumor_iou: 0.4644\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55370\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6065 - loss: 0.2575 - mean_iou_all: 0.4303 - precision_tumor: 0.6118 - recall_tumor: 0.6683 - tumor_iou: 0.4644 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.5076 - val_loss: 0.3378 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6665 - val_recall_tumor: 0.4685 - val_tumor_iou: 0.3755 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 191 lên WandB.\n\n--- Epoch 192/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6037 - loss: 0.2608 - mean_iou_all: 0.4660 - precision_tumor: 0.6084 - recall_tumor: 0.6545 - tumor_iou: 0.4625\nEpoch 1: val_dice_coef_metric_tumor improved from 0.55370 to 0.56741, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6036 - loss: 0.2608 - mean_iou_all: 0.4658 - precision_tumor: 0.6084 - recall_tumor: 0.6545 - tumor_iou: 0.4624 - val_acc: 0.9872 - val_dice_coef_metric_tumor: 0.5674 - val_loss: 0.3024 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5510 - val_recall_tumor: 0.6617 - val_tumor_iou: 0.4289 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 192 lên WandB.\n\n--- Epoch 193/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6031 - loss: 0.2587 - mean_iou_all: 0.4410 - precision_tumor: 0.6019 - recall_tumor: 0.6658 - tumor_iou: 0.4688\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56741\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6031 - loss: 0.2587 - mean_iou_all: 0.4408 - precision_tumor: 0.6018 - recall_tumor: 0.6657 - tumor_iou: 0.4687 - val_acc: 0.9882 - val_dice_coef_metric_tumor: 0.5373 - val_loss: 0.3213 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5897 - val_recall_tumor: 0.5506 - val_tumor_iou: 0.4053 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 193 lên WandB.\n\n--- Epoch 194/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9873 - dice_coef_metric_tumor: 0.5981 - loss: 0.2662 - mean_iou_all: 0.4393 - precision_tumor: 0.5998 - recall_tumor: 0.6709 - tumor_iou: 0.4561\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56741\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9873 - dice_coef_metric_tumor: 0.5981 - loss: 0.2662 - mean_iou_all: 0.4391 - precision_tumor: 0.5998 - recall_tumor: 0.6709 - tumor_iou: 0.4561 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5495 - val_loss: 0.3126 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6107 - val_recall_tumor: 0.5523 - val_tumor_iou: 0.4164 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 194 lên WandB.\n\n--- Epoch 195/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6083 - loss: 0.2590 - mean_iou_all: 0.4597 - precision_tumor: 0.6186 - recall_tumor: 0.6563 - tumor_iou: 0.4645\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56741\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6083 - loss: 0.2590 - mean_iou_all: 0.4596 - precision_tumor: 0.6186 - recall_tumor: 0.6563 - tumor_iou: 0.4645 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.5561 - val_loss: 0.3089 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6387 - val_recall_tumor: 0.5445 - val_tumor_iou: 0.4201 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 195 lên WandB.\n\n--- Epoch 196/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6118 - loss: 0.2560 - mean_iou_all: 0.4512 - precision_tumor: 0.6191 - recall_tumor: 0.6707 - tumor_iou: 0.4699\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56741\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6118 - loss: 0.2560 - mean_iou_all: 0.4511 - precision_tumor: 0.6191 - recall_tumor: 0.6707 - tumor_iou: 0.4699 - val_acc: 0.9886 - val_dice_coef_metric_tumor: 0.5430 - val_loss: 0.3168 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5974 - val_recall_tumor: 0.5478 - val_tumor_iou: 0.4095 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 196 lên WandB.\n\n--- Epoch 197/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.6042 - loss: 0.2676 - mean_iou_all: 0.4454 - precision_tumor: 0.6117 - recall_tumor: 0.6593 - tumor_iou: 0.4622\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56741\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.6042 - loss: 0.2675 - mean_iou_all: 0.4453 - precision_tumor: 0.6117 - recall_tumor: 0.6593 - tumor_iou: 0.4622 - val_acc: 0.9832 - val_dice_coef_metric_tumor: 0.5197 - val_loss: 0.3337 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5049 - val_recall_tumor: 0.6394 - val_tumor_iou: 0.3863 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 197 lên WandB.\n\n--- Epoch 198/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5875 - loss: 0.2758 - mean_iou_all: 0.4664 - precision_tumor: 0.5884 - recall_tumor: 0.6593 - tumor_iou: 0.4465\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56741\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5875 - loss: 0.2758 - mean_iou_all: 0.4663 - precision_tumor: 0.5885 - recall_tumor: 0.6593 - tumor_iou: 0.4466 - val_acc: 0.9894 - val_dice_coef_metric_tumor: 0.5665 - val_loss: 0.3027 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6137 - val_recall_tumor: 0.5778 - val_tumor_iou: 0.4286 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 198 lên WandB.\n\n--- Epoch 199/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.6116 - loss: 0.2572 - mean_iou_all: 0.4690 - precision_tumor: 0.6055 - recall_tumor: 0.6801 - tumor_iou: 0.4708\nEpoch 1: val_dice_coef_metric_tumor improved from 0.56741 to 0.57146, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.6116 - loss: 0.2572 - mean_iou_all: 0.4689 - precision_tumor: 0.6055 - recall_tumor: 0.6801 - tumor_iou: 0.4708 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5715 - val_loss: 0.2997 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6194 - val_recall_tumor: 0.5844 - val_tumor_iou: 0.4379 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 199 lên WandB.\n\n--- Epoch 200/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9873 - dice_coef_metric_tumor: 0.6089 - loss: 0.2592 - mean_iou_all: 0.4614 - precision_tumor: 0.6047 - recall_tumor: 0.6846 - tumor_iou: 0.4698\nEpoch 1: val_dice_coef_metric_tumor improved from 0.57146 to 0.57206, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9873 - dice_coef_metric_tumor: 0.6089 - loss: 0.2592 - mean_iou_all: 0.4612 - precision_tumor: 0.6047 - recall_tumor: 0.6846 - tumor_iou: 0.4697 - val_acc: 0.9882 - val_dice_coef_metric_tumor: 0.5721 - val_loss: 0.2997 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5710 - val_recall_tumor: 0.6409 - val_tumor_iou: 0.4330 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 200 lên WandB.\n\n--- Epoch 201/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.5937 - loss: 0.2664 - mean_iou_all: 0.4552 - precision_tumor: 0.5980 - recall_tumor: 0.6636 - tumor_iou: 0.4489\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57206\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.5937 - loss: 0.2664 - mean_iou_all: 0.4550 - precision_tumor: 0.5980 - recall_tumor: 0.6636 - tumor_iou: 0.4489 - val_acc: 0.9815 - val_dice_coef_metric_tumor: 0.5085 - val_loss: 0.3406 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4209 - val_recall_tumor: 0.7358 - val_tumor_iou: 0.3737 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 201 lên WandB.\n\n--- Epoch 202/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6118 - loss: 0.2564 - mean_iou_all: 0.4449 - precision_tumor: 0.6122 - recall_tumor: 0.6798 - tumor_iou: 0.4707\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57206\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 462ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6118 - loss: 0.2563 - mean_iou_all: 0.4448 - precision_tumor: 0.6122 - recall_tumor: 0.6798 - tumor_iou: 0.4707 - val_acc: 0.9890 - val_dice_coef_metric_tumor: 0.5351 - val_loss: 0.3223 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6688 - val_recall_tumor: 0.5058 - val_tumor_iou: 0.4029 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 202 lên WandB.\n\n--- Epoch 203/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6268 - loss: 0.2512 - mean_iou_all: 0.4629 - precision_tumor: 0.6404 - recall_tumor: 0.6696 - tumor_iou: 0.4834\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57206\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6267 - loss: 0.2512 - mean_iou_all: 0.4628 - precision_tumor: 0.6403 - recall_tumor: 0.6695 - tumor_iou: 0.4833 - val_acc: 0.9875 - val_dice_coef_metric_tumor: 0.5326 - val_loss: 0.3244 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6099 - val_recall_tumor: 0.5367 - val_tumor_iou: 0.3972 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 203 lên WandB.\n\n--- Epoch 204/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6206 - loss: 0.2526 - mean_iou_all: 0.4475 - precision_tumor: 0.6296 - recall_tumor: 0.6753 - tumor_iou: 0.4789\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57206\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6206 - loss: 0.2526 - mean_iou_all: 0.4473 - precision_tumor: 0.6296 - recall_tumor: 0.6753 - tumor_iou: 0.4789 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5701 - val_loss: 0.3016 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6118 - val_recall_tumor: 0.5885 - val_tumor_iou: 0.4353 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 204 lên WandB.\n\n--- Epoch 205/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6046 - loss: 0.2584 - mean_iou_all: 0.4457 - precision_tumor: 0.6183 - recall_tumor: 0.6599 - tumor_iou: 0.4626\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57206\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6046 - loss: 0.2584 - mean_iou_all: 0.4455 - precision_tumor: 0.6184 - recall_tumor: 0.6598 - tumor_iou: 0.4626 - val_acc: 0.9874 - val_dice_coef_metric_tumor: 0.5571 - val_loss: 0.3092 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5416 - val_recall_tumor: 0.6517 - val_tumor_iou: 0.4203 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 205 lên WandB.\n\n--- Epoch 206/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6169 - loss: 0.2583 - mean_iou_all: 0.4580 - precision_tumor: 0.6222 - recall_tumor: 0.6685 - tumor_iou: 0.4769\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57206\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6169 - loss: 0.2583 - mean_iou_all: 0.4579 - precision_tumor: 0.6222 - recall_tumor: 0.6684 - tumor_iou: 0.4769 - val_acc: 0.9895 - val_dice_coef_metric_tumor: 0.5531 - val_loss: 0.3114 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6228 - val_recall_tumor: 0.5542 - val_tumor_iou: 0.4200 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 206 lên WandB.\n\n--- Epoch 207/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.6156 - loss: 0.2618 - mean_iou_all: 0.4559 - precision_tumor: 0.6175 - recall_tumor: 0.6824 - tumor_iou: 0.4739\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57206\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.6156 - loss: 0.2618 - mean_iou_all: 0.4557 - precision_tumor: 0.6175 - recall_tumor: 0.6823 - tumor_iou: 0.4739 - val_acc: 0.9881 - val_dice_coef_metric_tumor: 0.5517 - val_loss: 0.3131 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5768 - val_recall_tumor: 0.5975 - val_tumor_iou: 0.4145 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 207 lên WandB.\n\n--- Epoch 208/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6273 - loss: 0.2486 - mean_iou_all: 0.4319 - precision_tumor: 0.6482 - recall_tumor: 0.6677 - tumor_iou: 0.4847\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57206\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 462ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6273 - loss: 0.2486 - mean_iou_all: 0.4317 - precision_tumor: 0.6482 - recall_tumor: 0.6677 - tumor_iou: 0.4847 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5706 - val_loss: 0.3011 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5773 - val_recall_tumor: 0.6244 - val_tumor_iou: 0.4327 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 208 lên WandB.\n\n--- Epoch 209/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6218 - loss: 0.2565 - mean_iou_all: 0.4447 - precision_tumor: 0.6361 - recall_tumor: 0.6684 - tumor_iou: 0.4813\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57206\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6218 - loss: 0.2564 - mean_iou_all: 0.4445 - precision_tumor: 0.6361 - recall_tumor: 0.6684 - tumor_iou: 0.4813 - val_acc: 0.9886 - val_dice_coef_metric_tumor: 0.5310 - val_loss: 0.3252 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6319 - val_recall_tumor: 0.5320 - val_tumor_iou: 0.3973 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 209 lên WandB.\n\n--- Epoch 210/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6137 - loss: 0.2559 - mean_iou_all: 0.4339 - precision_tumor: 0.6251 - recall_tumor: 0.6704 - tumor_iou: 0.4724\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57206\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6137 - loss: 0.2559 - mean_iou_all: 0.4338 - precision_tumor: 0.6251 - recall_tumor: 0.6704 - tumor_iou: 0.4724 - val_acc: 0.9871 - val_dice_coef_metric_tumor: 0.5673 - val_loss: 0.3039 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5310 - val_recall_tumor: 0.6820 - val_tumor_iou: 0.4315 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 210 lên WandB.\n\n--- Epoch 211/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.6084 - loss: 0.2602 - mean_iou_all: 0.4544 - precision_tumor: 0.6175 - recall_tumor: 0.6665 - tumor_iou: 0.4683\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57206\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.6084 - loss: 0.2602 - mean_iou_all: 0.4543 - precision_tumor: 0.6175 - recall_tumor: 0.6665 - tumor_iou: 0.4682 - val_acc: 0.9898 - val_dice_coef_metric_tumor: 0.5603 - val_loss: 0.3074 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6653 - val_recall_tumor: 0.5258 - val_tumor_iou: 0.4245 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 211 lên WandB.\n\n--- Epoch 212/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6137 - loss: 0.2527 - mean_iou_all: 0.4536 - precision_tumor: 0.6232 - recall_tumor: 0.6700 - tumor_iou: 0.4758\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57206\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6137 - loss: 0.2527 - mean_iou_all: 0.4535 - precision_tumor: 0.6232 - recall_tumor: 0.6700 - tumor_iou: 0.4758 - val_acc: 0.9890 - val_dice_coef_metric_tumor: 0.5661 - val_loss: 0.3042 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5992 - val_recall_tumor: 0.5909 - val_tumor_iou: 0.4366 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 212 lên WandB.\n\n--- Epoch 213/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6269 - loss: 0.2520 - mean_iou_all: 0.4354 - precision_tumor: 0.6502 - recall_tumor: 0.6667 - tumor_iou: 0.4892\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57206\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6268 - loss: 0.2520 - mean_iou_all: 0.4353 - precision_tumor: 0.6501 - recall_tumor: 0.6667 - tumor_iou: 0.4892 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.5628 - val_loss: 0.3059 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6220 - val_recall_tumor: 0.5711 - val_tumor_iou: 0.4260 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 213 lên WandB.\n\n--- Epoch 214/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6345 - loss: 0.2442 - mean_iou_all: 0.4392 - precision_tumor: 0.6385 - recall_tumor: 0.6868 - tumor_iou: 0.4922\nEpoch 1: val_dice_coef_metric_tumor improved from 0.57206 to 0.58435, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6344 - loss: 0.2442 - mean_iou_all: 0.4391 - precision_tumor: 0.6385 - recall_tumor: 0.6867 - tumor_iou: 0.4922 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.5843 - val_loss: 0.2929 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6003 - val_recall_tumor: 0.6217 - val_tumor_iou: 0.4487 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 214 lên WandB.\n\n--- Epoch 215/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6228 - loss: 0.2515 - mean_iou_all: 0.4525 - precision_tumor: 0.6335 - recall_tumor: 0.6713 - tumor_iou: 0.4843\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6228 - loss: 0.2516 - mean_iou_all: 0.4524 - precision_tumor: 0.6335 - recall_tumor: 0.6713 - tumor_iou: 0.4842 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5772 - val_loss: 0.2977 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5512 - val_recall_tumor: 0.6607 - val_tumor_iou: 0.4411 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 215 lên WandB.\n\n--- Epoch 216/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6202 - loss: 0.2550 - mean_iou_all: 0.4530 - precision_tumor: 0.6181 - recall_tumor: 0.6854 - tumor_iou: 0.4787\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6202 - loss: 0.2550 - mean_iou_all: 0.4529 - precision_tumor: 0.6181 - recall_tumor: 0.6853 - tumor_iou: 0.4786 - val_acc: 0.9897 - val_dice_coef_metric_tumor: 0.5687 - val_loss: 0.3030 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6265 - val_recall_tumor: 0.5703 - val_tumor_iou: 0.4357 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 216 lên WandB.\n\n--- Epoch 217/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6328 - loss: 0.2462 - mean_iou_all: 0.4464 - precision_tumor: 0.6417 - recall_tumor: 0.6724 - tumor_iou: 0.4907\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6327 - loss: 0.2462 - mean_iou_all: 0.4463 - precision_tumor: 0.6417 - recall_tumor: 0.6724 - tumor_iou: 0.4906 - val_acc: 0.9895 - val_dice_coef_metric_tumor: 0.5721 - val_loss: 0.3006 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6165 - val_recall_tumor: 0.5868 - val_tumor_iou: 0.4362 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 217 lên WandB.\n\n--- Epoch 218/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6077 - loss: 0.2584 - mean_iou_all: 0.4478 - precision_tumor: 0.6167 - recall_tumor: 0.6623 - tumor_iou: 0.4667\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6077 - loss: 0.2584 - mean_iou_all: 0.4477 - precision_tumor: 0.6167 - recall_tumor: 0.6623 - tumor_iou: 0.4667 - val_acc: 0.9878 - val_dice_coef_metric_tumor: 0.5590 - val_loss: 0.3093 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5739 - val_recall_tumor: 0.6107 - val_tumor_iou: 0.4251 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 218 lên WandB.\n\n--- Epoch 219/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6206 - loss: 0.2553 - mean_iou_all: 0.4584 - precision_tumor: 0.6390 - recall_tumor: 0.6723 - tumor_iou: 0.4778\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 491ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6206 - loss: 0.2553 - mean_iou_all: 0.4583 - precision_tumor: 0.6389 - recall_tumor: 0.6723 - tumor_iou: 0.4778 - val_acc: 0.9851 - val_dice_coef_metric_tumor: 0.5272 - val_loss: 0.3295 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5108 - val_recall_tumor: 0.6187 - val_tumor_iou: 0.3927 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 219 lên WandB.\n\n--- Epoch 220/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6274 - loss: 0.2543 - mean_iou_all: 0.4561 - precision_tumor: 0.6426 - recall_tumor: 0.6703 - tumor_iou: 0.4817\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6274 - loss: 0.2543 - mean_iou_all: 0.4559 - precision_tumor: 0.6426 - recall_tumor: 0.6703 - tumor_iou: 0.4817 - val_acc: 0.9896 - val_dice_coef_metric_tumor: 0.5602 - val_loss: 0.3085 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6701 - val_recall_tumor: 0.5329 - val_tumor_iou: 0.4254 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 220 lên WandB.\n\n--- Epoch 221/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6287 - loss: 0.2506 - mean_iou_all: 0.4254 - precision_tumor: 0.6299 - recall_tumor: 0.6854 - tumor_iou: 0.4878\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6287 - loss: 0.2505 - mean_iou_all: 0.4252 - precision_tumor: 0.6299 - recall_tumor: 0.6854 - tumor_iou: 0.4878 - val_acc: 0.9866 - val_dice_coef_metric_tumor: 0.5357 - val_loss: 0.3236 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5594 - val_recall_tumor: 0.5952 - val_tumor_iou: 0.4027 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 221 lên WandB.\n\n--- Epoch 222/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6253 - loss: 0.2490 - mean_iou_all: 0.4219 - precision_tumor: 0.6363 - recall_tumor: 0.6748 - tumor_iou: 0.4836\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6253 - loss: 0.2490 - mean_iou_all: 0.4218 - precision_tumor: 0.6363 - recall_tumor: 0.6748 - tumor_iou: 0.4836 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5734 - val_loss: 0.3002 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6122 - val_recall_tumor: 0.5917 - val_tumor_iou: 0.4369 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 222 lên WandB.\n\n--- Epoch 223/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6395 - loss: 0.2450 - mean_iou_all: 0.4510 - precision_tumor: 0.6535 - recall_tumor: 0.6809 - tumor_iou: 0.4955\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6394 - loss: 0.2450 - mean_iou_all: 0.4509 - precision_tumor: 0.6535 - recall_tumor: 0.6809 - tumor_iou: 0.4955 - val_acc: 0.9895 - val_dice_coef_metric_tumor: 0.5565 - val_loss: 0.3113 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6565 - val_recall_tumor: 0.5409 - val_tumor_iou: 0.4231 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 223 lên WandB.\n\n--- Epoch 224/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6317 - loss: 0.2494 - mean_iou_all: 0.4450 - precision_tumor: 0.6491 - recall_tumor: 0.6710 - tumor_iou: 0.4913\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6317 - loss: 0.2493 - mean_iou_all: 0.4448 - precision_tumor: 0.6490 - recall_tumor: 0.6710 - tumor_iou: 0.4913 - val_acc: 0.9898 - val_dice_coef_metric_tumor: 0.5683 - val_loss: 0.3032 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6732 - val_recall_tumor: 0.5487 - val_tumor_iou: 0.4326 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 224 lên WandB.\n\n--- Epoch 225/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6326 - loss: 0.2508 - mean_iou_all: 0.4418 - precision_tumor: 0.6250 - recall_tumor: 0.6993 - tumor_iou: 0.4909\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6326 - loss: 0.2508 - mean_iou_all: 0.4416 - precision_tumor: 0.6250 - recall_tumor: 0.6992 - tumor_iou: 0.4908 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.5780 - val_loss: 0.2977 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6018 - val_recall_tumor: 0.6099 - val_tumor_iou: 0.4405 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 225 lên WandB.\n\n--- Epoch 226/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6447 - loss: 0.2411 - mean_iou_all: 0.4444 - precision_tumor: 0.6589 - recall_tumor: 0.6810 - tumor_iou: 0.5013\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6447 - loss: 0.2411 - mean_iou_all: 0.4442 - precision_tumor: 0.6588 - recall_tumor: 0.6809 - tumor_iou: 0.5012 - val_acc: 0.9902 - val_dice_coef_metric_tumor: 0.5573 - val_loss: 0.3103 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6982 - val_recall_tumor: 0.5045 - val_tumor_iou: 0.4250 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 226 lên WandB.\n\n--- Epoch 227/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6222 - loss: 0.2510 - mean_iou_all: 0.4491 - precision_tumor: 0.6419 - recall_tumor: 0.6563 - tumor_iou: 0.4822\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6222 - loss: 0.2510 - mean_iou_all: 0.4490 - precision_tumor: 0.6419 - recall_tumor: 0.6563 - tumor_iou: 0.4822 - val_acc: 0.9888 - val_dice_coef_metric_tumor: 0.5594 - val_loss: 0.3094 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6315 - val_recall_tumor: 0.5559 - val_tumor_iou: 0.4254 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 227 lên WandB.\n\n--- Epoch 228/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6280 - loss: 0.2551 - mean_iou_all: 0.4289 - precision_tumor: 0.6338 - recall_tumor: 0.6807 - tumor_iou: 0.4875\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6279 - loss: 0.2551 - mean_iou_all: 0.4287 - precision_tumor: 0.6338 - recall_tumor: 0.6807 - tumor_iou: 0.4875 - val_acc: 0.9896 - val_dice_coef_metric_tumor: 0.5782 - val_loss: 0.2981 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6247 - val_recall_tumor: 0.5963 - val_tumor_iou: 0.4402 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 228 lên WandB.\n\n--- Epoch 229/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6272 - loss: 0.2508 - mean_iou_all: 0.4479 - precision_tumor: 0.6432 - recall_tumor: 0.6719 - tumor_iou: 0.4838\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6272 - loss: 0.2508 - mean_iou_all: 0.4477 - precision_tumor: 0.6432 - recall_tumor: 0.6719 - tumor_iou: 0.4838 - val_acc: 0.9882 - val_dice_coef_metric_tumor: 0.5562 - val_loss: 0.3116 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5776 - val_recall_tumor: 0.5992 - val_tumor_iou: 0.4211 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 229 lên WandB.\n\n--- Epoch 230/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6236 - loss: 0.2511 - mean_iou_all: 0.4284 - precision_tumor: 0.6330 - recall_tumor: 0.6758 - tumor_iou: 0.4818\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6236 - loss: 0.2511 - mean_iou_all: 0.4282 - precision_tumor: 0.6330 - recall_tumor: 0.6758 - tumor_iou: 0.4819 - val_acc: 0.9872 - val_dice_coef_metric_tumor: 0.5506 - val_loss: 0.3151 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5696 - val_recall_tumor: 0.6016 - val_tumor_iou: 0.4128 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 230 lên WandB.\n\n--- Epoch 231/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6528 - loss: 0.2376 - mean_iou_all: 0.4379 - precision_tumor: 0.6616 - recall_tumor: 0.6967 - tumor_iou: 0.5123\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6528 - loss: 0.2376 - mean_iou_all: 0.4377 - precision_tumor: 0.6616 - recall_tumor: 0.6967 - tumor_iou: 0.5123 - val_acc: 0.9853 - val_dice_coef_metric_tumor: 0.5442 - val_loss: 0.3200 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5069 - val_recall_tumor: 0.6752 - val_tumor_iou: 0.4068 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 231 lên WandB.\n\n--- Epoch 232/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6381 - loss: 0.2479 - mean_iou_all: 0.4369 - precision_tumor: 0.6454 - recall_tumor: 0.7020 - tumor_iou: 0.4955\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6381 - loss: 0.2479 - mean_iou_all: 0.4367 - precision_tumor: 0.6454 - recall_tumor: 0.7019 - tumor_iou: 0.4955 - val_acc: 0.9872 - val_dice_coef_metric_tumor: 0.5538 - val_loss: 0.3136 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5825 - val_recall_tumor: 0.6109 - val_tumor_iou: 0.4172 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 232 lên WandB.\n\n--- Epoch 233/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6433 - loss: 0.2418 - mean_iou_all: 0.4685 - precision_tumor: 0.6532 - recall_tumor: 0.6780 - tumor_iou: 0.4999\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6433 - loss: 0.2418 - mean_iou_all: 0.4684 - precision_tumor: 0.6531 - recall_tumor: 0.6780 - tumor_iou: 0.4999 - val_acc: 0.9898 - val_dice_coef_metric_tumor: 0.5505 - val_loss: 0.3144 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6785 - val_recall_tumor: 0.5017 - val_tumor_iou: 0.4163 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 233 lên WandB.\n\n--- Epoch 234/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6270 - loss: 0.2538 - mean_iou_all: 0.4561 - precision_tumor: 0.6479 - recall_tumor: 0.6727 - tumor_iou: 0.4868\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6269 - loss: 0.2538 - mean_iou_all: 0.4560 - precision_tumor: 0.6478 - recall_tumor: 0.6727 - tumor_iou: 0.4867 - val_acc: 0.9899 - val_dice_coef_metric_tumor: 0.5817 - val_loss: 0.2959 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6275 - val_recall_tumor: 0.5861 - val_tumor_iou: 0.4495 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 234 lên WandB.\n\n--- Epoch 235/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6426 - loss: 0.2411 - mean_iou_all: 0.4614 - precision_tumor: 0.6573 - recall_tumor: 0.6797 - tumor_iou: 0.5020\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6425 - loss: 0.2412 - mean_iou_all: 0.4613 - precision_tumor: 0.6573 - recall_tumor: 0.6797 - tumor_iou: 0.5020 - val_acc: 0.9886 - val_dice_coef_metric_tumor: 0.5410 - val_loss: 0.3210 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6320 - val_recall_tumor: 0.5295 - val_tumor_iou: 0.4013 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 235 lên WandB.\n\n--- Epoch 236/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6328 - loss: 0.2453 - mean_iou_all: 0.4577 - precision_tumor: 0.6547 - recall_tumor: 0.6678 - tumor_iou: 0.4915\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6328 - loss: 0.2453 - mean_iou_all: 0.4575 - precision_tumor: 0.6547 - recall_tumor: 0.6678 - tumor_iou: 0.4915 - val_acc: 0.9887 - val_dice_coef_metric_tumor: 0.5737 - val_loss: 0.3010 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5926 - val_recall_tumor: 0.6197 - val_tumor_iou: 0.4427 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 236 lên WandB.\n\n--- Epoch 237/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6425 - loss: 0.2448 - mean_iou_all: 0.4303 - precision_tumor: 0.6585 - recall_tumor: 0.6852 - tumor_iou: 0.5033\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6424 - loss: 0.2448 - mean_iou_all: 0.4301 - precision_tumor: 0.6585 - recall_tumor: 0.6852 - tumor_iou: 0.5032 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5819 - val_loss: 0.2963 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5530 - val_recall_tumor: 0.6713 - val_tumor_iou: 0.4452 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 237 lên WandB.\n\n--- Epoch 238/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.6161 - loss: 0.2617 - mean_iou_all: 0.4553 - precision_tumor: 0.6164 - recall_tumor: 0.6853 - tumor_iou: 0.4724\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.6161 - loss: 0.2616 - mean_iou_all: 0.4551 - precision_tumor: 0.6164 - recall_tumor: 0.6853 - tumor_iou: 0.4724 - val_acc: 0.9897 - val_dice_coef_metric_tumor: 0.5608 - val_loss: 0.3087 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6776 - val_recall_tumor: 0.5243 - val_tumor_iou: 0.4250 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 238 lên WandB.\n\n--- Epoch 239/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9899 - dice_coef_metric_tumor: 0.6448 - loss: 0.2364 - mean_iou_all: 0.4475 - precision_tumor: 0.6617 - recall_tumor: 0.6920 - tumor_iou: 0.5038\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9899 - dice_coef_metric_tumor: 0.6448 - loss: 0.2364 - mean_iou_all: 0.4473 - precision_tumor: 0.6617 - recall_tumor: 0.6920 - tumor_iou: 0.5037 - val_acc: 0.9851 - val_dice_coef_metric_tumor: 0.5238 - val_loss: 0.3328 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4987 - val_recall_tumor: 0.6386 - val_tumor_iou: 0.3908 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 239 lên WandB.\n\n--- Epoch 240/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6271 - loss: 0.2537 - mean_iou_all: 0.4415 - precision_tumor: 0.6428 - recall_tumor: 0.6726 - tumor_iou: 0.4842\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 462ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6271 - loss: 0.2537 - mean_iou_all: 0.4413 - precision_tumor: 0.6428 - recall_tumor: 0.6726 - tumor_iou: 0.4842 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5564 - val_loss: 0.3121 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6542 - val_recall_tumor: 0.5405 - val_tumor_iou: 0.4196 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 240 lên WandB.\n\n--- Epoch 241/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6480 - loss: 0.2402 - mean_iou_all: 0.4542 - precision_tumor: 0.6587 - recall_tumor: 0.6841 - tumor_iou: 0.5072\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6480 - loss: 0.2402 - mean_iou_all: 0.4540 - precision_tumor: 0.6587 - recall_tumor: 0.6841 - tumor_iou: 0.5072 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5438 - val_loss: 0.3193 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6240 - val_recall_tumor: 0.5496 - val_tumor_iou: 0.4102 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 241 lên WandB.\n\n--- Epoch 242/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6561 - loss: 0.2401 - mean_iou_all: 0.4353 - precision_tumor: 0.6744 - recall_tumor: 0.6925 - tumor_iou: 0.5135\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6561 - loss: 0.2401 - mean_iou_all: 0.4351 - precision_tumor: 0.6744 - recall_tumor: 0.6925 - tumor_iou: 0.5134 - val_acc: 0.9898 - val_dice_coef_metric_tumor: 0.5631 - val_loss: 0.3074 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6314 - val_recall_tumor: 0.5560 - val_tumor_iou: 0.4271 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 242 lên WandB.\n\n--- Epoch 243/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9899 - dice_coef_metric_tumor: 0.6456 - loss: 0.2386 - mean_iou_all: 0.4384 - precision_tumor: 0.6609 - recall_tumor: 0.6841 - tumor_iou: 0.5059\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9899 - dice_coef_metric_tumor: 0.6455 - loss: 0.2386 - mean_iou_all: 0.4383 - precision_tumor: 0.6609 - recall_tumor: 0.6840 - tumor_iou: 0.5059 - val_acc: 0.9890 - val_dice_coef_metric_tumor: 0.5353 - val_loss: 0.3246 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6308 - val_recall_tumor: 0.5266 - val_tumor_iou: 0.4027 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 243 lên WandB.\n\n--- Epoch 244/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6384 - loss: 0.2486 - mean_iou_all: 0.4658 - precision_tumor: 0.6468 - recall_tumor: 0.6830 - tumor_iou: 0.4985\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6383 - loss: 0.2486 - mean_iou_all: 0.4657 - precision_tumor: 0.6468 - recall_tumor: 0.6829 - tumor_iou: 0.4985 - val_acc: 0.9871 - val_dice_coef_metric_tumor: 0.5637 - val_loss: 0.3084 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5585 - val_recall_tumor: 0.6409 - val_tumor_iou: 0.4270 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 244 lên WandB.\n\n--- Epoch 245/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6501 - loss: 0.2406 - mean_iou_all: 0.4310 - precision_tumor: 0.6679 - recall_tumor: 0.6825 - tumor_iou: 0.5075\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6501 - loss: 0.2406 - mean_iou_all: 0.4308 - precision_tumor: 0.6679 - recall_tumor: 0.6825 - tumor_iou: 0.5075 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.5464 - val_loss: 0.3188 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5627 - val_recall_tumor: 0.6035 - val_tumor_iou: 0.4119 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 245 lên WandB.\n\n--- Epoch 246/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6490 - loss: 0.2416 - mean_iou_all: 0.4381 - precision_tumor: 0.6595 - recall_tumor: 0.6887 - tumor_iou: 0.5081\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6489 - loss: 0.2416 - mean_iou_all: 0.4379 - precision_tumor: 0.6594 - recall_tumor: 0.6887 - tumor_iou: 0.5081 - val_acc: 0.9901 - val_dice_coef_metric_tumor: 0.5151 - val_loss: 0.3375 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7304 - val_recall_tumor: 0.4486 - val_tumor_iou: 0.3891 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 246 lên WandB.\n\n--- Epoch 247/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9901 - dice_coef_metric_tumor: 0.6458 - loss: 0.2384 - mean_iou_all: 0.4547 - precision_tumor: 0.6693 - recall_tumor: 0.6756 - tumor_iou: 0.5082\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9901 - dice_coef_metric_tumor: 0.6458 - loss: 0.2384 - mean_iou_all: 0.4545 - precision_tumor: 0.6693 - recall_tumor: 0.6756 - tumor_iou: 0.5081 - val_acc: 0.9875 - val_dice_coef_metric_tumor: 0.5514 - val_loss: 0.3153 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5302 - val_recall_tumor: 0.6451 - val_tumor_iou: 0.4200 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 247 lên WandB.\n\n--- Epoch 248/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6506 - loss: 0.2394 - mean_iou_all: 0.4425 - precision_tumor: 0.6604 - recall_tumor: 0.6881 - tumor_iou: 0.5097\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6506 - loss: 0.2394 - mean_iou_all: 0.4424 - precision_tumor: 0.6604 - recall_tumor: 0.6881 - tumor_iou: 0.5097 - val_acc: 0.9851 - val_dice_coef_metric_tumor: 0.5376 - val_loss: 0.3250 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4845 - val_recall_tumor: 0.6927 - val_tumor_iou: 0.4041 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 248 lên WandB.\n\n--- Epoch 249/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6267 - loss: 0.2506 - mean_iou_all: 0.4186 - precision_tumor: 0.6355 - recall_tumor: 0.6875 - tumor_iou: 0.4839\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6267 - loss: 0.2505 - mean_iou_all: 0.4183 - precision_tumor: 0.6355 - recall_tumor: 0.6874 - tumor_iou: 0.4839 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.5600 - val_loss: 0.3101 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6536 - val_recall_tumor: 0.5417 - val_tumor_iou: 0.4238 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 249 lên WandB.\n\n--- Epoch 250/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6389 - loss: 0.2460 - mean_iou_all: 0.4121 - precision_tumor: 0.6539 - recall_tumor: 0.6729 - tumor_iou: 0.5001\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6389 - loss: 0.2459 - mean_iou_all: 0.4119 - precision_tumor: 0.6539 - recall_tumor: 0.6729 - tumor_iou: 0.5001 - val_acc: 0.9901 - val_dice_coef_metric_tumor: 0.5473 - val_loss: 0.3176 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7216 - val_recall_tumor: 0.4963 - val_tumor_iou: 0.4156 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 250 lên WandB.\n\n--- Epoch 251/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6358 - loss: 0.2454 - mean_iou_all: 0.4387 - precision_tumor: 0.6466 - recall_tumor: 0.6807 - tumor_iou: 0.4977\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6358 - loss: 0.2454 - mean_iou_all: 0.4385 - precision_tumor: 0.6466 - recall_tumor: 0.6807 - tumor_iou: 0.4977 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.5730 - val_loss: 0.3020 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6039 - val_recall_tumor: 0.6168 - val_tumor_iou: 0.4406 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 251 lên WandB.\n\n--- Epoch 252/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.6600 - loss: 0.2304 - mean_iou_all: 0.4298 - precision_tumor: 0.6647 - recall_tumor: 0.6956 - tumor_iou: 0.5207\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.6600 - loss: 0.2304 - mean_iou_all: 0.4296 - precision_tumor: 0.6647 - recall_tumor: 0.6956 - tumor_iou: 0.5207 - val_acc: 0.9896 - val_dice_coef_metric_tumor: 0.5072 - val_loss: 0.3429 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7538 - val_recall_tumor: 0.4240 - val_tumor_iou: 0.3723 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 252 lên WandB.\n\n--- Epoch 253/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6360 - loss: 0.2486 - mean_iou_all: 0.4277 - precision_tumor: 0.6587 - recall_tumor: 0.6662 - tumor_iou: 0.4949\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6360 - loss: 0.2486 - mean_iou_all: 0.4275 - precision_tumor: 0.6587 - recall_tumor: 0.6662 - tumor_iou: 0.4949 - val_acc: 0.9897 - val_dice_coef_metric_tumor: 0.5790 - val_loss: 0.2989 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6511 - val_recall_tumor: 0.5859 - val_tumor_iou: 0.4427 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 253 lên WandB.\n\n--- Epoch 254/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6420 - loss: 0.2436 - mean_iou_all: 0.4425 - precision_tumor: 0.6462 - recall_tumor: 0.6907 - tumor_iou: 0.5040\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6419 - loss: 0.2436 - mean_iou_all: 0.4424 - precision_tumor: 0.6462 - recall_tumor: 0.6906 - tumor_iou: 0.5040 - val_acc: 0.9854 - val_dice_coef_metric_tumor: 0.5584 - val_loss: 0.3128 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5369 - val_recall_tumor: 0.6690 - val_tumor_iou: 0.4208 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 254 lên WandB.\n\n--- Epoch 255/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6383 - loss: 0.2483 - mean_iou_all: 0.4493 - precision_tumor: 0.6424 - recall_tumor: 0.6923 - tumor_iou: 0.4972\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6383 - loss: 0.2483 - mean_iou_all: 0.4491 - precision_tumor: 0.6424 - recall_tumor: 0.6923 - tumor_iou: 0.4972 - val_acc: 0.9867 - val_dice_coef_metric_tumor: 0.5545 - val_loss: 0.3146 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5300 - val_recall_tumor: 0.6448 - val_tumor_iou: 0.4206 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 255 lên WandB.\n\n--- Epoch 256/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6368 - loss: 0.2529 - mean_iou_all: 0.4403 - precision_tumor: 0.6373 - recall_tumor: 0.6926 - tumor_iou: 0.4932\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6368 - loss: 0.2528 - mean_iou_all: 0.4401 - precision_tumor: 0.6374 - recall_tumor: 0.6926 - tumor_iou: 0.4932 - val_acc: 0.9905 - val_dice_coef_metric_tumor: 0.5748 - val_loss: 0.3012 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7385 - val_recall_tumor: 0.5171 - val_tumor_iou: 0.4420 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 256 lên WandB.\n\n--- Epoch 257/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6631 - loss: 0.2356 - mean_iou_all: 0.4430 - precision_tumor: 0.6829 - recall_tumor: 0.6925 - tumor_iou: 0.5197\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6630 - loss: 0.2356 - mean_iou_all: 0.4428 - precision_tumor: 0.6828 - recall_tumor: 0.6925 - tumor_iou: 0.5196 - val_acc: 0.9899 - val_dice_coef_metric_tumor: 0.5534 - val_loss: 0.3149 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6899 - val_recall_tumor: 0.5090 - val_tumor_iou: 0.4192 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 257 lên WandB.\n\n--- Epoch 258/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6490 - loss: 0.2414 - mean_iou_all: 0.4426 - precision_tumor: 0.6607 - recall_tumor: 0.6848 - tumor_iou: 0.5106\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6490 - loss: 0.2414 - mean_iou_all: 0.4424 - precision_tumor: 0.6607 - recall_tumor: 0.6848 - tumor_iou: 0.5106 - val_acc: 0.9888 - val_dice_coef_metric_tumor: 0.5740 - val_loss: 0.3022 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6107 - val_recall_tumor: 0.5993 - val_tumor_iou: 0.4365 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 258 lên WandB.\n\n--- Epoch 259/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9903 - dice_coef_metric_tumor: 0.6647 - loss: 0.2295 - mean_iou_all: 0.4348 - precision_tumor: 0.6810 - recall_tumor: 0.7068 - tumor_iou: 0.5236\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9903 - dice_coef_metric_tumor: 0.6647 - loss: 0.2296 - mean_iou_all: 0.4347 - precision_tumor: 0.6809 - recall_tumor: 0.7068 - tumor_iou: 0.5236 - val_acc: 0.9839 - val_dice_coef_metric_tumor: 0.5401 - val_loss: 0.3247 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4832 - val_recall_tumor: 0.7074 - val_tumor_iou: 0.4031 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 259 lên WandB.\n\n--- Epoch 260/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6367 - loss: 0.2486 - mean_iou_all: 0.4185 - precision_tumor: 0.6325 - recall_tumor: 0.7092 - tumor_iou: 0.4934\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6367 - loss: 0.2486 - mean_iou_all: 0.4183 - precision_tumor: 0.6326 - recall_tumor: 0.7092 - tumor_iou: 0.4934 - val_acc: 0.9895 - val_dice_coef_metric_tumor: 0.5648 - val_loss: 0.3081 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6233 - val_recall_tumor: 0.5774 - val_tumor_iou: 0.4342 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 260 lên WandB.\n\n--- Epoch 261/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6454 - loss: 0.2401 - mean_iou_all: 0.4267 - precision_tumor: 0.6575 - recall_tumor: 0.6862 - tumor_iou: 0.5031\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58435\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6454 - loss: 0.2401 - mean_iou_all: 0.4265 - precision_tumor: 0.6575 - recall_tumor: 0.6862 - tumor_iou: 0.5031 - val_acc: 0.9902 - val_dice_coef_metric_tumor: 0.5666 - val_loss: 0.3067 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6847 - val_recall_tumor: 0.5394 - val_tumor_iou: 0.4386 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 261 lên WandB.\n\n--- Epoch 262/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6602 - loss: 0.2394 - mean_iou_all: 0.4279 - precision_tumor: 0.6780 - recall_tumor: 0.6890 - tumor_iou: 0.5194\nEpoch 1: val_dice_coef_metric_tumor improved from 0.58435 to 0.58568, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6602 - loss: 0.2393 - mean_iou_all: 0.4277 - precision_tumor: 0.6780 - recall_tumor: 0.6890 - tumor_iou: 0.5194 - val_acc: 0.9902 - val_dice_coef_metric_tumor: 0.5857 - val_loss: 0.2956 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6669 - val_recall_tumor: 0.5752 - val_tumor_iou: 0.4537 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 262 lên WandB.\n\n--- Epoch 263/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6448 - loss: 0.2487 - mean_iou_all: 0.4590 - precision_tumor: 0.6523 - recall_tumor: 0.6897 - tumor_iou: 0.5020\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58568\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6448 - loss: 0.2486 - mean_iou_all: 0.4588 - precision_tumor: 0.6523 - recall_tumor: 0.6897 - tumor_iou: 0.5020 - val_acc: 0.9900 - val_dice_coef_metric_tumor: 0.5838 - val_loss: 0.2963 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6422 - val_recall_tumor: 0.5829 - val_tumor_iou: 0.4482 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 263 lên WandB.\n\n--- Epoch 264/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6249 - loss: 0.2508 - mean_iou_all: 0.4363 - precision_tumor: 0.6307 - recall_tumor: 0.6800 - tumor_iou: 0.4852\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58568\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 462ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6249 - loss: 0.2508 - mean_iou_all: 0.4361 - precision_tumor: 0.6307 - recall_tumor: 0.6800 - tumor_iou: 0.4852 - val_acc: 0.9900 - val_dice_coef_metric_tumor: 0.5541 - val_loss: 0.3151 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7119 - val_recall_tumor: 0.4931 - val_tumor_iou: 0.4203 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 264 lên WandB.\n\n--- Epoch 265/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9900 - dice_coef_metric_tumor: 0.6429 - loss: 0.2403 - mean_iou_all: 0.4393 - precision_tumor: 0.6551 - recall_tumor: 0.6880 - tumor_iou: 0.5046\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58568\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9900 - dice_coef_metric_tumor: 0.6429 - loss: 0.2403 - mean_iou_all: 0.4390 - precision_tumor: 0.6550 - recall_tumor: 0.6880 - tumor_iou: 0.5046 - val_acc: 0.9901 - val_dice_coef_metric_tumor: 0.5701 - val_loss: 0.3054 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6812 - val_recall_tumor: 0.5327 - val_tumor_iou: 0.4364 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 265 lên WandB.\n\n--- Epoch 266/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6446 - loss: 0.2395 - mean_iou_all: 0.4364 - precision_tumor: 0.6515 - recall_tumor: 0.6989 - tumor_iou: 0.5066\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58568\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6446 - loss: 0.2395 - mean_iou_all: 0.4362 - precision_tumor: 0.6515 - recall_tumor: 0.6989 - tumor_iou: 0.5066 - val_acc: 0.9902 - val_dice_coef_metric_tumor: 0.5678 - val_loss: 0.3061 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6734 - val_recall_tumor: 0.5444 - val_tumor_iou: 0.4373 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 266 lên WandB.\n\n--- Epoch 267/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6550 - loss: 0.2413 - mean_iou_all: 0.4171 - precision_tumor: 0.6675 - recall_tumor: 0.7000 - tumor_iou: 0.5138\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58568\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6550 - loss: 0.2413 - mean_iou_all: 0.4169 - precision_tumor: 0.6675 - recall_tumor: 0.7000 - tumor_iou: 0.5138 - val_acc: 0.9895 - val_dice_coef_metric_tumor: 0.5453 - val_loss: 0.3205 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6864 - val_recall_tumor: 0.5057 - val_tumor_iou: 0.4165 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 267 lên WandB.\n\n--- Epoch 268/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6396 - loss: 0.2461 - mean_iou_all: 0.4128 - precision_tumor: 0.6493 - recall_tumor: 0.6974 - tumor_iou: 0.5014\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58568\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6396 - loss: 0.2461 - mean_iou_all: 0.4126 - precision_tumor: 0.6493 - recall_tumor: 0.6974 - tumor_iou: 0.5013 - val_acc: 0.9854 - val_dice_coef_metric_tumor: 0.5454 - val_loss: 0.3219 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5161 - val_recall_tumor: 0.6646 - val_tumor_iou: 0.4136 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 268 lên WandB.\n\n--- Epoch 269/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9905 - dice_coef_metric_tumor: 0.6640 - loss: 0.2304 - mean_iou_all: 0.4265 - precision_tumor: 0.6769 - recall_tumor: 0.6940 - tumor_iou: 0.5266\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58568\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9905 - dice_coef_metric_tumor: 0.6640 - loss: 0.2304 - mean_iou_all: 0.4263 - precision_tumor: 0.6769 - recall_tumor: 0.6940 - tumor_iou: 0.5266 - val_acc: 0.9886 - val_dice_coef_metric_tumor: 0.5545 - val_loss: 0.3149 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6204 - val_recall_tumor: 0.5653 - val_tumor_iou: 0.4142 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 269 lên WandB.\n\n--- Epoch 270/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9899 - dice_coef_metric_tumor: 0.6545 - loss: 0.2372 - mean_iou_all: 0.4431 - precision_tumor: 0.6692 - recall_tumor: 0.6975 - tumor_iou: 0.5145\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58568\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9899 - dice_coef_metric_tumor: 0.6545 - loss: 0.2371 - mean_iou_all: 0.4429 - precision_tumor: 0.6692 - recall_tumor: 0.6975 - tumor_iou: 0.5145 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.5633 - val_loss: 0.3102 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5426 - val_recall_tumor: 0.6575 - val_tumor_iou: 0.4261 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 270 lên WandB.\n\n--- Epoch 271/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6565 - loss: 0.2418 - mean_iou_all: 0.4439 - precision_tumor: 0.6686 - recall_tumor: 0.7020 - tumor_iou: 0.5131\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58568\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6565 - loss: 0.2418 - mean_iou_all: 0.4437 - precision_tumor: 0.6686 - recall_tumor: 0.7020 - tumor_iou: 0.5131 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.5612 - val_loss: 0.3111 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6431 - val_recall_tumor: 0.5545 - val_tumor_iou: 0.4262 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 271 lên WandB.\n\n--- Epoch 272/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9902 - dice_coef_metric_tumor: 0.6463 - loss: 0.2386 - mean_iou_all: 0.4389 - precision_tumor: 0.6673 - recall_tumor: 0.6811 - tumor_iou: 0.5085\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58568\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9902 - dice_coef_metric_tumor: 0.6463 - loss: 0.2386 - mean_iou_all: 0.4387 - precision_tumor: 0.6673 - recall_tumor: 0.6811 - tumor_iou: 0.5084 - val_acc: 0.9883 - val_dice_coef_metric_tumor: 0.5232 - val_loss: 0.3346 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6184 - val_recall_tumor: 0.5088 - val_tumor_iou: 0.3885 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 272 lên WandB.\n\n--- Epoch 273/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6406 - loss: 0.2428 - mean_iou_all: 0.4330 - precision_tumor: 0.6409 - recall_tumor: 0.7028 - tumor_iou: 0.5018\nEpoch 1: val_dice_coef_metric_tumor improved from 0.58568 to 0.59014, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_30052025_115846.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6406 - loss: 0.2428 - mean_iou_all: 0.4328 - precision_tumor: 0.6409 - recall_tumor: 0.7028 - tumor_iou: 0.5018 - val_acc: 0.9903 - val_dice_coef_metric_tumor: 0.5901 - val_loss: 0.2936 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6841 - val_recall_tumor: 0.5616 - val_tumor_iou: 0.4557 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 273 lên WandB.\n\n--- Epoch 274/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9902 - dice_coef_metric_tumor: 0.6628 - loss: 0.2333 - mean_iou_all: 0.4231 - precision_tumor: 0.6816 - recall_tumor: 0.7021 - tumor_iou: 0.5231\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59014\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"   ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}