{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11709306,"sourceType":"datasetVersion","datasetId":6711261}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"ver 8 (6), v10","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n# Keras được tích hợp trong TensorFlow dưới dạng tf.keras\nkeras_version_from_tf = tf.keras.__version__\nprint(f\"Phiên bản Keras API (thông qua tf.keras): {keras_version_from_tf}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:05:09.857798Z","iopub.execute_input":"2025-05-22T19:05:09.858222Z","iopub.status.idle":"2025-05-22T19:05:21.492621Z","shell.execute_reply.started":"2025-05-22T19:05:09.858182Z","shell.execute_reply":"2025-05-22T19:05:21.491905Z"}},"outputs":[{"name":"stdout","text":"Phiên bản Keras API (thông qua tf.keras): 3.5.0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!cat /proc/cpuinfo | grep \"model name\" | uniq \n# Hoặc để xem số core\n!nproc ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:59:33.535913Z","iopub.execute_input":"2025-05-22T18:59:33.536271Z","iopub.status.idle":"2025-05-22T18:59:33.773679Z","shell.execute_reply.started":"2025-05-22T18:59:33.536241Z","shell.execute_reply":"2025-05-22T18:59:33.772865Z"}},"outputs":[{"name":"stdout","text":"model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n4\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!free -h \n# Hoặc chi tiết hơn\n!cat /proc/meminfo | grep MemTotal","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:00:22.805424Z","iopub.execute_input":"2025-05-22T19:00:22.805756Z","iopub.status.idle":"2025-05-22T19:00:23.085306Z","shell.execute_reply.started":"2025-05-22T19:00:22.805729Z","shell.execute_reply":"2025-05-22T19:00:23.084541Z"}},"outputs":[{"name":"stdout","text":"               total        used        free      shared  buff/cache   available\nMem:            31Gi       836Mi        23Gi       1.0Mi       6.9Gi        30Gi\nSwap:             0B          0B          0B\nMemTotal:       32873392 kB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:58:04.760970Z","iopub.execute_input":"2025-05-22T18:58:04.761387Z","iopub.status.idle":"2025-05-22T18:58:04.933902Z","shell.execute_reply.started":"2025-05-22T18:58:04.761350Z","shell.execute_reply":"2025-05-22T18:58:04.932229Z"}},"outputs":[{"name":"stdout","text":"Thu May 22 18:58:04 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   31C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport json\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw\nfrom typing import Tuple\n\nimport cv2\nimport json\nfrom tqdm.notebook import tqdm\n\n\nimport pandas as pd\nimport glob\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\nimport shutil \n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom typing import List, Tuple, Optional","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T01:23:03.884791Z","iopub.execute_input":"2025-05-29T01:23:03.885138Z","iopub.status.idle":"2025-05-29T01:23:04.830944Z","shell.execute_reply.started":"2025-05-29T01:23:03.885110Z","shell.execute_reply":"2025-05-29T01:23:04.830264Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"base_input_dir = \"/kaggle/input/btxrd-data/BTXRD/BTXRD\" \nimage_dir = os.path.join(base_input_dir, \"images\")\nannotation_dir = os.path.join(base_input_dir, \"Annotations\")\nexcel_path = \"/kaggle/input/btxrd-data/classification.xlsx\"\n\n\n# output_dir = \"/kaggle/working/btxrd-v2.2\"\n# output_image_dir = os.path.join(output_dir, \"images\")\n# output_anno_dir = os.path.join(output_dir, \"Annotations\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.430179Z","iopub.status.idle":"2025-05-13T01:54:09.431135Z","shell.execute_reply.started":"2025-05-13T01:54:09.430368Z","shell.execute_reply":"2025-05-13T01:54:09.430415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Đọc file Excel\n# file_path = '/kaggle/input/btxrd-data/classification.xlsx'\ndf = pd.read_excel(excel_path)\n\n# Hiển thị 10 dòng đầu tiên\ndf.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.432391Z","iopub.status.idle":"2025-05-13T01:54:09.433268Z","shell.execute_reply.started":"2025-05-13T01:54:09.432557Z","shell.execute_reply":"2025-05-13T01:54:09.432619Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Xử lý ảnh**","metadata":{}},{"cell_type":"code","source":"# in 30 ảnh trước xử lý\nnum_images_to_show = 30\nimages_per_row = 5  # Số ảnh mỗi hàng\nmask_color = [255, 0, 0]  # Red\n\ndef create_mask(img_size: Tuple[int, int], ann_path: str) -> np.ndarray:\n    mask = Image.new('L', img_size, 0)\n    if os.path.exists(ann_path):\n        try:\n            with open(ann_path, 'r') as f:\n                data = json.load(f)\n                for shape in data.get('shapes', []):\n                    points = shape.get('points', [])\n                    polygon_points = [(int(x), int(y)) for x, y in points]\n                    if polygon_points:\n                        ImageDraw.Draw(mask).polygon(polygon_points, outline=1, fill=1)\n        except Exception as e:\n            print(f\"Lỗi annotation {ann_path}: {e}\")\n    return np.array(mask)\n\n# Lấy danh sách tất cả ảnh trong thư mục\nall_filenames = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# Chọn ngẫu nhiên 30 ảnh\nselected_filenames = random.sample(all_filenames, min(num_images_to_show, len(all_filenames)))\n\n# Plot ảnh với mask\nplt.figure(figsize=(18, 18))  # Tăng kích thước ảnh\nfor i, fname in enumerate(selected_filenames):\n    img_path = os.path.join(image_dir, fname)\n    ann_fname = os.path.splitext(fname)[0] + '.json'\n    ann_path = os.path.join(annotation_dir, ann_fname)\n\n    try:\n        img_pil = Image.open(img_path).convert('L')\n        img_np = np.array(img_pil)\n\n        mask_np = create_mask(img_pil.size, ann_path)\n        color_img = np.stack([img_np] * 3, axis=-1)\n        color_img[mask_np == 1] = mask_color\n\n        # Chia bố cục thành 6 hàng và 5 cột (số ảnh mỗi hàng là 5)\n        plt.subplot(6, 5, i + 1)\n        plt.imshow(color_img)\n        plt.axis('off')  # Tắt trục\n    except Exception as e:\n        print(f\"Lỗi khi xử lý {fname}: {e}\")\n        continue\n\n# Loại bỏ khoảng trống giữa các ảnh\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.434296Z","iopub.status.idle":"2025-05-13T01:54:09.435136Z","shell.execute_reply.started":"2025-05-13T01:54:09.434455Z","shell.execute_reply":"2025-05-13T01:54:09.434496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nTARGET_SIZE = 512\n\n# base_input_dir = \"/kaggle/input/btxrd-data/BTXRD/BTXRD\" # Đường dẫn gốc chứa ảnh và annotation\n# image_dir = os.path.join(base_input_dir, \"images\")      # Thư mục chứa ảnh gốc\n# annotation_dir = os.path.join(base_input_dir, \"Annotations\") # Thư mục chứa annotation gốc\n\noutput_dir = \"/kaggle/working/btxrd-v2.2\"\noutput_image_dir = os.path.join(output_dir, \"images\")\noutput_anno_dir = os.path.join(output_dir, \"annotations\")\n\nos.makedirs(output_image_dir, exist_ok=True)\nos.makedirs(output_anno_dir, exist_ok=True)\n\nMAX_VISUALIZATIONS = 5 # Số lượng ảnh tối đa để trực quan hóa\nvisualized_count = 0\n\n\ndef get_bounding_box(points):\n    if not points:\n        return None\n    points_array = np.array(points)\n    xmin = int(np.min(points_array[:, 0]))\n    ymin = int(np.min(points_array[:, 1]))\n    xmax = int(np.max(points_array[:, 0]))\n    ymax = int(np.max(points_array[:, 1]))\n    # Đảm bảo tọa độ không âm\n    xmin = max(0, xmin)\n    ymin = max(0, ymin)\n    return (xmin, ymin, xmax, ymax)\n\ntry:\n    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg'))]\n    total_images = len(image_files)\n    if total_images == 0:\n        print(f\"Không tìm thấy file ảnh nào trong: {image_dir}\")\n        exit()\n    print(f\"Tìm thấy {total_images} ảnh để xử lý.\")\nexcept FileNotFoundError:\n    print(f\"Không tìm thấy thư mục ảnh: {image_dir}\")\n    exit()\n\nprint(f\"Bắt đầu xử lý ảnh và lưu vào: {output_dir}\")\n# Sử dụng tqdm để hiển thị thanh tiến trình\nfor file in tqdm(image_files, desc=\"Processing Images\"):\n    img_path = os.path.join(image_dir, file)\n    anno_filename = file.rsplit('.', 1)[0] + '.json'\n    anno_path = os.path.join(annotation_dir, anno_filename)\n\n    # Đọc ảnh gốc\n    img_orig = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    if img_orig is None:\n        # print(f\"Không thể đọc ảnh: {file}\"\n        continue\n    orig_height, orig_width = img_orig.shape[:2]\n\n    # Đọc annotation gốc \n    annotation_orig = None\n    has_annotation = os.path.exists(anno_path)\n    if has_annotation:\n        try:\n            with open(anno_path, \"r\", encoding=\"utf-8\") as f:\n                annotation_orig = json.load(f)\n        except Exception as e:\n            # print(f\"Lỗi khi đọc annotation {anno_filename}: {e}\")\n            has_annotation = False # Coi như không có nếu đọc lỗi\n\n    img_to_draw_orig = None\n    img_to_draw_padded = None\n    original_bboxes = []\n    transformed_bboxes = []\n\n    should_visualize = has_annotation and (visualized_count < MAX_VISUALIZATIONS)\n\n    if should_visualize:\n        img_to_draw_orig = cv2.cvtColor(img_orig, cv2.COLOR_GRAY2BGR) # Chuyển sang BGR để vẽ màu\n        if annotation_orig and \"shapes\" in annotation_orig:\n             for shape in annotation_orig[\"shapes\"]:\n                if shape.get(\"shape_type\") == \"rectangle\" and \"points\" in shape and len(shape[\"points\"]) == 2:\n                     # LabelMe rectangle format uses [top-left, bottom-right]\n                     p1 = shape[\"points\"][0]\n                     p2 = shape[\"points\"][1]\n                     xmin = int(min(p1[0], p2[0]))\n                     ymin = int(min(p1[1], p2[1]))\n                     xmax = int(max(p1[0], p2[0]))\n                     ymax = int(max(p1[1], p2[1]))\n                     bbox = (max(0, xmin), max(0, ymin), xmax, ymax)\n                     original_bboxes.append(bbox)\n                     cv2.rectangle(img_to_draw_orig, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 2) # Vẽ màu đỏ (BGR)\n                elif shape.get(\"shape_type\") in [\"polygon\", \"linestrip\", \"point\"] and \"points\" in shape and shape[\"points\"]:\n                     # Lấy bounding box bao quanh các loại shape khác\n                     bbox = get_bounding_box(shape[\"points\"])\n                     if bbox:\n                        original_bboxes.append(bbox)\n                        cv2.rectangle(img_to_draw_orig, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 2) # Red\n\n    # Resize ảnh với padding để giữ tỉ lệ\n    # Tính tỉ lệ resize để cạnh dài nhất bằng TARGET_SIZE\n    scale = TARGET_SIZE / max(orig_height, orig_width)\n    new_width = int(orig_width * scale)\n    new_height = int(orig_height * scale)\n\n    # Đảm bảo kích thước mới không lớn hơn TARGET_SIZE\n    new_width = min(new_width, TARGET_SIZE)\n    new_height = min(new_height, TARGET_SIZE)\n\n    # Resize ảnh\n    img_resized = cv2.resize(img_orig, (new_width, new_height), interpolation=cv2.INTER_AREA)\n\n    # Tính toán padding\n    pad_h = TARGET_SIZE - new_height\n    pad_w = TARGET_SIZE - new_width\n    top = pad_h // 2\n    bottom = pad_h - top\n    left = pad_w // 2\n    right = pad_w - left\n\n    # Thêm padding\n    # Sử dụng giá trị 0 (màu đen) cho padding vì ảnh là grayscale\n    padded_img = cv2.copyMakeBorder(img_resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n\n    # Lưu ảnh đã xử lý\n    output_img_path = os.path.join(output_image_dir, file)\n    try:\n        # Đảm bảo kích thước cuối cùng đúng là TARGET_SIZE x TARGET_SIZE\n        if padded_img.shape[0] != TARGET_SIZE or padded_img.shape[1] != TARGET_SIZE:\n             # Nếu có sai lệch nhỏ do làm tròn, resize lại lần cuối\n             padded_img = cv2.resize(padded_img, (TARGET_SIZE, TARGET_SIZE), interpolation=cv2.INTER_AREA)\n             # print(f\"Final resize needed for {file}. Original: ({orig_width}x{orig_height}), Resized: ({new_width}x{new_height}), Padded: {padded_img.shape[:2]}\")\n\n\n        cv2.imwrite(output_img_path, padded_img)\n    except Exception as e:\n        # print(f\"Lỗi khi lưu ảnh {output_img_path}: {e}\") # Bỏ comment nếu cần debug\n        continue # Bỏ qua ảnh này nếu không lưu được\n\n    # Xử lý và lưu annotation\n    if has_annotation and annotation_orig:\n        # Tạo bản sao sâu để không ảnh hưởng annotation gốc\n        annotation_new = json.loads(json.dumps(annotation_orig))\n\n        if \"shapes\" in annotation_new:\n            new_shapes = [] # Tạo list mới để chứa các shape đã chuyển đổi\n            for shape in annotation_new[\"shapes\"]:\n                if \"points\" in shape and shape[\"points\"]:\n                    original_points = shape[\"points\"]\n                    new_points_transformed = []\n                    valid_shape = True\n                    for x, y in original_points:\n                        # Áp dụng tỉ lệ resize\n                        new_x = x * scale\n                        new_y = y * scale\n                        # Áp dụng padding offset\n                        new_x += left\n                        new_y += top\n\n                        # Kiểm tra xem điểm có nằm trong ảnh mới không\n                        # new_x = max(0, min(TARGET_SIZE - 1, new_x))\n                        # new_y = max(0, min(TARGET_SIZE - 1, new_y))\n                        new_points_transformed.append([new_x, new_y])\n\n                    # Cập nhật điểm trong shape\n                    shape[\"points\"] = new_points_transformed\n                    new_shapes.append(shape) # Thêm shape đã chuyển đổi vào list mới\n\n                    # Tính bbox mới để trực quan hóa\n                    if should_visualize:\n                        new_bbox = get_bounding_box(new_points_transformed)\n                        if new_bbox:\n                            # Đảm bảo bbox không vượt ra ngoài TARGET_SIZE\n                            xmin = max(0, min(TARGET_SIZE - 1, new_bbox[0]))\n                            ymin = max(0, min(TARGET_SIZE - 1, new_bbox[1]))\n                            xmax = max(0, min(TARGET_SIZE - 1, new_bbox[2]))\n                            ymax = max(0, min(TARGET_SIZE - 1, new_bbox[3]))\n                            # Chỉ thêm vào nếu bbox hợp lệ\n                            if xmax > xmin and ymax > ymin:\n                                transformed_bboxes.append((xmin, ymin, xmax, ymax))\n\n            # Cập nhật lại danh sách shapes và kích thước ảnh trong annotation\n            annotation_new[\"shapes\"] = new_shapes\n            annotation_new[\"imagePath\"] = file # Cập nhật tên file ảnh mới\n            annotation_new[\"imageWidth\"] = TARGET_SIZE\n            annotation_new[\"imageHeight\"] = TARGET_SIZE\n            \n            if \"imageData\" in annotation_new:\n                annotation_new[\"imageData\"] = None\n\n            # Lưu file annotation mới\n            output_annotation_path = os.path.join(output_anno_dir, anno_filename)\n            try:\n                with open(output_annotation_path, \"w\", encoding=\"utf-8\") as f:\n                    json.dump(annotation_new, f, indent=4, ensure_ascii=False)\n            except Exception as e:\n                # print(f\"Lỗi khi lưu annotation {anno_filename}: {e}\") # Bỏ comment nếu cần debug\n                pass # Bỏ qua nếu lưu lỗi\n\n            if should_visualize and img_to_draw_orig is not None:\n                # Chuyển ảnh đã padding sang BGR để vẽ màu\n                img_to_draw_padded = cv2.cvtColor(padded_img, cv2.COLOR_GRAY2BGR)\n                # Vẽ các bounding box đã biến đổi\n                for bbox in transformed_bboxes:\n                     # Đảm bảo tọa độ là số nguyên để vẽ\n                     pt1 = (int(bbox[0]), int(bbox[1]))\n                     pt2 = (int(bbox[2]), int(bbox[3]))\n                     cv2.rectangle(img_to_draw_padded, pt1, pt2, (0, 255, 0), 2) # Vẽ màu xanh lá (BGR)\n\n                # Hiển thị ảnh gốc và ảnh đã xử lý\n                fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\n                # Ảnh gốc với bbox gốc (màu đỏ)\n                axes[0].imshow(cv2.cvtColor(img_to_draw_orig, cv2.COLOR_BGR2RGB)) # Chuyển BGR sang RGB cho matplotlib\n                axes[0].set_title(f'Original: {file}\\nSize: {orig_width}x{orig_height}')\n                axes[0].axis('off')\n\n                # Ảnh đã xử lý với bbox mới (màu xanh)\n                axes[1].imshow(cv2.cvtColor(img_to_draw_padded, cv2.COLOR_BGR2RGB)) # Chuyển BGR sang RGB\n                axes[1].set_title(f'Processed (Resized & Padded)\\nSize: {TARGET_SIZE}x{TARGET_SIZE}')\n                axes[1].axis('off')\n\n                plt.suptitle(f\"Visualization {visualized_count + 1}/{MAX_VISUALIZATIONS}\")\n                plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Điều chỉnh layout để tiêu đề không bị che\n                plt.show()\n\n                visualized_count += 1\n\nprint(f\"Xử lý {total_images} ảnh.\")\nif visualized_count > 0:\n    print(f\"Hiển thị {visualized_count} ảnh trực quan hóa.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.436168Z","iopub.status.idle":"2025-05-13T01:54:09.436694Z","shell.execute_reply.started":"2025-05-13T01:54:09.436347Z","shell.execute_reply":"2025-05-13T01:54:09.436393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hiển thị random 30 hình sau khi xử lý ảnh\n\n\n# Cấu hình\nimage_dir_test = '/kaggle/working/btxrd-v2.2/images'\nannotation_dir_test = '/kaggle/working/btxrd-v2.2/annotations'\n# Cấu hình\nnum_images_to_show = 30\nimages_per_row = 5  # Số ảnh mỗi hàng\nmask_color = [255, 0, 0]  # Red\n\ndef create_mask(img_size: Tuple[int, int], ann_path: str) -> np.ndarray:\n    mask = Image.new('L', img_size, 0)\n    if os.path.exists(ann_path):\n        try:\n            with open(ann_path, 'r') as f:\n                data = json.load(f)\n                for shape in data.get('shapes', []):\n                    points = shape.get('points', [])\n                    polygon_points = [(int(x), int(y)) for x, y in points]\n                    if polygon_points:\n                        ImageDraw.Draw(mask).polygon(polygon_points, outline=1, fill=1)\n        except Exception as e:\n            print(f\"Lỗi annotation {ann_path}: {e}\")\n    return np.array(mask)\n\n# Lấy danh sách tất cả ảnh trong thư mục\nall_filenames = [f for f in os.listdir(image_dir_test) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# Chọn ngẫu nhiên 30 ảnh\nselected_filenames = random.sample(all_filenames, min(num_images_to_show, len(all_filenames)))\n\n# Plot ảnh với mask\nplt.figure(figsize=(18, 18))  # Tăng kích thước ảnh\nfor i, fname in enumerate(selected_filenames):\n    img_path = os.path.join(image_dir_test, fname)\n    ann_fname = os.path.splitext(fname)[0] + '.json'\n    ann_path = os.path.join(annotation_dir_test, ann_fname)\n\n    try:\n        img_pil = Image.open(img_path).convert('L')\n        img_np = np.array(img_pil)\n\n        mask_np = create_mask(img_pil.size, ann_path)\n        color_img = np.stack([img_np] * 3, axis=-1)\n        color_img[mask_np == 1] = mask_color\n\n        # Chia bố cục thành 6 hàng và 5 cột (số ảnh mỗi hàng là 5)\n        plt.subplot(6, 5, i + 1)\n        plt.imshow(color_img)\n        plt.axis('off')  # Tắt trục\n    except Exception as e:\n        print(f\"Lỗi khi xử lý {fname}: {e}\")\n        continue\n\n# Loại bỏ khoảng trống giữa các ảnh\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.437653Z","iopub.status.idle":"2025-05-13T01:54:09.438769Z","shell.execute_reply.started":"2025-05-13T01:54:09.437797Z","shell.execute_reply":"2025-05-13T01:54:09.437838Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Chia tập dữ liệu**","metadata":{}},{"cell_type":"code","source":"output_split_dir = \"/kaggle/working/btxrd-v2.1\"\n\nANNOTATION_EXTENSION = \".json\"\n\nVAL_SIZE = 0.20   # 20% cho tập validation\nTRAIN_SIZE = 0.70 # 70% cho tập train\nTEST_SIZE = 1.0 - VAL_SIZE - TRAIN_SIZE\n\nRANDOM_STATE = 42","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.439717Z","iopub.status.idle":"2025-05-13T01:54:09.440264Z","shell.execute_reply.started":"2025-05-13T01:54:09.439865Z","shell.execute_reply":"2025-05-13T01:54:09.439927Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Đọc Dữ liệu Phân loại từ Excel\ntry:\n    df_classification = pd.read_excel(excel_path)\n    required_columns = ['image_id', 'tumor_type', 'image_filename']\n    if not all(col in df_classification.columns for col in required_columns):\n        missing = [col for col in required_columns if col not in df_classification.columns]\n        raise ValueError(f\"File Excel thiếu các cột bắt buộc: {missing}\")\n\n    df_classification['image_id'] = df_classification['image_id'].astype(str).str.strip()\n    df_classification['image_filename'] = df_classification['image_filename'].astype(str).str.strip()\n\n    print(f\"Đọc thành công {len(df_classification)} dòng\")\n    print(df_classification['tumor_type'].value_counts())\nexcept FileNotFoundError:\n    print(f\"Không tìm thấy file Excel tại {excel_path}\")\n    exit()\nexcept ValueError as ve:\n    print(f\"Lỗi dữ liệu trong file Excel: {ve}\")\n    exit()\nexcept Exception as e:\n    print(f\"không xác định khi đọc file Excel: {e}\")\n    exit()\n\ntry:\n    all_image_files = glob.glob(os.path.join(image_dir_test, \"*.*\"))\n    annotation_files = glob.glob(os.path.join(annotation_dir_test, f\"*{ANNOTATION_EXTENSION}\"))\n\n    image_basenames_actual = set(os.path.splitext(os.path.basename(f))[0] for f in all_image_files)\n    annotation_basenames_actual = set(os.path.splitext(os.path.basename(f))[0] for f in annotation_files)\n\n    print(f\"Tìm thấy {len(all_image_files)} tệp\")\n    print(f\"Tìm thấy {len(annotation_files)} tệp annotation\")\nexcept Exception as e:\n    print(f\"Lỗi khi quét thư mục ảnh hoặc annotation: {e}\")\n    exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.441610Z","iopub.status.idle":"2025-05-13T01:54:09.442492Z","shell.execute_reply.started":"2025-05-13T01:54:09.442254Z","shell.execute_reply":"2025-05-13T01:54:09.442305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"excel_image_ids = set(df_classification['image_id'])\nvalid_ids = list(excel_image_ids.intersection(image_basenames_actual).intersection(annotation_basenames_actual))\n\nif not valid_ids:\n    print(\"Không tìm thấy dữ liệu hợp lệ nào.\")\n    exit()\ndf_filtered = df_classification[df_classification['image_id'].isin(valid_ids)].copy()\ndf_filtered = df_filtered.drop_duplicates(subset=['image_id'])\nfilename_map = pd.Series(df_filtered.image_filename.values, index=df_filtered.image_id).to_dict()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.443533Z","iopub.status.idle":"2025-05-13T01:54:09.444176Z","shell.execute_reply.started":"2025-05-13T01:54:09.443693Z","shell.execute_reply":"2025-05-13T01:54:09.443733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Chuẩn bị dữ liệu (X=IDs, y=Labels) cho việc chia\nX = df_filtered['image_id'].tolist() # Danh sách ID ảnh \ny = df_filtered['tumor_type'].tolist() # Danh sách nhãn tương ứng\n\n# Chia Lần 1 (Train+Val / Test)\nX_train_val, X_test, y_train_val, y_test = [], [], [], []\nif len(X) < 2:\n    print(\"Không đủ mẫu dữ liệu (< 2) để thực hiện chia.\")\n    exit()\nif TEST_SIZE <= 0 or TEST_SIZE >= 1:\n     print(f\"Tỷ lệ Test ({TEST_SIZE:.2f}) không hợp lệ. Toàn bộ dữ liệu sẽ là Train+Val.\")\n     X_train_val, y_train_val = X, y\nelse:\n    try:\n        unique_classes_total, counts_total = np.unique(y, return_counts=True)\n        stratify_option_1 = y\n        if len(unique_classes_total) < 2:\n            print(\"Chỉ có 1 lớp. Chia ngẫu nhiên cho Test.\")\n            stratify_option_1 = None\n        elif np.any(counts_total < 2):\n             print(f\"Có lớp < 2 mẫu. Chia ngẫu nhiên cho Test.\")\n             stratify_option_1 = None\n\n        X_train_val, X_test, y_train_val, y_test = train_test_split(\n            X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=stratify_option_1\n        )\n        print(f\"Chia lần 1: {len(X_train_val)} Train+Val, {len(X_test)} Test.\")\n        print(\"Phân phối 'tumor_type' trong Test:\", sorted(Counter(y_test).items()))\n    except ValueError as e:\n         print(f\"Lỗi khi chia lần 1 (Test): {e}. Thoát.\")\n         exit()\n\n\n# Chia lần 2 (Train / Validation)\nX_train, X_val, y_train, y_val = [], [], [], []\nif not X_train_val:\n     print(\"Tập Train+Val rỗng.\")\nelif len(X_train_val) == 1:\n     print(\"Tập Train+Val chỉ có 1 mẫu -> vào Train.\")\n     X_train, y_train = X_train_val, y_train_val\nelif VAL_SIZE <= 0 or VAL_SIZE >= 1:\n     print(f\"Tỷ lệ Val ({VAL_SIZE:.4f}) không hợp lệ. Toàn bộ Train+Val -> Train.\")\n     X_train, y_train = X_train_val, y_train_val\nelse:\n    try:\n        unique_classes_tv, counts_tv = np.unique(y_train_val, return_counts=True)\n        stratify_option_2 = y_train_val\n        if len(unique_classes_tv) < 2:\n            print(\"Train+Val chỉ còn 1 lớp. Chia ngẫu nhiên cho Val.\")\n            stratify_option_2 = None\n        elif np.any(counts_tv < 2):\n             print(f\"Có lớp < 2 mẫu trong Train+Val. Chia ngẫu nhiên cho Val.\")\n             stratify_option_2 = None\n\n        X_train, X_val, y_train, y_val = train_test_split(\n            X_train_val, y_train_val, test_size=VAL_SIZE,\n            random_state=RANDOM_STATE, stratify=stratify_option_2\n        )\n        print(f\"Chia lần 2: {len(X_train)} Train, {len(X_val)} Validation.\")\n        print(\"Phân phối 'tumor_type' trong Train:\", sorted(Counter(y_train).items()))\n        print(\"Phân phối 'tumor_type' trong Validation:\", sorted(Counter(y_val).items()))\n    except ValueError as e:\n        print(f\"Lỗi khi chia lần 2 (Validation): {e}. Toàn bộ Train+Val -> Train.\")\n        X_train, y_train = X_train_val, y_train_val # Gán lại vào Train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.445355Z","iopub.status.idle":"2025-05-13T01:54:09.445873Z","shell.execute_reply.started":"2025-05-13T01:54:09.445521Z","shell.execute_reply":"2025-05-13T01:54:09.445564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# kết quả sau khi chia\ntotal_ids_split = len(X_train) + len(X_val) + len(X_test)\noriginal_valid_count = len(df_filtered)\n\nprint(f\"Tổng số mẫu hợp lệ ban đầu: {original_valid_count}\")\nprint(f\"Tổng số IDs được chia vào các tập: {total_ids_split}\")\nif total_ids_split != original_valid_count:\n     print(f\"Số ID được chia ({total_ids_split}) không khớp số ID hợp lệ ({original_valid_count}). Kiểm tra logic chia.\")\n\nprint(f\"Train set IDs:      {len(X_train):>5}\")\nprint(f\"Validation set IDs: {len(X_val):>5}\")\nprint(f\"Test set IDs:       {len(X_test):>5}\")\n\nif total_ids_split > 0:\n    print(f\"\\nTỷ lệ thực tế (dựa trên IDs):\")\n    print(f\"  Train: {len(X_train) / total_ids_split * 100:>6.1f}%\")\n    print(f\"  Val:   {len(X_val) / total_ids_split * 100:>6.1f}%\")\n    print(f\"  Test:  {len(X_test) / total_ids_split * 100:>6.1f}%\")\n\nprint(\"\\nPhân phối 'tumor_type' cuối cùng (dựa trên IDs đã chia):\")\nprint(f\"Train:      {sorted(Counter(y_train).items())}\")\nprint(f\"Validation: {sorted(Counter(y_val).items())}\")\nprint(f\"Test:       {sorted(Counter(y_test).items())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.447098Z","iopub.status.idle":"2025-05-13T01:54:09.447781Z","shell.execute_reply.started":"2025-05-13T01:54:09.447359Z","shell.execute_reply":"2025-05-13T01:54:09.447402Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Huấn luyện mô hình**","metadata":{}},{"cell_type":"code","source":"!pip install wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T00:26:42.422684Z","iopub.execute_input":"2025-05-22T00:26:42.422966Z","iopub.status.idle":"2025-05-22T00:26:49.207863Z","shell.execute_reply.started":"2025-05-22T00:26:42.422940Z","shell.execute_reply":"2025-05-22T00:26:49.206145Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.11.0a2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.29.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# --- Cấu hình ---\nimport os # Thêm import os nếu chưa có\nimport numpy as np # Thêm import numpy nếu dùng trong tính mean/std\nimport pandas as pd # Thêm import pandas nếu dùng trong tải metadata\nfrom tqdm import tqdm # Thêm import tqdm\nimport tensorflow as tf # Thêm import tensorflow\nfrom PIL import Image, ImageDraw # Thêm import PIL\nimport json # Thêm import json\nimport matplotlib.pyplot as plt # Thêm import matplotlib nếu dùng plot_image\n\nINPUT_DATA_ROOT = '/kaggle/input/btxrd-data' # THAY ĐỔI NẾU MÔI TRƯỜNG CỦA BẠN KHÁC\nBASE_DATA_DIR = os.path.join(INPUT_DATA_ROOT, 'btxrd-v2.1')\nCLASSIFICATION_FILE = os.path.join(INPUT_DATA_ROOT, 'classification.xlsx')\nIMAGE_SUBDIR_NAME = 'images'\nANNOTATION_SUBDIR_NAME = 'annotations'\n\n# Tham số Model & Huấn luyện\nTARGET_SIZE = 512\nN_CLASSES = 2 # 2 lớp: 0 (nền), 1 (khối u)\nBATCH_SIZE = 4 # Sẽ được dùng trong config wandb\nBUFFER_SIZE = 100 # Dùng cho dataset.shuffle\nEPOCHS = 300 # Sẽ được dùng trong config wandb và vòng lặp for\nLEARNING_RATE = 1e-4 # Sẽ được dùng trong config wandb\nL2_REG_FACTOR = 1e-5\nDROPOUT_RATE = 0.3\n\n# --- Cải tiến để tăng IoU ---\nUSE_COMBINED_LOSS = True\nDICE_LOSS_WEIGHT = 0.6\nUSE_FOCAL_LOSS_IN_COMBINED = True\nFOCAL_LOSS_ALPHA = 0.25\nFOCAL_LOSS_GAMMA = 2.0\n\nUSE_ATTENTION_UNET = False\n\n# APPLY_POST_PROCESSING, POST_PROCESSING_KERNEL_SIZE, MIN_AREA_POST_PROCESSING\n# thường dùng sau huấn luyện, không trực tiếp ảnh hưởng đến vòng lặp huấn luyện này\n\nMODEL_CHECKPOINT_BASENAME = \"unet_model\"\nTENSORBOARD_LOG_DIR = \"./logs_unet_iou_focused\"\n\n# --- Các hằng số cho callback Keras tiêu chuẩn ---\nPATIENCE_EARLY_STOPPING = 35\nPATIENCE_REDUCE_LR = 12\nMONITOR_METRIC_CB = 'val_dice_coef_metric_tumor' # QUAN TRỌNG: Phải khớp với key trong history.history\n\n# --- Cấu hình WandB ---\nWANDB_PROJECT_NAME = \"btxrd-project\" # Đặt tên project của bạn trên WandB\nWANDB_ENTITY = \"nganltt2333\" # Đặt entity của bạn\nWANDB_API_KEY = \"2b7e633df37247dd52582a893eecab6314151a62\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T01:23:12.120545Z","iopub.execute_input":"2025-05-29T01:23:12.121157Z","iopub.status.idle":"2025-05-29T01:23:12.127307Z","shell.execute_reply.started":"2025-05-29T01:23:12.121125Z","shell.execute_reply":"2025-05-29T01:23:12.126586Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def get_valid_paths(base_dir: str, split_type: str, img_filename_with_ext: str) -> Optional[Tuple[str, str]]:\n    split_dir = os.path.join(base_dir, split_type); image_dir_path = os.path.join(split_dir, IMAGE_SUBDIR_NAME); annotation_dir_path = os.path.join(split_dir, ANNOTATION_SUBDIR_NAME)\n    img_path = os.path.join(image_dir_path, img_filename_with_ext); base_name = os.path.splitext(img_filename_with_ext)[0]; json_filename = base_name + '.json'\n    json_path = os.path.join(annotation_dir_path, json_filename)\n    if os.path.exists(img_path) and os.path.exists(json_path): return img_path, json_path\n    return None\n\ndef create_mask_pil(mask_size: Tuple[int, int], json_path: str) -> Image.Image:\n    if not os.path.exists(json_path): return Image.new('L', (mask_size[1], mask_size[0]), 0)\n    mask = Image.new('L', (mask_size[1], mask_size[0]), 0)\n    try:\n        with open(json_path, 'r') as f: data = json.load(f)\n        if 'shapes' not in data or not isinstance(data['shapes'], list) or not data['shapes']: return mask\n        for shape in data['shapes']:\n             if 'points' in shape and isinstance(shape['points'], list):\n                  polygon = [tuple(point) for point in shape['points']]\n                  if len(polygon) >= 3: ImageDraw.Draw(mask).polygon(polygon, outline=255, fill=255)\n    except (json.JSONDecodeError, Exception): return Image.new('L', (mask_size[1], mask_size[0]), 0)\n    return mask\n\ndef plot_image(ax: plt.Axes, image_data: np.ndarray, title: str, cmap='gray'):\n    if image_data.ndim == 2 or (image_data.ndim == 3 and image_data.shape[2] == 1): ax.imshow(image_data.squeeze(), cmap=cmap)\n    else: ax.imshow(image_data)\n    ax.set_title(title, fontsize=10); ax.axis('off')\n\nall_image_paths = []; all_mask_paths = []; all_types = []\ntry:\n    if not os.path.exists(CLASSIFICATION_FILE): raise FileNotFoundError(f\"Không tìm thấy file phân loại tại {CLASSIFICATION_FILE}\")\n    if not os.path.isdir(BASE_DATA_DIR): raise FileNotFoundError(f\"Không tìm thấy thư mục dữ liệu cơ sở: {BASE_DATA_DIR}\")\n    df_classification = pd.read_excel(CLASSIFICATION_FILE)\n    required_cols = ['image_filename', 'type']\n    if not all(col in df_classification.columns for col in required_cols): raise ValueError(f\"File Excel phải chứa các cột: {required_cols}\")\n    for index, row in tqdm(df_classification.iterrows(), total=len(df_classification), desc=\"Kiểm tra file\"):\n        img_filename_with_ext = row['image_filename']; file_type = row['type']\n        if pd.isna(img_filename_with_ext) or pd.isna(file_type) or file_type not in ['train', 'val', 'test']: continue\n        paths = get_valid_paths(BASE_DATA_DIR, str(file_type).lower(), str(img_filename_with_ext))\n        if paths: img_path, json_path = paths; all_image_paths.append(img_path); all_mask_paths.append(json_path); all_types.append(str(file_type).lower())\n    if not all_image_paths: print(\"\\nLỗi: Không tìm thấy cặp ảnh-chú thích hợp lệ nào.\"); exit()\n    df_paths = pd.DataFrame({'image_path': all_image_paths, 'mask_path': all_mask_paths, 'type': all_types})\n    df_train = df_paths[df_paths['type'] == 'train'].reset_index(drop=True); df_val = df_paths[df_paths['type'] == 'val'].reset_index(drop=True); df_test = df_paths[df_paths['type'] == 'test'].reset_index(drop=True)\n    train_image_paths = df_train['image_path'].tolist(); train_mask_paths = df_train['mask_path'].tolist()\n    val_image_paths = df_val['image_path'].tolist(); val_mask_paths = df_val['mask_path'].tolist()\n    test_image_paths = df_test['image_path'].tolist(); test_mask_paths = df_test['mask_path'].tolist()\n    print(f\"\\nPhân chia dữ liệu: Train({len(train_image_paths)}), Val({len(val_image_paths)}), Test({len(test_image_paths)})\")\n    if not train_image_paths: print(\"Cảnh báo: Tập huấn luyện rỗng!\"); exit()\nexcept Exception as e: print(f\"Lỗi khi tải siêu dữ liệu: {e}\"); import traceback; traceback.print_exc(); exit()\n\n# Tính toán Mean/Std\nmean_pixel = 0.5; std_pixel = 0.1\nnum_train_images = len(train_image_paths)\nif num_train_images > 0:\n    print(\"Đang tính toán Mean/Std...\")\n    pixel_sum = 0.0; pixel_sum_sq = 0.0; total_pixels_calculated = 0; processed_count = 0\n    sample_size_for_stats = min(num_train_images, 250) # Tăng nhẹ sample size\n    sampled_train_paths = np.random.choice(train_image_paths, size=sample_size_for_stats, replace=False)\n    for img_path in tqdm(sampled_train_paths, desc=\"Tính Mean/Std\"):\n        try:\n            img_bytes = tf.io.read_file(img_path); img = tf.io.decode_image(img_bytes, channels=1, expand_animations=False, dtype=tf.float32)\n            img = tf.image.resize(img, [TARGET_SIZE, TARGET_SIZE])\n            pixel_sum += tf.reduce_sum(img).numpy(); pixel_sum_sq += tf.reduce_sum(tf.square(img)).numpy()\n            total_pixels_calculated += (TARGET_SIZE * TARGET_SIZE); processed_count += 1\n        except Exception: pass\n    if processed_count > 0 and total_pixels_calculated > 0:\n        mean_pixel = pixel_sum / total_pixels_calculated; variance = (pixel_sum_sq / total_pixels_calculated) - (mean_pixel ** 2)\n        std_pixel = np.sqrt(max(variance, 1e-7)); print(f\"Mean: {mean_pixel:.4f}, Std Dev: {std_pixel:.4f}\")\n        if std_pixel < 1e-4: std_pixel = 0.1; print(\"Std Dev quá thấp, dùng mặc định 0.1.\")\n    else: print(f\"Cảnh báo: Không tính được mean/std, dùng mặc định.\")\nstd_pixel = max(std_pixel, 1e-7)\n\n# Pipeline Dữ liệu TensorFlow\ndef load_mask_from_json_py(json_path_bytes):\n    json_path = json_path_bytes.numpy().decode('utf-8'); pil_mask = create_mask_pil((TARGET_SIZE, TARGET_SIZE), json_path)\n    mask_np = np.array(pil_mask, dtype=np.uint8); mask_np = (mask_np > 128).astype(np.uint8)\n    return mask_np\n\n@tf.function\ndef load_and_preprocess(image_path, mask_json_path):\n    img_bytes = tf.io.read_file(image_path)\n    try: img = tf.io.decode_image(img_bytes, channels=1, expand_animations=False, dtype=tf.float32)\n    except tf.errors.InvalidArgumentError:\n        try: img = tf.image.decode_png(img_bytes, channels=1, dtype=tf.uint8); img = tf.cast(img, tf.float32) / 255.0\n        except tf.errors.InvalidArgumentError: img = tf.image.decode_jpeg(img_bytes, channels=1); img = tf.cast(img, tf.float32) / 255.0\n    img = tf.image.resize(img, [TARGET_SIZE, TARGET_SIZE]); img.set_shape([TARGET_SIZE, TARGET_SIZE, 1])\n    mask_np_binary = tf.py_function(func=load_mask_from_json_py, inp=[mask_json_path], Tout=tf.uint8)\n    mask_np_binary.set_shape([TARGET_SIZE, TARGET_SIZE])\n    mask_onehot = tf.one_hot(tf.cast(mask_np_binary, tf.int32), depth=N_CLASSES, dtype=tf.float32)\n    mask_onehot.set_shape([TARGET_SIZE, TARGET_SIZE, N_CLASSES])\n    img = (img - mean_pixel) / std_pixel\n    return img, mask_onehot\n\n@tf.function\ndef augment_data_tf(image, mask_onehot):\n    combined = tf.concat([image, tf.cast(mask_onehot, image.dtype)], axis=-1) # Nối image và mask (đã cast về dtype của image)\n    if tf.random.uniform(()) > 0.5: combined = tf.image.flip_left_right(combined)\n    if tf.random.uniform(()) > 0.5: combined = tf.image.flip_up_down(combined)\n    k_rot = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n    combined = tf.image.rot90(combined, k=k_rot)\n    img_aug = combined[..., :1]\n    mask_aug = tf.cast(combined[..., 1:], tf.float32)\n    img_aug = tf.image.random_brightness(img_aug, max_delta=0.25)\n    img_aug = tf.image.random_contrast(img_aug, lower=0.7, upper=1.3)\n    if tf.random.uniform(()) > 0.3:\n        scale = tf.random.uniform((), 0.8, 1.2)\n        new_height = tf.cast(TARGET_SIZE * scale, tf.int32)\n        new_width = tf.cast(TARGET_SIZE * scale, tf.int32)\n        img_scaled = tf.image.resize(img_aug, [new_height, new_width], method=tf.image.ResizeMethod.BILINEAR)\n        mask_scaled = tf.image.resize(mask_aug, [new_height, new_width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        img_aug = tf.image.resize_with_crop_or_pad(img_scaled, TARGET_SIZE, TARGET_SIZE)\n        mask_aug = tf.image.resize_with_crop_or_pad(mask_scaled, TARGET_SIZE, TARGET_SIZE)\n    img_aug = tf.clip_by_value(img_aug, -3.0, 3.0)\n    img_aug.set_shape([TARGET_SIZE, TARGET_SIZE, 1])\n    mask_aug.set_shape([TARGET_SIZE, TARGET_SIZE, N_CLASSES])\n    return img_aug, mask_aug\n\ndef create_dataset(image_paths, mask_paths, is_training=True):\n    if not image_paths or not mask_paths: return tf.data.Dataset.from_tensor_slices(([], [])).batch(BATCH_SIZE)\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n    if is_training: dataset = dataset.shuffle(buffer_size=min(BUFFER_SIZE, len(image_paths)), reshuffle_each_iteration=True)\n    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n    if is_training: dataset = dataset.map(augment_data_tf, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=(is_training if len(image_paths) >= BATCH_SIZE else False))\n    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return dataset\n\ntrain_ds = create_dataset(train_image_paths, train_mask_paths, is_training=True)\nval_ds = create_dataset(val_image_paths, val_mask_paths, is_training=False)\ntest_ds = create_dataset(test_image_paths, test_mask_paths, is_training=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T01:23:24.005774Z","iopub.execute_input":"2025-05-29T01:23:24.006124Z","iopub.status.idle":"2025-05-29T01:23:43.761732Z","shell.execute_reply.started":"2025-05-29T01:23:24.006098Z","shell.execute_reply":"2025-05-29T01:23:43.761093Z"}},"outputs":[{"name":"stderr","text":"Kiểm tra file: 100%|██████████| 3746/3746 [00:14<00:00, 262.30it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nPhân chia dữ liệu: Train(1344), Val(336), Test(187)\nĐang tính toán Mean/Std...\n","output_type":"stream"},{"name":"stderr","text":"Tính Mean/Std: 100%|██████████| 250/250 [00:03<00:00, 73.26it/s] \n","output_type":"stream"},{"name":"stdout","text":"Mean: 0.1964, Std Dev: 0.2387\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# UNET\nclass AttentionGate(layers.Layer):\n    def __init__(self, F_g, F_l, F_int, **kwargs): super(AttentionGate, self).__init__(**kwargs); self.W_g = layers.Conv2D(F_int, 1, padding='same', kernel_initializer='he_normal'); self.W_x = layers.Conv2D(F_int, 1, padding='same', kernel_initializer='he_normal'); self.psi = layers.Conv2D(1, 1, padding='same', kernel_initializer='he_normal', activation='sigmoid'); self.relu = layers.Activation('relu')\n    def call(self, g, x): g1 = self.W_g(g); x1 = self.W_x(x); psi_input = self.relu(g1 + x1); alpha = self.psi(psi_input); return x * alpha\ndef conv_block(inputs, num_filters, l2_reg, dropout):\n    x = layers.Conv2D(num_filters, 3, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(inputs); x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n    if dropout > 0: x = layers.Dropout(dropout)(x)\n    x = layers.Conv2D(num_filters, 3, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x); x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n    return x\ndef encoder_block(inputs, num_filters, l2_reg, dropout, pool=True): c = conv_block(inputs, num_filters, l2_reg, dropout); p = layers.MaxPooling2D(2)(c) if pool else None; return c, p\ndef decoder_block(inputs, skip_features, num_filters, l2_reg, dropout, use_attention):\n    x = layers.Conv2DTranspose(num_filters, 2, strides=2, padding='same')(inputs)\n    if use_attention and skip_features is not None: att_gate = AttentionGate(num_filters, skip_features.shape[-1], max(1, skip_features.shape[-1] // 2) ); skip_features = att_gate(g=x, x=skip_features)\n    if skip_features is not None: x = layers.Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters, l2_reg, dropout); return x\ndef build_unet(input_shape, n_classes=N_CLASSES, l2_reg=L2_REG_FACTOR, dropout=DROPOUT_RATE, use_attention=USE_ATTENTION_UNET):\n    filters = [64, 128, 256, 512, 1024]\n    inputs = keras.Input(shape=input_shape); skips = []; x = inputs\n    for f in filters[:-1]: s, p = encoder_block(x, f, l2_reg, dropout, pool=True); skips.append(s); x = p\n    x, _ = encoder_block(x, filters[-1], l2_reg, dropout*1.3, pool=False)\n    for i, f in reversed(list(enumerate(filters[:-1]))): x = decoder_block(x, skips[i], f, l2_reg, dropout, use_attention)\n    outputs = layers.Conv2D(n_classes, 1, padding='same', activation='softmax')(x)\n    return keras.Model(inputs, outputs, name=f\"{'Attention' if use_attention else ''}UNet_filters{filters[0]}\")\n\n# --- HÀM MẤT MÁT (LOSS FUNCTIONS) ---\nSMOOTH = 1e-6\ndef dice_coef(y_true_one_hot, y_pred_softmax):\n    y_true_f = tf.keras.backend.flatten(y_true_one_hot)\n    y_pred_f = tf.keras.backend.flatten(y_pred_softmax)\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    return (2. * intersection + SMOOTH) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + SMOOTH)\n\ndef dice_coef_metric_tumor(y_true, y_pred):\n    # y_true: (batch, H, W, N_CLASSES), y_pred: (batch, H, W, N_CLASSES)\n    return dice_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\ndice_coef_metric_tumor.__name__ = 'dice_coef_metric_tumor' # Khớp với `metrics_to_plot`\n\ndef dice_loss_tumor(y_true, y_pred):\n    return 1.0 - dice_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\n\ndef iou_coef(y_true_one_hot, y_pred_softmax):\n    y_true_f = tf.keras.backend.flatten(y_true_one_hot)\n    y_pred_f = tf.keras.backend.flatten(y_pred_softmax)\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n    return (intersection + SMOOTH) / (union + SMOOTH)\n\ndef iou_metric_tumor(y_true, y_pred):\n    return iou_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\niou_metric_tumor.__name__ = 'tumor_iou' # Khớp với `metrics_to_plot`\n\n# --- CÁC METRICS MỚI CHO LỚP TUMOR ---\ndef precision_recall_tumor_base(y_true, y_pred, metric_type):\n    if N_CLASSES < 2:\n        return tf.constant(0.0, dtype=tf.float32)\n\n    # Lấy kênh của lớp tumor (giả sử lớp 1 là tumor)\n    y_true_tumor = y_true[..., 1] # Ground truth cho lớp tumor (0 hoặc 1)\n    \n    # Chuyển đổi y_pred (softmax probabilities) thành dự đoán nhãn cứng (0 hoặc 1) cho lớp tumor\n    # Cách 1: Dựa trên xác suất cao nhất (argmax)\n    y_pred_labels = tf.argmax(y_pred, axis=-1) # Shape: (batch, H, W)\n    y_pred_tumor_binary = tf.cast(tf.equal(y_pred_labels, 1), tf.float32) # 1 nếu dự đoán là tumor (lớp 1), 0 nếu khác\n\n    # Cách 2: (Nếu chỉ có 2 lớp, có thể dùng ngưỡng 0.5 cho xác suất lớp tumor)\n    # y_pred_tumor_binary = tf.cast(y_pred[..., 1] > 0.5, tf.float32) # Chỉ phù hợp nếu N_CLASSES=2 và lớp 1 là tumor\n\n    # Flatten để tính toán\n    y_true_tumor_flat = tf.keras.backend.flatten(y_true_tumor)\n    y_pred_tumor_binary_flat = tf.keras.backend.flatten(y_pred_tumor_binary)\n\n    true_positives = tf.keras.backend.sum(y_true_tumor_flat * y_pred_tumor_binary_flat)\n    \n    if metric_type == 'precision':\n        predicted_positives = tf.keras.backend.sum(y_pred_tumor_binary_flat)\n        value = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n    elif metric_type == 'recall':\n        possible_positives = tf.keras.backend.sum(y_true_tumor_flat)\n        value = true_positives / (possible_positives + tf.keras.backend.epsilon())\n    else:\n        value = tf.constant(0.0, dtype=tf.float32)\n        \n    return value\n\ndef precision_tumor_metric(y_true, y_pred):\n    return precision_recall_tumor_base(y_true, y_pred, 'precision')\nprecision_tumor_metric.__name__ = 'precision_tumor' # Khớp với `metrics_to_plot`\n\ndef recall_tumor_metric(y_true, y_pred):\n    return precision_recall_tumor_base(y_true, y_pred, 'recall')\nrecall_tumor_metric.__name__ = 'recall_tumor' # Khớp với `metrics_to_plot`\n# --- KẾT THÚC METRICS MỚI ---\n\ndef categorical_focal_loss_wrapper(alpha=FOCAL_LOSS_ALPHA, gamma=FOCAL_LOSS_GAMMA):\n    def focal_loss_fn(y_true, y_pred):\n        epsilon = tf.keras.backend.epsilon(); y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n        cross_entropy = -y_true * tf.math.log(y_pred)\n        loss = alpha * tf.pow(1 - y_pred, gamma) * cross_entropy\n        return tf.reduce_mean(tf.reduce_sum(loss, axis=-1))\n    focal_loss_fn.__name__ = f'focal_loss_alpha{alpha}_gamma{gamma}'\n    return focal_loss_fn\n\ndef combined_loss_fn(y_true, y_pred, dice_w=DICE_LOSS_WEIGHT):\n    d_loss = dice_loss_tumor(y_true, y_pred)\n    if USE_FOCAL_LOSS_IN_COMBINED: ce_or_focal_loss = categorical_focal_loss_wrapper()(y_true, y_pred)\n    else: ce_or_focal_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true, y_pred))\n    return (dice_w * d_loss) + ((1.0 - dice_w) * ce_or_focal_loss)\ncombined_loss_fn.__name__ = f'combined_dice{DICE_LOSS_WEIGHT}_{\"focal\" if USE_FOCAL_LOSS_IN_COMBINED else \"cce\"}'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T01:24:15.198739Z","iopub.execute_input":"2025-05-29T01:24:15.199088Z","iopub.status.idle":"2025-05-29T01:24:15.218711Z","shell.execute_reply.started":"2025-05-29T01:24:15.199061Z","shell.execute_reply":"2025-05-29T01:24:15.217839Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import wandb # Đảm bảo wandb đã được import\nfrom datetime import datetime, timedelta # Để tạo tên run\n\n# --- Build và Compile Model ---\nmodel = build_unet((TARGET_SIZE, TARGET_SIZE, 1), N_CLASSES, L2_REG_FACTOR, DROPOUT_RATE, USE_ATTENTION_UNET)\noptimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n\nif USE_COMBINED_LOSS:\n    loss_to_use = combined_loss_fn\nelse:\n    if USE_FOCAL_LOSS_IN_COMBINED:\n        loss_to_use = categorical_focal_loss_wrapper(alpha=FOCAL_LOSS_ALPHA, gamma=FOCAL_LOSS_GAMMA)\n    else:\n        loss_to_use = tf.keras.losses.CategoricalCrossentropy()\n        loss_to_use.__name__ = \"categorical_crossentropy\" # Đặt tên nếu là object\n\nloss_name_str = loss_to_use.__name__ if hasattr(loss_to_use, '__name__') else \"custom_loss\"\n\n# --- Định nghĩa danh sách metrics cho model.compile() ---\n# Đảm bảo các tên này sẽ xuất hiện trong history.history\nmetrics_to_compile = [ # Đổi tên biến để tránh nhầm lẫn với list dùng để log\n    dice_coef_metric_tumor,\n    iou_metric_tumor,\n    precision_tumor_metric,\n    recall_tumor_metric,\n    tf.keras.metrics.MeanIoU(num_classes=N_CLASSES, name='mean_iou_all'),\n    tf.keras.metrics.CategoricalAccuracy(name='acc') # Keras có thể trả về 'acc' hoặc 'categorical_accuracy'\n]\n# Tạo list các tên metric thực tế sẽ dùng để log (từ history.history)\n# Điều này quan trọng để đảm bảo key khớp khi log thủ công\n# Keras trả về tên của hàm/object metric, hoặc tên bạn đặt trong tf.keras.metrics.Metric(name='...')\n# Nếu metric là một hàm, history.history sẽ dùng tên hàm.\n# Nếu là một object tf.keras.metrics.Metric, nó sẽ dùng thuộc tính .name\n# Đối với CategoricalAccuracy, Keras có thể dùng 'acc' hoặc 'categorical_accuracy'.\n# Chúng ta sẽ xử lý điều này linh hoạt hơn trong vòng lặp log.\n\n# Các tên metric cơ bản mà chúng ta muốn log, không bao gồm 'loss' và 'val_loss' (vì chúng luôn có)\n# và 'acc'/'val_acc' (sẽ xử lý riêng)\nmetric_names_to_log_manually = []\nfor m in metrics_to_compile:\n    if hasattr(m, 'name'):\n        metric_names_to_log_manually.append(m.name)\n    elif hasattr(m, '__name__'):\n        metric_names_to_log_manually.append(m.__name__)\n# Loại bỏ 'acc' nếu có, vì sẽ xử lý riêng\nif 'acc' in metric_names_to_log_manually:\n    metric_names_to_log_manually.remove('acc')\nif 'categorical_accuracy' in metric_names_to_log_manually:\n     metric_names_to_log_manually.remove('categorical_accuracy')\n\n\nmodel.compile(optimizer=optimizer, loss=loss_to_use, metrics=metrics_to_compile)\nmodel.summary()\n\n# --- KHỞI TẠO WEIGHTS & BIASES ---\nif WANDB_API_KEY:\n    wandb.login(key=WANDB_API_KEY)\nelse:\n    try:\n        wandb.login() # Thử đăng nhập tương tác nếu không có key\n    except Exception as e:\n        print(f\"Lỗi khi đăng nhập WandB: {e}. Vui lòng đảm bảo bạn đã đăng nhập WandB.\")\n        # Có thể exit() ở đây nếu WandB là bắt buộc\n\n# Lấy giờ VN cho tên run\nnow_vn = datetime.utcnow() + timedelta(hours=7)\n# Chỉnh sửa format tên run để không có ký tự '/' không hợp lệ cho tên file/directory\nrun_name_wandb = f\"{MODEL_CHECKPOINT_BASENAME}_{loss_name_str}_attn{USE_ATTENTION_UNET}_\" + now_vn.strftime(\"%d%m%Y_%H%M%S\")\n\nwandb_config = {\n    \"epochs\": EPOCHS,\n    \"batch_size\": BATCH_SIZE,\n    \"learning_rate\": LEARNING_RATE,\n    \"target_size\": TARGET_SIZE,\n    \"n_classes\": N_CLASSES,\n    \"l2_reg_factor\": L2_REG_FACTOR,\n    \"dropout_rate\": DROPOUT_RATE,\n    \"use_combined_loss\": USE_COMBINED_LOSS,\n    \"dice_loss_weight\": DICE_LOSS_WEIGHT,\n    \"use_focal_loss_in_combined\": USE_FOCAL_LOSS_IN_COMBINED,\n    \"focal_loss_alpha\": FOCAL_LOSS_ALPHA,\n    \"focal_loss_gamma\": FOCAL_LOSS_GAMMA,\n    \"use_attention_unet\": USE_ATTENTION_UNET,\n    \"architecture\": model.name,\n    \"optimizer\": type(optimizer).__name__,\n    \"loss_function\": loss_name_str,\n    \"mean_pixel_train\": mean_pixel, # Giả sử mean_pixel, std_pixel đã được tính\n    \"std_pixel_train\": std_pixel,\n    \"monitor_metric_callbacks\": MONITOR_METRIC_CB # Metric cho các Keras callback\n}\n\nwandb.init(\n    project=WANDB_PROJECT_NAME,\n    entity=WANDB_ENTITY,\n    name=run_name_wandb,\n    config=wandb_config\n    # sync_tensorboard=True # Vẫn có thể dùng nếu bạn có TensorBoard callback\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T01:24:20.442300Z","iopub.execute_input":"2025-05-29T01:24:20.442613Z","iopub.status.idle":"2025-05-29T01:24:38.986831Z","shell.execute_reply.started":"2025-05-29T01:24:20.442590Z","shell.execute_reply":"2025-05-29T01:24:38.986119Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"UNet_filters64\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"UNet_filters64\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m640\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_2 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_3 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_4 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m590,080\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_5 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_6 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_7 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │      \u001b[38;5;34m4,719,616\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_8 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │      \u001b[38;5;34m9,438,208\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_9 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,097,664\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                           │                        │                │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m4,719,104\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m524,544\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │      \u001b[38;5;34m1,179,904\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_12             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m590,080\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_13             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m131,200\u001b[0m │ activation_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_2[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m295,040\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_14             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_15             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m32,832\u001b[0m │ activation_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_3[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m73,792\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_16             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_17             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m2\u001b[0m)    │            \u001b[38;5;34m130\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                           │                        │                │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_12             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_13             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_14             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_15             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_16             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_17             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,054,210\u001b[0m (118.46 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,054,210</span> (118.46 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,042,434\u001b[0m (118.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,042,434</span> (118.42 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m11,776\u001b[0m (46.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,776</span> (46.00 KB)\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnganltt23\u001b[0m (\u001b[33mnganltt2333\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250529_012431-5wbo7hfz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nganltt2333/btxrd-project/runs/5wbo7hfz' target=\"_blank\">unet_model_combined_dice0.6_focal_attnFalse_29052025_082431</a></strong> to <a href='https://wandb.ai/nganltt2333/btxrd-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nganltt2333/btxrd-project' target=\"_blank\">https://wandb.ai/nganltt2333/btxrd-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nganltt2333/btxrd-project/runs/5wbo7hfz' target=\"_blank\">https://wandb.ai/nganltt2333/btxrd-project/runs/5wbo7hfz</a>"},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nganltt2333/btxrd-project/runs/5wbo7hfz?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7b55da01b2b0>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Callbacks Keras tiêu chuẩn (KHÔNG BAO GỒM WandbCallback)\n\n# Đường dẫn lưu checkpoint\ncheckpoint_path = f\"{MODEL_CHECKPOINT_BASENAME}_{run_name_wandb}.keras\" # Dùng run_name_wandb để duy nhất\n\n# MONITOR_METRIC_CB ('val_dice_coef_metric_tumor') phải là một key có trong history.history khi val_ds được dùng\nkeras_callbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_path, # Đổi tên tham số cho rõ ràng\n        save_best_only=True,\n        monitor=MONITOR_METRIC_CB,\n        mode='max',\n        verbose=1\n    ),\n    tf.keras.callbacks.EarlyStopping(\n        monitor=MONITOR_METRIC_CB,\n        patience=PATIENCE_EARLY_STOPPING,\n        mode='max',\n        restore_best_weights=True,\n        verbose=1\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor=MONITOR_METRIC_CB,\n        factor=0.3,\n        patience=PATIENCE_REDUCE_LR,\n        mode='max',\n        min_lr=1e-7,\n        verbose=1\n    ),\n    tf.keras.callbacks.TensorBoard(\n        log_dir=TENSORBOARD_LOG_DIR, # WandB có thể sync từ đây nếu sync_tensorboard=True trong init\n        histogram_freq=1 # Có thể gây chậm, cân nhắc\n    )\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T01:24:47.161840Z","iopub.execute_input":"2025-05-29T01:24:47.162214Z","iopub.status.idle":"2025-05-29T01:24:47.168034Z","shell.execute_reply.started":"2025-05-29T01:24:47.162185Z","shell.execute_reply":"2025-05-29T01:24:47.167180Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Class Weights\npix_cls0 = 0; pix_cls1 = 0\n# Giả sử train_mask_paths đã được tạo ở Đoạn 2\nif 'train_mask_paths' in locals() and train_mask_paths: # Kiểm tra biến tồn tại\n    for mask_p in tqdm(train_mask_paths, desc=\"Đếm pixels cho class weights\"):\n        try:\n            m = create_mask_pil((TARGET_SIZE, TARGET_SIZE), mask_p)\n            m_np = (np.array(m) > 128).astype(np.uint8)\n            pix_cls0 += np.sum(m_np == 0)\n            pix_cls1 += np.sum(m_np == 1)\n        except Exception as e:\n            print(f\"Lỗi khi xử lý mask {mask_p} cho class weights: {e}\")\n            continue\nelse:\n    print(\"Cảnh báo: train_mask_paths không tồn tại hoặc rỗng, không thể tính class weights.\")\n\nclass_weights = None # Khởi tạo class_weights\nif pix_cls1 > 0 and pix_cls0 > 0:\n    total_pix = float(pix_cls0 + pix_cls1)\n    w0 = (total_pix / (N_CLASSES * float(pix_cls0)))\n    w1 = (total_pix / (N_CLASSES * float(pix_cls1)))\n    class_weights = {0: w0, 1: w1} # Gán giá trị cho class_weights\n    print(f\"Class weights đã tính: Lớp 0: {w0:.4f}, Lớp 1: {w1:.4f}\")\n    if w1 < w0 :\n        print(\"Cảnh báo: Trọng số lớp khối u (1) nhỏ hơn lớp nền (0). Kiểm tra lại số lượng pixel hoặc dữ liệu.\")\n    if wandb.run:\n        wandb.config.update({\"class_weight_0\": w0, \"class_weight_1\": w1, \"calculated_class_weights\": True})\nelse:\n    print(\"Không tính được class weights (số pixel lớp 0 hoặc 1 bằng 0 hoặc train_mask_paths rỗng). Sử dụng None.\")\n    if wandb.run:\n        wandb.config.update({\"calculated_class_weights\": False})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T01:24:51.410313Z","iopub.execute_input":"2025-05-29T01:24:51.410650Z","iopub.status.idle":"2025-05-29T01:24:59.719994Z","shell.execute_reply.started":"2025-05-29T01:24:51.410620Z","shell.execute_reply":"2025-05-29T01:24:59.719058Z"}},"outputs":[{"name":"stderr","text":"Đếm pixels cho class weights: 100%|██████████| 1344/1344 [00:08<00:00, 162.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Class weights đã tính: Lớp 0: 0.5089, Lớp 1: 28.6592\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Huấn luyện Model với vòng lặp thủ công và log thủ công lên WandB\n\n# Kiểm tra sự tồn tại của train_ds và val_ds (nếu val_image_paths có)\nif 'train_ds' not in locals() or not train_ds:\n    print(\"Lỗi: Tập huấn luyện (train_ds) chưa được tạo hoặc rỗng.\")\n    if wandb.run: wandb.finish(exit_code=1)\n    exit()\n\nuse_validation = 'val_image_paths' in locals() and val_image_paths and 'val_ds' in locals() and val_ds\nif 'val_image_paths' in locals() and val_image_paths and ('val_ds' not in locals() or not val_ds):\n    print(\"Lỗi: Có val_image_paths nhưng tập validation (val_ds) chưa được tạo hoặc rỗng.\")\n    if wandb.run: wandb.finish(exit_code=1)\n    exit()\n\nprint(f\"\\nBắt đầu huấn luyện cho {EPOCHS} epochs...\")\n\nfor epoch in range(EPOCHS):\n    print(f\"\\n--- Epoch {epoch + 1}/{EPOCHS} ---\")\n\n    history = model.fit(\n        train_ds,\n        validation_data=val_ds if use_validation else None,\n        epochs=1, # CHỈ HUẤN LUYỆN 1 EPOCH MỖI LẦN GỌI FIT\n        class_weight=class_weights, # Từ Đoạn 6\n        callbacks=keras_callbacks, # Callbacks Keras tiêu chuẩn từ Đoạn 5\n        verbose=1\n    )\n\n    current_logs = history.history\n    if not current_logs:\n        print(f\"Cảnh báo: Không có logs nào được trả về từ model.fit() ở epoch {epoch + 1}.\")\n        continue\n\n    # --- Ghi log thủ công cho W&B ---\n    log_data_to_wandb = {\"epoch\": epoch + 1}\n\n    # Metrics huấn luyện\n    log_data_to_wandb[\"loss\"] = current_logs.get(\"loss\", [None])[0]\n    # Xử lý 'acc' hoặc 'categorical_accuracy' cho training\n    train_acc_key = None\n    if \"acc\" in current_logs:\n        train_acc_key = \"acc\"\n    elif \"categorical_accuracy\" in current_logs:\n        train_acc_key = \"categorical_accuracy\"\n    if train_acc_key:\n        log_data_to_wandb[train_acc_key] = current_logs.get(train_acc_key, [None])[0]\n\n    # Log các metrics tùy chỉnh khác cho training\n    for metric_name in metric_names_to_log_manually: # Từ Đoạn 4\n        if metric_name in current_logs:\n            log_data_to_wandb[metric_name] = current_logs.get(metric_name, [None])[0]\n\n\n    # Metrics validation (nếu có)\n    if use_validation:\n        log_data_to_wandb[\"val_loss\"] = current_logs.get(\"val_loss\", [None])[0]\n        # Xử lý 'val_acc' hoặc 'val_categorical_accuracy'\n        val_acc_key = None\n        if \"val_acc\" in current_logs:\n            val_acc_key = \"val_acc\"\n        elif \"val_categorical_accuracy\" in current_logs:\n            val_acc_key = \"val_categorical_accuracy\"\n        if val_acc_key:\n            log_data_to_wandb[val_acc_key] = current_logs.get(val_acc_key, [None])[0]\n\n        # Log các metrics tùy chỉnh khác cho validation\n        for metric_name in metric_names_to_log_manually: # Từ Đoạn 4\n            val_metric_key = f\"val_{metric_name}\"\n            if val_metric_key in current_logs:\n                log_data_to_wandb[val_metric_key] = current_logs.get(val_metric_key, [None])[0]\n\n    wandb.log(log_data_to_wandb)\n    print(f\"Đã log metrics cho epoch {epoch + 1} lên WandB.\")\n\n    # Kiểm tra điều kiện dừng sớm từ EarlyStopping callback\n    if model.stop_training:\n        print(f\"Huấn luyện dừng sớm bởi EarlyStopping callback sau epoch {epoch + 1}.\")\n        break\n\nprint(\"\\nHuấn luyện hoàn tất (hoặc dừng sớm)!\")\n\n# Kết thúc run WandB\nif wandb.run:\n    # (Tùy chọn) Log model tốt nhất như một artifact\n    # Giả sử ModelCheckpoint đã lưu model tốt nhất vào checkpoint_path\n    if os.path.exists(checkpoint_path):\n        print(f\"Đang log model tốt nhất từ: {checkpoint_path}\")\n        best_model_artifact = wandb.Artifact(\n            f'{MODEL_CHECKPOINT_BASENAME}-best_model',\n            type='model',\n            description=f'Best model based on {MONITOR_METRIC_CB} from run {run_name_wandb}',\n            metadata=dict(wandb.config) # Lưu config của run vào metadata artifact\n        )\n        best_model_artifact.add_file(checkpoint_path)\n        wandb.log_artifact(best_model_artifact)\n        print(\"Đã log model tốt nhất lên WandB Artifacts.\")\n    else:\n        print(f\"Không tìm thấy model checkpoint tại: {checkpoint_path} để log artifact.\")\n\n    wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T01:25:01.804276Z","iopub.execute_input":"2025-05-29T01:25:01.804573Z"}},"outputs":[{"name":"stdout","text":"\nBắt đầu huấn luyện cho 300 epochs...\n\n--- Epoch 1/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.8232 - dice_coef_metric_tumor: 0.0645 - loss: 0.6883 - mean_iou_all: 0.2517 - precision_tumor: 0.0594 - recall_tumor: 0.5629 - tumor_iou: 0.0341\nEpoch 1: val_dice_coef_metric_tumor improved from -inf to 0.07598, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 480ms/step - acc: 0.8232 - dice_coef_metric_tumor: 0.0646 - loss: 0.6882 - mean_iou_all: 0.2517 - precision_tumor: 0.0594 - recall_tumor: 0.5629 - tumor_iou: 0.0342 - val_acc: 0.9238 - val_dice_coef_metric_tumor: 0.0760 - val_loss: 0.6182 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0578 - val_recall_tumor: 0.2210 - val_tumor_iou: 0.0406 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 1 lên WandB.\n\n--- Epoch 2/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.8684 - dice_coef_metric_tumor: 0.1078 - loss: 0.5887 - mean_iou_all: 0.2523 - precision_tumor: 0.0805 - recall_tumor: 0.6092 - tumor_iou: 0.0591\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.07598\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.8685 - dice_coef_metric_tumor: 0.1078 - loss: 0.5887 - mean_iou_all: 0.2523 - precision_tumor: 0.0805 - recall_tumor: 0.6091 - tumor_iou: 0.0591 - val_acc: 0.9763 - val_dice_coef_metric_tumor: 0.0550 - val_loss: 0.6151 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1002 - val_recall_tumor: 0.0585 - val_tumor_iou: 0.0291 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 2 lên WandB.\n\n--- Epoch 3/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9141 - dice_coef_metric_tumor: 0.1451 - loss: 0.5629 - mean_iou_all: 0.2520 - precision_tumor: 0.1149 - recall_tumor: 0.5047 - tumor_iou: 0.0824\nEpoch 1: val_dice_coef_metric_tumor improved from 0.07598 to 0.11485, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9142 - dice_coef_metric_tumor: 0.1450 - loss: 0.5628 - mean_iou_all: 0.2520 - precision_tumor: 0.1149 - recall_tumor: 0.5047 - tumor_iou: 0.0824 - val_acc: 0.9470 - val_dice_coef_metric_tumor: 0.1148 - val_loss: 0.5788 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1070 - val_recall_tumor: 0.2944 - val_tumor_iou: 0.0646 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 3 lên WandB.\n\n--- Epoch 4/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9350 - dice_coef_metric_tumor: 0.1716 - loss: 0.5343 - mean_iou_all: 0.2512 - precision_tumor: 0.1351 - recall_tumor: 0.4625 - tumor_iou: 0.1005\nEpoch 1: val_dice_coef_metric_tumor improved from 0.11485 to 0.14423, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9350 - dice_coef_metric_tumor: 0.1716 - loss: 0.5343 - mean_iou_all: 0.2512 - precision_tumor: 0.1351 - recall_tumor: 0.4625 - tumor_iou: 0.1005 - val_acc: 0.9513 - val_dice_coef_metric_tumor: 0.1442 - val_loss: 0.5578 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1243 - val_recall_tumor: 0.3224 - val_tumor_iou: 0.0843 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 4 lên WandB.\n\n--- Epoch 5/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9402 - dice_coef_metric_tumor: 0.1867 - loss: 0.5194 - mean_iou_all: 0.2522 - precision_tumor: 0.1458 - recall_tumor: 0.4516 - tumor_iou: 0.1104\nEpoch 1: val_dice_coef_metric_tumor improved from 0.14423 to 0.14522, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9402 - dice_coef_metric_tumor: 0.1867 - loss: 0.5194 - mean_iou_all: 0.2522 - precision_tumor: 0.1457 - recall_tumor: 0.4516 - tumor_iou: 0.1104 - val_acc: 0.9310 - val_dice_coef_metric_tumor: 0.1452 - val_loss: 0.5614 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1074 - val_recall_tumor: 0.4292 - val_tumor_iou: 0.0842 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 5 lên WandB.\n\n--- Epoch 6/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9399 - dice_coef_metric_tumor: 0.2027 - loss: 0.5147 - mean_iou_all: 0.2524 - precision_tumor: 0.1565 - recall_tumor: 0.4661 - tumor_iou: 0.1213\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.14522\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9399 - dice_coef_metric_tumor: 0.2026 - loss: 0.5147 - mean_iou_all: 0.2524 - precision_tumor: 0.1565 - recall_tumor: 0.4661 - tumor_iou: 0.1213 - val_acc: 0.9707 - val_dice_coef_metric_tumor: 0.1096 - val_loss: 0.5753 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1503 - val_recall_tumor: 0.1461 - val_tumor_iou: 0.0630 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 6 lên WandB.\n\n--- Epoch 7/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9430 - dice_coef_metric_tumor: 0.2017 - loss: 0.5053 - mean_iou_all: 0.2524 - precision_tumor: 0.1565 - recall_tumor: 0.4622 - tumor_iou: 0.1210\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.14522\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9430 - dice_coef_metric_tumor: 0.2017 - loss: 0.5053 - mean_iou_all: 0.2524 - precision_tumor: 0.1565 - recall_tumor: 0.4623 - tumor_iou: 0.1210 - val_acc: 0.9067 - val_dice_coef_metric_tumor: 0.1394 - val_loss: 0.5606 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0979 - val_recall_tumor: 0.5518 - val_tumor_iou: 0.0793 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 7 lên WandB.\n\n--- Epoch 8/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9422 - dice_coef_metric_tumor: 0.2108 - loss: 0.5078 - mean_iou_all: 0.2525 - precision_tumor: 0.1667 - recall_tumor: 0.4734 - tumor_iou: 0.1268\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.14522\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9422 - dice_coef_metric_tumor: 0.2107 - loss: 0.5077 - mean_iou_all: 0.2526 - precision_tumor: 0.1667 - recall_tumor: 0.4734 - tumor_iou: 0.1267 - val_acc: 0.9668 - val_dice_coef_metric_tumor: 0.1335 - val_loss: 0.5584 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1499 - val_recall_tumor: 0.1828 - val_tumor_iou: 0.0787 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 8 lên WandB.\n\n--- Epoch 9/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9490 - dice_coef_metric_tumor: 0.2208 - loss: 0.4967 - mean_iou_all: 0.2527 - precision_tumor: 0.1792 - recall_tumor: 0.4546 - tumor_iou: 0.1344\nEpoch 1: val_dice_coef_metric_tumor improved from 0.14522 to 0.15664, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9490 - dice_coef_metric_tumor: 0.2208 - loss: 0.4967 - mean_iou_all: 0.2527 - precision_tumor: 0.1792 - recall_tumor: 0.4546 - tumor_iou: 0.1344 - val_acc: 0.9477 - val_dice_coef_metric_tumor: 0.1566 - val_loss: 0.5466 - val_mean_iou_all: 0.2505 - val_precision_tumor: 0.1264 - val_recall_tumor: 0.3541 - val_tumor_iou: 0.0928 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 9 lên WandB.\n\n--- Epoch 10/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9489 - dice_coef_metric_tumor: 0.2304 - loss: 0.4901 - mean_iou_all: 0.2538 - precision_tumor: 0.1863 - recall_tumor: 0.4782 - tumor_iou: 0.1412\nEpoch 1: val_dice_coef_metric_tumor improved from 0.15664 to 0.16283, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9489 - dice_coef_metric_tumor: 0.2303 - loss: 0.4901 - mean_iou_all: 0.2538 - precision_tumor: 0.1863 - recall_tumor: 0.4782 - tumor_iou: 0.1412 - val_acc: 0.9447 - val_dice_coef_metric_tumor: 0.1628 - val_loss: 0.5428 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1288 - val_recall_tumor: 0.3815 - val_tumor_iou: 0.0969 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 10 lên WandB.\n\n--- Epoch 11/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9515 - dice_coef_metric_tumor: 0.2295 - loss: 0.4863 - mean_iou_all: 0.2530 - precision_tumor: 0.1853 - recall_tumor: 0.4442 - tumor_iou: 0.1415\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.16283\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9515 - dice_coef_metric_tumor: 0.2294 - loss: 0.4863 - mean_iou_all: 0.2530 - precision_tumor: 0.1852 - recall_tumor: 0.4441 - tumor_iou: 0.1415 - val_acc: 0.9646 - val_dice_coef_metric_tumor: 0.1426 - val_loss: 0.5533 - val_mean_iou_all: 0.2503 - val_precision_tumor: 0.1543 - val_recall_tumor: 0.2168 - val_tumor_iou: 0.0850 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 11 lên WandB.\n\n--- Epoch 12/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9538 - dice_coef_metric_tumor: 0.2354 - loss: 0.4899 - mean_iou_all: 0.2541 - precision_tumor: 0.1962 - recall_tumor: 0.4278 - tumor_iou: 0.1449\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.16283\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9537 - dice_coef_metric_tumor: 0.2353 - loss: 0.4899 - mean_iou_all: 0.2541 - precision_tumor: 0.1962 - recall_tumor: 0.4277 - tumor_iou: 0.1448 - val_acc: 0.9576 - val_dice_coef_metric_tumor: 0.1627 - val_loss: 0.5407 - val_mean_iou_all: 0.2502 - val_precision_tumor: 0.1439 - val_recall_tumor: 0.3056 - val_tumor_iou: 0.0975 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 12 lên WandB.\n\n--- Epoch 13/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9544 - dice_coef_metric_tumor: 0.2342 - loss: 0.4857 - mean_iou_all: 0.2538 - precision_tumor: 0.1934 - recall_tumor: 0.4422 - tumor_iou: 0.1439\nEpoch 1: val_dice_coef_metric_tumor improved from 0.16283 to 0.19302, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9544 - dice_coef_metric_tumor: 0.2342 - loss: 0.4857 - mean_iou_all: 0.2538 - precision_tumor: 0.1934 - recall_tumor: 0.4423 - tumor_iou: 0.1439 - val_acc: 0.9551 - val_dice_coef_metric_tumor: 0.1930 - val_loss: 0.5224 - val_mean_iou_all: 0.2502 - val_precision_tumor: 0.1654 - val_recall_tumor: 0.3717 - val_tumor_iou: 0.1173 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 13 lên WandB.\n\n--- Epoch 14/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9596 - dice_coef_metric_tumor: 0.2458 - loss: 0.4737 - mean_iou_all: 0.2543 - precision_tumor: 0.2112 - recall_tumor: 0.4236 - tumor_iou: 0.1534\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.19302\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9596 - dice_coef_metric_tumor: 0.2458 - loss: 0.4737 - mean_iou_all: 0.2543 - precision_tumor: 0.2112 - recall_tumor: 0.4237 - tumor_iou: 0.1534 - val_acc: 0.9626 - val_dice_coef_metric_tumor: 0.1537 - val_loss: 0.5455 - val_mean_iou_all: 0.2563 - val_precision_tumor: 0.1611 - val_recall_tumor: 0.2635 - val_tumor_iou: 0.0920 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 14 lên WandB.\n\n--- Epoch 15/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9639 - dice_coef_metric_tumor: 0.2539 - loss: 0.4677 - mean_iou_all: 0.2581 - precision_tumor: 0.2241 - recall_tumor: 0.4052 - tumor_iou: 0.1604\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.19302\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9639 - dice_coef_metric_tumor: 0.2539 - loss: 0.4677 - mean_iou_all: 0.2581 - precision_tumor: 0.2241 - recall_tumor: 0.4052 - tumor_iou: 0.1604 - val_acc: 0.9054 - val_dice_coef_metric_tumor: 0.1635 - val_loss: 0.5652 - val_mean_iou_all: 0.2517 - val_precision_tumor: 0.1050 - val_recall_tumor: 0.6226 - val_tumor_iou: 0.0960 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 15 lên WandB.\n\n--- Epoch 16/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9576 - dice_coef_metric_tumor: 0.2399 - loss: 0.4717 - mean_iou_all: 0.2581 - precision_tumor: 0.1992 - recall_tumor: 0.4252 - tumor_iou: 0.1489\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.19302\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9576 - dice_coef_metric_tumor: 0.2398 - loss: 0.4717 - mean_iou_all: 0.2582 - precision_tumor: 0.1992 - recall_tumor: 0.4252 - tumor_iou: 0.1489 - val_acc: 0.9238 - val_dice_coef_metric_tumor: 0.1725 - val_loss: 0.5462 - val_mean_iou_all: 0.2535 - val_precision_tumor: 0.1221 - val_recall_tumor: 0.5243 - val_tumor_iou: 0.1029 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 16 lên WandB.\n\n--- Epoch 17/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9602 - dice_coef_metric_tumor: 0.2551 - loss: 0.4578 - mean_iou_all: 0.2583 - precision_tumor: 0.2190 - recall_tumor: 0.4455 - tumor_iou: 0.1606\nEpoch 1: val_dice_coef_metric_tumor improved from 0.19302 to 0.20664, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 470ms/step - acc: 0.9602 - dice_coef_metric_tumor: 0.2550 - loss: 0.4578 - mean_iou_all: 0.2583 - precision_tumor: 0.2190 - recall_tumor: 0.4454 - tumor_iou: 0.1606 - val_acc: 0.9643 - val_dice_coef_metric_tumor: 0.2066 - val_loss: 0.5125 - val_mean_iou_all: 0.2595 - val_precision_tumor: 0.1832 - val_recall_tumor: 0.3487 - val_tumor_iou: 0.1259 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 17 lên WandB.\n\n--- Epoch 18/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9596 - dice_coef_metric_tumor: 0.2611 - loss: 0.4789 - mean_iou_all: 0.2604 - precision_tumor: 0.2213 - recall_tumor: 0.4433 - tumor_iou: 0.1636\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.20664\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9596 - dice_coef_metric_tumor: 0.2610 - loss: 0.4788 - mean_iou_all: 0.2605 - precision_tumor: 0.2212 - recall_tumor: 0.4433 - tumor_iou: 0.1635 - val_acc: 0.9661 - val_dice_coef_metric_tumor: 0.1953 - val_loss: 0.5200 - val_mean_iou_all: 0.2576 - val_precision_tumor: 0.1900 - val_recall_tumor: 0.2987 - val_tumor_iou: 0.1197 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 18 lên WandB.\n\n--- Epoch 19/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9632 - dice_coef_metric_tumor: 0.2644 - loss: 0.4617 - mean_iou_all: 0.2593 - precision_tumor: 0.2306 - recall_tumor: 0.4230 - tumor_iou: 0.1671\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.20664\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9632 - dice_coef_metric_tumor: 0.2643 - loss: 0.4617 - mean_iou_all: 0.2593 - precision_tumor: 0.2306 - recall_tumor: 0.4230 - tumor_iou: 0.1670 - val_acc: 0.9263 - val_dice_coef_metric_tumor: 0.1854 - val_loss: 0.5363 - val_mean_iou_all: 0.2522 - val_precision_tumor: 0.1259 - val_recall_tumor: 0.5669 - val_tumor_iou: 0.1110 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 19 lên WandB.\n\n--- Epoch 20/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9641 - dice_coef_metric_tumor: 0.2880 - loss: 0.4441 - mean_iou_all: 0.2579 - precision_tumor: 0.2550 - recall_tumor: 0.4544 - tumor_iou: 0.1859\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.20664\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9641 - dice_coef_metric_tumor: 0.2880 - loss: 0.4441 - mean_iou_all: 0.2579 - precision_tumor: 0.2550 - recall_tumor: 0.4544 - tumor_iou: 0.1858 - val_acc: 0.9676 - val_dice_coef_metric_tumor: 0.1961 - val_loss: 0.5196 - val_mean_iou_all: 0.2542 - val_precision_tumor: 0.2073 - val_recall_tumor: 0.2746 - val_tumor_iou: 0.1236 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 20 lên WandB.\n\n--- Epoch 21/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9681 - dice_coef_metric_tumor: 0.3062 - loss: 0.4322 - mean_iou_all: 0.2620 - precision_tumor: 0.2714 - recall_tumor: 0.4655 - tumor_iou: 0.1977\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.20664\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9681 - dice_coef_metric_tumor: 0.3061 - loss: 0.4322 - mean_iou_all: 0.2621 - precision_tumor: 0.2714 - recall_tumor: 0.4654 - tumor_iou: 0.1977 - val_acc: 0.9836 - val_dice_coef_metric_tumor: 0.0441 - val_loss: 0.6109 - val_mean_iou_all: 0.2592 - val_precision_tumor: 0.2832 - val_recall_tumor: 0.0244 - val_tumor_iou: 0.0246 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 21 lên WandB.\n\n--- Epoch 22/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9655 - dice_coef_metric_tumor: 0.2857 - loss: 0.4460 - mean_iou_all: 0.2583 - precision_tumor: 0.2571 - recall_tumor: 0.4461 - tumor_iou: 0.1836\nEpoch 1: val_dice_coef_metric_tumor improved from 0.20664 to 0.21154, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9655 - dice_coef_metric_tumor: 0.2856 - loss: 0.4460 - mean_iou_all: 0.2584 - precision_tumor: 0.2571 - recall_tumor: 0.4461 - tumor_iou: 0.1836 - val_acc: 0.9755 - val_dice_coef_metric_tumor: 0.2115 - val_loss: 0.5085 - val_mean_iou_all: 0.2603 - val_precision_tumor: 0.2413 - val_recall_tumor: 0.2479 - val_tumor_iou: 0.1325 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 22 lên WandB.\n\n--- Epoch 23/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9672 - dice_coef_metric_tumor: 0.2993 - loss: 0.4391 - mean_iou_all: 0.2618 - precision_tumor: 0.2685 - recall_tumor: 0.4463 - tumor_iou: 0.1934\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.21154\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9672 - dice_coef_metric_tumor: 0.2993 - loss: 0.4391 - mean_iou_all: 0.2619 - precision_tumor: 0.2684 - recall_tumor: 0.4463 - tumor_iou: 0.1934 - val_acc: 0.9803 - val_dice_coef_metric_tumor: 0.1846 - val_loss: 0.5236 - val_mean_iou_all: 0.2553 - val_precision_tumor: 0.3122 - val_recall_tumor: 0.1766 - val_tumor_iou: 0.1129 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 23 lên WandB.\n\n--- Epoch 24/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9664 - dice_coef_metric_tumor: 0.2993 - loss: 0.4341 - mean_iou_all: 0.2571 - precision_tumor: 0.2640 - recall_tumor: 0.4607 - tumor_iou: 0.1933\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.21154\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9664 - dice_coef_metric_tumor: 0.2992 - loss: 0.4340 - mean_iou_all: 0.2571 - precision_tumor: 0.2640 - recall_tumor: 0.4607 - tumor_iou: 0.1933 - val_acc: 0.9270 - val_dice_coef_metric_tumor: 0.2085 - val_loss: 0.5309 - val_mean_iou_all: 0.2530 - val_precision_tumor: 0.1393 - val_recall_tumor: 0.6318 - val_tumor_iou: 0.1264 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 24 lên WandB.\n\n--- Epoch 25/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9668 - dice_coef_metric_tumor: 0.2922 - loss: 0.4455 - mean_iou_all: 0.2563 - precision_tumor: 0.2610 - recall_tumor: 0.4378 - tumor_iou: 0.1905\nEpoch 1: val_dice_coef_metric_tumor improved from 0.21154 to 0.23389, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9668 - dice_coef_metric_tumor: 0.2922 - loss: 0.4455 - mean_iou_all: 0.2563 - precision_tumor: 0.2609 - recall_tumor: 0.4378 - tumor_iou: 0.1904 - val_acc: 0.9679 - val_dice_coef_metric_tumor: 0.2339 - val_loss: 0.4965 - val_mean_iou_all: 0.2550 - val_precision_tumor: 0.2345 - val_recall_tumor: 0.3373 - val_tumor_iou: 0.1497 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 25 lên WandB.\n\n--- Epoch 26/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9683 - dice_coef_metric_tumor: 0.3070 - loss: 0.4298 - mean_iou_all: 0.2581 - precision_tumor: 0.2764 - recall_tumor: 0.4513 - tumor_iou: 0.2003\nEpoch 1: val_dice_coef_metric_tumor improved from 0.23389 to 0.23507, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 470ms/step - acc: 0.9683 - dice_coef_metric_tumor: 0.3070 - loss: 0.4298 - mean_iou_all: 0.2582 - precision_tumor: 0.2763 - recall_tumor: 0.4513 - tumor_iou: 0.2003 - val_acc: 0.9750 - val_dice_coef_metric_tumor: 0.2351 - val_loss: 0.4941 - val_mean_iou_all: 0.2567 - val_precision_tumor: 0.2777 - val_recall_tumor: 0.2824 - val_tumor_iou: 0.1500 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 26 lên WandB.\n\n--- Epoch 27/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9682 - dice_coef_metric_tumor: 0.3185 - loss: 0.4280 - mean_iou_all: 0.2587 - precision_tumor: 0.3034 - recall_tumor: 0.4788 - tumor_iou: 0.2083\nEpoch 1: val_dice_coef_metric_tumor improved from 0.23507 to 0.26113, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 470ms/step - acc: 0.9683 - dice_coef_metric_tumor: 0.3184 - loss: 0.4280 - mean_iou_all: 0.2587 - precision_tumor: 0.3033 - recall_tumor: 0.4787 - tumor_iou: 0.2083 - val_acc: 0.9537 - val_dice_coef_metric_tumor: 0.2611 - val_loss: 0.4850 - val_mean_iou_all: 0.2557 - val_precision_tumor: 0.2093 - val_recall_tumor: 0.5368 - val_tumor_iou: 0.1635 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 27 lên WandB.\n\n--- Epoch 28/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9730 - dice_coef_metric_tumor: 0.3408 - loss: 0.4118 - mean_iou_all: 0.2586 - precision_tumor: 0.3258 - recall_tumor: 0.4544 - tumor_iou: 0.2265\nEpoch 1: val_dice_coef_metric_tumor improved from 0.26113 to 0.26845, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 470ms/step - acc: 0.9730 - dice_coef_metric_tumor: 0.3407 - loss: 0.4118 - mean_iou_all: 0.2587 - precision_tumor: 0.3257 - recall_tumor: 0.4544 - tumor_iou: 0.2265 - val_acc: 0.9729 - val_dice_coef_metric_tumor: 0.2685 - val_loss: 0.4743 - val_mean_iou_all: 0.2588 - val_precision_tumor: 0.2812 - val_recall_tumor: 0.3657 - val_tumor_iou: 0.1728 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 28 lên WandB.\n\n--- Epoch 29/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9700 - dice_coef_metric_tumor: 0.3250 - loss: 0.4177 - mean_iou_all: 0.2642 - precision_tumor: 0.2951 - recall_tumor: 0.4714 - tumor_iou: 0.2140\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.26845\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9700 - dice_coef_metric_tumor: 0.3249 - loss: 0.4177 - mean_iou_all: 0.2642 - precision_tumor: 0.2951 - recall_tumor: 0.4714 - tumor_iou: 0.2139 - val_acc: 0.9483 - val_dice_coef_metric_tumor: 0.2440 - val_loss: 0.4939 - val_mean_iou_all: 0.2547 - val_precision_tumor: 0.1892 - val_recall_tumor: 0.5475 - val_tumor_iou: 0.1528 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 29 lên WandB.\n\n--- Epoch 30/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9725 - dice_coef_metric_tumor: 0.3508 - loss: 0.4022 - mean_iou_all: 0.2642 - precision_tumor: 0.3215 - recall_tumor: 0.4863 - tumor_iou: 0.2343\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.26845\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9725 - dice_coef_metric_tumor: 0.3507 - loss: 0.4022 - mean_iou_all: 0.2643 - precision_tumor: 0.3215 - recall_tumor: 0.4863 - tumor_iou: 0.2343 - val_acc: 0.9632 - val_dice_coef_metric_tumor: 0.2339 - val_loss: 0.4979 - val_mean_iou_all: 0.2544 - val_precision_tumor: 0.2050 - val_recall_tumor: 0.3968 - val_tumor_iou: 0.1479 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 30 lên WandB.\n\n--- Epoch 31/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9734 - dice_coef_metric_tumor: 0.3478 - loss: 0.4025 - mean_iou_all: 0.2594 - precision_tumor: 0.3276 - recall_tumor: 0.4741 - tumor_iou: 0.2323\nEpoch 1: val_dice_coef_metric_tumor improved from 0.26845 to 0.27360, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9734 - dice_coef_metric_tumor: 0.3477 - loss: 0.4025 - mean_iou_all: 0.2594 - precision_tumor: 0.3275 - recall_tumor: 0.4741 - tumor_iou: 0.2323 - val_acc: 0.9761 - val_dice_coef_metric_tumor: 0.2736 - val_loss: 0.4703 - val_mean_iou_all: 0.2535 - val_precision_tumor: 0.3244 - val_recall_tumor: 0.3248 - val_tumor_iou: 0.1762 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 31 lên WandB.\n\n--- Epoch 32/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9722 - dice_coef_metric_tumor: 0.3426 - loss: 0.4101 - mean_iou_all: 0.2654 - precision_tumor: 0.3172 - recall_tumor: 0.4745 - tumor_iou: 0.2253\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.27360\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9722 - dice_coef_metric_tumor: 0.3426 - loss: 0.4101 - mean_iou_all: 0.2655 - precision_tumor: 0.3171 - recall_tumor: 0.4745 - tumor_iou: 0.2252 - val_acc: 0.9845 - val_dice_coef_metric_tumor: 0.1273 - val_loss: 0.5585 - val_mean_iou_all: 0.2540 - val_precision_tumor: 0.4134 - val_recall_tumor: 0.0865 - val_tumor_iou: 0.0763 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 32 lên WandB.\n\n--- Epoch 33/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9719 - dice_coef_metric_tumor: 0.3482 - loss: 0.4054 - mean_iou_all: 0.2628 - precision_tumor: 0.3138 - recall_tumor: 0.4973 - tumor_iou: 0.2312\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.27360\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9719 - dice_coef_metric_tumor: 0.3481 - loss: 0.4054 - mean_iou_all: 0.2628 - precision_tumor: 0.3138 - recall_tumor: 0.4973 - tumor_iou: 0.2312 - val_acc: 0.9803 - val_dice_coef_metric_tumor: 0.2445 - val_loss: 0.4881 - val_mean_iou_all: 0.2538 - val_precision_tumor: 0.3306 - val_recall_tumor: 0.2486 - val_tumor_iou: 0.1581 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 33 lên WandB.\n\n--- Epoch 34/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9752 - dice_coef_metric_tumor: 0.3584 - loss: 0.4008 - mean_iou_all: 0.2584 - precision_tumor: 0.3433 - recall_tumor: 0.4668 - tumor_iou: 0.2402\nEpoch 1: val_dice_coef_metric_tumor improved from 0.27360 to 0.28625, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9751 - dice_coef_metric_tumor: 0.3583 - loss: 0.4008 - mean_iou_all: 0.2584 - precision_tumor: 0.3432 - recall_tumor: 0.4668 - tumor_iou: 0.2401 - val_acc: 0.9672 - val_dice_coef_metric_tumor: 0.2862 - val_loss: 0.4659 - val_mean_iou_all: 0.2558 - val_precision_tumor: 0.2647 - val_recall_tumor: 0.4477 - val_tumor_iou: 0.1868 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 34 lên WandB.\n\n--- Epoch 35/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9732 - dice_coef_metric_tumor: 0.3510 - loss: 0.4021 - mean_iou_all: 0.2651 - precision_tumor: 0.3185 - recall_tumor: 0.4817 - tumor_iou: 0.2340\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.28625\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9732 - dice_coef_metric_tumor: 0.3510 - loss: 0.4021 - mean_iou_all: 0.2651 - precision_tumor: 0.3185 - recall_tumor: 0.4817 - tumor_iou: 0.2340 - val_acc: 0.9643 - val_dice_coef_metric_tumor: 0.2689 - val_loss: 0.4771 - val_mean_iou_all: 0.2630 - val_precision_tumor: 0.2271 - val_recall_tumor: 0.4536 - val_tumor_iou: 0.1713 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 35 lên WandB.\n\n--- Epoch 36/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9719 - dice_coef_metric_tumor: 0.3653 - loss: 0.3973 - mean_iou_all: 0.2735 - precision_tumor: 0.3312 - recall_tumor: 0.5129 - tumor_iou: 0.2474\nEpoch 1: val_dice_coef_metric_tumor improved from 0.28625 to 0.29104, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9719 - dice_coef_metric_tumor: 0.3652 - loss: 0.3973 - mean_iou_all: 0.2735 - precision_tumor: 0.3312 - recall_tumor: 0.5128 - tumor_iou: 0.2474 - val_acc: 0.9760 - val_dice_coef_metric_tumor: 0.2910 - val_loss: 0.4598 - val_mean_iou_all: 0.2724 - val_precision_tumor: 0.3053 - val_recall_tumor: 0.3717 - val_tumor_iou: 0.1914 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 36 lên WandB.\n\n--- Epoch 37/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9748 - dice_coef_metric_tumor: 0.3704 - loss: 0.3931 - mean_iou_all: 0.2795 - precision_tumor: 0.3506 - recall_tumor: 0.4987 - tumor_iou: 0.2485\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.29104\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9748 - dice_coef_metric_tumor: 0.3703 - loss: 0.3931 - mean_iou_all: 0.2795 - precision_tumor: 0.3505 - recall_tumor: 0.4987 - tumor_iou: 0.2485 - val_acc: 0.9805 - val_dice_coef_metric_tumor: 0.2585 - val_loss: 0.4786 - val_mean_iou_all: 0.2568 - val_precision_tumor: 0.3551 - val_recall_tumor: 0.2659 - val_tumor_iou: 0.1713 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 37 lên WandB.\n\n--- Epoch 38/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9764 - dice_coef_metric_tumor: 0.3889 - loss: 0.3784 - mean_iou_all: 0.2662 - precision_tumor: 0.3866 - recall_tumor: 0.4920 - tumor_iou: 0.2690\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.29104\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9764 - dice_coef_metric_tumor: 0.3888 - loss: 0.3785 - mean_iou_all: 0.2663 - precision_tumor: 0.3864 - recall_tumor: 0.4920 - tumor_iou: 0.2689 - val_acc: 0.9598 - val_dice_coef_metric_tumor: 0.2627 - val_loss: 0.4840 - val_mean_iou_all: 0.2647 - val_precision_tumor: 0.2239 - val_recall_tumor: 0.4816 - val_tumor_iou: 0.1683 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 38 lên WandB.\n\n--- Epoch 39/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9739 - dice_coef_metric_tumor: 0.3631 - loss: 0.3949 - mean_iou_all: 0.2689 - precision_tumor: 0.3495 - recall_tumor: 0.4742 - tumor_iou: 0.2472\nEpoch 1: val_dice_coef_metric_tumor improved from 0.29104 to 0.31980, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9739 - dice_coef_metric_tumor: 0.3631 - loss: 0.3949 - mean_iou_all: 0.2689 - precision_tumor: 0.3494 - recall_tumor: 0.4742 - tumor_iou: 0.2472 - val_acc: 0.9758 - val_dice_coef_metric_tumor: 0.3198 - val_loss: 0.4426 - val_mean_iou_all: 0.2736 - val_precision_tumor: 0.3393 - val_recall_tumor: 0.4040 - val_tumor_iou: 0.2114 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 39 lên WandB.\n\n--- Epoch 40/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9765 - dice_coef_metric_tumor: 0.3892 - loss: 0.3866 - mean_iou_all: 0.2786 - precision_tumor: 0.3710 - recall_tumor: 0.4898 - tumor_iou: 0.2656\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31980\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 462ms/step - acc: 0.9765 - dice_coef_metric_tumor: 0.3892 - loss: 0.3866 - mean_iou_all: 0.2787 - precision_tumor: 0.3709 - recall_tumor: 0.4898 - tumor_iou: 0.2655 - val_acc: 0.9834 - val_dice_coef_metric_tumor: 0.2433 - val_loss: 0.4880 - val_mean_iou_all: 0.2665 - val_precision_tumor: 0.4715 - val_recall_tumor: 0.1983 - val_tumor_iou: 0.1559 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 40 lên WandB.\n\n--- Epoch 41/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9767 - dice_coef_metric_tumor: 0.3682 - loss: 0.3916 - mean_iou_all: 0.2896 - precision_tumor: 0.3505 - recall_tumor: 0.4635 - tumor_iou: 0.2506\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31980\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9767 - dice_coef_metric_tumor: 0.3682 - loss: 0.3916 - mean_iou_all: 0.2897 - precision_tumor: 0.3504 - recall_tumor: 0.4635 - tumor_iou: 0.2506 - val_acc: 0.9791 - val_dice_coef_metric_tumor: 0.2927 - val_loss: 0.4590 - val_mean_iou_all: 0.2587 - val_precision_tumor: 0.3613 - val_recall_tumor: 0.3150 - val_tumor_iou: 0.1908 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 41 lên WandB.\n\n--- Epoch 42/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9775 - dice_coef_metric_tumor: 0.3934 - loss: 0.3794 - mean_iou_all: 0.2721 - precision_tumor: 0.3815 - recall_tumor: 0.5022 - tumor_iou: 0.2691\nEpoch 1: val_dice_coef_metric_tumor improved from 0.31980 to 0.33195, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9775 - dice_coef_metric_tumor: 0.3933 - loss: 0.3794 - mean_iou_all: 0.2721 - precision_tumor: 0.3814 - recall_tumor: 0.5022 - tumor_iou: 0.2690 - val_acc: 0.9721 - val_dice_coef_metric_tumor: 0.3319 - val_loss: 0.4362 - val_mean_iou_all: 0.2724 - val_precision_tumor: 0.3063 - val_recall_tumor: 0.5007 - val_tumor_iou: 0.2187 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 42 lên WandB.\n\n--- Epoch 43/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9755 - dice_coef_metric_tumor: 0.3841 - loss: 0.3845 - mean_iou_all: 0.2868 - precision_tumor: 0.3590 - recall_tumor: 0.5142 - tumor_iou: 0.2626\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.33195\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9755 - dice_coef_metric_tumor: 0.3840 - loss: 0.3845 - mean_iou_all: 0.2869 - precision_tumor: 0.3590 - recall_tumor: 0.5142 - tumor_iou: 0.2625 - val_acc: 0.9625 - val_dice_coef_metric_tumor: 0.2961 - val_loss: 0.4627 - val_mean_iou_all: 0.2601 - val_precision_tumor: 0.2479 - val_recall_tumor: 0.5463 - val_tumor_iou: 0.1902 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 43 lên WandB.\n\n--- Epoch 44/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9756 - dice_coef_metric_tumor: 0.3830 - loss: 0.3799 - mean_iou_all: 0.2916 - precision_tumor: 0.3623 - recall_tumor: 0.5126 - tumor_iou: 0.2613\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.33195\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9756 - dice_coef_metric_tumor: 0.3829 - loss: 0.3799 - mean_iou_all: 0.2917 - precision_tumor: 0.3623 - recall_tumor: 0.5126 - tumor_iou: 0.2612 - val_acc: 0.9713 - val_dice_coef_metric_tumor: 0.2943 - val_loss: 0.4595 - val_mean_iou_all: 0.2766 - val_precision_tumor: 0.2811 - val_recall_tumor: 0.4274 - val_tumor_iou: 0.1931 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 44 lên WandB.\n\n--- Epoch 45/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9779 - dice_coef_metric_tumor: 0.4022 - loss: 0.3814 - mean_iou_all: 0.2968 - precision_tumor: 0.4082 - recall_tumor: 0.4797 - tumor_iou: 0.2780\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.33195\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9779 - dice_coef_metric_tumor: 0.4022 - loss: 0.3814 - mean_iou_all: 0.2969 - precision_tumor: 0.4080 - recall_tumor: 0.4797 - tumor_iou: 0.2779 - val_acc: 0.9621 - val_dice_coef_metric_tumor: 0.2984 - val_loss: 0.4615 - val_mean_iou_all: 0.2637 - val_precision_tumor: 0.2500 - val_recall_tumor: 0.5422 - val_tumor_iou: 0.1937 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 45 lên WandB.\n\n--- Epoch 46/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9762 - dice_coef_metric_tumor: 0.3969 - loss: 0.3735 - mean_iou_all: 0.2984 - precision_tumor: 0.3723 - recall_tumor: 0.5259 - tumor_iou: 0.2729\nEpoch 1: val_dice_coef_metric_tumor improved from 0.33195 to 0.33368, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 470ms/step - acc: 0.9762 - dice_coef_metric_tumor: 0.3968 - loss: 0.3735 - mean_iou_all: 0.2984 - precision_tumor: 0.3723 - recall_tumor: 0.5258 - tumor_iou: 0.2728 - val_acc: 0.9803 - val_dice_coef_metric_tumor: 0.3337 - val_loss: 0.4330 - val_mean_iou_all: 0.2581 - val_precision_tumor: 0.3663 - val_recall_tumor: 0.4017 - val_tumor_iou: 0.2217 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 46 lên WandB.\n\n--- Epoch 47/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9754 - dice_coef_metric_tumor: 0.3866 - loss: 0.3811 - mean_iou_all: 0.2931 - precision_tumor: 0.3656 - recall_tumor: 0.5194 - tumor_iou: 0.2636\nEpoch 1: val_dice_coef_metric_tumor improved from 0.33368 to 0.34049, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9754 - dice_coef_metric_tumor: 0.3865 - loss: 0.3811 - mean_iou_all: 0.2933 - precision_tumor: 0.3655 - recall_tumor: 0.5194 - tumor_iou: 0.2636 - val_acc: 0.9832 - val_dice_coef_metric_tumor: 0.3405 - val_loss: 0.4284 - val_mean_iou_all: 0.2646 - val_precision_tumor: 0.4298 - val_recall_tumor: 0.3364 - val_tumor_iou: 0.2288 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 47 lên WandB.\n\n--- Epoch 48/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9755 - dice_coef_metric_tumor: 0.3868 - loss: 0.3813 - mean_iou_all: 0.2973 - precision_tumor: 0.3718 - recall_tumor: 0.5035 - tumor_iou: 0.2679\nEpoch 1: val_dice_coef_metric_tumor improved from 0.34049 to 0.34457, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9755 - dice_coef_metric_tumor: 0.3868 - loss: 0.3813 - mean_iou_all: 0.2974 - precision_tumor: 0.3718 - recall_tumor: 0.5035 - tumor_iou: 0.2678 - val_acc: 0.9794 - val_dice_coef_metric_tumor: 0.3446 - val_loss: 0.4273 - val_mean_iou_all: 0.2695 - val_precision_tumor: 0.3847 - val_recall_tumor: 0.4028 - val_tumor_iou: 0.2327 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 48 lên WandB.\n\n--- Epoch 49/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9772 - dice_coef_metric_tumor: 0.3996 - loss: 0.3698 - mean_iou_all: 0.2943 - precision_tumor: 0.3806 - recall_tumor: 0.5160 - tumor_iou: 0.2767\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34457\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9772 - dice_coef_metric_tumor: 0.3996 - loss: 0.3698 - mean_iou_all: 0.2944 - precision_tumor: 0.3805 - recall_tumor: 0.5160 - tumor_iou: 0.2767 - val_acc: 0.9783 - val_dice_coef_metric_tumor: 0.2901 - val_loss: 0.4602 - val_mean_iou_all: 0.2752 - val_precision_tumor: 0.3528 - val_recall_tumor: 0.3491 - val_tumor_iou: 0.1929 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 49 lên WandB.\n\n--- Epoch 50/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9750 - dice_coef_metric_tumor: 0.4021 - loss: 0.3736 - mean_iou_all: 0.2981 - precision_tumor: 0.3899 - recall_tumor: 0.5346 - tumor_iou: 0.2771\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34457\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9750 - dice_coef_metric_tumor: 0.4021 - loss: 0.3736 - mean_iou_all: 0.2982 - precision_tumor: 0.3899 - recall_tumor: 0.5346 - tumor_iou: 0.2771 - val_acc: 0.9739 - val_dice_coef_metric_tumor: 0.3390 - val_loss: 0.4321 - val_mean_iou_all: 0.2588 - val_precision_tumor: 0.3341 - val_recall_tumor: 0.4705 - val_tumor_iou: 0.2252 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 50 lên WandB.\n\n--- Epoch 51/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9774 - dice_coef_metric_tumor: 0.4154 - loss: 0.3637 - mean_iou_all: 0.2767 - precision_tumor: 0.3932 - recall_tumor: 0.5541 - tumor_iou: 0.2867\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34457\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9774 - dice_coef_metric_tumor: 0.4153 - loss: 0.3637 - mean_iou_all: 0.2768 - precision_tumor: 0.3932 - recall_tumor: 0.5541 - tumor_iou: 0.2866 - val_acc: 0.9751 - val_dice_coef_metric_tumor: 0.3018 - val_loss: 0.4556 - val_mean_iou_all: 0.2780 - val_precision_tumor: 0.2934 - val_recall_tumor: 0.4050 - val_tumor_iou: 0.1986 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 51 lên WandB.\n\n--- Epoch 52/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9753 - dice_coef_metric_tumor: 0.3954 - loss: 0.3788 - mean_iou_all: 0.3083 - precision_tumor: 0.3650 - recall_tumor: 0.5427 - tumor_iou: 0.2713\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34457\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9753 - dice_coef_metric_tumor: 0.3953 - loss: 0.3787 - mean_iou_all: 0.3085 - precision_tumor: 0.3650 - recall_tumor: 0.5426 - tumor_iou: 0.2712 - val_acc: 0.9674 - val_dice_coef_metric_tumor: 0.3445 - val_loss: 0.4306 - val_mean_iou_all: 0.2610 - val_precision_tumor: 0.2814 - val_recall_tumor: 0.5893 - val_tumor_iou: 0.2291 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 52 lên WandB.\n\n--- Epoch 53/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9766 - dice_coef_metric_tumor: 0.4046 - loss: 0.3668 - mean_iou_all: 0.3394 - precision_tumor: 0.3818 - recall_tumor: 0.5429 - tumor_iou: 0.2796\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34457\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9766 - dice_coef_metric_tumor: 0.4045 - loss: 0.3668 - mean_iou_all: 0.3396 - precision_tumor: 0.3818 - recall_tumor: 0.5429 - tumor_iou: 0.2795 - val_acc: 0.9674 - val_dice_coef_metric_tumor: 0.2984 - val_loss: 0.4604 - val_mean_iou_all: 0.3053 - val_precision_tumor: 0.2572 - val_recall_tumor: 0.4762 - val_tumor_iou: 0.1936 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 53 lên WandB.\n\n--- Epoch 54/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9744 - dice_coef_metric_tumor: 0.3925 - loss: 0.3792 - mean_iou_all: 0.3728 - precision_tumor: 0.3603 - recall_tumor: 0.5565 - tumor_iou: 0.2670\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34457\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9744 - dice_coef_metric_tumor: 0.3925 - loss: 0.3792 - mean_iou_all: 0.3730 - precision_tumor: 0.3603 - recall_tumor: 0.5564 - tumor_iou: 0.2670 - val_acc: 0.9850 - val_dice_coef_metric_tumor: 0.2867 - val_loss: 0.4608 - val_mean_iou_all: 0.2715 - val_precision_tumor: 0.4518 - val_recall_tumor: 0.2501 - val_tumor_iou: 0.1928 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 54 lên WandB.\n\n--- Epoch 55/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9781 - dice_coef_metric_tumor: 0.4166 - loss: 0.3671 - mean_iou_all: 0.3904 - precision_tumor: 0.4042 - recall_tumor: 0.5219 - tumor_iou: 0.2899\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34457\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9781 - dice_coef_metric_tumor: 0.4166 - loss: 0.3671 - mean_iou_all: 0.3907 - precision_tumor: 0.4041 - recall_tumor: 0.5219 - tumor_iou: 0.2899 - val_acc: 0.9580 - val_dice_coef_metric_tumor: 0.2737 - val_loss: 0.4788 - val_mean_iou_all: 0.2618 - val_precision_tumor: 0.2365 - val_recall_tumor: 0.5177 - val_tumor_iou: 0.1762 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 55 lên WandB.\n\n--- Epoch 56/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9783 - dice_coef_metric_tumor: 0.4245 - loss: 0.3612 - mean_iou_all: 0.3898 - precision_tumor: 0.4006 - recall_tumor: 0.5409 - tumor_iou: 0.2962\nEpoch 1: val_dice_coef_metric_tumor improved from 0.34457 to 0.34484, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9783 - dice_coef_metric_tumor: 0.4244 - loss: 0.3612 - mean_iou_all: 0.3901 - precision_tumor: 0.4005 - recall_tumor: 0.5409 - tumor_iou: 0.2962 - val_acc: 0.9710 - val_dice_coef_metric_tumor: 0.3448 - val_loss: 0.4295 - val_mean_iou_all: 0.3438 - val_precision_tumor: 0.2948 - val_recall_tumor: 0.5456 - val_tumor_iou: 0.2271 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 56 lên WandB.\n\n--- Epoch 57/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9782 - dice_coef_metric_tumor: 0.4224 - loss: 0.3599 - mean_iou_all: 0.3769 - precision_tumor: 0.4033 - recall_tumor: 0.5406 - tumor_iou: 0.2959\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34484\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9782 - dice_coef_metric_tumor: 0.4223 - loss: 0.3599 - mean_iou_all: 0.3771 - precision_tumor: 0.4032 - recall_tumor: 0.5406 - tumor_iou: 0.2959 - val_acc: 0.9788 - val_dice_coef_metric_tumor: 0.3395 - val_loss: 0.4321 - val_mean_iou_all: 0.3428 - val_precision_tumor: 0.3686 - val_recall_tumor: 0.3913 - val_tumor_iou: 0.2286 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 57 lên WandB.\n\n--- Epoch 58/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9786 - dice_coef_metric_tumor: 0.4145 - loss: 0.3604 - mean_iou_all: 0.3564 - precision_tumor: 0.3989 - recall_tumor: 0.5308 - tumor_iou: 0.2901\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34484\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9786 - dice_coef_metric_tumor: 0.4145 - loss: 0.3604 - mean_iou_all: 0.3567 - precision_tumor: 0.3989 - recall_tumor: 0.5308 - tumor_iou: 0.2901 - val_acc: 0.9814 - val_dice_coef_metric_tumor: 0.3293 - val_loss: 0.4360 - val_mean_iou_all: 0.3155 - val_precision_tumor: 0.4129 - val_recall_tumor: 0.3665 - val_tumor_iou: 0.2228 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 58 lên WandB.\n\n--- Epoch 59/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9775 - dice_coef_metric_tumor: 0.4128 - loss: 0.3662 - mean_iou_all: 0.3676 - precision_tumor: 0.3930 - recall_tumor: 0.5419 - tumor_iou: 0.2862\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34484\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9775 - dice_coef_metric_tumor: 0.4127 - loss: 0.3662 - mean_iou_all: 0.3678 - precision_tumor: 0.3929 - recall_tumor: 0.5419 - tumor_iou: 0.2862 - val_acc: 0.9812 - val_dice_coef_metric_tumor: 0.3366 - val_loss: 0.4311 - val_mean_iou_all: 0.2653 - val_precision_tumor: 0.4033 - val_recall_tumor: 0.3880 - val_tumor_iou: 0.2250 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 59 lên WandB.\n\n--- Epoch 60/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9785 - dice_coef_metric_tumor: 0.4289 - loss: 0.3518 - mean_iou_all: 0.3895 - precision_tumor: 0.4198 - recall_tumor: 0.5412 - tumor_iou: 0.3015\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34484\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9785 - dice_coef_metric_tumor: 0.4289 - loss: 0.3518 - mean_iou_all: 0.3898 - precision_tumor: 0.4198 - recall_tumor: 0.5412 - tumor_iou: 0.3014 - val_acc: 0.9839 - val_dice_coef_metric_tumor: 0.3388 - val_loss: 0.4301 - val_mean_iou_all: 0.2982 - val_precision_tumor: 0.5062 - val_recall_tumor: 0.3094 - val_tumor_iou: 0.2283 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 60 lên WandB.\n\n--- Epoch 61/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9789 - dice_coef_metric_tumor: 0.4148 - loss: 0.3619 - mean_iou_all: 0.4159 - precision_tumor: 0.4110 - recall_tumor: 0.5200 - tumor_iou: 0.2897\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34484\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9789 - dice_coef_metric_tumor: 0.4148 - loss: 0.3619 - mean_iou_all: 0.4161 - precision_tumor: 0.4109 - recall_tumor: 0.5200 - tumor_iou: 0.2897 - val_acc: 0.9856 - val_dice_coef_metric_tumor: 0.3151 - val_loss: 0.4442 - val_mean_iou_all: 0.2787 - val_precision_tumor: 0.5317 - val_recall_tumor: 0.2696 - val_tumor_iou: 0.2130 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 61 lên WandB.\n\n--- Epoch 62/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9795 - dice_coef_metric_tumor: 0.4406 - loss: 0.3535 - mean_iou_all: 0.3908 - precision_tumor: 0.4296 - recall_tumor: 0.5435 - tumor_iou: 0.3099\nEpoch 1: val_dice_coef_metric_tumor improved from 0.34484 to 0.35537, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9795 - dice_coef_metric_tumor: 0.4406 - loss: 0.3535 - mean_iou_all: 0.3911 - precision_tumor: 0.4295 - recall_tumor: 0.5435 - tumor_iou: 0.3098 - val_acc: 0.9800 - val_dice_coef_metric_tumor: 0.3554 - val_loss: 0.4210 - val_mean_iou_all: 0.3373 - val_precision_tumor: 0.3810 - val_recall_tumor: 0.4140 - val_tumor_iou: 0.2433 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 62 lên WandB.\n\n--- Epoch 63/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9786 - dice_coef_metric_tumor: 0.4323 - loss: 0.3549 - mean_iou_all: 0.4241 - precision_tumor: 0.4242 - recall_tumor: 0.5492 - tumor_iou: 0.3006\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.35537\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9786 - dice_coef_metric_tumor: 0.4323 - loss: 0.3549 - mean_iou_all: 0.4243 - precision_tumor: 0.4241 - recall_tumor: 0.5492 - tumor_iou: 0.3006 - val_acc: 0.9777 - val_dice_coef_metric_tumor: 0.3492 - val_loss: 0.4257 - val_mean_iou_all: 0.2610 - val_precision_tumor: 0.3435 - val_recall_tumor: 0.4418 - val_tumor_iou: 0.2367 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 63 lên WandB.\n\n--- Epoch 64/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9787 - dice_coef_metric_tumor: 0.4214 - loss: 0.3568 - mean_iou_all: 0.3753 - precision_tumor: 0.4208 - recall_tumor: 0.5300 - tumor_iou: 0.2943\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.35537\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9787 - dice_coef_metric_tumor: 0.4214 - loss: 0.3568 - mean_iou_all: 0.3757 - precision_tumor: 0.4207 - recall_tumor: 0.5300 - tumor_iou: 0.2943 - val_acc: 0.9580 - val_dice_coef_metric_tumor: 0.3301 - val_loss: 0.4449 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.2392 - val_recall_tumor: 0.7117 - val_tumor_iou: 0.2147 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 64 lên WandB.\n\n--- Epoch 65/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4478 - loss: 0.3445 - mean_iou_all: 0.4094 - precision_tumor: 0.4296 - recall_tumor: 0.5794 - tumor_iou: 0.3175\nEpoch 1: val_dice_coef_metric_tumor improved from 0.35537 to 0.38474, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4478 - loss: 0.3445 - mean_iou_all: 0.4097 - precision_tumor: 0.4295 - recall_tumor: 0.5794 - tumor_iou: 0.3175 - val_acc: 0.9813 - val_dice_coef_metric_tumor: 0.3847 - val_loss: 0.4028 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4208 - val_recall_tumor: 0.4402 - val_tumor_iou: 0.2679 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 65 lên WandB.\n\n--- Epoch 66/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9786 - dice_coef_metric_tumor: 0.4305 - loss: 0.3536 - mean_iou_all: 0.4484 - precision_tumor: 0.4053 - recall_tumor: 0.5606 - tumor_iou: 0.3006\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.38474\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9786 - dice_coef_metric_tumor: 0.4305 - loss: 0.3536 - mean_iou_all: 0.4485 - precision_tumor: 0.4053 - recall_tumor: 0.5606 - tumor_iou: 0.3006 - val_acc: 0.9803 - val_dice_coef_metric_tumor: 0.3810 - val_loss: 0.4067 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4061 - val_recall_tumor: 0.4328 - val_tumor_iou: 0.2623 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 66 lên WandB.\n\n--- Epoch 67/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9792 - dice_coef_metric_tumor: 0.4385 - loss: 0.3511 - mean_iou_all: 0.4242 - precision_tumor: 0.4301 - recall_tumor: 0.5522 - tumor_iou: 0.3081\nEpoch 1: val_dice_coef_metric_tumor improved from 0.38474 to 0.38542, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9793 - dice_coef_metric_tumor: 0.4384 - loss: 0.3511 - mean_iou_all: 0.4244 - precision_tumor: 0.4301 - recall_tumor: 0.5522 - tumor_iou: 0.3081 - val_acc: 0.9808 - val_dice_coef_metric_tumor: 0.3854 - val_loss: 0.4033 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3898 - val_recall_tumor: 0.4616 - val_tumor_iou: 0.2653 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 67 lên WandB.\n\n--- Epoch 68/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9804 - dice_coef_metric_tumor: 0.4632 - loss: 0.3359 - mean_iou_all: 0.3950 - precision_tumor: 0.4514 - recall_tumor: 0.5752 - tumor_iou: 0.3300\nEpoch 1: val_dice_coef_metric_tumor improved from 0.38542 to 0.39429, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9804 - dice_coef_metric_tumor: 0.4631 - loss: 0.3359 - mean_iou_all: 0.3953 - precision_tumor: 0.4513 - recall_tumor: 0.5751 - tumor_iou: 0.3299 - val_acc: 0.9845 - val_dice_coef_metric_tumor: 0.3943 - val_loss: 0.3967 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4976 - val_recall_tumor: 0.3920 - val_tumor_iou: 0.2774 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 68 lên WandB.\n\n--- Epoch 69/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4436 - loss: 0.3504 - mean_iou_all: 0.4336 - precision_tumor: 0.4313 - recall_tumor: 0.5557 - tumor_iou: 0.3146\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.39429\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4435 - loss: 0.3504 - mean_iou_all: 0.4338 - precision_tumor: 0.4313 - recall_tumor: 0.5557 - tumor_iou: 0.3145 - val_acc: 0.9830 - val_dice_coef_metric_tumor: 0.3691 - val_loss: 0.4127 - val_mean_iou_all: 0.4371 - val_precision_tumor: 0.4066 - val_recall_tumor: 0.3996 - val_tumor_iou: 0.2529 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 69 lên WandB.\n\n--- Epoch 70/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9792 - dice_coef_metric_tumor: 0.4419 - loss: 0.3516 - mean_iou_all: 0.4012 - precision_tumor: 0.4299 - recall_tumor: 0.5663 - tumor_iou: 0.3102\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.39429\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9792 - dice_coef_metric_tumor: 0.4419 - loss: 0.3516 - mean_iou_all: 0.4014 - precision_tumor: 0.4299 - recall_tumor: 0.5662 - tumor_iou: 0.3102 - val_acc: 0.9825 - val_dice_coef_metric_tumor: 0.3124 - val_loss: 0.4468 - val_mean_iou_all: 0.4977 - val_precision_tumor: 0.4287 - val_recall_tumor: 0.2998 - val_tumor_iou: 0.2120 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 70 lên WandB.\n\n--- Epoch 71/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9806 - dice_coef_metric_tumor: 0.4543 - loss: 0.3407 - mean_iou_all: 0.4081 - precision_tumor: 0.4472 - recall_tumor: 0.5500 - tumor_iou: 0.3239\nEpoch 1: val_dice_coef_metric_tumor improved from 0.39429 to 0.40513, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9806 - dice_coef_metric_tumor: 0.4542 - loss: 0.3407 - mean_iou_all: 0.4084 - precision_tumor: 0.4471 - recall_tumor: 0.5500 - tumor_iou: 0.3238 - val_acc: 0.9804 - val_dice_coef_metric_tumor: 0.4051 - val_loss: 0.3909 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4130 - val_recall_tumor: 0.5155 - val_tumor_iou: 0.2805 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 71 lên WandB.\n\n--- Epoch 72/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9823 - dice_coef_metric_tumor: 0.4743 - loss: 0.3312 - mean_iou_all: 0.4268 - precision_tumor: 0.4653 - recall_tumor: 0.5534 - tumor_iou: 0.3358\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.40513\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9823 - dice_coef_metric_tumor: 0.4742 - loss: 0.3312 - mean_iou_all: 0.4270 - precision_tumor: 0.4652 - recall_tumor: 0.5534 - tumor_iou: 0.3357 - val_acc: 0.9832 - val_dice_coef_metric_tumor: 0.3818 - val_loss: 0.4046 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4663 - val_recall_tumor: 0.4062 - val_tumor_iou: 0.2625 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 72 lên WandB.\n\n--- Epoch 73/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9798 - dice_coef_metric_tumor: 0.4405 - loss: 0.3466 - mean_iou_all: 0.4439 - precision_tumor: 0.4271 - recall_tumor: 0.5396 - tumor_iou: 0.3141\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.40513\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9798 - dice_coef_metric_tumor: 0.4405 - loss: 0.3466 - mean_iou_all: 0.4440 - precision_tumor: 0.4270 - recall_tumor: 0.5395 - tumor_iou: 0.3140 - val_acc: 0.9794 - val_dice_coef_metric_tumor: 0.3816 - val_loss: 0.4065 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4197 - val_recall_tumor: 0.4515 - val_tumor_iou: 0.2599 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 73 lên WandB.\n\n--- Epoch 74/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9811 - dice_coef_metric_tumor: 0.4511 - loss: 0.3473 - mean_iou_all: 0.4588 - precision_tumor: 0.4542 - recall_tumor: 0.5334 - tumor_iou: 0.3196\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.40513\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9811 - dice_coef_metric_tumor: 0.4510 - loss: 0.3473 - mean_iou_all: 0.4589 - precision_tumor: 0.4542 - recall_tumor: 0.5334 - tumor_iou: 0.3196 - val_acc: 0.9828 - val_dice_coef_metric_tumor: 0.3985 - val_loss: 0.3947 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4321 - val_recall_tumor: 0.4527 - val_tumor_iou: 0.2780 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 74 lên WandB.\n\n--- Epoch 75/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4484 - loss: 0.3418 - mean_iou_all: 0.4332 - precision_tumor: 0.4287 - recall_tumor: 0.5809 - tumor_iou: 0.3162\nEpoch 1: val_dice_coef_metric_tumor improved from 0.40513 to 0.41789, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4484 - loss: 0.3418 - mean_iou_all: 0.4334 - precision_tumor: 0.4287 - recall_tumor: 0.5808 - tumor_iou: 0.3161 - val_acc: 0.9814 - val_dice_coef_metric_tumor: 0.4179 - val_loss: 0.3840 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4456 - val_recall_tumor: 0.4921 - val_tumor_iou: 0.2940 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 75 lên WandB.\n\n--- Epoch 76/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9828 - dice_coef_metric_tumor: 0.4723 - loss: 0.3241 - mean_iou_all: 0.4499 - precision_tumor: 0.4662 - recall_tumor: 0.5627 - tumor_iou: 0.3376\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41789\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9828 - dice_coef_metric_tumor: 0.4722 - loss: 0.3242 - mean_iou_all: 0.4500 - precision_tumor: 0.4661 - recall_tumor: 0.5627 - tumor_iou: 0.3375 - val_acc: 0.9769 - val_dice_coef_metric_tumor: 0.4094 - val_loss: 0.3904 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3531 - val_recall_tumor: 0.5998 - val_tumor_iou: 0.2816 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 76 lên WandB.\n\n--- Epoch 77/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9811 - dice_coef_metric_tumor: 0.4610 - loss: 0.3353 - mean_iou_all: 0.4283 - precision_tumor: 0.4513 - recall_tumor: 0.5648 - tumor_iou: 0.3289\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41789\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9811 - dice_coef_metric_tumor: 0.4610 - loss: 0.3353 - mean_iou_all: 0.4285 - precision_tumor: 0.4512 - recall_tumor: 0.5648 - tumor_iou: 0.3289 - val_acc: 0.9833 - val_dice_coef_metric_tumor: 0.3901 - val_loss: 0.4005 - val_mean_iou_all: 0.4914 - val_precision_tumor: 0.4732 - val_recall_tumor: 0.4041 - val_tumor_iou: 0.2706 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 77 lên WandB.\n\n--- Epoch 78/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9815 - dice_coef_metric_tumor: 0.4595 - loss: 0.3375 - mean_iou_all: 0.4123 - precision_tumor: 0.4540 - recall_tumor: 0.5548 - tumor_iou: 0.3262\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41789\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9815 - dice_coef_metric_tumor: 0.4594 - loss: 0.3375 - mean_iou_all: 0.4126 - precision_tumor: 0.4539 - recall_tumor: 0.5548 - tumor_iou: 0.3262 - val_acc: 0.9849 - val_dice_coef_metric_tumor: 0.3433 - val_loss: 0.4279 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5329 - val_recall_tumor: 0.3142 - val_tumor_iou: 0.2352 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 78 lên WandB.\n\n--- Epoch 79/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9806 - dice_coef_metric_tumor: 0.4640 - loss: 0.3377 - mean_iou_all: 0.4435 - precision_tumor: 0.4446 - recall_tumor: 0.5832 - tumor_iou: 0.3301\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41789\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9806 - dice_coef_metric_tumor: 0.4640 - loss: 0.3377 - mean_iou_all: 0.4436 - precision_tumor: 0.4445 - recall_tumor: 0.5831 - tumor_iou: 0.3301 - val_acc: 0.9735 - val_dice_coef_metric_tumor: 0.3863 - val_loss: 0.4065 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3258 - val_recall_tumor: 0.6082 - val_tumor_iou: 0.2643 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 79 lên WandB.\n\n--- Epoch 80/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9813 - dice_coef_metric_tumor: 0.4709 - loss: 0.3382 - mean_iou_all: 0.4400 - precision_tumor: 0.4599 - recall_tumor: 0.5722 - tumor_iou: 0.3342\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41789\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9813 - dice_coef_metric_tumor: 0.4709 - loss: 0.3381 - mean_iou_all: 0.4401 - precision_tumor: 0.4599 - recall_tumor: 0.5722 - tumor_iou: 0.3341 - val_acc: 0.9862 - val_dice_coef_metric_tumor: 0.3970 - val_loss: 0.3955 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5518 - val_recall_tumor: 0.3635 - val_tumor_iou: 0.2766 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 80 lên WandB.\n\n--- Epoch 81/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9825 - dice_coef_metric_tumor: 0.4733 - loss: 0.3286 - mean_iou_all: 0.4607 - precision_tumor: 0.4715 - recall_tumor: 0.5631 - tumor_iou: 0.3400\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41789\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9825 - dice_coef_metric_tumor: 0.4732 - loss: 0.3287 - mean_iou_all: 0.4608 - precision_tumor: 0.4714 - recall_tumor: 0.5630 - tumor_iou: 0.3399 - val_acc: 0.9788 - val_dice_coef_metric_tumor: 0.4025 - val_loss: 0.3948 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3757 - val_recall_tumor: 0.5521 - val_tumor_iou: 0.2765 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 81 lên WandB.\n\n--- Epoch 82/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9813 - dice_coef_metric_tumor: 0.4553 - loss: 0.3355 - mean_iou_all: 0.4509 - precision_tumor: 0.4468 - recall_tumor: 0.5480 - tumor_iou: 0.3244\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41789\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9813 - dice_coef_metric_tumor: 0.4553 - loss: 0.3355 - mean_iou_all: 0.4510 - precision_tumor: 0.4468 - recall_tumor: 0.5480 - tumor_iou: 0.3244 - val_acc: 0.9824 - val_dice_coef_metric_tumor: 0.3776 - val_loss: 0.4089 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4236 - val_recall_tumor: 0.4142 - val_tumor_iou: 0.2610 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 82 lên WandB.\n\n--- Epoch 83/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9826 - dice_coef_metric_tumor: 0.4831 - loss: 0.3311 - mean_iou_all: 0.4591 - precision_tumor: 0.4859 - recall_tumor: 0.5639 - tumor_iou: 0.3479\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41789\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9826 - dice_coef_metric_tumor: 0.4831 - loss: 0.3310 - mean_iou_all: 0.4591 - precision_tumor: 0.4859 - recall_tumor: 0.5639 - tumor_iou: 0.3479 - val_acc: 0.9858 - val_dice_coef_metric_tumor: 0.3881 - val_loss: 0.4016 - val_mean_iou_all: 0.4875 - val_precision_tumor: 0.5768 - val_recall_tumor: 0.3507 - val_tumor_iou: 0.2760 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 83 lên WandB.\n\n--- Epoch 84/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - acc: 0.9828 - dice_coef_metric_tumor: 0.4651 - loss: 0.3275 - mean_iou_all: 0.4383 - precision_tumor: 0.4660 - recall_tumor: 0.5499 - tumor_iou: 0.3334\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41789\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9828 - dice_coef_metric_tumor: 0.4650 - loss: 0.3275 - mean_iou_all: 0.4385 - precision_tumor: 0.4660 - recall_tumor: 0.5499 - tumor_iou: 0.3334 - val_acc: 0.9778 - val_dice_coef_metric_tumor: 0.4044 - val_loss: 0.3943 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3956 - val_recall_tumor: 0.5272 - val_tumor_iou: 0.2803 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 84 lên WandB.\n\n--- Epoch 85/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9817 - dice_coef_metric_tumor: 0.4797 - loss: 0.3228 - mean_iou_all: 0.4547 - precision_tumor: 0.4651 - recall_tumor: 0.5956 - tumor_iou: 0.3447\nEpoch 1: val_dice_coef_metric_tumor improved from 0.41789 to 0.43422, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 472ms/step - acc: 0.9817 - dice_coef_metric_tumor: 0.4797 - loss: 0.3228 - mean_iou_all: 0.4548 - precision_tumor: 0.4650 - recall_tumor: 0.5955 - tumor_iou: 0.3446 - val_acc: 0.9821 - val_dice_coef_metric_tumor: 0.4342 - val_loss: 0.3753 - val_mean_iou_all: 0.3538 - val_precision_tumor: 0.4311 - val_recall_tumor: 0.5276 - val_tumor_iou: 0.3054 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 85 lên WandB.\n\n--- Epoch 86/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9824 - dice_coef_metric_tumor: 0.4643 - loss: 0.3289 - mean_iou_all: 0.4429 - precision_tumor: 0.4679 - recall_tumor: 0.5529 - tumor_iou: 0.3330\nEpoch 1: val_dice_coef_metric_tumor improved from 0.43422 to 0.44357, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9824 - dice_coef_metric_tumor: 0.4643 - loss: 0.3289 - mean_iou_all: 0.4430 - precision_tumor: 0.4679 - recall_tumor: 0.5529 - tumor_iou: 0.3330 - val_acc: 0.9813 - val_dice_coef_metric_tumor: 0.4436 - val_loss: 0.3701 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4284 - val_recall_tumor: 0.5571 - val_tumor_iou: 0.3132 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 86 lên WandB.\n\n--- Epoch 87/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9822 - dice_coef_metric_tumor: 0.4910 - loss: 0.3224 - mean_iou_all: 0.4606 - precision_tumor: 0.4842 - recall_tumor: 0.5962 - tumor_iou: 0.3529\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.44357\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9822 - dice_coef_metric_tumor: 0.4909 - loss: 0.3224 - mean_iou_all: 0.4607 - precision_tumor: 0.4842 - recall_tumor: 0.5962 - tumor_iou: 0.3529 - val_acc: 0.9845 - val_dice_coef_metric_tumor: 0.3817 - val_loss: 0.4061 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5226 - val_recall_tumor: 0.3708 - val_tumor_iou: 0.2661 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 87 lên WandB.\n\n--- Epoch 88/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9832 - dice_coef_metric_tumor: 0.4920 - loss: 0.3184 - mean_iou_all: 0.4463 - precision_tumor: 0.4941 - recall_tumor: 0.5708 - tumor_iou: 0.3562\nEpoch 1: val_dice_coef_metric_tumor improved from 0.44357 to 0.44521, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9832 - dice_coef_metric_tumor: 0.4920 - loss: 0.3184 - mean_iou_all: 0.4464 - precision_tumor: 0.4940 - recall_tumor: 0.5708 - tumor_iou: 0.3561 - val_acc: 0.9836 - val_dice_coef_metric_tumor: 0.4452 - val_loss: 0.3682 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4517 - val_recall_tumor: 0.5246 - val_tumor_iou: 0.3142 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 88 lên WandB.\n\n--- Epoch 89/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9805 - dice_coef_metric_tumor: 0.4654 - loss: 0.3306 - mean_iou_all: 0.4457 - precision_tumor: 0.4536 - recall_tumor: 0.5811 - tumor_iou: 0.3341\nEpoch 1: val_dice_coef_metric_tumor improved from 0.44521 to 0.45206, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9805 - dice_coef_metric_tumor: 0.4654 - loss: 0.3306 - mean_iou_all: 0.4458 - precision_tumor: 0.4536 - recall_tumor: 0.5811 - tumor_iou: 0.3341 - val_acc: 0.9857 - val_dice_coef_metric_tumor: 0.4521 - val_loss: 0.3632 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5353 - val_recall_tumor: 0.4710 - val_tumor_iou: 0.3221 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 89 lên WandB.\n\n--- Epoch 90/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9828 - dice_coef_metric_tumor: 0.4805 - loss: 0.3250 - mean_iou_all: 0.4577 - precision_tumor: 0.4716 - recall_tumor: 0.5726 - tumor_iou: 0.3460\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45206\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9828 - dice_coef_metric_tumor: 0.4805 - loss: 0.3249 - mean_iou_all: 0.4578 - precision_tumor: 0.4716 - recall_tumor: 0.5726 - tumor_iou: 0.3460 - val_acc: 0.9810 - val_dice_coef_metric_tumor: 0.4465 - val_loss: 0.3683 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4243 - val_recall_tumor: 0.5849 - val_tumor_iou: 0.3146 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 90 lên WandB.\n\n--- Epoch 91/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.4888 - loss: 0.3184 - mean_iou_all: 0.4612 - precision_tumor: 0.4920 - recall_tumor: 0.5598 - tumor_iou: 0.3502\nEpoch 1: val_dice_coef_metric_tumor improved from 0.45206 to 0.46333, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.4887 - loss: 0.3184 - mean_iou_all: 0.4612 - precision_tumor: 0.4919 - recall_tumor: 0.5598 - tumor_iou: 0.3502 - val_acc: 0.9818 - val_dice_coef_metric_tumor: 0.4633 - val_loss: 0.3580 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4713 - val_recall_tumor: 0.5645 - val_tumor_iou: 0.3310 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 91 lên WandB.\n\n--- Epoch 92/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9816 - dice_coef_metric_tumor: 0.4820 - loss: 0.3291 - mean_iou_all: 0.4779 - precision_tumor: 0.4749 - recall_tumor: 0.5857 - tumor_iou: 0.3471\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46333\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9816 - dice_coef_metric_tumor: 0.4820 - loss: 0.3290 - mean_iou_all: 0.4780 - precision_tumor: 0.4749 - recall_tumor: 0.5857 - tumor_iou: 0.3471 - val_acc: 0.9810 - val_dice_coef_metric_tumor: 0.4505 - val_loss: 0.3658 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4269 - val_recall_tumor: 0.6055 - val_tumor_iou: 0.3187 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 92 lên WandB.\n\n--- Epoch 93/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.5160 - loss: 0.3039 - mean_iou_all: 0.4743 - precision_tumor: 0.5077 - recall_tumor: 0.6042 - tumor_iou: 0.3772\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46333\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.5159 - loss: 0.3040 - mean_iou_all: 0.4743 - precision_tumor: 0.5076 - recall_tumor: 0.6042 - tumor_iou: 0.3771 - val_acc: 0.9806 - val_dice_coef_metric_tumor: 0.3988 - val_loss: 0.3976 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4059 - val_recall_tumor: 0.5195 - val_tumor_iou: 0.2755 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 93 lên WandB.\n\n--- Epoch 94/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.4910 - loss: 0.3158 - mean_iou_all: 0.4763 - precision_tumor: 0.4863 - recall_tumor: 0.5828 - tumor_iou: 0.3561\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46333\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.4909 - loss: 0.3158 - mean_iou_all: 0.4764 - precision_tumor: 0.4862 - recall_tumor: 0.5828 - tumor_iou: 0.3561 - val_acc: 0.9858 - val_dice_coef_metric_tumor: 0.4137 - val_loss: 0.3867 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5106 - val_recall_tumor: 0.4150 - val_tumor_iou: 0.2924 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 94 lên WandB.\n\n--- Epoch 95/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.5121 - loss: 0.3077 - mean_iou_all: 0.4737 - precision_tumor: 0.5105 - recall_tumor: 0.5973 - tumor_iou: 0.3756\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46333\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.5120 - loss: 0.3077 - mean_iou_all: 0.4738 - precision_tumor: 0.5104 - recall_tumor: 0.5972 - tumor_iou: 0.3756 - val_acc: 0.9740 - val_dice_coef_metric_tumor: 0.4174 - val_loss: 0.3888 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3513 - val_recall_tumor: 0.6779 - val_tumor_iou: 0.2887 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 95 lên WandB.\n\n--- Epoch 96/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9817 - dice_coef_metric_tumor: 0.4814 - loss: 0.3280 - mean_iou_all: 0.4552 - precision_tumor: 0.4665 - recall_tumor: 0.5986 - tumor_iou: 0.3449\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46333\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9817 - dice_coef_metric_tumor: 0.4813 - loss: 0.3280 - mean_iou_all: 0.4552 - precision_tumor: 0.4665 - recall_tumor: 0.5986 - tumor_iou: 0.3449 - val_acc: 0.9824 - val_dice_coef_metric_tumor: 0.4307 - val_loss: 0.3777 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4197 - val_recall_tumor: 0.5345 - val_tumor_iou: 0.3019 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 96 lên WandB.\n\n--- Epoch 97/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9826 - dice_coef_metric_tumor: 0.4937 - loss: 0.3232 - mean_iou_all: 0.4754 - precision_tumor: 0.4927 - recall_tumor: 0.5882 - tumor_iou: 0.3555\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46333\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9826 - dice_coef_metric_tumor: 0.4936 - loss: 0.3232 - mean_iou_all: 0.4754 - precision_tumor: 0.4926 - recall_tumor: 0.5881 - tumor_iou: 0.3555 - val_acc: 0.9828 - val_dice_coef_metric_tumor: 0.3961 - val_loss: 0.3985 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4600 - val_recall_tumor: 0.4325 - val_tumor_iou: 0.2763 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 97 lên WandB.\n\n--- Epoch 98/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9829 - dice_coef_metric_tumor: 0.4883 - loss: 0.3219 - mean_iou_all: 0.4794 - precision_tumor: 0.4788 - recall_tumor: 0.5809 - tumor_iou: 0.3524\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46333\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9829 - dice_coef_metric_tumor: 0.4882 - loss: 0.3219 - mean_iou_all: 0.4794 - precision_tumor: 0.4788 - recall_tumor: 0.5809 - tumor_iou: 0.3524 - val_acc: 0.9834 - val_dice_coef_metric_tumor: 0.4406 - val_loss: 0.3725 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4751 - val_recall_tumor: 0.4889 - val_tumor_iou: 0.3142 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 98 lên WandB.\n\n--- Epoch 99/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9838 - dice_coef_metric_tumor: 0.5052 - loss: 0.3174 - mean_iou_all: 0.4779 - precision_tumor: 0.5098 - recall_tumor: 0.5798 - tumor_iou: 0.3657\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46333\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9838 - dice_coef_metric_tumor: 0.5051 - loss: 0.3174 - mean_iou_all: 0.4779 - precision_tumor: 0.5097 - recall_tumor: 0.5798 - tumor_iou: 0.3657 - val_acc: 0.9684 - val_dice_coef_metric_tumor: 0.3950 - val_loss: 0.4057 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3090 - val_recall_tumor: 0.6843 - val_tumor_iou: 0.2687 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 99 lên WandB.\n\n--- Epoch 100/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9823 - dice_coef_metric_tumor: 0.4917 - loss: 0.3170 - mean_iou_all: 0.4805 - precision_tumor: 0.4693 - recall_tumor: 0.6101 - tumor_iou: 0.3559\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46333\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9823 - dice_coef_metric_tumor: 0.4917 - loss: 0.3170 - mean_iou_all: 0.4805 - precision_tumor: 0.4693 - recall_tumor: 0.6100 - tumor_iou: 0.3558 - val_acc: 0.9839 - val_dice_coef_metric_tumor: 0.3775 - val_loss: 0.4105 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5072 - val_recall_tumor: 0.3657 - val_tumor_iou: 0.2599 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 100 lên WandB.\n\n--- Epoch 101/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9823 - dice_coef_metric_tumor: 0.4922 - loss: 0.3202 - mean_iou_all: 0.4736 - precision_tumor: 0.4766 - recall_tumor: 0.5972 - tumor_iou: 0.3558\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46333\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9823 - dice_coef_metric_tumor: 0.4922 - loss: 0.3202 - mean_iou_all: 0.4736 - precision_tumor: 0.4766 - recall_tumor: 0.5972 - tumor_iou: 0.3558 - val_acc: 0.9791 - val_dice_coef_metric_tumor: 0.4173 - val_loss: 0.3884 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3929 - val_recall_tumor: 0.5479 - val_tumor_iou: 0.2882 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 101 lên WandB.\n\n--- Epoch 102/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9834 - dice_coef_metric_tumor: 0.5054 - loss: 0.3112 - mean_iou_all: 0.4807 - precision_tumor: 0.5063 - recall_tumor: 0.6012 - tumor_iou: 0.3703\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46333\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9834 - dice_coef_metric_tumor: 0.5053 - loss: 0.3112 - mean_iou_all: 0.4807 - precision_tumor: 0.5062 - recall_tumor: 0.6012 - tumor_iou: 0.3703 - val_acc: 0.9758 - val_dice_coef_metric_tumor: 0.4185 - val_loss: 0.3888 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3461 - val_recall_tumor: 0.6676 - val_tumor_iou: 0.2898 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 102 lên WandB.\n\n--- Epoch 103/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9822 - dice_coef_metric_tumor: 0.5036 - loss: 0.3091 - mean_iou_all: 0.4780 - precision_tumor: 0.4857 - recall_tumor: 0.6302 - tumor_iou: 0.3652\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46333\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9822 - dice_coef_metric_tumor: 0.5036 - loss: 0.3091 - mean_iou_all: 0.4780 - precision_tumor: 0.4857 - recall_tumor: 0.6301 - tumor_iou: 0.3652 - val_acc: 0.9850 - val_dice_coef_metric_tumor: 0.4515 - val_loss: 0.3649 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4895 - val_recall_tumor: 0.4997 - val_tumor_iou: 0.3237 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 103 lên WandB.\n\n--- Epoch 104/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9829 - dice_coef_metric_tumor: 0.4937 - loss: 0.3174 - mean_iou_all: 0.4763 - precision_tumor: 0.4888 - recall_tumor: 0.5970 - tumor_iou: 0.3578\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46333\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9829 - dice_coef_metric_tumor: 0.4937 - loss: 0.3174 - mean_iou_all: 0.4764 - precision_tumor: 0.4888 - recall_tumor: 0.5970 - tumor_iou: 0.3578 - val_acc: 0.9856 - val_dice_coef_metric_tumor: 0.4289 - val_loss: 0.3790 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5331 - val_recall_tumor: 0.4268 - val_tumor_iou: 0.3086 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 104 lên WandB.\n\n--- Epoch 105/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9849 - dice_coef_metric_tumor: 0.5281 - loss: 0.2970 - mean_iou_all: 0.4675 - precision_tumor: 0.5259 - recall_tumor: 0.6200 - tumor_iou: 0.3884\nEpoch 1: val_dice_coef_metric_tumor improved from 0.46333 to 0.47358, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 472ms/step - acc: 0.9849 - dice_coef_metric_tumor: 0.5281 - loss: 0.2971 - mean_iou_all: 0.4674 - precision_tumor: 0.5259 - recall_tumor: 0.6200 - tumor_iou: 0.3884 - val_acc: 0.9852 - val_dice_coef_metric_tumor: 0.4736 - val_loss: 0.3526 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4864 - val_recall_tumor: 0.5489 - val_tumor_iou: 0.3413 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 105 lên WandB.\n\n--- Epoch 106/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9825 - dice_coef_metric_tumor: 0.5091 - loss: 0.3101 - mean_iou_all: 0.4739 - precision_tumor: 0.4833 - recall_tumor: 0.6267 - tumor_iou: 0.3707\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47358\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9825 - dice_coef_metric_tumor: 0.5091 - loss: 0.3101 - mean_iou_all: 0.4739 - precision_tumor: 0.4833 - recall_tumor: 0.6266 - tumor_iou: 0.3707 - val_acc: 0.9851 - val_dice_coef_metric_tumor: 0.4380 - val_loss: 0.3737 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5145 - val_recall_tumor: 0.4546 - val_tumor_iou: 0.3107 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 106 lên WandB.\n\n--- Epoch 107/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5177 - loss: 0.3023 - mean_iou_all: 0.4705 - precision_tumor: 0.5296 - recall_tumor: 0.6088 - tumor_iou: 0.3774\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47358\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5176 - loss: 0.3023 - mean_iou_all: 0.4705 - precision_tumor: 0.5296 - recall_tumor: 0.6088 - tumor_iou: 0.3773 - val_acc: 0.9851 - val_dice_coef_metric_tumor: 0.4381 - val_loss: 0.3744 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5080 - val_recall_tumor: 0.4591 - val_tumor_iou: 0.3102 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 107 lên WandB.\n\n--- Epoch 108/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9838 - dice_coef_metric_tumor: 0.5087 - loss: 0.3105 - mean_iou_all: 0.4765 - precision_tumor: 0.5048 - recall_tumor: 0.6078 - tumor_iou: 0.3704\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47358\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9838 - dice_coef_metric_tumor: 0.5087 - loss: 0.3105 - mean_iou_all: 0.4765 - precision_tumor: 0.5048 - recall_tumor: 0.6077 - tumor_iou: 0.3704 - val_acc: 0.9863 - val_dice_coef_metric_tumor: 0.4664 - val_loss: 0.3565 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5269 - val_recall_tumor: 0.4925 - val_tumor_iou: 0.3326 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 108 lên WandB.\n\n--- Epoch 109/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.4974 - loss: 0.3148 - mean_iou_all: 0.4749 - precision_tumor: 0.4873 - recall_tumor: 0.6071 - tumor_iou: 0.3593\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47358\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.4974 - loss: 0.3148 - mean_iou_all: 0.4749 - precision_tumor: 0.4873 - recall_tumor: 0.6071 - tumor_iou: 0.3592 - val_acc: 0.9821 - val_dice_coef_metric_tumor: 0.4672 - val_loss: 0.3573 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4527 - val_recall_tumor: 0.5852 - val_tumor_iou: 0.3344 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 109 lên WandB.\n\n--- Epoch 110/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9841 - dice_coef_metric_tumor: 0.5160 - loss: 0.3095 - mean_iou_all: 0.4879 - precision_tumor: 0.5179 - recall_tumor: 0.5970 - tumor_iou: 0.3771\nEpoch 1: val_dice_coef_metric_tumor improved from 0.47358 to 0.47659, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9841 - dice_coef_metric_tumor: 0.5160 - loss: 0.3095 - mean_iou_all: 0.4879 - precision_tumor: 0.5179 - recall_tumor: 0.5970 - tumor_iou: 0.3771 - val_acc: 0.9840 - val_dice_coef_metric_tumor: 0.4766 - val_loss: 0.3513 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4953 - val_recall_tumor: 0.5588 - val_tumor_iou: 0.3460 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 110 lên WandB.\n\n--- Epoch 111/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.5307 - loss: 0.3044 - mean_iou_all: 0.4818 - precision_tumor: 0.5187 - recall_tumor: 0.6226 - tumor_iou: 0.3910\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47659\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.5306 - loss: 0.3044 - mean_iou_all: 0.4818 - precision_tumor: 0.5187 - recall_tumor: 0.6225 - tumor_iou: 0.3909 - val_acc: 0.9861 - val_dice_coef_metric_tumor: 0.4764 - val_loss: 0.3512 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5393 - val_recall_tumor: 0.4935 - val_tumor_iou: 0.3472 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 111 lên WandB.\n\n--- Epoch 112/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.5331 - loss: 0.3003 - mean_iou_all: 0.4801 - precision_tumor: 0.5138 - recall_tumor: 0.6339 - tumor_iou: 0.3945\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47659\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.5331 - loss: 0.3003 - mean_iou_all: 0.4801 - precision_tumor: 0.5138 - recall_tumor: 0.6339 - tumor_iou: 0.3945 - val_acc: 0.9813 - val_dice_coef_metric_tumor: 0.4707 - val_loss: 0.3550 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4357 - val_recall_tumor: 0.6166 - val_tumor_iou: 0.3369 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 112 lên WandB.\n\n--- Epoch 113/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9840 - dice_coef_metric_tumor: 0.5182 - loss: 0.3072 - mean_iou_all: 0.4840 - precision_tumor: 0.5197 - recall_tumor: 0.6026 - tumor_iou: 0.3787\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47659\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9840 - dice_coef_metric_tumor: 0.5182 - loss: 0.3072 - mean_iou_all: 0.4840 - precision_tumor: 0.5197 - recall_tumor: 0.6026 - tumor_iou: 0.3786 - val_acc: 0.9769 - val_dice_coef_metric_tumor: 0.4281 - val_loss: 0.3844 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3555 - val_recall_tumor: 0.6645 - val_tumor_iou: 0.2994 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 113 lên WandB.\n\n--- Epoch 114/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9843 - dice_coef_metric_tumor: 0.5198 - loss: 0.3043 - mean_iou_all: 0.4837 - precision_tumor: 0.5136 - recall_tumor: 0.6071 - tumor_iou: 0.3805\nEpoch 1: val_dice_coef_metric_tumor improved from 0.47659 to 0.48468, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9843 - dice_coef_metric_tumor: 0.5198 - loss: 0.3043 - mean_iou_all: 0.4837 - precision_tumor: 0.5135 - recall_tumor: 0.6071 - tumor_iou: 0.3805 - val_acc: 0.9856 - val_dice_coef_metric_tumor: 0.4847 - val_loss: 0.3465 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5229 - val_recall_tumor: 0.5314 - val_tumor_iou: 0.3533 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 114 lên WandB.\n\n--- Epoch 115/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5423 - loss: 0.2928 - mean_iou_all: 0.4780 - precision_tumor: 0.5477 - recall_tumor: 0.6169 - tumor_iou: 0.4012\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48468\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5423 - loss: 0.2928 - mean_iou_all: 0.4780 - precision_tumor: 0.5476 - recall_tumor: 0.6169 - tumor_iou: 0.4011 - val_acc: 0.9842 - val_dice_coef_metric_tumor: 0.4759 - val_loss: 0.3523 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4813 - val_recall_tumor: 0.5570 - val_tumor_iou: 0.3452 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 115 lên WandB.\n\n--- Epoch 116/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9849 - dice_coef_metric_tumor: 0.5421 - loss: 0.2948 - mean_iou_all: 0.4839 - precision_tumor: 0.5366 - recall_tumor: 0.6291 - tumor_iou: 0.4016\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48468\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9849 - dice_coef_metric_tumor: 0.5420 - loss: 0.2948 - mean_iou_all: 0.4839 - precision_tumor: 0.5365 - recall_tumor: 0.6290 - tumor_iou: 0.4015 - val_acc: 0.9828 - val_dice_coef_metric_tumor: 0.4689 - val_loss: 0.3573 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4320 - val_recall_tumor: 0.5985 - val_tumor_iou: 0.3399 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 116 lên WandB.\n\n--- Epoch 117/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5380 - loss: 0.2949 - mean_iou_all: 0.4782 - precision_tumor: 0.5316 - recall_tumor: 0.6301 - tumor_iou: 0.3956\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48468\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5380 - loss: 0.2949 - mean_iou_all: 0.4782 - precision_tumor: 0.5316 - recall_tumor: 0.6301 - tumor_iou: 0.3956 - val_acc: 0.9879 - val_dice_coef_metric_tumor: 0.4835 - val_loss: 0.3469 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5899 - val_recall_tumor: 0.4629 - val_tumor_iou: 0.3503 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 117 lên WandB.\n\n--- Epoch 118/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5489 - loss: 0.2855 - mean_iou_all: 0.4751 - precision_tumor: 0.5568 - recall_tumor: 0.6228 - tumor_iou: 0.4084\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48468\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5488 - loss: 0.2855 - mean_iou_all: 0.4751 - precision_tumor: 0.5567 - recall_tumor: 0.6228 - tumor_iou: 0.4083 - val_acc: 0.9861 - val_dice_coef_metric_tumor: 0.4654 - val_loss: 0.3583 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5120 - val_recall_tumor: 0.5066 - val_tumor_iou: 0.3406 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 118 lên WandB.\n\n--- Epoch 119/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9857 - dice_coef_metric_tumor: 0.5403 - loss: 0.2936 - mean_iou_all: 0.4825 - precision_tumor: 0.5411 - recall_tumor: 0.6180 - tumor_iou: 0.3985\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48468\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9857 - dice_coef_metric_tumor: 0.5403 - loss: 0.2936 - mean_iou_all: 0.4825 - precision_tumor: 0.5411 - recall_tumor: 0.6179 - tumor_iou: 0.3985 - val_acc: 0.9867 - val_dice_coef_metric_tumor: 0.4771 - val_loss: 0.3510 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5921 - val_recall_tumor: 0.4676 - val_tumor_iou: 0.3467 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 119 lên WandB.\n\n--- Epoch 120/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5353 - loss: 0.2935 - mean_iou_all: 0.4785 - precision_tumor: 0.5416 - recall_tumor: 0.6024 - tumor_iou: 0.3976\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48468\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 466ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5352 - loss: 0.2935 - mean_iou_all: 0.4785 - precision_tumor: 0.5416 - recall_tumor: 0.6024 - tumor_iou: 0.3976 - val_acc: 0.9848 - val_dice_coef_metric_tumor: 0.4759 - val_loss: 0.3527 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4808 - val_recall_tumor: 0.5558 - val_tumor_iou: 0.3388 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 120 lên WandB.\n\n--- Epoch 121/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5415 - loss: 0.2909 - mean_iou_all: 0.4668 - precision_tumor: 0.5413 - recall_tumor: 0.6220 - tumor_iou: 0.4023\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48468\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 466ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5415 - loss: 0.2909 - mean_iou_all: 0.4668 - precision_tumor: 0.5412 - recall_tumor: 0.6220 - tumor_iou: 0.4022 - val_acc: 0.9867 - val_dice_coef_metric_tumor: 0.4747 - val_loss: 0.3530 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5331 - val_recall_tumor: 0.4913 - val_tumor_iou: 0.3444 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 121 lên WandB.\n\n--- Epoch 122/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5590 - loss: 0.2813 - mean_iou_all: 0.4827 - precision_tumor: 0.5554 - recall_tumor: 0.6326 - tumor_iou: 0.4172\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48468\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 466ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5589 - loss: 0.2813 - mean_iou_all: 0.4827 - precision_tumor: 0.5553 - recall_tumor: 0.6326 - tumor_iou: 0.4171 - val_acc: 0.9868 - val_dice_coef_metric_tumor: 0.4664 - val_loss: 0.3578 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5397 - val_recall_tumor: 0.4793 - val_tumor_iou: 0.3373 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 122 lên WandB.\n\n--- Epoch 123/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5392 - loss: 0.2967 - mean_iou_all: 0.4763 - precision_tumor: 0.5446 - recall_tumor: 0.6180 - tumor_iou: 0.3996\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48468\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5391 - loss: 0.2967 - mean_iou_all: 0.4763 - precision_tumor: 0.5446 - recall_tumor: 0.6180 - tumor_iou: 0.3996 - val_acc: 0.9818 - val_dice_coef_metric_tumor: 0.4735 - val_loss: 0.3564 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4363 - val_recall_tumor: 0.6026 - val_tumor_iou: 0.3436 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 123 lên WandB.\n\n--- Epoch 124/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5424 - loss: 0.2960 - mean_iou_all: 0.4706 - precision_tumor: 0.5555 - recall_tumor: 0.6038 - tumor_iou: 0.3981\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48468\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5423 - loss: 0.2960 - mean_iou_all: 0.4707 - precision_tumor: 0.5555 - recall_tumor: 0.6038 - tumor_iou: 0.3981 - val_acc: 0.9882 - val_dice_coef_metric_tumor: 0.4787 - val_loss: 0.3508 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6144 - val_recall_tumor: 0.4626 - val_tumor_iou: 0.3502 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 124 lên WandB.\n\n--- Epoch 125/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5420 - loss: 0.2910 - mean_iou_all: 0.4821 - precision_tumor: 0.5439 - recall_tumor: 0.6311 - tumor_iou: 0.4019\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48468\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 466ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5420 - loss: 0.2910 - mean_iou_all: 0.4821 - precision_tumor: 0.5439 - recall_tumor: 0.6311 - tumor_iou: 0.4019 - val_acc: 0.9824 - val_dice_coef_metric_tumor: 0.4743 - val_loss: 0.3546 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4423 - val_recall_tumor: 0.6185 - val_tumor_iou: 0.3400 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 125 lên WandB.\n\n--- Epoch 126/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5542 - loss: 0.2861 - mean_iou_all: 0.4792 - precision_tumor: 0.5593 - recall_tumor: 0.6229 - tumor_iou: 0.4184\nEpoch 1: val_dice_coef_metric_tumor improved from 0.48468 to 0.51022, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5542 - loss: 0.2861 - mean_iou_all: 0.4792 - precision_tumor: 0.5593 - recall_tumor: 0.6229 - tumor_iou: 0.4184 - val_acc: 0.9858 - val_dice_coef_metric_tumor: 0.5102 - val_loss: 0.3320 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5038 - val_recall_tumor: 0.5901 - val_tumor_iou: 0.3754 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 126 lên WandB.\n\n--- Epoch 127/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9855 - dice_coef_metric_tumor: 0.5444 - loss: 0.2952 - mean_iou_all: 0.4777 - precision_tumor: 0.5506 - recall_tumor: 0.6197 - tumor_iou: 0.4027\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51022\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9855 - dice_coef_metric_tumor: 0.5444 - loss: 0.2952 - mean_iou_all: 0.4777 - precision_tumor: 0.5506 - recall_tumor: 0.6197 - tumor_iou: 0.4027 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.4661 - val_loss: 0.3585 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6076 - val_recall_tumor: 0.4328 - val_tumor_iou: 0.3354 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 127 lên WandB.\n\n--- Epoch 128/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9846 - dice_coef_metric_tumor: 0.5379 - loss: 0.3023 - mean_iou_all: 0.4718 - precision_tumor: 0.5328 - recall_tumor: 0.6140 - tumor_iou: 0.3949\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51022\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9846 - dice_coef_metric_tumor: 0.5379 - loss: 0.3023 - mean_iou_all: 0.4718 - precision_tumor: 0.5328 - recall_tumor: 0.6139 - tumor_iou: 0.3948 - val_acc: 0.9820 - val_dice_coef_metric_tumor: 0.4763 - val_loss: 0.3546 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4459 - val_recall_tumor: 0.5841 - val_tumor_iou: 0.3434 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 128 lên WandB.\n\n--- Epoch 129/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.5561 - loss: 0.2838 - mean_iou_all: 0.4709 - precision_tumor: 0.5687 - recall_tumor: 0.6115 - tumor_iou: 0.4163\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51022\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.5561 - loss: 0.2838 - mean_iou_all: 0.4709 - precision_tumor: 0.5687 - recall_tumor: 0.6115 - tumor_iou: 0.4162 - val_acc: 0.9836 - val_dice_coef_metric_tumor: 0.5092 - val_loss: 0.3341 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4616 - val_recall_tumor: 0.6460 - val_tumor_iou: 0.3740 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 129 lên WandB.\n\n--- Epoch 130/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5676 - loss: 0.2781 - mean_iou_all: 0.4712 - precision_tumor: 0.5768 - recall_tumor: 0.6187 - tumor_iou: 0.4292\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51022\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5675 - loss: 0.2781 - mean_iou_all: 0.4711 - precision_tumor: 0.5767 - recall_tumor: 0.6186 - tumor_iou: 0.4291 - val_acc: 0.9867 - val_dice_coef_metric_tumor: 0.4882 - val_loss: 0.3459 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5151 - val_recall_tumor: 0.5326 - val_tumor_iou: 0.3556 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 130 lên WandB.\n\n--- Epoch 131/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5431 - loss: 0.2948 - mean_iou_all: 0.4704 - precision_tumor: 0.5651 - recall_tumor: 0.6159 - tumor_iou: 0.4014\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51022\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5430 - loss: 0.2948 - mean_iou_all: 0.4704 - precision_tumor: 0.5650 - recall_tumor: 0.6159 - tumor_iou: 0.4014 - val_acc: 0.9860 - val_dice_coef_metric_tumor: 0.4590 - val_loss: 0.3638 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5366 - val_recall_tumor: 0.4698 - val_tumor_iou: 0.3293 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 131 lên WandB.\n\n--- Epoch 132/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5618 - loss: 0.2794 - mean_iou_all: 0.4670 - precision_tumor: 0.5648 - recall_tumor: 0.6466 - tumor_iou: 0.4185\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51022\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5618 - loss: 0.2794 - mean_iou_all: 0.4670 - precision_tumor: 0.5648 - recall_tumor: 0.6465 - tumor_iou: 0.4185 - val_acc: 0.9829 - val_dice_coef_metric_tumor: 0.5007 - val_loss: 0.3398 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4619 - val_recall_tumor: 0.6457 - val_tumor_iou: 0.3638 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 132 lên WandB.\n\n--- Epoch 133/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5432 - loss: 0.2923 - mean_iou_all: 0.4692 - precision_tumor: 0.5588 - recall_tumor: 0.6087 - tumor_iou: 0.4055\nEpoch 1: val_dice_coef_metric_tumor improved from 0.51022 to 0.51855, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 472ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5432 - loss: 0.2923 - mean_iou_all: 0.4692 - precision_tumor: 0.5588 - recall_tumor: 0.6087 - tumor_iou: 0.4055 - val_acc: 0.9863 - val_dice_coef_metric_tumor: 0.5186 - val_loss: 0.3280 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5107 - val_recall_tumor: 0.6073 - val_tumor_iou: 0.3786 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 133 lên WandB.\n\n--- Epoch 134/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5504 - loss: 0.2890 - mean_iou_all: 0.4699 - precision_tumor: 0.5547 - recall_tumor: 0.6287 - tumor_iou: 0.4099\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5503 - loss: 0.2890 - mean_iou_all: 0.4699 - precision_tumor: 0.5546 - recall_tumor: 0.6287 - tumor_iou: 0.4098 - val_acc: 0.9851 - val_dice_coef_metric_tumor: 0.4927 - val_loss: 0.3434 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5012 - val_recall_tumor: 0.5620 - val_tumor_iou: 0.3573 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 134 lên WandB.\n\n--- Epoch 135/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9857 - dice_coef_metric_tumor: 0.5548 - loss: 0.2837 - mean_iou_all: 0.4717 - precision_tumor: 0.5498 - recall_tumor: 0.6451 - tumor_iou: 0.4167\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9857 - dice_coef_metric_tumor: 0.5548 - loss: 0.2837 - mean_iou_all: 0.4716 - precision_tumor: 0.5498 - recall_tumor: 0.6450 - tumor_iou: 0.4167 - val_acc: 0.9867 - val_dice_coef_metric_tumor: 0.5141 - val_loss: 0.3307 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5495 - val_recall_tumor: 0.5416 - val_tumor_iou: 0.3835 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 135 lên WandB.\n\n--- Epoch 136/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5571 - loss: 0.2832 - mean_iou_all: 0.4723 - precision_tumor: 0.5576 - recall_tumor: 0.6340 - tumor_iou: 0.4173\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5570 - loss: 0.2832 - mean_iou_all: 0.4723 - precision_tumor: 0.5576 - recall_tumor: 0.6340 - tumor_iou: 0.4173 - val_acc: 0.9873 - val_dice_coef_metric_tumor: 0.4895 - val_loss: 0.3448 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5587 - val_recall_tumor: 0.5098 - val_tumor_iou: 0.3523 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 136 lên WandB.\n\n--- Epoch 137/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5756 - loss: 0.2783 - mean_iou_all: 0.4814 - precision_tumor: 0.5876 - recall_tumor: 0.6349 - tumor_iou: 0.4300\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5756 - loss: 0.2783 - mean_iou_all: 0.4814 - precision_tumor: 0.5875 - recall_tumor: 0.6349 - tumor_iou: 0.4299 - val_acc: 0.9826 - val_dice_coef_metric_tumor: 0.4920 - val_loss: 0.3459 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4498 - val_recall_tumor: 0.6405 - val_tumor_iou: 0.3601 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 137 lên WandB.\n\n--- Epoch 138/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5789 - loss: 0.2778 - mean_iou_all: 0.4791 - precision_tumor: 0.5791 - recall_tumor: 0.6510 - tumor_iou: 0.4369\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5789 - loss: 0.2778 - mean_iou_all: 0.4791 - precision_tumor: 0.5790 - recall_tumor: 0.6510 - tumor_iou: 0.4369 - val_acc: 0.9857 - val_dice_coef_metric_tumor: 0.4850 - val_loss: 0.3486 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5085 - val_recall_tumor: 0.5570 - val_tumor_iou: 0.3469 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 138 lên WandB.\n\n--- Epoch 139/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5681 - loss: 0.2821 - mean_iou_all: 0.4841 - precision_tumor: 0.5669 - recall_tumor: 0.6471 - tumor_iou: 0.4229\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5680 - loss: 0.2821 - mean_iou_all: 0.4841 - precision_tumor: 0.5669 - recall_tumor: 0.6471 - tumor_iou: 0.4229 - val_acc: 0.9850 - val_dice_coef_metric_tumor: 0.5185 - val_loss: 0.3288 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4785 - val_recall_tumor: 0.6485 - val_tumor_iou: 0.3852 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 139 lên WandB.\n\n--- Epoch 140/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.5832 - loss: 0.2730 - mean_iou_all: 0.4888 - precision_tumor: 0.5945 - recall_tumor: 0.6334 - tumor_iou: 0.4402\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.5832 - loss: 0.2730 - mean_iou_all: 0.4888 - precision_tumor: 0.5945 - recall_tumor: 0.6333 - tumor_iou: 0.4402 - val_acc: 0.9822 - val_dice_coef_metric_tumor: 0.4607 - val_loss: 0.3649 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4175 - val_recall_tumor: 0.6266 - val_tumor_iou: 0.3308 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 140 lên WandB.\n\n--- Epoch 141/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5575 - loss: 0.2865 - mean_iou_all: 0.4740 - precision_tumor: 0.5671 - recall_tumor: 0.6269 - tumor_iou: 0.4160\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5575 - loss: 0.2865 - mean_iou_all: 0.4740 - precision_tumor: 0.5670 - recall_tumor: 0.6269 - tumor_iou: 0.4159 - val_acc: 0.9850 - val_dice_coef_metric_tumor: 0.5134 - val_loss: 0.3321 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4714 - val_recall_tumor: 0.6549 - val_tumor_iou: 0.3765 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 141 lên WandB.\n\n--- Epoch 142/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5584 - loss: 0.2792 - mean_iou_all: 0.4769 - precision_tumor: 0.5454 - recall_tumor: 0.6487 - tumor_iou: 0.4213\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5584 - loss: 0.2792 - mean_iou_all: 0.4769 - precision_tumor: 0.5454 - recall_tumor: 0.6487 - tumor_iou: 0.4213 - val_acc: 0.9869 - val_dice_coef_metric_tumor: 0.4988 - val_loss: 0.3411 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5406 - val_recall_tumor: 0.5293 - val_tumor_iou: 0.3662 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 142 lên WandB.\n\n--- Epoch 143/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5747 - loss: 0.2771 - mean_iou_all: 0.4822 - precision_tumor: 0.5767 - recall_tumor: 0.6430 - tumor_iou: 0.4350\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5747 - loss: 0.2771 - mean_iou_all: 0.4822 - precision_tumor: 0.5767 - recall_tumor: 0.6430 - tumor_iou: 0.4349 - val_acc: 0.9859 - val_dice_coef_metric_tumor: 0.4858 - val_loss: 0.3486 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5132 - val_recall_tumor: 0.5327 - val_tumor_iou: 0.3557 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 143 lên WandB.\n\n--- Epoch 144/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5748 - loss: 0.2763 - mean_iou_all: 0.4806 - precision_tumor: 0.5735 - recall_tumor: 0.6506 - tumor_iou: 0.4315\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5747 - loss: 0.2763 - mean_iou_all: 0.4805 - precision_tumor: 0.5735 - recall_tumor: 0.6505 - tumor_iou: 0.4315 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5174 - val_loss: 0.3290 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5834 - val_recall_tumor: 0.5245 - val_tumor_iou: 0.3852 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 144 lên WandB.\n\n--- Epoch 145/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5631 - loss: 0.2834 - mean_iou_all: 0.4822 - precision_tumor: 0.5606 - recall_tumor: 0.6241 - tumor_iou: 0.4256\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5631 - loss: 0.2834 - mean_iou_all: 0.4822 - precision_tumor: 0.5606 - recall_tumor: 0.6242 - tumor_iou: 0.4255 - val_acc: 0.9881 - val_dice_coef_metric_tumor: 0.4959 - val_loss: 0.3417 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5938 - val_recall_tumor: 0.4891 - val_tumor_iou: 0.3677 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 145 lên WandB.\n\n--- Epoch 146/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5689 - loss: 0.2811 - mean_iou_all: 0.4757 - precision_tumor: 0.5715 - recall_tumor: 0.6389 - tumor_iou: 0.4295\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5689 - loss: 0.2811 - mean_iou_all: 0.4757 - precision_tumor: 0.5715 - recall_tumor: 0.6389 - tumor_iou: 0.4295 - val_acc: 0.9848 - val_dice_coef_metric_tumor: 0.5095 - val_loss: 0.3346 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4722 - val_recall_tumor: 0.6377 - val_tumor_iou: 0.3742 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 146 lên WandB.\n\n--- Epoch 147/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5774 - loss: 0.2783 - mean_iou_all: 0.4809 - precision_tumor: 0.5748 - recall_tumor: 0.6523 - tumor_iou: 0.4371\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5774 - loss: 0.2783 - mean_iou_all: 0.4809 - precision_tumor: 0.5747 - recall_tumor: 0.6523 - tumor_iou: 0.4370 - val_acc: 0.9843 - val_dice_coef_metric_tumor: 0.5078 - val_loss: 0.3361 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4720 - val_recall_tumor: 0.6453 - val_tumor_iou: 0.3717 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 147 lên WandB.\n\n--- Epoch 148/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5663 - loss: 0.2788 - mean_iou_all: 0.4860 - precision_tumor: 0.5603 - recall_tumor: 0.6598 - tumor_iou: 0.4249\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5663 - loss: 0.2788 - mean_iou_all: 0.4860 - precision_tumor: 0.5603 - recall_tumor: 0.6597 - tumor_iou: 0.4249 - val_acc: 0.9875 - val_dice_coef_metric_tumor: 0.4768 - val_loss: 0.3543 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5810 - val_recall_tumor: 0.4781 - val_tumor_iou: 0.3503 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 148 lên WandB.\n\n--- Epoch 149/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5609 - loss: 0.2872 - mean_iou_all: 0.4874 - precision_tumor: 0.5643 - recall_tumor: 0.6293 - tumor_iou: 0.4190\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5609 - loss: 0.2872 - mean_iou_all: 0.4874 - precision_tumor: 0.5643 - recall_tumor: 0.6293 - tumor_iou: 0.4190 - val_acc: 0.9862 - val_dice_coef_metric_tumor: 0.5057 - val_loss: 0.3367 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5570 - val_recall_tumor: 0.5423 - val_tumor_iou: 0.3755 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 149 lên WandB.\n\n--- Epoch 150/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.5842 - loss: 0.2712 - mean_iou_all: 0.4793 - precision_tumor: 0.5871 - recall_tumor: 0.6483 - tumor_iou: 0.4448\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.5842 - loss: 0.2712 - mean_iou_all: 0.4792 - precision_tumor: 0.5871 - recall_tumor: 0.6483 - tumor_iou: 0.4448 - val_acc: 0.9888 - val_dice_coef_metric_tumor: 0.4832 - val_loss: 0.3503 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6468 - val_recall_tumor: 0.4378 - val_tumor_iou: 0.3558 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 150 lên WandB.\n\n--- Epoch 151/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5783 - loss: 0.2820 - mean_iou_all: 0.4692 - precision_tumor: 0.6043 - recall_tumor: 0.6208 - tumor_iou: 0.4353\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5783 - loss: 0.2820 - mean_iou_all: 0.4691 - precision_tumor: 0.6043 - recall_tumor: 0.6208 - tumor_iou: 0.4353 - val_acc: 0.9866 - val_dice_coef_metric_tumor: 0.4713 - val_loss: 0.3580 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5633 - val_recall_tumor: 0.4743 - val_tumor_iou: 0.3391 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 151 lên WandB.\n\n--- Epoch 152/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5817 - loss: 0.2779 - mean_iou_all: 0.4673 - precision_tumor: 0.5846 - recall_tumor: 0.6558 - tumor_iou: 0.4405\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 466ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5817 - loss: 0.2779 - mean_iou_all: 0.4672 - precision_tumor: 0.5845 - recall_tumor: 0.6557 - tumor_iou: 0.4405 - val_acc: 0.9854 - val_dice_coef_metric_tumor: 0.4682 - val_loss: 0.3604 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5222 - val_recall_tumor: 0.5130 - val_tumor_iou: 0.3391 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 152 lên WandB.\n\n--- Epoch 153/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9865 - dice_coef_metric_tumor: 0.5618 - loss: 0.2822 - mean_iou_all: 0.4739 - precision_tumor: 0.5707 - recall_tumor: 0.6350 - tumor_iou: 0.4230\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9865 - dice_coef_metric_tumor: 0.5618 - loss: 0.2822 - mean_iou_all: 0.4739 - precision_tumor: 0.5707 - recall_tumor: 0.6349 - tumor_iou: 0.4230 - val_acc: 0.9880 - val_dice_coef_metric_tumor: 0.4279 - val_loss: 0.3847 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6826 - val_recall_tumor: 0.3650 - val_tumor_iou: 0.3100 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 153 lên WandB.\n\n--- Epoch 154/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5771 - loss: 0.2746 - mean_iou_all: 0.4725 - precision_tumor: 0.5783 - recall_tumor: 0.6487 - tumor_iou: 0.4351\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5771 - loss: 0.2746 - mean_iou_all: 0.4725 - precision_tumor: 0.5783 - recall_tumor: 0.6487 - tumor_iou: 0.4351 - val_acc: 0.9866 - val_dice_coef_metric_tumor: 0.4990 - val_loss: 0.3416 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5123 - val_recall_tumor: 0.5542 - val_tumor_iou: 0.3690 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 154 lên WandB.\n\n--- Epoch 155/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5765 - loss: 0.2757 - mean_iou_all: 0.4728 - precision_tumor: 0.5846 - recall_tumor: 0.6419 - tumor_iou: 0.4355\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5765 - loss: 0.2757 - mean_iou_all: 0.4727 - precision_tumor: 0.5846 - recall_tumor: 0.6418 - tumor_iou: 0.4354 - val_acc: 0.9890 - val_dice_coef_metric_tumor: 0.4949 - val_loss: 0.3437 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6719 - val_recall_tumor: 0.4475 - val_tumor_iou: 0.3650 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 155 lên WandB.\n\n--- Epoch 156/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9874 - dice_coef_metric_tumor: 0.5760 - loss: 0.2755 - mean_iou_all: 0.4718 - precision_tumor: 0.5895 - recall_tumor: 0.6395 - tumor_iou: 0.4371\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9874 - dice_coef_metric_tumor: 0.5759 - loss: 0.2755 - mean_iou_all: 0.4717 - precision_tumor: 0.5895 - recall_tumor: 0.6395 - tumor_iou: 0.4370 - val_acc: 0.9872 - val_dice_coef_metric_tumor: 0.5141 - val_loss: 0.3325 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5842 - val_recall_tumor: 0.5387 - val_tumor_iou: 0.3846 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 156 lên WandB.\n\n--- Epoch 157/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.5976 - loss: 0.2666 - mean_iou_all: 0.4708 - precision_tumor: 0.6054 - recall_tumor: 0.6531 - tumor_iou: 0.4565\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51855\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.5975 - loss: 0.2666 - mean_iou_all: 0.4707 - precision_tumor: 0.6054 - recall_tumor: 0.6530 - tumor_iou: 0.4564 - val_acc: 0.9875 - val_dice_coef_metric_tumor: 0.4757 - val_loss: 0.3558 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5769 - val_recall_tumor: 0.4815 - val_tumor_iou: 0.3503 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 157 lên WandB.\n\n--- Epoch 158/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.5786 - loss: 0.2679 - mean_iou_all: 0.4733 - precision_tumor: 0.5897 - recall_tumor: 0.6245 - tumor_iou: 0.4405\nEpoch 1: val_dice_coef_metric_tumor improved from 0.51855 to 0.52407, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_29052025_082431.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.5785 - loss: 0.2679 - mean_iou_all: 0.4732 - precision_tumor: 0.5896 - recall_tumor: 0.6245 - tumor_iou: 0.4405 - val_acc: 0.9873 - val_dice_coef_metric_tumor: 0.5241 - val_loss: 0.3263 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5801 - val_recall_tumor: 0.5390 - val_tumor_iou: 0.3889 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 158 lên WandB.\n\n--- Epoch 159/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9873 - dice_coef_metric_tumor: 0.5801 - loss: 0.2733 - mean_iou_all: 0.4666 - precision_tumor: 0.5912 - recall_tumor: 0.6463 - tumor_iou: 0.4374\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52407\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9873 - dice_coef_metric_tumor: 0.5801 - loss: 0.2733 - mean_iou_all: 0.4666 - precision_tumor: 0.5912 - recall_tumor: 0.6462 - tumor_iou: 0.4374 - val_acc: 0.9864 - val_dice_coef_metric_tumor: 0.5205 - val_loss: 0.3297 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5401 - val_recall_tumor: 0.5655 - val_tumor_iou: 0.3822 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 159 lên WandB.\n\n--- Epoch 160/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.5703 - loss: 0.2789 - mean_iou_all: 0.4738 - precision_tumor: 0.5743 - recall_tumor: 0.6360 - tumor_iou: 0.4306\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52407\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.5703 - loss: 0.2789 - mean_iou_all: 0.4738 - precision_tumor: 0.5742 - recall_tumor: 0.6361 - tumor_iou: 0.4306 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.4725 - val_loss: 0.3581 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6076 - val_recall_tumor: 0.4460 - val_tumor_iou: 0.3419 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 160 lên WandB.\n\n--- Epoch 161/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5794 - loss: 0.2746 - mean_iou_all: 0.4738 - precision_tumor: 0.5877 - recall_tumor: 0.6435 - tumor_iou: 0.4402\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52407\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5794 - loss: 0.2746 - mean_iou_all: 0.4737 - precision_tumor: 0.5877 - recall_tumor: 0.6435 - tumor_iou: 0.4402 - val_acc: 0.9864 - val_dice_coef_metric_tumor: 0.5152 - val_loss: 0.3323 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5431 - val_recall_tumor: 0.5646 - val_tumor_iou: 0.3797 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 161 lên WandB.\n\n--- Epoch 162/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.5773 - loss: 0.2741 - mean_iou_all: 0.4454 - precision_tumor: 0.5934 - recall_tumor: 0.6322 - tumor_iou: 0.4362\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52407\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.5773 - loss: 0.2741 - mean_iou_all: 0.4453 - precision_tumor: 0.5934 - recall_tumor: 0.6322 - tumor_iou: 0.4362 - val_acc: 0.9834 - val_dice_coef_metric_tumor: 0.5153 - val_loss: 0.3337 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4832 - val_recall_tumor: 0.6463 - val_tumor_iou: 0.3803 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 162 lên WandB.\n\n--- Epoch 163/300 ---\n\u001b[1m145/336\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 415ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.6305 - loss: 0.2760 - mean_iou_all: 0.4841 - precision_tumor: 0.6440 - recall_tumor: 0.6765 - tumor_iou: 0.4854","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}