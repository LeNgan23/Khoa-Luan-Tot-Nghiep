{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11709306,"sourceType":"datasetVersion","datasetId":6711261}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"ver 8 (6), v10","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw\nfrom typing import Tuple\n\nimport cv2\nimport json\nfrom tqdm.notebook import tqdm\n\n\nimport pandas as pd\nimport glob\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\nimport shutil \n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom typing import List, Tuple, Optional","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:55:39.021205Z","iopub.execute_input":"2025-05-13T01:55:39.021701Z","iopub.status.idle":"2025-05-13T01:55:56.663439Z","shell.execute_reply.started":"2025-05-13T01:55:39.021662Z","shell.execute_reply":"2025-05-13T01:55:56.662370Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"base_input_dir = \"/kaggle/input/btxrd-data/BTXRD/BTXRD\" \nimage_dir = os.path.join(base_input_dir, \"images\")\nannotation_dir = os.path.join(base_input_dir, \"Annotations\")\nexcel_path = \"/kaggle/input/btxrd-data/classification.xlsx\"\n\n\n# output_dir = \"/kaggle/working/btxrd-v2.2\"\n# output_image_dir = os.path.join(output_dir, \"images\")\n# output_anno_dir = os.path.join(output_dir, \"Annotations\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.430179Z","iopub.status.idle":"2025-05-13T01:54:09.431135Z","shell.execute_reply.started":"2025-05-13T01:54:09.430368Z","shell.execute_reply":"2025-05-13T01:54:09.430415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Đọc file Excel\n# file_path = '/kaggle/input/btxrd-data/classification.xlsx'\ndf = pd.read_excel(excel_path)\n\n# Hiển thị 10 dòng đầu tiên\ndf.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.432391Z","iopub.status.idle":"2025-05-13T01:54:09.433268Z","shell.execute_reply.started":"2025-05-13T01:54:09.432557Z","shell.execute_reply":"2025-05-13T01:54:09.432619Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Xử lý ảnh**","metadata":{}},{"cell_type":"code","source":"# in 30 ảnh trước xử lý\nnum_images_to_show = 30\nimages_per_row = 5  # Số ảnh mỗi hàng\nmask_color = [255, 0, 0]  # Red\n\ndef create_mask(img_size: Tuple[int, int], ann_path: str) -> np.ndarray:\n    mask = Image.new('L', img_size, 0)\n    if os.path.exists(ann_path):\n        try:\n            with open(ann_path, 'r') as f:\n                data = json.load(f)\n                for shape in data.get('shapes', []):\n                    points = shape.get('points', [])\n                    polygon_points = [(int(x), int(y)) for x, y in points]\n                    if polygon_points:\n                        ImageDraw.Draw(mask).polygon(polygon_points, outline=1, fill=1)\n        except Exception as e:\n            print(f\"Lỗi annotation {ann_path}: {e}\")\n    return np.array(mask)\n\n# Lấy danh sách tất cả ảnh trong thư mục\nall_filenames = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# Chọn ngẫu nhiên 30 ảnh\nselected_filenames = random.sample(all_filenames, min(num_images_to_show, len(all_filenames)))\n\n# Plot ảnh với mask\nplt.figure(figsize=(18, 18))  # Tăng kích thước ảnh\nfor i, fname in enumerate(selected_filenames):\n    img_path = os.path.join(image_dir, fname)\n    ann_fname = os.path.splitext(fname)[0] + '.json'\n    ann_path = os.path.join(annotation_dir, ann_fname)\n\n    try:\n        img_pil = Image.open(img_path).convert('L')\n        img_np = np.array(img_pil)\n\n        mask_np = create_mask(img_pil.size, ann_path)\n        color_img = np.stack([img_np] * 3, axis=-1)\n        color_img[mask_np == 1] = mask_color\n\n        # Chia bố cục thành 6 hàng và 5 cột (số ảnh mỗi hàng là 5)\n        plt.subplot(6, 5, i + 1)\n        plt.imshow(color_img)\n        plt.axis('off')  # Tắt trục\n    except Exception as e:\n        print(f\"Lỗi khi xử lý {fname}: {e}\")\n        continue\n\n# Loại bỏ khoảng trống giữa các ảnh\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.434296Z","iopub.status.idle":"2025-05-13T01:54:09.435136Z","shell.execute_reply.started":"2025-05-13T01:54:09.434455Z","shell.execute_reply":"2025-05-13T01:54:09.434496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nTARGET_SIZE = 512\n\n# base_input_dir = \"/kaggle/input/btxrd-data/BTXRD/BTXRD\" # Đường dẫn gốc chứa ảnh và annotation\n# image_dir = os.path.join(base_input_dir, \"images\")      # Thư mục chứa ảnh gốc\n# annotation_dir = os.path.join(base_input_dir, \"Annotations\") # Thư mục chứa annotation gốc\n\noutput_dir = \"/kaggle/working/btxrd-v2.2\"\noutput_image_dir = os.path.join(output_dir, \"images\")\noutput_anno_dir = os.path.join(output_dir, \"annotations\")\n\nos.makedirs(output_image_dir, exist_ok=True)\nos.makedirs(output_anno_dir, exist_ok=True)\n\nMAX_VISUALIZATIONS = 5 # Số lượng ảnh tối đa để trực quan hóa\nvisualized_count = 0\n\n\ndef get_bounding_box(points):\n    if not points:\n        return None\n    points_array = np.array(points)\n    xmin = int(np.min(points_array[:, 0]))\n    ymin = int(np.min(points_array[:, 1]))\n    xmax = int(np.max(points_array[:, 0]))\n    ymax = int(np.max(points_array[:, 1]))\n    # Đảm bảo tọa độ không âm\n    xmin = max(0, xmin)\n    ymin = max(0, ymin)\n    return (xmin, ymin, xmax, ymax)\n\ntry:\n    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg'))]\n    total_images = len(image_files)\n    if total_images == 0:\n        print(f\"Không tìm thấy file ảnh nào trong: {image_dir}\")\n        exit()\n    print(f\"Tìm thấy {total_images} ảnh để xử lý.\")\nexcept FileNotFoundError:\n    print(f\"Không tìm thấy thư mục ảnh: {image_dir}\")\n    exit()\n\nprint(f\"Bắt đầu xử lý ảnh và lưu vào: {output_dir}\")\n# Sử dụng tqdm để hiển thị thanh tiến trình\nfor file in tqdm(image_files, desc=\"Processing Images\"):\n    img_path = os.path.join(image_dir, file)\n    anno_filename = file.rsplit('.', 1)[0] + '.json'\n    anno_path = os.path.join(annotation_dir, anno_filename)\n\n    # Đọc ảnh gốc\n    img_orig = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    if img_orig is None:\n        # print(f\"Không thể đọc ảnh: {file}\"\n        continue\n    orig_height, orig_width = img_orig.shape[:2]\n\n    # Đọc annotation gốc \n    annotation_orig = None\n    has_annotation = os.path.exists(anno_path)\n    if has_annotation:\n        try:\n            with open(anno_path, \"r\", encoding=\"utf-8\") as f:\n                annotation_orig = json.load(f)\n        except Exception as e:\n            # print(f\"Lỗi khi đọc annotation {anno_filename}: {e}\")\n            has_annotation = False # Coi như không có nếu đọc lỗi\n\n    img_to_draw_orig = None\n    img_to_draw_padded = None\n    original_bboxes = []\n    transformed_bboxes = []\n\n    should_visualize = has_annotation and (visualized_count < MAX_VISUALIZATIONS)\n\n    if should_visualize:\n        img_to_draw_orig = cv2.cvtColor(img_orig, cv2.COLOR_GRAY2BGR) # Chuyển sang BGR để vẽ màu\n        if annotation_orig and \"shapes\" in annotation_orig:\n             for shape in annotation_orig[\"shapes\"]:\n                if shape.get(\"shape_type\") == \"rectangle\" and \"points\" in shape and len(shape[\"points\"]) == 2:\n                     # LabelMe rectangle format uses [top-left, bottom-right]\n                     p1 = shape[\"points\"][0]\n                     p2 = shape[\"points\"][1]\n                     xmin = int(min(p1[0], p2[0]))\n                     ymin = int(min(p1[1], p2[1]))\n                     xmax = int(max(p1[0], p2[0]))\n                     ymax = int(max(p1[1], p2[1]))\n                     bbox = (max(0, xmin), max(0, ymin), xmax, ymax)\n                     original_bboxes.append(bbox)\n                     cv2.rectangle(img_to_draw_orig, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 2) # Vẽ màu đỏ (BGR)\n                elif shape.get(\"shape_type\") in [\"polygon\", \"linestrip\", \"point\"] and \"points\" in shape and shape[\"points\"]:\n                     # Lấy bounding box bao quanh các loại shape khác\n                     bbox = get_bounding_box(shape[\"points\"])\n                     if bbox:\n                        original_bboxes.append(bbox)\n                        cv2.rectangle(img_to_draw_orig, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 2) # Red\n\n    # Resize ảnh với padding để giữ tỉ lệ\n    # Tính tỉ lệ resize để cạnh dài nhất bằng TARGET_SIZE\n    scale = TARGET_SIZE / max(orig_height, orig_width)\n    new_width = int(orig_width * scale)\n    new_height = int(orig_height * scale)\n\n    # Đảm bảo kích thước mới không lớn hơn TARGET_SIZE\n    new_width = min(new_width, TARGET_SIZE)\n    new_height = min(new_height, TARGET_SIZE)\n\n    # Resize ảnh\n    img_resized = cv2.resize(img_orig, (new_width, new_height), interpolation=cv2.INTER_AREA)\n\n    # Tính toán padding\n    pad_h = TARGET_SIZE - new_height\n    pad_w = TARGET_SIZE - new_width\n    top = pad_h // 2\n    bottom = pad_h - top\n    left = pad_w // 2\n    right = pad_w - left\n\n    # Thêm padding\n    # Sử dụng giá trị 0 (màu đen) cho padding vì ảnh là grayscale\n    padded_img = cv2.copyMakeBorder(img_resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n\n    # Lưu ảnh đã xử lý\n    output_img_path = os.path.join(output_image_dir, file)\n    try:\n        # Đảm bảo kích thước cuối cùng đúng là TARGET_SIZE x TARGET_SIZE\n        if padded_img.shape[0] != TARGET_SIZE or padded_img.shape[1] != TARGET_SIZE:\n             # Nếu có sai lệch nhỏ do làm tròn, resize lại lần cuối\n             padded_img = cv2.resize(padded_img, (TARGET_SIZE, TARGET_SIZE), interpolation=cv2.INTER_AREA)\n             # print(f\"Final resize needed for {file}. Original: ({orig_width}x{orig_height}), Resized: ({new_width}x{new_height}), Padded: {padded_img.shape[:2]}\")\n\n\n        cv2.imwrite(output_img_path, padded_img)\n    except Exception as e:\n        # print(f\"Lỗi khi lưu ảnh {output_img_path}: {e}\") # Bỏ comment nếu cần debug\n        continue # Bỏ qua ảnh này nếu không lưu được\n\n    # Xử lý và lưu annotation\n    if has_annotation and annotation_orig:\n        # Tạo bản sao sâu để không ảnh hưởng annotation gốc\n        annotation_new = json.loads(json.dumps(annotation_orig))\n\n        if \"shapes\" in annotation_new:\n            new_shapes = [] # Tạo list mới để chứa các shape đã chuyển đổi\n            for shape in annotation_new[\"shapes\"]:\n                if \"points\" in shape and shape[\"points\"]:\n                    original_points = shape[\"points\"]\n                    new_points_transformed = []\n                    valid_shape = True\n                    for x, y in original_points:\n                        # Áp dụng tỉ lệ resize\n                        new_x = x * scale\n                        new_y = y * scale\n                        # Áp dụng padding offset\n                        new_x += left\n                        new_y += top\n\n                        # Kiểm tra xem điểm có nằm trong ảnh mới không\n                        # new_x = max(0, min(TARGET_SIZE - 1, new_x))\n                        # new_y = max(0, min(TARGET_SIZE - 1, new_y))\n                        new_points_transformed.append([new_x, new_y])\n\n                    # Cập nhật điểm trong shape\n                    shape[\"points\"] = new_points_transformed\n                    new_shapes.append(shape) # Thêm shape đã chuyển đổi vào list mới\n\n                    # Tính bbox mới để trực quan hóa\n                    if should_visualize:\n                        new_bbox = get_bounding_box(new_points_transformed)\n                        if new_bbox:\n                            # Đảm bảo bbox không vượt ra ngoài TARGET_SIZE\n                            xmin = max(0, min(TARGET_SIZE - 1, new_bbox[0]))\n                            ymin = max(0, min(TARGET_SIZE - 1, new_bbox[1]))\n                            xmax = max(0, min(TARGET_SIZE - 1, new_bbox[2]))\n                            ymax = max(0, min(TARGET_SIZE - 1, new_bbox[3]))\n                            # Chỉ thêm vào nếu bbox hợp lệ\n                            if xmax > xmin and ymax > ymin:\n                                transformed_bboxes.append((xmin, ymin, xmax, ymax))\n\n            # Cập nhật lại danh sách shapes và kích thước ảnh trong annotation\n            annotation_new[\"shapes\"] = new_shapes\n            annotation_new[\"imagePath\"] = file # Cập nhật tên file ảnh mới\n            annotation_new[\"imageWidth\"] = TARGET_SIZE\n            annotation_new[\"imageHeight\"] = TARGET_SIZE\n            \n            if \"imageData\" in annotation_new:\n                annotation_new[\"imageData\"] = None\n\n            # Lưu file annotation mới\n            output_annotation_path = os.path.join(output_anno_dir, anno_filename)\n            try:\n                with open(output_annotation_path, \"w\", encoding=\"utf-8\") as f:\n                    json.dump(annotation_new, f, indent=4, ensure_ascii=False)\n            except Exception as e:\n                # print(f\"Lỗi khi lưu annotation {anno_filename}: {e}\") # Bỏ comment nếu cần debug\n                pass # Bỏ qua nếu lưu lỗi\n\n            if should_visualize and img_to_draw_orig is not None:\n                # Chuyển ảnh đã padding sang BGR để vẽ màu\n                img_to_draw_padded = cv2.cvtColor(padded_img, cv2.COLOR_GRAY2BGR)\n                # Vẽ các bounding box đã biến đổi\n                for bbox in transformed_bboxes:\n                     # Đảm bảo tọa độ là số nguyên để vẽ\n                     pt1 = (int(bbox[0]), int(bbox[1]))\n                     pt2 = (int(bbox[2]), int(bbox[3]))\n                     cv2.rectangle(img_to_draw_padded, pt1, pt2, (0, 255, 0), 2) # Vẽ màu xanh lá (BGR)\n\n                # Hiển thị ảnh gốc và ảnh đã xử lý\n                fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\n                # Ảnh gốc với bbox gốc (màu đỏ)\n                axes[0].imshow(cv2.cvtColor(img_to_draw_orig, cv2.COLOR_BGR2RGB)) # Chuyển BGR sang RGB cho matplotlib\n                axes[0].set_title(f'Original: {file}\\nSize: {orig_width}x{orig_height}')\n                axes[0].axis('off')\n\n                # Ảnh đã xử lý với bbox mới (màu xanh)\n                axes[1].imshow(cv2.cvtColor(img_to_draw_padded, cv2.COLOR_BGR2RGB)) # Chuyển BGR sang RGB\n                axes[1].set_title(f'Processed (Resized & Padded)\\nSize: {TARGET_SIZE}x{TARGET_SIZE}')\n                axes[1].axis('off')\n\n                plt.suptitle(f\"Visualization {visualized_count + 1}/{MAX_VISUALIZATIONS}\")\n                plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Điều chỉnh layout để tiêu đề không bị che\n                plt.show()\n\n                visualized_count += 1\n\nprint(f\"Xử lý {total_images} ảnh.\")\nif visualized_count > 0:\n    print(f\"Hiển thị {visualized_count} ảnh trực quan hóa.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.436168Z","iopub.status.idle":"2025-05-13T01:54:09.436694Z","shell.execute_reply.started":"2025-05-13T01:54:09.436347Z","shell.execute_reply":"2025-05-13T01:54:09.436393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hiển thị random 30 hình sau khi xử lý ảnh\n\n\n# Cấu hình\nimage_dir_test = '/kaggle/working/btxrd-v2.2/images'\nannotation_dir_test = '/kaggle/working/btxrd-v2.2/annotations'\n# Cấu hình\nnum_images_to_show = 30\nimages_per_row = 5  # Số ảnh mỗi hàng\nmask_color = [255, 0, 0]  # Red\n\ndef create_mask(img_size: Tuple[int, int], ann_path: str) -> np.ndarray:\n    mask = Image.new('L', img_size, 0)\n    if os.path.exists(ann_path):\n        try:\n            with open(ann_path, 'r') as f:\n                data = json.load(f)\n                for shape in data.get('shapes', []):\n                    points = shape.get('points', [])\n                    polygon_points = [(int(x), int(y)) for x, y in points]\n                    if polygon_points:\n                        ImageDraw.Draw(mask).polygon(polygon_points, outline=1, fill=1)\n        except Exception as e:\n            print(f\"Lỗi annotation {ann_path}: {e}\")\n    return np.array(mask)\n\n# Lấy danh sách tất cả ảnh trong thư mục\nall_filenames = [f for f in os.listdir(image_dir_test) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# Chọn ngẫu nhiên 30 ảnh\nselected_filenames = random.sample(all_filenames, min(num_images_to_show, len(all_filenames)))\n\n# Plot ảnh với mask\nplt.figure(figsize=(18, 18))  # Tăng kích thước ảnh\nfor i, fname in enumerate(selected_filenames):\n    img_path = os.path.join(image_dir_test, fname)\n    ann_fname = os.path.splitext(fname)[0] + '.json'\n    ann_path = os.path.join(annotation_dir_test, ann_fname)\n\n    try:\n        img_pil = Image.open(img_path).convert('L')\n        img_np = np.array(img_pil)\n\n        mask_np = create_mask(img_pil.size, ann_path)\n        color_img = np.stack([img_np] * 3, axis=-1)\n        color_img[mask_np == 1] = mask_color\n\n        # Chia bố cục thành 6 hàng và 5 cột (số ảnh mỗi hàng là 5)\n        plt.subplot(6, 5, i + 1)\n        plt.imshow(color_img)\n        plt.axis('off')  # Tắt trục\n    except Exception as e:\n        print(f\"Lỗi khi xử lý {fname}: {e}\")\n        continue\n\n# Loại bỏ khoảng trống giữa các ảnh\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.437653Z","iopub.status.idle":"2025-05-13T01:54:09.438769Z","shell.execute_reply.started":"2025-05-13T01:54:09.437797Z","shell.execute_reply":"2025-05-13T01:54:09.437838Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Chia tập dữ liệu**","metadata":{}},{"cell_type":"code","source":"output_split_dir = \"/kaggle/working/btxrd-v2.1\"\n\nANNOTATION_EXTENSION = \".json\"\n\nVAL_SIZE = 0.20   # 20% cho tập validation\nTRAIN_SIZE = 0.70 # 70% cho tập train\nTEST_SIZE = 1.0 - VAL_SIZE - TRAIN_SIZE\n\nRANDOM_STATE = 42","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.439717Z","iopub.status.idle":"2025-05-13T01:54:09.440264Z","shell.execute_reply.started":"2025-05-13T01:54:09.439865Z","shell.execute_reply":"2025-05-13T01:54:09.439927Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Đọc Dữ liệu Phân loại từ Excel\ntry:\n    df_classification = pd.read_excel(excel_path)\n    required_columns = ['image_id', 'tumor_type', 'image_filename']\n    if not all(col in df_classification.columns for col in required_columns):\n        missing = [col for col in required_columns if col not in df_classification.columns]\n        raise ValueError(f\"File Excel thiếu các cột bắt buộc: {missing}\")\n\n    df_classification['image_id'] = df_classification['image_id'].astype(str).str.strip()\n    df_classification['image_filename'] = df_classification['image_filename'].astype(str).str.strip()\n\n    print(f\"Đọc thành công {len(df_classification)} dòng\")\n    print(df_classification['tumor_type'].value_counts())\nexcept FileNotFoundError:\n    print(f\"Không tìm thấy file Excel tại {excel_path}\")\n    exit()\nexcept ValueError as ve:\n    print(f\"Lỗi dữ liệu trong file Excel: {ve}\")\n    exit()\nexcept Exception as e:\n    print(f\"không xác định khi đọc file Excel: {e}\")\n    exit()\n\ntry:\n    all_image_files = glob.glob(os.path.join(image_dir_test, \"*.*\"))\n    annotation_files = glob.glob(os.path.join(annotation_dir_test, f\"*{ANNOTATION_EXTENSION}\"))\n\n    image_basenames_actual = set(os.path.splitext(os.path.basename(f))[0] for f in all_image_files)\n    annotation_basenames_actual = set(os.path.splitext(os.path.basename(f))[0] for f in annotation_files)\n\n    print(f\"Tìm thấy {len(all_image_files)} tệp\")\n    print(f\"Tìm thấy {len(annotation_files)} tệp annotation\")\nexcept Exception as e:\n    print(f\"Lỗi khi quét thư mục ảnh hoặc annotation: {e}\")\n    exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.441610Z","iopub.status.idle":"2025-05-13T01:54:09.442492Z","shell.execute_reply.started":"2025-05-13T01:54:09.442254Z","shell.execute_reply":"2025-05-13T01:54:09.442305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"excel_image_ids = set(df_classification['image_id'])\nvalid_ids = list(excel_image_ids.intersection(image_basenames_actual).intersection(annotation_basenames_actual))\n\nif not valid_ids:\n    print(\"Không tìm thấy dữ liệu hợp lệ nào.\")\n    exit()\ndf_filtered = df_classification[df_classification['image_id'].isin(valid_ids)].copy()\ndf_filtered = df_filtered.drop_duplicates(subset=['image_id'])\nfilename_map = pd.Series(df_filtered.image_filename.values, index=df_filtered.image_id).to_dict()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.443533Z","iopub.status.idle":"2025-05-13T01:54:09.444176Z","shell.execute_reply.started":"2025-05-13T01:54:09.443693Z","shell.execute_reply":"2025-05-13T01:54:09.443733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Chuẩn bị dữ liệu (X=IDs, y=Labels) cho việc chia\nX = df_filtered['image_id'].tolist() # Danh sách ID ảnh \ny = df_filtered['tumor_type'].tolist() # Danh sách nhãn tương ứng\n\n# Chia Lần 1 (Train+Val / Test)\nX_train_val, X_test, y_train_val, y_test = [], [], [], []\nif len(X) < 2:\n    print(\"Không đủ mẫu dữ liệu (< 2) để thực hiện chia.\")\n    exit()\nif TEST_SIZE <= 0 or TEST_SIZE >= 1:\n     print(f\"Tỷ lệ Test ({TEST_SIZE:.2f}) không hợp lệ. Toàn bộ dữ liệu sẽ là Train+Val.\")\n     X_train_val, y_train_val = X, y\nelse:\n    try:\n        unique_classes_total, counts_total = np.unique(y, return_counts=True)\n        stratify_option_1 = y\n        if len(unique_classes_total) < 2:\n            print(\"Chỉ có 1 lớp. Chia ngẫu nhiên cho Test.\")\n            stratify_option_1 = None\n        elif np.any(counts_total < 2):\n             print(f\"Có lớp < 2 mẫu. Chia ngẫu nhiên cho Test.\")\n             stratify_option_1 = None\n\n        X_train_val, X_test, y_train_val, y_test = train_test_split(\n            X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=stratify_option_1\n        )\n        print(f\"Chia lần 1: {len(X_train_val)} Train+Val, {len(X_test)} Test.\")\n        print(\"Phân phối 'tumor_type' trong Test:\", sorted(Counter(y_test).items()))\n    except ValueError as e:\n         print(f\"Lỗi khi chia lần 1 (Test): {e}. Thoát.\")\n         exit()\n\n\n# Chia lần 2 (Train / Validation)\nX_train, X_val, y_train, y_val = [], [], [], []\nif not X_train_val:\n     print(\"Tập Train+Val rỗng.\")\nelif len(X_train_val) == 1:\n     print(\"Tập Train+Val chỉ có 1 mẫu -> vào Train.\")\n     X_train, y_train = X_train_val, y_train_val\nelif VAL_SIZE <= 0 or VAL_SIZE >= 1:\n     print(f\"Tỷ lệ Val ({VAL_SIZE:.4f}) không hợp lệ. Toàn bộ Train+Val -> Train.\")\n     X_train, y_train = X_train_val, y_train_val\nelse:\n    try:\n        unique_classes_tv, counts_tv = np.unique(y_train_val, return_counts=True)\n        stratify_option_2 = y_train_val\n        if len(unique_classes_tv) < 2:\n            print(\"Train+Val chỉ còn 1 lớp. Chia ngẫu nhiên cho Val.\")\n            stratify_option_2 = None\n        elif np.any(counts_tv < 2):\n             print(f\"Có lớp < 2 mẫu trong Train+Val. Chia ngẫu nhiên cho Val.\")\n             stratify_option_2 = None\n\n        X_train, X_val, y_train, y_val = train_test_split(\n            X_train_val, y_train_val, test_size=VAL_SIZE,\n            random_state=RANDOM_STATE, stratify=stratify_option_2\n        )\n        print(f\"Chia lần 2: {len(X_train)} Train, {len(X_val)} Validation.\")\n        print(\"Phân phối 'tumor_type' trong Train:\", sorted(Counter(y_train).items()))\n        print(\"Phân phối 'tumor_type' trong Validation:\", sorted(Counter(y_val).items()))\n    except ValueError as e:\n        print(f\"Lỗi khi chia lần 2 (Validation): {e}. Toàn bộ Train+Val -> Train.\")\n        X_train, y_train = X_train_val, y_train_val # Gán lại vào Train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.445355Z","iopub.status.idle":"2025-05-13T01:54:09.445873Z","shell.execute_reply.started":"2025-05-13T01:54:09.445521Z","shell.execute_reply":"2025-05-13T01:54:09.445564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# kết quả sau khi chia\ntotal_ids_split = len(X_train) + len(X_val) + len(X_test)\noriginal_valid_count = len(df_filtered)\n\nprint(f\"Tổng số mẫu hợp lệ ban đầu: {original_valid_count}\")\nprint(f\"Tổng số IDs được chia vào các tập: {total_ids_split}\")\nif total_ids_split != original_valid_count:\n     print(f\"Số ID được chia ({total_ids_split}) không khớp số ID hợp lệ ({original_valid_count}). Kiểm tra logic chia.\")\n\nprint(f\"Train set IDs:      {len(X_train):>5}\")\nprint(f\"Validation set IDs: {len(X_val):>5}\")\nprint(f\"Test set IDs:       {len(X_test):>5}\")\n\nif total_ids_split > 0:\n    print(f\"\\nTỷ lệ thực tế (dựa trên IDs):\")\n    print(f\"  Train: {len(X_train) / total_ids_split * 100:>6.1f}%\")\n    print(f\"  Val:   {len(X_val) / total_ids_split * 100:>6.1f}%\")\n    print(f\"  Test:  {len(X_test) / total_ids_split * 100:>6.1f}%\")\n\nprint(\"\\nPhân phối 'tumor_type' cuối cùng (dựa trên IDs đã chia):\")\nprint(f\"Train:      {sorted(Counter(y_train).items())}\")\nprint(f\"Validation: {sorted(Counter(y_val).items())}\")\nprint(f\"Test:       {sorted(Counter(y_test).items())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.447098Z","iopub.status.idle":"2025-05-13T01:54:09.447781Z","shell.execute_reply.started":"2025-05-13T01:54:09.447359Z","shell.execute_reply":"2025-05-13T01:54:09.447402Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Huấn luyện mô hình**","metadata":{}},{"cell_type":"code","source":"!pip install wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T00:26:42.422684Z","iopub.execute_input":"2025-05-22T00:26:42.422966Z","iopub.status.idle":"2025-05-22T00:26:49.207863Z","shell.execute_reply.started":"2025-05-22T00:26:42.422940Z","shell.execute_reply":"2025-05-22T00:26:49.206145Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.11.0a2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.29.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# --- Cấu hình ---\nimport os # Thêm import os nếu chưa có\nimport numpy as np # Thêm import numpy nếu dùng trong tính mean/std\nimport pandas as pd # Thêm import pandas nếu dùng trong tải metadata\nfrom tqdm import tqdm # Thêm import tqdm\nimport tensorflow as tf # Thêm import tensorflow\nfrom PIL import Image, ImageDraw # Thêm import PIL\nimport json # Thêm import json\nimport matplotlib.pyplot as plt # Thêm import matplotlib nếu dùng plot_image\n\nINPUT_DATA_ROOT = '/kaggle/input/btxrd-data' # THAY ĐỔI NẾU MÔI TRƯỜNG CỦA BẠN KHÁC\nBASE_DATA_DIR = os.path.join(INPUT_DATA_ROOT, 'btxrd-v2.1')\nCLASSIFICATION_FILE = os.path.join(INPUT_DATA_ROOT, 'classification.xlsx')\nIMAGE_SUBDIR_NAME = 'images'\nANNOTATION_SUBDIR_NAME = 'annotations'\n\n# Tham số Model & Huấn luyện\nTARGET_SIZE = 512\nN_CLASSES = 2 # 2 lớp: 0 (nền), 1 (khối u)\nBATCH_SIZE = 4 # Sẽ được dùng trong config wandb\nBUFFER_SIZE = 100 # Dùng cho dataset.shuffle\nEPOCHS = 300 # Sẽ được dùng trong config wandb và vòng lặp for\nLEARNING_RATE = 1e-4 # Sẽ được dùng trong config wandb\nL2_REG_FACTOR = 1e-5\nDROPOUT_RATE = 0.3\n\n# --- Cải tiến để tăng IoU ---\nUSE_COMBINED_LOSS = True\nDICE_LOSS_WEIGHT = 0.6\nUSE_FOCAL_LOSS_IN_COMBINED = True\nFOCAL_LOSS_ALPHA = 0.25\nFOCAL_LOSS_GAMMA = 2.0\n\nUSE_ATTENTION_UNET = False\n\n# APPLY_POST_PROCESSING, POST_PROCESSING_KERNEL_SIZE, MIN_AREA_POST_PROCESSING\n# thường dùng sau huấn luyện, không trực tiếp ảnh hưởng đến vòng lặp huấn luyện này\n\nMODEL_CHECKPOINT_BASENAME = \"unet_model\"\nTENSORBOARD_LOG_DIR = \"./logs_unet_iou_focused\"\n\n# --- Các hằng số cho callback Keras tiêu chuẩn ---\nPATIENCE_EARLY_STOPPING = 35\nPATIENCE_REDUCE_LR = 12\nMONITOR_METRIC_CB = 'val_dice_coef_metric_tumor' # QUAN TRỌNG: Phải khớp với key trong history.history\n\n# --- Cấu hình WandB ---\nWANDB_PROJECT_NAME = \"btxrd-project\" # Đặt tên project của bạn trên WandB\nWANDB_ENTITY = \"nganltt2333\" # Đặt entity của bạn\nWANDB_API_KEY = \"2b7e633df37247dd52582a893eecab6314151a62\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:46:49.028236Z","iopub.execute_input":"2025-05-22T02:46:49.028621Z","iopub.status.idle":"2025-05-22T02:46:49.036743Z","shell.execute_reply.started":"2025-05-22T02:46:49.028596Z","shell.execute_reply":"2025-05-22T02:46:49.035839Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"def get_valid_paths(base_dir: str, split_type: str, img_filename_with_ext: str) -> Optional[Tuple[str, str]]:\n    split_dir = os.path.join(base_dir, split_type); image_dir_path = os.path.join(split_dir, IMAGE_SUBDIR_NAME); annotation_dir_path = os.path.join(split_dir, ANNOTATION_SUBDIR_NAME)\n    img_path = os.path.join(image_dir_path, img_filename_with_ext); base_name = os.path.splitext(img_filename_with_ext)[0]; json_filename = base_name + '.json'\n    json_path = os.path.join(annotation_dir_path, json_filename)\n    if os.path.exists(img_path) and os.path.exists(json_path): return img_path, json_path\n    return None\n\ndef create_mask_pil(mask_size: Tuple[int, int], json_path: str) -> Image.Image:\n    if not os.path.exists(json_path): return Image.new('L', (mask_size[1], mask_size[0]), 0)\n    mask = Image.new('L', (mask_size[1], mask_size[0]), 0)\n    try:\n        with open(json_path, 'r') as f: data = json.load(f)\n        if 'shapes' not in data or not isinstance(data['shapes'], list) or not data['shapes']: return mask\n        for shape in data['shapes']:\n             if 'points' in shape and isinstance(shape['points'], list):\n                  polygon = [tuple(point) for point in shape['points']]\n                  if len(polygon) >= 3: ImageDraw.Draw(mask).polygon(polygon, outline=255, fill=255)\n    except (json.JSONDecodeError, Exception): return Image.new('L', (mask_size[1], mask_size[0]), 0)\n    return mask\n\ndef plot_image(ax: plt.Axes, image_data: np.ndarray, title: str, cmap='gray'):\n    if image_data.ndim == 2 or (image_data.ndim == 3 and image_data.shape[2] == 1): ax.imshow(image_data.squeeze(), cmap=cmap)\n    else: ax.imshow(image_data)\n    ax.set_title(title, fontsize=10); ax.axis('off')\n\nall_image_paths = []; all_mask_paths = []; all_types = []\ntry:\n    if not os.path.exists(CLASSIFICATION_FILE): raise FileNotFoundError(f\"Không tìm thấy file phân loại tại {CLASSIFICATION_FILE}\")\n    if not os.path.isdir(BASE_DATA_DIR): raise FileNotFoundError(f\"Không tìm thấy thư mục dữ liệu cơ sở: {BASE_DATA_DIR}\")\n    df_classification = pd.read_excel(CLASSIFICATION_FILE)\n    required_cols = ['image_filename', 'type']\n    if not all(col in df_classification.columns for col in required_cols): raise ValueError(f\"File Excel phải chứa các cột: {required_cols}\")\n    for index, row in tqdm(df_classification.iterrows(), total=len(df_classification), desc=\"Kiểm tra file\"):\n        img_filename_with_ext = row['image_filename']; file_type = row['type']\n        if pd.isna(img_filename_with_ext) or pd.isna(file_type) or file_type not in ['train', 'val', 'test']: continue\n        paths = get_valid_paths(BASE_DATA_DIR, str(file_type).lower(), str(img_filename_with_ext))\n        if paths: img_path, json_path = paths; all_image_paths.append(img_path); all_mask_paths.append(json_path); all_types.append(str(file_type).lower())\n    if not all_image_paths: print(\"\\nLỗi: Không tìm thấy cặp ảnh-chú thích hợp lệ nào.\"); exit()\n    df_paths = pd.DataFrame({'image_path': all_image_paths, 'mask_path': all_mask_paths, 'type': all_types})\n    df_train = df_paths[df_paths['type'] == 'train'].reset_index(drop=True); df_val = df_paths[df_paths['type'] == 'val'].reset_index(drop=True); df_test = df_paths[df_paths['type'] == 'test'].reset_index(drop=True)\n    train_image_paths = df_train['image_path'].tolist(); train_mask_paths = df_train['mask_path'].tolist()\n    val_image_paths = df_val['image_path'].tolist(); val_mask_paths = df_val['mask_path'].tolist()\n    test_image_paths = df_test['image_path'].tolist(); test_mask_paths = df_test['mask_path'].tolist()\n    print(f\"\\nPhân chia dữ liệu: Train({len(train_image_paths)}), Val({len(val_image_paths)}), Test({len(test_image_paths)})\")\n    if not train_image_paths: print(\"Cảnh báo: Tập huấn luyện rỗng!\"); exit()\nexcept Exception as e: print(f\"Lỗi khi tải siêu dữ liệu: {e}\"); import traceback; traceback.print_exc(); exit()\n\n# Tính toán Mean/Std\nmean_pixel = 0.5; std_pixel = 0.1\nnum_train_images = len(train_image_paths)\nif num_train_images > 0:\n    print(\"Đang tính toán Mean/Std...\")\n    pixel_sum = 0.0; pixel_sum_sq = 0.0; total_pixels_calculated = 0; processed_count = 0\n    sample_size_for_stats = min(num_train_images, 250) # Tăng nhẹ sample size\n    sampled_train_paths = np.random.choice(train_image_paths, size=sample_size_for_stats, replace=False)\n    for img_path in tqdm(sampled_train_paths, desc=\"Tính Mean/Std\"):\n        try:\n            img_bytes = tf.io.read_file(img_path); img = tf.io.decode_image(img_bytes, channels=1, expand_animations=False, dtype=tf.float32)\n            img = tf.image.resize(img, [TARGET_SIZE, TARGET_SIZE])\n            pixel_sum += tf.reduce_sum(img).numpy(); pixel_sum_sq += tf.reduce_sum(tf.square(img)).numpy()\n            total_pixels_calculated += (TARGET_SIZE * TARGET_SIZE); processed_count += 1\n        except Exception: pass\n    if processed_count > 0 and total_pixels_calculated > 0:\n        mean_pixel = pixel_sum / total_pixels_calculated; variance = (pixel_sum_sq / total_pixels_calculated) - (mean_pixel ** 2)\n        std_pixel = np.sqrt(max(variance, 1e-7)); print(f\"Mean: {mean_pixel:.4f}, Std Dev: {std_pixel:.4f}\")\n        if std_pixel < 1e-4: std_pixel = 0.1; print(\"Std Dev quá thấp, dùng mặc định 0.1.\")\n    else: print(f\"Cảnh báo: Không tính được mean/std, dùng mặc định.\")\nstd_pixel = max(std_pixel, 1e-7)\n\n# Pipeline Dữ liệu TensorFlow\ndef load_mask_from_json_py(json_path_bytes):\n    json_path = json_path_bytes.numpy().decode('utf-8'); pil_mask = create_mask_pil((TARGET_SIZE, TARGET_SIZE), json_path)\n    mask_np = np.array(pil_mask, dtype=np.uint8); mask_np = (mask_np > 128).astype(np.uint8)\n    return mask_np\n\n@tf.function\ndef load_and_preprocess(image_path, mask_json_path):\n    img_bytes = tf.io.read_file(image_path)\n    try: img = tf.io.decode_image(img_bytes, channels=1, expand_animations=False, dtype=tf.float32)\n    except tf.errors.InvalidArgumentError:\n        try: img = tf.image.decode_png(img_bytes, channels=1, dtype=tf.uint8); img = tf.cast(img, tf.float32) / 255.0\n        except tf.errors.InvalidArgumentError: img = tf.image.decode_jpeg(img_bytes, channels=1); img = tf.cast(img, tf.float32) / 255.0\n    img = tf.image.resize(img, [TARGET_SIZE, TARGET_SIZE]); img.set_shape([TARGET_SIZE, TARGET_SIZE, 1])\n    mask_np_binary = tf.py_function(func=load_mask_from_json_py, inp=[mask_json_path], Tout=tf.uint8)\n    mask_np_binary.set_shape([TARGET_SIZE, TARGET_SIZE])\n    mask_onehot = tf.one_hot(tf.cast(mask_np_binary, tf.int32), depth=N_CLASSES, dtype=tf.float32)\n    mask_onehot.set_shape([TARGET_SIZE, TARGET_SIZE, N_CLASSES])\n    img = (img - mean_pixel) / std_pixel\n    return img, mask_onehot\n\n@tf.function\ndef augment_data_tf(image, mask_onehot):\n    combined = tf.concat([image, tf.cast(mask_onehot, image.dtype)], axis=-1) # Nối image và mask (đã cast về dtype của image)\n    if tf.random.uniform(()) > 0.5: combined = tf.image.flip_left_right(combined)\n    if tf.random.uniform(()) > 0.5: combined = tf.image.flip_up_down(combined)\n    k_rot = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n    combined = tf.image.rot90(combined, k=k_rot)\n    img_aug = combined[..., :1]\n    mask_aug = tf.cast(combined[..., 1:], tf.float32)\n    img_aug = tf.image.random_brightness(img_aug, max_delta=0.25)\n    img_aug = tf.image.random_contrast(img_aug, lower=0.7, upper=1.3)\n    if tf.random.uniform(()) > 0.3:\n        scale = tf.random.uniform((), 0.8, 1.2)\n        new_height = tf.cast(TARGET_SIZE * scale, tf.int32)\n        new_width = tf.cast(TARGET_SIZE * scale, tf.int32)\n        img_scaled = tf.image.resize(img_aug, [new_height, new_width], method=tf.image.ResizeMethod.BILINEAR)\n        mask_scaled = tf.image.resize(mask_aug, [new_height, new_width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        img_aug = tf.image.resize_with_crop_or_pad(img_scaled, TARGET_SIZE, TARGET_SIZE)\n        mask_aug = tf.image.resize_with_crop_or_pad(mask_scaled, TARGET_SIZE, TARGET_SIZE)\n    img_aug = tf.clip_by_value(img_aug, -3.0, 3.0)\n    img_aug.set_shape([TARGET_SIZE, TARGET_SIZE, 1])\n    mask_aug.set_shape([TARGET_SIZE, TARGET_SIZE, N_CLASSES])\n    return img_aug, mask_aug\n\ndef create_dataset(image_paths, mask_paths, is_training=True):\n    if not image_paths or not mask_paths: return tf.data.Dataset.from_tensor_slices(([], [])).batch(BATCH_SIZE)\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n    if is_training: dataset = dataset.shuffle(buffer_size=min(BUFFER_SIZE, len(image_paths)), reshuffle_each_iteration=True)\n    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n    if is_training: dataset = dataset.map(augment_data_tf, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=(is_training if len(image_paths) >= BATCH_SIZE else False))\n    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return dataset\n\ntrain_ds = create_dataset(train_image_paths, train_mask_paths, is_training=True)\nval_ds = create_dataset(val_image_paths, val_mask_paths, is_training=False)\ntest_ds = create_dataset(test_image_paths, test_mask_paths, is_training=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:46:52.634624Z","iopub.execute_input":"2025-05-22T02:46:52.634962Z","iopub.status.idle":"2025-05-22T02:47:02.765668Z","shell.execute_reply.started":"2025-05-22T02:46:52.634934Z","shell.execute_reply":"2025-05-22T02:47:02.764651Z"}},"outputs":[{"name":"stderr","text":"Kiểm tra file: 100%|██████████| 3746/3746 [00:07<00:00, 499.32it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nPhân chia dữ liệu: Train(1344), Val(336), Test(187)\nĐang tính toán Mean/Std...\n","output_type":"stream"},{"name":"stderr","text":"Tính Mean/Std: 100%|██████████| 250/250 [00:01<00:00, 172.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Mean: 0.2117, Std Dev: 0.2460\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"# UNET\nclass AttentionGate(layers.Layer):\n    def __init__(self, F_g, F_l, F_int, **kwargs): super(AttentionGate, self).__init__(**kwargs); self.W_g = layers.Conv2D(F_int, 1, padding='same', kernel_initializer='he_normal'); self.W_x = layers.Conv2D(F_int, 1, padding='same', kernel_initializer='he_normal'); self.psi = layers.Conv2D(1, 1, padding='same', kernel_initializer='he_normal', activation='sigmoid'); self.relu = layers.Activation('relu')\n    def call(self, g, x): g1 = self.W_g(g); x1 = self.W_x(x); psi_input = self.relu(g1 + x1); alpha = self.psi(psi_input); return x * alpha\ndef conv_block(inputs, num_filters, l2_reg, dropout):\n    x = layers.Conv2D(num_filters, 3, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(inputs); x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n    if dropout > 0: x = layers.Dropout(dropout)(x)\n    x = layers.Conv2D(num_filters, 3, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x); x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n    return x\ndef encoder_block(inputs, num_filters, l2_reg, dropout, pool=True): c = conv_block(inputs, num_filters, l2_reg, dropout); p = layers.MaxPooling2D(2)(c) if pool else None; return c, p\ndef decoder_block(inputs, skip_features, num_filters, l2_reg, dropout, use_attention):\n    x = layers.Conv2DTranspose(num_filters, 2, strides=2, padding='same')(inputs)\n    if use_attention and skip_features is not None: att_gate = AttentionGate(num_filters, skip_features.shape[-1], max(1, skip_features.shape[-1] // 2) ); skip_features = att_gate(g=x, x=skip_features)\n    if skip_features is not None: x = layers.Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters, l2_reg, dropout); return x\ndef build_unet(input_shape, n_classes=N_CLASSES, l2_reg=L2_REG_FACTOR, dropout=DROPOUT_RATE, use_attention=USE_ATTENTION_UNET):\n    filters = [64, 128, 256, 512, 1024]\n    inputs = keras.Input(shape=input_shape); skips = []; x = inputs\n    for f in filters[:-1]: s, p = encoder_block(x, f, l2_reg, dropout, pool=True); skips.append(s); x = p\n    x, _ = encoder_block(x, filters[-1], l2_reg, dropout*1.3, pool=False)\n    for i, f in reversed(list(enumerate(filters[:-1]))): x = decoder_block(x, skips[i], f, l2_reg, dropout, use_attention)\n    outputs = layers.Conv2D(n_classes, 1, padding='same', activation='softmax')(x)\n    return keras.Model(inputs, outputs, name=f\"{'Attention' if use_attention else ''}UNet_filters{filters[0]}\")\n\n# --- HÀM MẤT MÁT (LOSS FUNCTIONS) ---\nSMOOTH = 1e-6\ndef dice_coef(y_true_one_hot, y_pred_softmax):\n    y_true_f = tf.keras.backend.flatten(y_true_one_hot)\n    y_pred_f = tf.keras.backend.flatten(y_pred_softmax)\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    return (2. * intersection + SMOOTH) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + SMOOTH)\n\ndef dice_coef_metric_tumor(y_true, y_pred):\n    # y_true: (batch, H, W, N_CLASSES), y_pred: (batch, H, W, N_CLASSES)\n    return dice_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\ndice_coef_metric_tumor.__name__ = 'dice_coef_metric_tumor' # Khớp với `metrics_to_plot`\n\ndef dice_loss_tumor(y_true, y_pred):\n    return 1.0 - dice_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\n\ndef iou_coef(y_true_one_hot, y_pred_softmax):\n    y_true_f = tf.keras.backend.flatten(y_true_one_hot)\n    y_pred_f = tf.keras.backend.flatten(y_pred_softmax)\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n    return (intersection + SMOOTH) / (union + SMOOTH)\n\ndef iou_metric_tumor(y_true, y_pred):\n    return iou_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\niou_metric_tumor.__name__ = 'tumor_iou' # Khớp với `metrics_to_plot`\n\n# --- CÁC METRICS MỚI CHO LỚP TUMOR ---\ndef precision_recall_tumor_base(y_true, y_pred, metric_type):\n    if N_CLASSES < 2:\n        return tf.constant(0.0, dtype=tf.float32)\n\n    # Lấy kênh của lớp tumor (giả sử lớp 1 là tumor)\n    y_true_tumor = y_true[..., 1] # Ground truth cho lớp tumor (0 hoặc 1)\n    \n    # Chuyển đổi y_pred (softmax probabilities) thành dự đoán nhãn cứng (0 hoặc 1) cho lớp tumor\n    # Cách 1: Dựa trên xác suất cao nhất (argmax)\n    y_pred_labels = tf.argmax(y_pred, axis=-1) # Shape: (batch, H, W)\n    y_pred_tumor_binary = tf.cast(tf.equal(y_pred_labels, 1), tf.float32) # 1 nếu dự đoán là tumor (lớp 1), 0 nếu khác\n\n    # Cách 2: (Nếu chỉ có 2 lớp, có thể dùng ngưỡng 0.5 cho xác suất lớp tumor)\n    # y_pred_tumor_binary = tf.cast(y_pred[..., 1] > 0.5, tf.float32) # Chỉ phù hợp nếu N_CLASSES=2 và lớp 1 là tumor\n\n    # Flatten để tính toán\n    y_true_tumor_flat = tf.keras.backend.flatten(y_true_tumor)\n    y_pred_tumor_binary_flat = tf.keras.backend.flatten(y_pred_tumor_binary)\n\n    true_positives = tf.keras.backend.sum(y_true_tumor_flat * y_pred_tumor_binary_flat)\n    \n    if metric_type == 'precision':\n        predicted_positives = tf.keras.backend.sum(y_pred_tumor_binary_flat)\n        value = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n    elif metric_type == 'recall':\n        possible_positives = tf.keras.backend.sum(y_true_tumor_flat)\n        value = true_positives / (possible_positives + tf.keras.backend.epsilon())\n    else:\n        value = tf.constant(0.0, dtype=tf.float32)\n        \n    return value\n\ndef precision_tumor_metric(y_true, y_pred):\n    return precision_recall_tumor_base(y_true, y_pred, 'precision')\nprecision_tumor_metric.__name__ = 'precision_tumor' # Khớp với `metrics_to_plot`\n\ndef recall_tumor_metric(y_true, y_pred):\n    return precision_recall_tumor_base(y_true, y_pred, 'recall')\nrecall_tumor_metric.__name__ = 'recall_tumor' # Khớp với `metrics_to_plot`\n# --- KẾT THÚC METRICS MỚI ---\n\ndef categorical_focal_loss_wrapper(alpha=FOCAL_LOSS_ALPHA, gamma=FOCAL_LOSS_GAMMA):\n    def focal_loss_fn(y_true, y_pred):\n        epsilon = tf.keras.backend.epsilon(); y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n        cross_entropy = -y_true * tf.math.log(y_pred)\n        loss = alpha * tf.pow(1 - y_pred, gamma) * cross_entropy\n        return tf.reduce_mean(tf.reduce_sum(loss, axis=-1))\n    focal_loss_fn.__name__ = f'focal_loss_alpha{alpha}_gamma{gamma}'\n    return focal_loss_fn\n\ndef combined_loss_fn(y_true, y_pred, dice_w=DICE_LOSS_WEIGHT):\n    d_loss = dice_loss_tumor(y_true, y_pred)\n    if USE_FOCAL_LOSS_IN_COMBINED: ce_or_focal_loss = categorical_focal_loss_wrapper()(y_true, y_pred)\n    else: ce_or_focal_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true, y_pred))\n    return (dice_w * d_loss) + ((1.0 - dice_w) * ce_or_focal_loss)\ncombined_loss_fn.__name__ = f'combined_dice{DICE_LOSS_WEIGHT}_{\"focal\" if USE_FOCAL_LOSS_IN_COMBINED else \"cce\"}'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:47:05.003800Z","iopub.execute_input":"2025-05-22T02:47:05.004135Z","iopub.status.idle":"2025-05-22T02:47:05.027313Z","shell.execute_reply.started":"2025-05-22T02:47:05.004106Z","shell.execute_reply":"2025-05-22T02:47:05.026432Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"import wandb # Đảm bảo wandb đã được import\nfrom datetime import datetime, timedelta # Để tạo tên run\n\n# --- Build và Compile Model ---\nmodel = build_unet((TARGET_SIZE, TARGET_SIZE, 1), N_CLASSES, L2_REG_FACTOR, DROPOUT_RATE, USE_ATTENTION_UNET)\noptimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n\nif USE_COMBINED_LOSS:\n    loss_to_use = combined_loss_fn\nelse:\n    if USE_FOCAL_LOSS_IN_COMBINED:\n        loss_to_use = categorical_focal_loss_wrapper(alpha=FOCAL_LOSS_ALPHA, gamma=FOCAL_LOSS_GAMMA)\n    else:\n        loss_to_use = tf.keras.losses.CategoricalCrossentropy()\n        loss_to_use.__name__ = \"categorical_crossentropy\" # Đặt tên nếu là object\n\nloss_name_str = loss_to_use.__name__ if hasattr(loss_to_use, '__name__') else \"custom_loss\"\n\n# --- Định nghĩa danh sách metrics cho model.compile() ---\n# Đảm bảo các tên này sẽ xuất hiện trong history.history\nmetrics_to_compile = [ # Đổi tên biến để tránh nhầm lẫn với list dùng để log\n    dice_coef_metric_tumor,\n    iou_metric_tumor,\n    precision_tumor_metric,\n    recall_tumor_metric,\n    tf.keras.metrics.MeanIoU(num_classes=N_CLASSES, name='mean_iou_all'),\n    tf.keras.metrics.CategoricalAccuracy(name='acc') # Keras có thể trả về 'acc' hoặc 'categorical_accuracy'\n]\n# Tạo list các tên metric thực tế sẽ dùng để log (từ history.history)\n# Điều này quan trọng để đảm bảo key khớp khi log thủ công\n# Keras trả về tên của hàm/object metric, hoặc tên bạn đặt trong tf.keras.metrics.Metric(name='...')\n# Nếu metric là một hàm, history.history sẽ dùng tên hàm.\n# Nếu là một object tf.keras.metrics.Metric, nó sẽ dùng thuộc tính .name\n# Đối với CategoricalAccuracy, Keras có thể dùng 'acc' hoặc 'categorical_accuracy'.\n# Chúng ta sẽ xử lý điều này linh hoạt hơn trong vòng lặp log.\n\n# Các tên metric cơ bản mà chúng ta muốn log, không bao gồm 'loss' và 'val_loss' (vì chúng luôn có)\n# và 'acc'/'val_acc' (sẽ xử lý riêng)\nmetric_names_to_log_manually = []\nfor m in metrics_to_compile:\n    if hasattr(m, 'name'):\n        metric_names_to_log_manually.append(m.name)\n    elif hasattr(m, '__name__'):\n        metric_names_to_log_manually.append(m.__name__)\n# Loại bỏ 'acc' nếu có, vì sẽ xử lý riêng\nif 'acc' in metric_names_to_log_manually:\n    metric_names_to_log_manually.remove('acc')\nif 'categorical_accuracy' in metric_names_to_log_manually:\n     metric_names_to_log_manually.remove('categorical_accuracy')\n\n\nmodel.compile(optimizer=optimizer, loss=loss_to_use, metrics=metrics_to_compile)\nmodel.summary()\n\n# --- KHỞI TẠO WEIGHTS & BIASES ---\nif WANDB_API_KEY:\n    wandb.login(key=WANDB_API_KEY)\nelse:\n    try:\n        wandb.login() # Thử đăng nhập tương tác nếu không có key\n    except Exception as e:\n        print(f\"Lỗi khi đăng nhập WandB: {e}. Vui lòng đảm bảo bạn đã đăng nhập WandB.\")\n        # Có thể exit() ở đây nếu WandB là bắt buộc\n\n# Lấy giờ VN cho tên run\nnow_vn = datetime.utcnow() + timedelta(hours=7)\n# Chỉnh sửa format tên run để không có ký tự '/' không hợp lệ cho tên file/directory\nrun_name_wandb = f\"{MODEL_CHECKPOINT_BASENAME}_{loss_name_str}_attn{USE_ATTENTION_UNET}_\" + now_vn.strftime(\"%d%m%Y_%H%M%S\")\n\nwandb_config = {\n    \"epochs\": EPOCHS,\n    \"batch_size\": BATCH_SIZE,\n    \"learning_rate\": LEARNING_RATE,\n    \"target_size\": TARGET_SIZE,\n    \"n_classes\": N_CLASSES,\n    \"l2_reg_factor\": L2_REG_FACTOR,\n    \"dropout_rate\": DROPOUT_RATE,\n    \"use_combined_loss\": USE_COMBINED_LOSS,\n    \"dice_loss_weight\": DICE_LOSS_WEIGHT,\n    \"use_focal_loss_in_combined\": USE_FOCAL_LOSS_IN_COMBINED,\n    \"focal_loss_alpha\": FOCAL_LOSS_ALPHA,\n    \"focal_loss_gamma\": FOCAL_LOSS_GAMMA,\n    \"use_attention_unet\": USE_ATTENTION_UNET,\n    \"architecture\": model.name,\n    \"optimizer\": type(optimizer).__name__,\n    \"loss_function\": loss_name_str,\n    \"mean_pixel_train\": mean_pixel, # Giả sử mean_pixel, std_pixel đã được tính\n    \"std_pixel_train\": std_pixel,\n    \"monitor_metric_callbacks\": MONITOR_METRIC_CB # Metric cho các Keras callback\n}\n\nwandb.init(\n    project=WANDB_PROJECT_NAME,\n    entity=WANDB_ENTITY,\n    name=run_name_wandb,\n    config=wandb_config\n    # sync_tensorboard=True # Vẫn có thể dùng nếu bạn có TensorBoard callback\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:47:09.035817Z","iopub.execute_input":"2025-05-22T02:47:09.036160Z","iopub.status.idle":"2025-05-22T02:47:09.452264Z","shell.execute_reply.started":"2025-05-22T02:47:09.036130Z","shell.execute_reply":"2025-05-22T02:47:09.451385Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"UNet_filters64\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"UNet_filters64\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_76 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m640\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_72    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_76[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_72             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_36 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_72[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_77 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ dropout_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_73    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_77[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_73             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_73[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_78 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_74    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_78[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_74             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_37 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_74[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_79 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ dropout_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_75    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_75             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_75[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_80 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_76    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_76             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_38 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_76[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_81 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m590,080\u001b[0m │ dropout_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_77    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_77             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_77[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_82 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_78    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_78             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_39 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_78[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_83 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ dropout_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_79    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_79             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_84 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │      \u001b[38;5;34m4,719,616\u001b[0m │ max_pooling2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_80    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_80             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_40 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_85 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │      \u001b[38;5;34m9,438,208\u001b[0m │ dropout_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_81    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_85[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_81             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_16       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,097,664\u001b[0m │ activation_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_16            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_16[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_86 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m4,719,104\u001b[0m │ concatenate_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_82    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_86[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_82             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_41 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_87 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ dropout_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_83    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_83             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_17       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m524,544\u001b[0m │ activation_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_17            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_17[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_77[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_88 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │      \u001b[38;5;34m1,179,904\u001b[0m │ concatenate_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_84    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_88[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_84             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_42 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_89 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m590,080\u001b[0m │ dropout_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_85    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_89[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_85             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_18       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m131,200\u001b[0m │ activation_85[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_18            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_18[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_75[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_90 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m295,040\u001b[0m │ concatenate_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_86    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_90[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_86             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_43 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_86[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_91 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ dropout_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_87    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_91[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_87             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_19       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m32,832\u001b[0m │ activation_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_19            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_19[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_73[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_92 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m73,792\u001b[0m │ concatenate_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_88    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_92[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_88             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_44 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_88[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_93 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ dropout_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_89    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_93[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_89             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_94 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m2\u001b[0m)    │            \u001b[38;5;34m130\u001b[0m │ activation_89[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_72    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_72             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ dropout_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_73    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_77[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_73             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_74    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_74             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_75    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_75             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_76    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_76             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ dropout_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_77    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_77             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_77[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_78    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_78             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ dropout_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_79    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_79             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> │ max_pooling2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_80    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_80             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span> │ dropout_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_81    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_81             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_16       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ activation_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_16            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │ concatenate_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_82    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_82             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ dropout_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_83    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_83             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_17       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ activation_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_17            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_77[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ concatenate_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_84    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_88[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_84             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ dropout_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_85    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_89[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_85             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_18       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ activation_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_18            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_86    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_90[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_86             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_87    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_91[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_87             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_19       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ activation_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_19            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_88    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_92[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_88             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_88[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ dropout_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_89    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_89             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ activation_89[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,054,210\u001b[0m (118.46 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,054,210</span> (118.46 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,042,434\u001b[0m (118.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,042,434</span> (118.42 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m11,776\u001b[0m (46.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,776</span> (46.00 KB)\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"execution_count":48,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nganltt2333/btxrd-project/runs/f0ny5wue?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x782a34cb6560>"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"# Callbacks Keras tiêu chuẩn (KHÔNG BAO GỒM WandbCallback)\n\n# Đường dẫn lưu checkpoint\ncheckpoint_path = f\"{MODEL_CHECKPOINT_BASENAME}_{run_name_wandb}.keras\" # Dùng run_name_wandb để duy nhất\n\n# MONITOR_METRIC_CB ('val_dice_coef_metric_tumor') phải là một key có trong history.history khi val_ds được dùng\nkeras_callbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_path, # Đổi tên tham số cho rõ ràng\n        save_best_only=True,\n        monitor=MONITOR_METRIC_CB,\n        mode='max',\n        verbose=1\n    ),\n    tf.keras.callbacks.EarlyStopping(\n        monitor=MONITOR_METRIC_CB,\n        patience=PATIENCE_EARLY_STOPPING,\n        mode='max',\n        restore_best_weights=True,\n        verbose=1\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor=MONITOR_METRIC_CB,\n        factor=0.3,\n        patience=PATIENCE_REDUCE_LR,\n        mode='max',\n        min_lr=1e-7,\n        verbose=1\n    ),\n    tf.keras.callbacks.TensorBoard(\n        log_dir=TENSORBOARD_LOG_DIR, # WandB có thể sync từ đây nếu sync_tensorboard=True trong init\n        histogram_freq=1 # Có thể gây chậm, cân nhắc\n    )\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:47:17.913165Z","iopub.execute_input":"2025-05-22T02:47:17.913500Z","iopub.status.idle":"2025-05-22T02:47:17.920514Z","shell.execute_reply.started":"2025-05-22T02:47:17.913471Z","shell.execute_reply":"2025-05-22T02:47:17.919457Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# Class Weights\npix_cls0 = 0; pix_cls1 = 0\n# Giả sử train_mask_paths đã được tạo ở Đoạn 2\nif 'train_mask_paths' in locals() and train_mask_paths: # Kiểm tra biến tồn tại\n    for mask_p in tqdm(train_mask_paths, desc=\"Đếm pixels cho class weights\"):\n        try:\n            m = create_mask_pil((TARGET_SIZE, TARGET_SIZE), mask_p)\n            m_np = (np.array(m) > 128).astype(np.uint8)\n            pix_cls0 += np.sum(m_np == 0)\n            pix_cls1 += np.sum(m_np == 1)\n        except Exception as e:\n            print(f\"Lỗi khi xử lý mask {mask_p} cho class weights: {e}\")\n            continue\nelse:\n    print(\"Cảnh báo: train_mask_paths không tồn tại hoặc rỗng, không thể tính class weights.\")\n\nclass_weights = None # Khởi tạo class_weights\nif pix_cls1 > 0 and pix_cls0 > 0:\n    total_pix = float(pix_cls0 + pix_cls1)\n    w0 = (total_pix / (N_CLASSES * float(pix_cls0)))\n    w1 = (total_pix / (N_CLASSES * float(pix_cls1)))\n    class_weights = {0: w0, 1: w1} # Gán giá trị cho class_weights\n    print(f\"Class weights đã tính: Lớp 0: {w0:.4f}, Lớp 1: {w1:.4f}\")\n    if w1 < w0 :\n        print(\"Cảnh báo: Trọng số lớp khối u (1) nhỏ hơn lớp nền (0). Kiểm tra lại số lượng pixel hoặc dữ liệu.\")\n    if wandb.run:\n        wandb.config.update({\"class_weight_0\": w0, \"class_weight_1\": w1, \"calculated_class_weights\": True})\nelse:\n    print(\"Không tính được class weights (số pixel lớp 0 hoặc 1 bằng 0 hoặc train_mask_paths rỗng). Sử dụng None.\")\n    if wandb.run:\n        wandb.config.update({\"calculated_class_weights\": False})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:47:22.537564Z","iopub.execute_input":"2025-05-22T02:47:22.537868Z","iopub.status.idle":"2025-05-22T02:47:25.157199Z","shell.execute_reply.started":"2025-05-22T02:47:22.537844Z","shell.execute_reply":"2025-05-22T02:47:25.156391Z"}},"outputs":[{"name":"stderr","text":"Đếm pixels cho class weights: 100%|██████████| 1344/1344 [00:02<00:00, 515.80it/s]","output_type":"stream"},{"name":"stdout","text":"Class weights đã tính: Lớp 0: 0.5089, Lớp 1: 28.6592\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"# Huấn luyện Model với vòng lặp thủ công và log thủ công lên WandB\n\n# Kiểm tra sự tồn tại của train_ds và val_ds (nếu val_image_paths có)\nif 'train_ds' not in locals() or not train_ds:\n    print(\"Lỗi: Tập huấn luyện (train_ds) chưa được tạo hoặc rỗng.\")\n    if wandb.run: wandb.finish(exit_code=1)\n    exit()\n\nuse_validation = 'val_image_paths' in locals() and val_image_paths and 'val_ds' in locals() and val_ds\nif 'val_image_paths' in locals() and val_image_paths and ('val_ds' not in locals() or not val_ds):\n    print(\"Lỗi: Có val_image_paths nhưng tập validation (val_ds) chưa được tạo hoặc rỗng.\")\n    if wandb.run: wandb.finish(exit_code=1)\n    exit()\n\nprint(f\"\\nBắt đầu huấn luyện cho {EPOCHS} epochs...\")\n\nfor epoch in range(EPOCHS):\n    print(f\"\\n--- Epoch {epoch + 1}/{EPOCHS} ---\")\n\n    history = model.fit(\n        train_ds,\n        validation_data=val_ds if use_validation else None,\n        epochs=1, # CHỈ HUẤN LUYỆN 1 EPOCH MỖI LẦN GỌI FIT\n        class_weight=class_weights, # Từ Đoạn 6\n        callbacks=keras_callbacks, # Callbacks Keras tiêu chuẩn từ Đoạn 5\n        verbose=1\n    )\n\n    current_logs = history.history\n    if not current_logs:\n        print(f\"Cảnh báo: Không có logs nào được trả về từ model.fit() ở epoch {epoch + 1}.\")\n        continue\n\n    # --- Ghi log thủ công cho W&B ---\n    log_data_to_wandb = {\"epoch\": epoch + 1}\n\n    # Metrics huấn luyện\n    log_data_to_wandb[\"loss\"] = current_logs.get(\"loss\", [None])[0]\n    # Xử lý 'acc' hoặc 'categorical_accuracy' cho training\n    train_acc_key = None\n    if \"acc\" in current_logs:\n        train_acc_key = \"acc\"\n    elif \"categorical_accuracy\" in current_logs:\n        train_acc_key = \"categorical_accuracy\"\n    if train_acc_key:\n        log_data_to_wandb[train_acc_key] = current_logs.get(train_acc_key, [None])[0]\n\n    # Log các metrics tùy chỉnh khác cho training\n    for metric_name in metric_names_to_log_manually: # Từ Đoạn 4\n        if metric_name in current_logs:\n            log_data_to_wandb[metric_name] = current_logs.get(metric_name, [None])[0]\n\n\n    # Metrics validation (nếu có)\n    if use_validation:\n        log_data_to_wandb[\"val_loss\"] = current_logs.get(\"val_loss\", [None])[0]\n        # Xử lý 'val_acc' hoặc 'val_categorical_accuracy'\n        val_acc_key = None\n        if \"val_acc\" in current_logs:\n            val_acc_key = \"val_acc\"\n        elif \"val_categorical_accuracy\" in current_logs:\n            val_acc_key = \"val_categorical_accuracy\"\n        if val_acc_key:\n            log_data_to_wandb[val_acc_key] = current_logs.get(val_acc_key, [None])[0]\n\n        # Log các metrics tùy chỉnh khác cho validation\n        for metric_name in metric_names_to_log_manually: # Từ Đoạn 4\n            val_metric_key = f\"val_{metric_name}\"\n            if val_metric_key in current_logs:\n                log_data_to_wandb[val_metric_key] = current_logs.get(val_metric_key, [None])[0]\n\n    wandb.log(log_data_to_wandb)\n    print(f\"Đã log metrics cho epoch {epoch + 1} lên WandB.\")\n\n    # Kiểm tra điều kiện dừng sớm từ EarlyStopping callback\n    if model.stop_training:\n        print(f\"Huấn luyện dừng sớm bởi EarlyStopping callback sau epoch {epoch + 1}.\")\n        break\n\nprint(\"\\nHuấn luyện hoàn tất (hoặc dừng sớm)!\")\n\n# Kết thúc run WandB\nif wandb.run:\n    # (Tùy chọn) Log model tốt nhất như một artifact\n    # Giả sử ModelCheckpoint đã lưu model tốt nhất vào checkpoint_path\n    if os.path.exists(checkpoint_path):\n        print(f\"Đang log model tốt nhất từ: {checkpoint_path}\")\n        best_model_artifact = wandb.Artifact(\n            f'{MODEL_CHECKPOINT_BASENAME}-best_model',\n            type='model',\n            description=f'Best model based on {MONITOR_METRIC_CB} from run {run_name_wandb}',\n            metadata=dict(wandb.config) # Lưu config của run vào metadata artifact\n        )\n        best_model_artifact.add_file(checkpoint_path)\n        wandb.log_artifact(best_model_artifact)\n        print(\"Đã log model tốt nhất lên WandB Artifacts.\")\n    else:\n        print(f\"Không tìm thấy model checkpoint tại: {checkpoint_path} để log artifact.\")\n\n    wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:55:54.251525Z","iopub.execute_input":"2025-05-22T02:55:54.251882Z","execution_failed":"2025-05-22T13:36:32.670Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nBắt đầu huấn luyện cho 300 epochs...\n\n--- Epoch 1/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9191 - dice_coef_metric_tumor: 0.1531 - loss: 0.5532 - mean_iou_all: 0.2530 - precision_tumor: 0.1211 - recall_tumor: 0.5103 - tumor_iou: 0.0873","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.09935 to 0.12056, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9191 - dice_coef_metric_tumor: 0.1531 - loss: 0.5532 - mean_iou_all: 0.2530 - precision_tumor: 0.1210 - recall_tumor: 0.5102 - tumor_iou: 0.0873 - val_acc: 0.8522 - val_dice_coef_metric_tumor: 0.1206 - val_loss: 0.5804 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0764 - val_recall_tumor: 0.7100 - val_tumor_iou: 0.0671 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 1 lên WandB.\n\n--- Epoch 2/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9214 - dice_coef_metric_tumor: 0.1589 - loss: 0.5534 - mean_iou_all: 0.2534 - precision_tumor: 0.1219 - recall_tumor: 0.4653 - tumor_iou: 0.0917","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.12056 to 0.13318, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9214 - dice_coef_metric_tumor: 0.1589 - loss: 0.5533 - mean_iou_all: 0.2534 - precision_tumor: 0.1219 - recall_tumor: 0.4653 - tumor_iou: 0.0917 - val_acc: 0.8635 - val_dice_coef_metric_tumor: 0.1332 - val_loss: 0.5732 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0839 - val_recall_tumor: 0.7173 - val_tumor_iou: 0.0751 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 2 lên WandB.\n\n--- Epoch 3/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9301 - dice_coef_metric_tumor: 0.1685 - loss: 0.5295 - mean_iou_all: 0.2537 - precision_tumor: 0.1283 - recall_tumor: 0.4699 - tumor_iou: 0.0980","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.13318 to 0.14229, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 468ms/step - acc: 0.9301 - dice_coef_metric_tumor: 0.1685 - loss: 0.5295 - mean_iou_all: 0.2537 - precision_tumor: 0.1282 - recall_tumor: 0.4699 - tumor_iou: 0.0980 - val_acc: 0.8777 - val_dice_coef_metric_tumor: 0.1423 - val_loss: 0.5640 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0903 - val_recall_tumor: 0.6820 - val_tumor_iou: 0.0810 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 3 lên WandB.\n\n--- Epoch 4/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9354 - dice_coef_metric_tumor: 0.1818 - loss: 0.5272 - mean_iou_all: 0.2547 - precision_tumor: 0.1390 - recall_tumor: 0.4733 - tumor_iou: 0.1073","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.14229\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9354 - dice_coef_metric_tumor: 0.1817 - loss: 0.5272 - mean_iou_all: 0.2547 - precision_tumor: 0.1389 - recall_tumor: 0.4732 - tumor_iou: 0.1072 - val_acc: 0.9533 - val_dice_coef_metric_tumor: 0.1372 - val_loss: 0.5560 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1274 - val_recall_tumor: 0.2889 - val_tumor_iou: 0.0788 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 4 lên WandB.\n\n--- Epoch 5/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9281 - dice_coef_metric_tumor: 0.1842 - loss: 0.5241 - mean_iou_all: 0.2550 - precision_tumor: 0.1388 - recall_tumor: 0.4991 - tumor_iou: 0.1084","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.14229\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9281 - dice_coef_metric_tumor: 0.1841 - loss: 0.5241 - mean_iou_all: 0.2550 - precision_tumor: 0.1387 - recall_tumor: 0.4991 - tumor_iou: 0.1083 - val_acc: 0.8516 - val_dice_coef_metric_tumor: 0.1308 - val_loss: 0.5701 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0793 - val_recall_tumor: 0.7542 - val_tumor_iou: 0.0734 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 5 lên WandB.\n\n--- Epoch 6/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9284 - dice_coef_metric_tumor: 0.1731 - loss: 0.5232 - mean_iou_all: 0.2552 - precision_tumor: 0.1286 - recall_tumor: 0.4813 - tumor_iou: 0.1016","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.14229 to 0.15171, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9284 - dice_coef_metric_tumor: 0.1731 - loss: 0.5231 - mean_iou_all: 0.2552 - precision_tumor: 0.1286 - recall_tumor: 0.4813 - tumor_iou: 0.1016 - val_acc: 0.8927 - val_dice_coef_metric_tumor: 0.1517 - val_loss: 0.5533 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0973 - val_recall_tumor: 0.6598 - val_tumor_iou: 0.0871 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 6 lên WandB.\n\n--- Epoch 7/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9302 - dice_coef_metric_tumor: 0.1864 - loss: 0.5187 - mean_iou_all: 0.2568 - precision_tumor: 0.1393 - recall_tumor: 0.4975 - tumor_iou: 0.1104","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.15171\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9302 - dice_coef_metric_tumor: 0.1863 - loss: 0.5187 - mean_iou_all: 0.2568 - precision_tumor: 0.1393 - recall_tumor: 0.4975 - tumor_iou: 0.1104 - val_acc: 0.8438 - val_dice_coef_metric_tumor: 0.1324 - val_loss: 0.5739 - val_mean_iou_all: 0.2527 - val_precision_tumor: 0.0784 - val_recall_tumor: 0.7692 - val_tumor_iou: 0.0746 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 7 lên WandB.\n\n--- Epoch 8/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9373 - dice_coef_metric_tumor: 0.1921 - loss: 0.5071 - mean_iou_all: 0.2565 - precision_tumor: 0.1452 - recall_tumor: 0.4776 - tumor_iou: 0.1144","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.15171 to 0.15670, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9372 - dice_coef_metric_tumor: 0.1920 - loss: 0.5071 - mean_iou_all: 0.2565 - precision_tumor: 0.1451 - recall_tumor: 0.4776 - tumor_iou: 0.1143 - val_acc: 0.9118 - val_dice_coef_metric_tumor: 0.1567 - val_loss: 0.5445 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1058 - val_recall_tumor: 0.5752 - val_tumor_iou: 0.0903 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 8 lên WandB.\n\n--- Epoch 9/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9441 - dice_coef_metric_tumor: 0.2080 - loss: 0.5044 - mean_iou_all: 0.2559 - precision_tumor: 0.1618 - recall_tumor: 0.4579 - tumor_iou: 0.1251","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.15670 to 0.16479, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9441 - dice_coef_metric_tumor: 0.2079 - loss: 0.5043 - mean_iou_all: 0.2559 - precision_tumor: 0.1618 - recall_tumor: 0.4578 - tumor_iou: 0.1251 - val_acc: 0.9411 - val_dice_coef_metric_tumor: 0.1648 - val_loss: 0.5354 - val_mean_iou_all: 0.2501 - val_precision_tumor: 0.1275 - val_recall_tumor: 0.4328 - val_tumor_iou: 0.0961 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 9 lên WandB.\n\n--- Epoch 10/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9431 - dice_coef_metric_tumor: 0.1987 - loss: 0.5088 - mean_iou_all: 0.2566 - precision_tumor: 0.1561 - recall_tumor: 0.4372 - tumor_iou: 0.1189","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.16479\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 463ms/step - acc: 0.9431 - dice_coef_metric_tumor: 0.1987 - loss: 0.5087 - mean_iou_all: 0.2566 - precision_tumor: 0.1560 - recall_tumor: 0.4372 - tumor_iou: 0.1189 - val_acc: 0.9351 - val_dice_coef_metric_tumor: 0.1640 - val_loss: 0.5360 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1217 - val_recall_tumor: 0.4646 - val_tumor_iou: 0.0957 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 10 lên WandB.\n\n--- Epoch 11/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9416 - dice_coef_metric_tumor: 0.2067 - loss: 0.5043 - mean_iou_all: 0.2572 - precision_tumor: 0.1624 - recall_tumor: 0.4741 - tumor_iou: 0.1240","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.16479\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9416 - dice_coef_metric_tumor: 0.2066 - loss: 0.5043 - mean_iou_all: 0.2572 - precision_tumor: 0.1623 - recall_tumor: 0.4739 - tumor_iou: 0.1239 - val_acc: 0.9661 - val_dice_coef_metric_tumor: 0.1118 - val_loss: 0.5667 - val_mean_iou_all: 0.2509 - val_precision_tumor: 0.1402 - val_recall_tumor: 0.1756 - val_tumor_iou: 0.0639 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 11 lên WandB.\n\n--- Epoch 12/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9331 - dice_coef_metric_tumor: 0.1759 - loss: 0.5263 - mean_iou_all: 0.2584 - precision_tumor: 0.1302 - recall_tumor: 0.4507 - tumor_iou: 0.1029","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.16479\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9331 - dice_coef_metric_tumor: 0.1759 - loss: 0.5263 - mean_iou_all: 0.2584 - precision_tumor: 0.1302 - recall_tumor: 0.4508 - tumor_iou: 0.1029 - val_acc: 0.8715 - val_dice_coef_metric_tumor: 0.1481 - val_loss: 0.5511 - val_mean_iou_all: 0.2507 - val_precision_tumor: 0.0926 - val_recall_tumor: 0.7537 - val_tumor_iou: 0.0846 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 12 lên WandB.\n\n--- Epoch 13/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9445 - dice_coef_metric_tumor: 0.2042 - loss: 0.5083 - mean_iou_all: 0.2586 - precision_tumor: 0.1625 - recall_tumor: 0.4387 - tumor_iou: 0.1229","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.16479\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9445 - dice_coef_metric_tumor: 0.2042 - loss: 0.5083 - mean_iou_all: 0.2586 - precision_tumor: 0.1625 - recall_tumor: 0.4386 - tumor_iou: 0.1229 - val_acc: 0.9682 - val_dice_coef_metric_tumor: 0.1405 - val_loss: 0.5469 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1730 - val_recall_tumor: 0.1901 - val_tumor_iou: 0.0824 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 13 lên WandB.\n\n--- Epoch 14/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9465 - dice_coef_metric_tumor: 0.1989 - loss: 0.5105 - mean_iou_all: 0.2596 - precision_tumor: 0.1567 - recall_tumor: 0.4313 - tumor_iou: 0.1191","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.16479 to 0.16900, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9465 - dice_coef_metric_tumor: 0.1989 - loss: 0.5105 - mean_iou_all: 0.2596 - precision_tumor: 0.1567 - recall_tumor: 0.4313 - tumor_iou: 0.1191 - val_acc: 0.9248 - val_dice_coef_metric_tumor: 0.1690 - val_loss: 0.5339 - val_mean_iou_all: 0.2594 - val_precision_tumor: 0.1159 - val_recall_tumor: 0.5173 - val_tumor_iou: 0.0991 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 14 lên WandB.\n\n--- Epoch 15/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9477 - dice_coef_metric_tumor: 0.2146 - loss: 0.4880 - mean_iou_all: 0.2661 - precision_tumor: 0.1698 - recall_tumor: 0.4601 - tumor_iou: 0.1309","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.16900 to 0.17450, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9477 - dice_coef_metric_tumor: 0.2145 - loss: 0.4880 - mean_iou_all: 0.2662 - precision_tumor: 0.1697 - recall_tumor: 0.4601 - tumor_iou: 0.1308 - val_acc: 0.9148 - val_dice_coef_metric_tumor: 0.1745 - val_loss: 0.5365 - val_mean_iou_all: 0.2577 - val_precision_tumor: 0.1148 - val_recall_tumor: 0.5890 - val_tumor_iou: 0.1029 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 15 lên WandB.\n\n--- Epoch 16/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9471 - dice_coef_metric_tumor: 0.2249 - loss: 0.4827 - mean_iou_all: 0.2635 - precision_tumor: 0.1754 - recall_tumor: 0.4838 - tumor_iou: 0.1366","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.17450 to 0.18269, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9471 - dice_coef_metric_tumor: 0.2248 - loss: 0.4827 - mean_iou_all: 0.2635 - precision_tumor: 0.1754 - recall_tumor: 0.4838 - tumor_iou: 0.1366 - val_acc: 0.9535 - val_dice_coef_metric_tumor: 0.1827 - val_loss: 0.5223 - val_mean_iou_all: 0.2547 - val_precision_tumor: 0.1469 - val_recall_tumor: 0.3772 - val_tumor_iou: 0.1088 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 16 lên WandB.\n\n--- Epoch 17/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9512 - dice_coef_metric_tumor: 0.2331 - loss: 0.4802 - mean_iou_all: 0.2631 - precision_tumor: 0.1883 - recall_tumor: 0.4610 - tumor_iou: 0.1437","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18269\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9512 - dice_coef_metric_tumor: 0.2331 - loss: 0.4802 - mean_iou_all: 0.2631 - precision_tumor: 0.1882 - recall_tumor: 0.4609 - tumor_iou: 0.1437 - val_acc: 0.8591 - val_dice_coef_metric_tumor: 0.1425 - val_loss: 0.5731 - val_mean_iou_all: 0.2522 - val_precision_tumor: 0.0839 - val_recall_tumor: 0.7648 - val_tumor_iou: 0.0808 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 17 lên WandB.\n\n--- Epoch 18/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9470 - dice_coef_metric_tumor: 0.2253 - loss: 0.4851 - mean_iou_all: 0.2614 - precision_tumor: 0.1832 - recall_tumor: 0.4754 - tumor_iou: 0.1383","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.18269 to 0.18788, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9470 - dice_coef_metric_tumor: 0.2253 - loss: 0.4850 - mean_iou_all: 0.2615 - precision_tumor: 0.1831 - recall_tumor: 0.4753 - tumor_iou: 0.1383 - val_acc: 0.9416 - val_dice_coef_metric_tumor: 0.1879 - val_loss: 0.5198 - val_mean_iou_all: 0.2595 - val_precision_tumor: 0.1410 - val_recall_tumor: 0.4566 - val_tumor_iou: 0.1128 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 18 lên WandB.\n\n--- Epoch 19/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9535 - dice_coef_metric_tumor: 0.2344 - loss: 0.4786 - mean_iou_all: 0.2698 - precision_tumor: 0.1892 - recall_tumor: 0.4514 - tumor_iou: 0.1432","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18788\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9535 - dice_coef_metric_tumor: 0.2343 - loss: 0.4785 - mean_iou_all: 0.2698 - precision_tumor: 0.1892 - recall_tumor: 0.4514 - tumor_iou: 0.1432 - val_acc: 0.9170 - val_dice_coef_metric_tumor: 0.1835 - val_loss: 0.5324 - val_mean_iou_all: 0.2548 - val_precision_tumor: 0.1202 - val_recall_tumor: 0.6211 - val_tumor_iou: 0.1084 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 19 lên WandB.\n\n--- Epoch 20/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9585 - dice_coef_metric_tumor: 0.2460 - loss: 0.4680 - mean_iou_all: 0.2625 - precision_tumor: 0.2059 - recall_tumor: 0.4261 - tumor_iou: 0.1535","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18788\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9585 - dice_coef_metric_tumor: 0.2459 - loss: 0.4680 - mean_iou_all: 0.2625 - precision_tumor: 0.2059 - recall_tumor: 0.4260 - tumor_iou: 0.1535 - val_acc: 0.9068 - val_dice_coef_metric_tumor: 0.1803 - val_loss: 0.5341 - val_mean_iou_all: 0.2575 - val_precision_tumor: 0.1160 - val_recall_tumor: 0.6950 - val_tumor_iou: 0.1062 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 20 lên WandB.\n\n--- Epoch 21/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9602 - dice_coef_metric_tumor: 0.2500 - loss: 0.4636 - mean_iou_all: 0.2641 - precision_tumor: 0.2129 - recall_tumor: 0.4188 - tumor_iou: 0.1565","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18788\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9602 - dice_coef_metric_tumor: 0.2499 - loss: 0.4636 - mean_iou_all: 0.2642 - precision_tumor: 0.2128 - recall_tumor: 0.4188 - tumor_iou: 0.1564 - val_acc: 0.9547 - val_dice_coef_metric_tumor: 0.1789 - val_loss: 0.5236 - val_mean_iou_all: 0.2505 - val_precision_tumor: 0.1568 - val_recall_tumor: 0.3577 - val_tumor_iou: 0.1067 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 21 lên WandB.\n\n--- Epoch 22/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9560 - dice_coef_metric_tumor: 0.2344 - loss: 0.4737 - mean_iou_all: 0.2624 - precision_tumor: 0.1972 - recall_tumor: 0.4245 - tumor_iou: 0.1450","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.18788 to 0.19313, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9560 - dice_coef_metric_tumor: 0.2344 - loss: 0.4737 - mean_iou_all: 0.2625 - precision_tumor: 0.1972 - recall_tumor: 0.4246 - tumor_iou: 0.1450 - val_acc: 0.9661 - val_dice_coef_metric_tumor: 0.1931 - val_loss: 0.5138 - val_mean_iou_all: 0.2537 - val_precision_tumor: 0.1948 - val_recall_tumor: 0.2896 - val_tumor_iou: 0.1184 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 22 lên WandB.\n\n--- Epoch 23/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9577 - dice_coef_metric_tumor: 0.2538 - loss: 0.4669 - mean_iou_all: 0.2638 - precision_tumor: 0.2188 - recall_tumor: 0.4349 - tumor_iou: 0.1581","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.19313 to 0.19391, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9577 - dice_coef_metric_tumor: 0.2537 - loss: 0.4669 - mean_iou_all: 0.2638 - precision_tumor: 0.2187 - recall_tumor: 0.4349 - tumor_iou: 0.1581 - val_acc: 0.9178 - val_dice_coef_metric_tumor: 0.1939 - val_loss: 0.5249 - val_mean_iou_all: 0.2592 - val_precision_tumor: 0.1274 - val_recall_tumor: 0.6719 - val_tumor_iou: 0.1152 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 23 lên WandB.\n\n--- Epoch 24/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9585 - dice_coef_metric_tumor: 0.2437 - loss: 0.4688 - mean_iou_all: 0.2617 - precision_tumor: 0.2024 - recall_tumor: 0.4324 - tumor_iou: 0.1507","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.19391 to 0.21042, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9585 - dice_coef_metric_tumor: 0.2437 - loss: 0.4688 - mean_iou_all: 0.2617 - precision_tumor: 0.2024 - recall_tumor: 0.4323 - tumor_iou: 0.1507 - val_acc: 0.9690 - val_dice_coef_metric_tumor: 0.2104 - val_loss: 0.5034 - val_mean_iou_all: 0.2653 - val_precision_tumor: 0.2034 - val_recall_tumor: 0.3142 - val_tumor_iou: 0.1275 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 24 lên WandB.\n\n--- Epoch 25/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9597 - dice_coef_metric_tumor: 0.2636 - loss: 0.4577 - mean_iou_all: 0.2660 - precision_tumor: 0.2264 - recall_tumor: 0.4583 - tumor_iou: 0.1650","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.21042\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9597 - dice_coef_metric_tumor: 0.2636 - loss: 0.4577 - mean_iou_all: 0.2661 - precision_tumor: 0.2264 - recall_tumor: 0.4583 - tumor_iou: 0.1650 - val_acc: 0.9743 - val_dice_coef_metric_tumor: 0.1772 - val_loss: 0.5229 - val_mean_iou_all: 0.2626 - val_precision_tumor: 0.2182 - val_recall_tumor: 0.2078 - val_tumor_iou: 0.1063 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 25 lên WandB.\n\n--- Epoch 26/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9631 - dice_coef_metric_tumor: 0.2702 - loss: 0.4468 - mean_iou_all: 0.2672 - precision_tumor: 0.2312 - recall_tumor: 0.4390 - tumor_iou: 0.1697","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.21042 to 0.22875, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9631 - dice_coef_metric_tumor: 0.2701 - loss: 0.4468 - mean_iou_all: 0.2673 - precision_tumor: 0.2312 - recall_tumor: 0.4390 - tumor_iou: 0.1697 - val_acc: 0.9650 - val_dice_coef_metric_tumor: 0.2287 - val_loss: 0.4930 - val_mean_iou_all: 0.2527 - val_precision_tumor: 0.2114 - val_recall_tumor: 0.3758 - val_tumor_iou: 0.1425 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 26 lên WandB.\n\n--- Epoch 27/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9601 - dice_coef_metric_tumor: 0.2683 - loss: 0.4523 - mean_iou_all: 0.2631 - precision_tumor: 0.2260 - recall_tumor: 0.4588 - tumor_iou: 0.1680","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.22875\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9601 - dice_coef_metric_tumor: 0.2683 - loss: 0.4522 - mean_iou_all: 0.2631 - precision_tumor: 0.2260 - recall_tumor: 0.4588 - tumor_iou: 0.1680 - val_acc: 0.9758 - val_dice_coef_metric_tumor: 0.2198 - val_loss: 0.4975 - val_mean_iou_all: 0.2570 - val_precision_tumor: 0.2615 - val_recall_tumor: 0.2584 - val_tumor_iou: 0.1384 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 27 lên WandB.\n\n--- Epoch 28/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9613 - dice_coef_metric_tumor: 0.2709 - loss: 0.4587 - mean_iou_all: 0.2712 - precision_tumor: 0.2355 - recall_tumor: 0.4517 - tumor_iou: 0.1707","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.22875\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9613 - dice_coef_metric_tumor: 0.2709 - loss: 0.4587 - mean_iou_all: 0.2713 - precision_tumor: 0.2355 - recall_tumor: 0.4517 - tumor_iou: 0.1707 - val_acc: 0.9686 - val_dice_coef_metric_tumor: 0.1863 - val_loss: 0.5187 - val_mean_iou_all: 0.2659 - val_precision_tumor: 0.2057 - val_recall_tumor: 0.2497 - val_tumor_iou: 0.1137 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 28 lên WandB.\n\n--- Epoch 29/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9648 - dice_coef_metric_tumor: 0.2748 - loss: 0.4544 - mean_iou_all: 0.2704 - precision_tumor: 0.2462 - recall_tumor: 0.4249 - tumor_iou: 0.1753","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.22875\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9648 - dice_coef_metric_tumor: 0.2747 - loss: 0.4544 - mean_iou_all: 0.2705 - precision_tumor: 0.2461 - recall_tumor: 0.4249 - tumor_iou: 0.1753 - val_acc: 0.9741 - val_dice_coef_metric_tumor: 0.2119 - val_loss: 0.5023 - val_mean_iou_all: 0.2519 - val_precision_tumor: 0.2408 - val_recall_tumor: 0.2553 - val_tumor_iou: 0.1323 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 29 lên WandB.\n\n--- Epoch 30/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9682 - dice_coef_metric_tumor: 0.2987 - loss: 0.4346 - mean_iou_all: 0.2640 - precision_tumor: 0.2706 - recall_tumor: 0.4474 - tumor_iou: 0.1938","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.22875 to 0.24763, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9682 - dice_coef_metric_tumor: 0.2986 - loss: 0.4346 - mean_iou_all: 0.2640 - precision_tumor: 0.2706 - recall_tumor: 0.4474 - tumor_iou: 0.1938 - val_acc: 0.9557 - val_dice_coef_metric_tumor: 0.2476 - val_loss: 0.4870 - val_mean_iou_all: 0.2577 - val_precision_tumor: 0.2027 - val_recall_tumor: 0.4908 - val_tumor_iou: 0.1551 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 30 lên WandB.\n\n--- Epoch 31/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9684 - dice_coef_metric_tumor: 0.3147 - loss: 0.4198 - mean_iou_all: 0.2660 - precision_tumor: 0.2817 - recall_tumor: 0.4644 - tumor_iou: 0.2059","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.24763\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9684 - dice_coef_metric_tumor: 0.3147 - loss: 0.4198 - mean_iou_all: 0.2660 - precision_tumor: 0.2816 - recall_tumor: 0.4644 - tumor_iou: 0.2059 - val_acc: 0.9367 - val_dice_coef_metric_tumor: 0.2182 - val_loss: 0.5102 - val_mean_iou_all: 0.2585 - val_precision_tumor: 0.1553 - val_recall_tumor: 0.5879 - val_tumor_iou: 0.1332 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 31 lên WandB.\n\n--- Epoch 32/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9698 - dice_coef_metric_tumor: 0.3180 - loss: 0.4272 - mean_iou_all: 0.2697 - precision_tumor: 0.3003 - recall_tumor: 0.4387 - tumor_iou: 0.2095","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.24763\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 466ms/step - acc: 0.9698 - dice_coef_metric_tumor: 0.3180 - loss: 0.4272 - mean_iou_all: 0.2698 - precision_tumor: 0.3002 - recall_tumor: 0.4387 - tumor_iou: 0.2094 - val_acc: 0.9824 - val_dice_coef_metric_tumor: 0.1538 - val_loss: 0.5371 - val_mean_iou_all: 0.2679 - val_precision_tumor: 0.3740 - val_recall_tumor: 0.1139 - val_tumor_iou: 0.0919 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 32 lên WandB.\n\n--- Epoch 33/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9701 - dice_coef_metric_tumor: 0.3124 - loss: 0.4326 - mean_iou_all: 0.2684 - precision_tumor: 0.2958 - recall_tumor: 0.4310 - tumor_iou: 0.2025","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.24763\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9701 - dice_coef_metric_tumor: 0.3124 - loss: 0.4326 - mean_iou_all: 0.2684 - precision_tumor: 0.2957 - recall_tumor: 0.4310 - tumor_iou: 0.2024 - val_acc: 0.9720 - val_dice_coef_metric_tumor: 0.2452 - val_loss: 0.4838 - val_mean_iou_all: 0.2575 - val_precision_tumor: 0.2595 - val_recall_tumor: 0.3394 - val_tumor_iou: 0.1561 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 33 lên WandB.\n\n--- Epoch 34/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9717 - dice_coef_metric_tumor: 0.3281 - loss: 0.4137 - mean_iou_all: 0.2649 - precision_tumor: 0.3045 - recall_tumor: 0.4526 - tumor_iou: 0.2172","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.24763 to 0.25158, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9717 - dice_coef_metric_tumor: 0.3281 - loss: 0.4137 - mean_iou_all: 0.2650 - precision_tumor: 0.3045 - recall_tumor: 0.4526 - tumor_iou: 0.2172 - val_acc: 0.9632 - val_dice_coef_metric_tumor: 0.2516 - val_loss: 0.4847 - val_mean_iou_all: 0.2575 - val_precision_tumor: 0.2314 - val_recall_tumor: 0.4200 - val_tumor_iou: 0.1599 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 34 lên WandB.\n\n--- Epoch 35/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9716 - dice_coef_metric_tumor: 0.3297 - loss: 0.4114 - mean_iou_all: 0.2650 - precision_tumor: 0.3030 - recall_tumor: 0.4625 - tumor_iou: 0.2178","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.25158\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9716 - dice_coef_metric_tumor: 0.3297 - loss: 0.4115 - mean_iou_all: 0.2651 - precision_tumor: 0.3029 - recall_tumor: 0.4625 - tumor_iou: 0.2177 - val_acc: 0.9770 - val_dice_coef_metric_tumor: 0.2353 - val_loss: 0.4886 - val_mean_iou_all: 0.2685 - val_precision_tumor: 0.3091 - val_recall_tumor: 0.2633 - val_tumor_iou: 0.1496 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 35 lên WandB.\n\n--- Epoch 36/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9696 - dice_coef_metric_tumor: 0.3378 - loss: 0.4180 - mean_iou_all: 0.2691 - precision_tumor: 0.3059 - recall_tumor: 0.4886 - tumor_iou: 0.2257","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.25158\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9696 - dice_coef_metric_tumor: 0.3377 - loss: 0.4180 - mean_iou_all: 0.2691 - precision_tumor: 0.3058 - recall_tumor: 0.4885 - tumor_iou: 0.2257 - val_acc: 0.9833 - val_dice_coef_metric_tumor: 0.1265 - val_loss: 0.5542 - val_mean_iou_all: 0.2618 - val_precision_tumor: 0.3350 - val_recall_tumor: 0.0904 - val_tumor_iou: 0.0757 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 36 lên WandB.\n\n--- Epoch 37/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9690 - dice_coef_metric_tumor: 0.3167 - loss: 0.4280 - mean_iou_all: 0.2650 - precision_tumor: 0.2846 - recall_tumor: 0.4671 - tumor_iou: 0.2076","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.25158 to 0.25824, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 472ms/step - acc: 0.9690 - dice_coef_metric_tumor: 0.3167 - loss: 0.4280 - mean_iou_all: 0.2651 - precision_tumor: 0.2845 - recall_tumor: 0.4671 - tumor_iou: 0.2076 - val_acc: 0.9555 - val_dice_coef_metric_tumor: 0.2582 - val_loss: 0.4805 - val_mean_iou_all: 0.2527 - val_precision_tumor: 0.2118 - val_recall_tumor: 0.5227 - val_tumor_iou: 0.1619 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 37 lên WandB.\n\n--- Epoch 38/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9713 - dice_coef_metric_tumor: 0.3299 - loss: 0.4069 - mean_iou_all: 0.2623 - precision_tumor: 0.3024 - recall_tumor: 0.4604 - tumor_iou: 0.2182","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.25824 to 0.30147, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9713 - dice_coef_metric_tumor: 0.3298 - loss: 0.4069 - mean_iou_all: 0.2623 - precision_tumor: 0.3024 - recall_tumor: 0.4604 - tumor_iou: 0.2182 - val_acc: 0.9776 - val_dice_coef_metric_tumor: 0.3015 - val_loss: 0.4491 - val_mean_iou_all: 0.2539 - val_precision_tumor: 0.3278 - val_recall_tumor: 0.3712 - val_tumor_iou: 0.1969 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 38 lên WandB.\n\n--- Epoch 39/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9705 - dice_coef_metric_tumor: 0.3353 - loss: 0.4033 - mean_iou_all: 0.2699 - precision_tumor: 0.3075 - recall_tumor: 0.4846 - tumor_iou: 0.2211","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.30147\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9705 - dice_coef_metric_tumor: 0.3353 - loss: 0.4033 - mean_iou_all: 0.2700 - precision_tumor: 0.3075 - recall_tumor: 0.4846 - tumor_iou: 0.2211 - val_acc: 0.9754 - val_dice_coef_metric_tumor: 0.2714 - val_loss: 0.4678 - val_mean_iou_all: 0.2633 - val_precision_tumor: 0.3024 - val_recall_tumor: 0.3429 - val_tumor_iou: 0.1756 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 39 lên WandB.\n\n--- Epoch 40/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9729 - dice_coef_metric_tumor: 0.3535 - loss: 0.4021 - mean_iou_all: 0.2739 - precision_tumor: 0.3285 - recall_tumor: 0.4938 - tumor_iou: 0.2360","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.30147 to 0.31993, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 472ms/step - acc: 0.9729 - dice_coef_metric_tumor: 0.3535 - loss: 0.4021 - mean_iou_all: 0.2740 - precision_tumor: 0.3284 - recall_tumor: 0.4937 - tumor_iou: 0.2360 - val_acc: 0.9714 - val_dice_coef_metric_tumor: 0.3199 - val_loss: 0.4395 - val_mean_iou_all: 0.2677 - val_precision_tumor: 0.2962 - val_recall_tumor: 0.4756 - val_tumor_iou: 0.2080 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 40 lên WandB.\n\n--- Epoch 41/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9742 - dice_coef_metric_tumor: 0.3606 - loss: 0.3964 - mean_iou_all: 0.2703 - precision_tumor: 0.3491 - recall_tumor: 0.4723 - tumor_iou: 0.2432","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31993\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9742 - dice_coef_metric_tumor: 0.3605 - loss: 0.3964 - mean_iou_all: 0.2703 - precision_tumor: 0.3489 - recall_tumor: 0.4723 - tumor_iou: 0.2431 - val_acc: 0.9791 - val_dice_coef_metric_tumor: 0.2703 - val_loss: 0.4671 - val_mean_iou_all: 0.2655 - val_precision_tumor: 0.3307 - val_recall_tumor: 0.2954 - val_tumor_iou: 0.1761 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 41 lên WandB.\n\n--- Epoch 42/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9742 - dice_coef_metric_tumor: 0.3674 - loss: 0.3920 - mean_iou_all: 0.2710 - precision_tumor: 0.3536 - recall_tumor: 0.4964 - tumor_iou: 0.2489","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31993\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9742 - dice_coef_metric_tumor: 0.3673 - loss: 0.3920 - mean_iou_all: 0.2710 - precision_tumor: 0.3535 - recall_tumor: 0.4964 - tumor_iou: 0.2488 - val_acc: 0.9694 - val_dice_coef_metric_tumor: 0.3034 - val_loss: 0.4500 - val_mean_iou_all: 0.2605 - val_precision_tumor: 0.2788 - val_recall_tumor: 0.4709 - val_tumor_iou: 0.1972 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 42 lên WandB.\n\n--- Epoch 43/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9734 - dice_coef_metric_tumor: 0.3566 - loss: 0.3954 - mean_iou_all: 0.2771 - precision_tumor: 0.3293 - recall_tumor: 0.4858 - tumor_iou: 0.2400","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31993\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9734 - dice_coef_metric_tumor: 0.3565 - loss: 0.3954 - mean_iou_all: 0.2772 - precision_tumor: 0.3292 - recall_tumor: 0.4858 - tumor_iou: 0.2400 - val_acc: 0.9770 - val_dice_coef_metric_tumor: 0.3008 - val_loss: 0.4494 - val_mean_iou_all: 0.2624 - val_precision_tumor: 0.3219 - val_recall_tumor: 0.3638 - val_tumor_iou: 0.1948 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 43 lên WandB.\n\n--- Epoch 44/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9717 - dice_coef_metric_tumor: 0.3572 - loss: 0.3948 - mean_iou_all: 0.2793 - precision_tumor: 0.3320 - recall_tumor: 0.5167 - tumor_iou: 0.2399","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31993\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9717 - dice_coef_metric_tumor: 0.3571 - loss: 0.3948 - mean_iou_all: 0.2794 - precision_tumor: 0.3319 - recall_tumor: 0.5167 - tumor_iou: 0.2398 - val_acc: 0.9634 - val_dice_coef_metric_tumor: 0.2898 - val_loss: 0.4594 - val_mean_iou_all: 0.2546 - val_precision_tumor: 0.2395 - val_recall_tumor: 0.5206 - val_tumor_iou: 0.1858 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 44 lên WandB.\n\n--- Epoch 45/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9736 - dice_coef_metric_tumor: 0.3562 - loss: 0.3946 - mean_iou_all: 0.2681 - precision_tumor: 0.3238 - recall_tumor: 0.4974 - tumor_iou: 0.2375","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31993\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9736 - dice_coef_metric_tumor: 0.3561 - loss: 0.3946 - mean_iou_all: 0.2682 - precision_tumor: 0.3237 - recall_tumor: 0.4974 - tumor_iou: 0.2375 - val_acc: 0.9793 - val_dice_coef_metric_tumor: 0.2668 - val_loss: 0.4703 - val_mean_iou_all: 0.2627 - val_precision_tumor: 0.3604 - val_recall_tumor: 0.2837 - val_tumor_iou: 0.1740 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 45 lên WandB.\n\n--- Epoch 46/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9739 - dice_coef_metric_tumor: 0.3564 - loss: 0.3916 - mean_iou_all: 0.2773 - precision_tumor: 0.3412 - recall_tumor: 0.4938 - tumor_iou: 0.2402","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31993\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9739 - dice_coef_metric_tumor: 0.3564 - loss: 0.3916 - mean_iou_all: 0.2774 - precision_tumor: 0.3411 - recall_tumor: 0.4938 - tumor_iou: 0.2402 - val_acc: 0.9830 - val_dice_coef_metric_tumor: 0.2934 - val_loss: 0.4529 - val_mean_iou_all: 0.2672 - val_precision_tumor: 0.4058 - val_recall_tumor: 0.2814 - val_tumor_iou: 0.1942 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 46 lên WandB.\n\n--- Epoch 47/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9736 - dice_coef_metric_tumor: 0.3726 - loss: 0.3882 - mean_iou_all: 0.2738 - precision_tumor: 0.3493 - recall_tumor: 0.5148 - tumor_iou: 0.2525","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31993\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9736 - dice_coef_metric_tumor: 0.3725 - loss: 0.3882 - mean_iou_all: 0.2739 - precision_tumor: 0.3492 - recall_tumor: 0.5147 - tumor_iou: 0.2524 - val_acc: 0.9742 - val_dice_coef_metric_tumor: 0.2931 - val_loss: 0.4557 - val_mean_iou_all: 0.2597 - val_precision_tumor: 0.2961 - val_recall_tumor: 0.3991 - val_tumor_iou: 0.1905 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 47 lên WandB.\n\n--- Epoch 48/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9745 - dice_coef_metric_tumor: 0.3704 - loss: 0.3818 - mean_iou_all: 0.2781 - precision_tumor: 0.3503 - recall_tumor: 0.5054 - tumor_iou: 0.2515","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.31993 to 0.32936, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9745 - dice_coef_metric_tumor: 0.3704 - loss: 0.3818 - mean_iou_all: 0.2782 - precision_tumor: 0.3503 - recall_tumor: 0.5054 - tumor_iou: 0.2514 - val_acc: 0.9767 - val_dice_coef_metric_tumor: 0.3294 - val_loss: 0.4332 - val_mean_iou_all: 0.2701 - val_precision_tumor: 0.3463 - val_recall_tumor: 0.4121 - val_tumor_iou: 0.2171 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 48 lên WandB.\n\n--- Epoch 49/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9748 - dice_coef_metric_tumor: 0.3698 - loss: 0.3841 - mean_iou_all: 0.2817 - precision_tumor: 0.3481 - recall_tumor: 0.4969 - tumor_iou: 0.2522","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.32936\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 465ms/step - acc: 0.9748 - dice_coef_metric_tumor: 0.3698 - loss: 0.3841 - mean_iou_all: 0.2817 - precision_tumor: 0.3480 - recall_tumor: 0.4969 - tumor_iou: 0.2521 - val_acc: 0.9787 - val_dice_coef_metric_tumor: 0.3126 - val_loss: 0.4420 - val_mean_iou_all: 0.2645 - val_precision_tumor: 0.3714 - val_recall_tumor: 0.3715 - val_tumor_iou: 0.2058 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 49 lên WandB.\n\n--- Epoch 50/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9762 - dice_coef_metric_tumor: 0.3969 - loss: 0.3789 - mean_iou_all: 0.2850 - precision_tumor: 0.3911 - recall_tumor: 0.5072 - tumor_iou: 0.2710","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.32936\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9762 - dice_coef_metric_tumor: 0.3968 - loss: 0.3789 - mean_iou_all: 0.2851 - precision_tumor: 0.3910 - recall_tumor: 0.5072 - tumor_iou: 0.2709 - val_acc: 0.9683 - val_dice_coef_metric_tumor: 0.3126 - val_loss: 0.4457 - val_mean_iou_all: 0.2595 - val_precision_tumor: 0.2696 - val_recall_tumor: 0.5069 - val_tumor_iou: 0.2026 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 50 lên WandB.\n\n--- Epoch 51/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9742 - dice_coef_metric_tumor: 0.3743 - loss: 0.3855 - mean_iou_all: 0.2882 - precision_tumor: 0.3550 - recall_tumor: 0.5144 - tumor_iou: 0.2546","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.32936 to 0.32951, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 473ms/step - acc: 0.9742 - dice_coef_metric_tumor: 0.3743 - loss: 0.3855 - mean_iou_all: 0.2883 - precision_tumor: 0.3550 - recall_tumor: 0.5144 - tumor_iou: 0.2545 - val_acc: 0.9737 - val_dice_coef_metric_tumor: 0.3295 - val_loss: 0.4342 - val_mean_iou_all: 0.2552 - val_precision_tumor: 0.3015 - val_recall_tumor: 0.4659 - val_tumor_iou: 0.2179 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 51 lên WandB.\n\n--- Epoch 52/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9755 - dice_coef_metric_tumor: 0.3836 - loss: 0.3757 - mean_iou_all: 0.2969 - precision_tumor: 0.3607 - recall_tumor: 0.5171 - tumor_iou: 0.2633","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.32951\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9755 - dice_coef_metric_tumor: 0.3835 - loss: 0.3757 - mean_iou_all: 0.2970 - precision_tumor: 0.3606 - recall_tumor: 0.5171 - tumor_iou: 0.2633 - val_acc: 0.9729 - val_dice_coef_metric_tumor: 0.3029 - val_loss: 0.4506 - val_mean_iou_all: 0.2570 - val_precision_tumor: 0.2895 - val_recall_tumor: 0.4260 - val_tumor_iou: 0.2003 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 52 lên WandB.\n\n--- Epoch 53/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9756 - dice_coef_metric_tumor: 0.3983 - loss: 0.3707 - mean_iou_all: 0.2995 - precision_tumor: 0.3759 - recall_tumor: 0.5327 - tumor_iou: 0.2734","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.32951\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9756 - dice_coef_metric_tumor: 0.3983 - loss: 0.3707 - mean_iou_all: 0.2997 - precision_tumor: 0.3758 - recall_tumor: 0.5327 - tumor_iou: 0.2734 - val_acc: 0.9659 - val_dice_coef_metric_tumor: 0.3205 - val_loss: 0.4414 - val_mean_iou_all: 0.2566 - val_precision_tumor: 0.2788 - val_recall_tumor: 0.5511 - val_tumor_iou: 0.2080 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 53 lên WandB.\n\n--- Epoch 54/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9776 - dice_coef_metric_tumor: 0.3992 - loss: 0.3695 - mean_iou_all: 0.2943 - precision_tumor: 0.3865 - recall_tumor: 0.4987 - tumor_iou: 0.2737","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.32951\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9776 - dice_coef_metric_tumor: 0.3992 - loss: 0.3695 - mean_iou_all: 0.2944 - precision_tumor: 0.3864 - recall_tumor: 0.4988 - tumor_iou: 0.2736 - val_acc: 0.9833 - val_dice_coef_metric_tumor: 0.2896 - val_loss: 0.4564 - val_mean_iou_all: 0.2547 - val_precision_tumor: 0.4233 - val_recall_tumor: 0.2818 - val_tumor_iou: 0.1909 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 54 lên WandB.\n\n--- Epoch 55/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9749 - dice_coef_metric_tumor: 0.3857 - loss: 0.3811 - mean_iou_all: 0.2777 - precision_tumor: 0.3611 - recall_tumor: 0.5189 - tumor_iou: 0.2634","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.32951 to 0.33765, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 472ms/step - acc: 0.9749 - dice_coef_metric_tumor: 0.3856 - loss: 0.3811 - mean_iou_all: 0.2778 - precision_tumor: 0.3611 - recall_tumor: 0.5188 - tumor_iou: 0.2634 - val_acc: 0.9776 - val_dice_coef_metric_tumor: 0.3377 - val_loss: 0.4290 - val_mean_iou_all: 0.2581 - val_precision_tumor: 0.3374 - val_recall_tumor: 0.4184 - val_tumor_iou: 0.2286 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 55 lên WandB.\n\n--- Epoch 56/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9766 - dice_coef_metric_tumor: 0.3964 - loss: 0.3710 - mean_iou_all: 0.3072 - precision_tumor: 0.3712 - recall_tumor: 0.5284 - tumor_iou: 0.2719","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.33765\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9766 - dice_coef_metric_tumor: 0.3963 - loss: 0.3710 - mean_iou_all: 0.3073 - precision_tumor: 0.3712 - recall_tumor: 0.5283 - tumor_iou: 0.2719 - val_acc: 0.9699 - val_dice_coef_metric_tumor: 0.2906 - val_loss: 0.4612 - val_mean_iou_all: 0.2680 - val_precision_tumor: 0.2746 - val_recall_tumor: 0.4247 - val_tumor_iou: 0.1899 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 56 lên WandB.\n\n--- Epoch 57/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9736 - dice_coef_metric_tumor: 0.3841 - loss: 0.3863 - mean_iou_all: 0.3306 - precision_tumor: 0.3511 - recall_tumor: 0.5357 - tumor_iou: 0.2610","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.33765 to 0.36216, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9736 - dice_coef_metric_tumor: 0.3841 - loss: 0.3862 - mean_iou_all: 0.3308 - precision_tumor: 0.3511 - recall_tumor: 0.5357 - tumor_iou: 0.2610 - val_acc: 0.9785 - val_dice_coef_metric_tumor: 0.3622 - val_loss: 0.4139 - val_mean_iou_all: 0.2585 - val_precision_tumor: 0.3700 - val_recall_tumor: 0.4490 - val_tumor_iou: 0.2444 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 57 lên WandB.\n\n--- Epoch 58/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9771 - dice_coef_metric_tumor: 0.4042 - loss: 0.3692 - mean_iou_all: 0.3253 - precision_tumor: 0.3881 - recall_tumor: 0.5392 - tumor_iou: 0.2786","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.36216\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9771 - dice_coef_metric_tumor: 0.4041 - loss: 0.3692 - mean_iou_all: 0.3255 - precision_tumor: 0.3881 - recall_tumor: 0.5392 - tumor_iou: 0.2786 - val_acc: 0.9775 - val_dice_coef_metric_tumor: 0.3441 - val_loss: 0.4259 - val_mean_iou_all: 0.2580 - val_precision_tumor: 0.3551 - val_recall_tumor: 0.4316 - val_tumor_iou: 0.2320 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 58 lên WandB.\n\n--- Epoch 59/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9768 - dice_coef_metric_tumor: 0.3871 - loss: 0.3762 - mean_iou_all: 0.3324 - precision_tumor: 0.3730 - recall_tumor: 0.5097 - tumor_iou: 0.2645","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.36216\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9768 - dice_coef_metric_tumor: 0.3871 - loss: 0.3761 - mean_iou_all: 0.3326 - precision_tumor: 0.3730 - recall_tumor: 0.5097 - tumor_iou: 0.2645 - val_acc: 0.9809 - val_dice_coef_metric_tumor: 0.3615 - val_loss: 0.4142 - val_mean_iou_all: 0.2606 - val_precision_tumor: 0.4092 - val_recall_tumor: 0.4011 - val_tumor_iou: 0.2452 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 59 lên WandB.\n\n--- Epoch 60/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9780 - dice_coef_metric_tumor: 0.4231 - loss: 0.3583 - mean_iou_all: 0.3356 - precision_tumor: 0.4066 - recall_tumor: 0.5353 - tumor_iou: 0.2973","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.36216\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 465ms/step - acc: 0.9780 - dice_coef_metric_tumor: 0.4230 - loss: 0.3583 - mean_iou_all: 0.3358 - precision_tumor: 0.4065 - recall_tumor: 0.5353 - tumor_iou: 0.2972 - val_acc: 0.9790 - val_dice_coef_metric_tumor: 0.3207 - val_loss: 0.4382 - val_mean_iou_all: 0.2581 - val_precision_tumor: 0.3696 - val_recall_tumor: 0.3808 - val_tumor_iou: 0.2132 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 60 lên WandB.\n\n--- Epoch 61/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9755 - dice_coef_metric_tumor: 0.3771 - loss: 0.3779 - mean_iou_all: 0.3438 - precision_tumor: 0.3637 - recall_tumor: 0.5250 - tumor_iou: 0.2579","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.36216\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 465ms/step - acc: 0.9755 - dice_coef_metric_tumor: 0.3771 - loss: 0.3779 - mean_iou_all: 0.3440 - precision_tumor: 0.3637 - recall_tumor: 0.5251 - tumor_iou: 0.2579 - val_acc: 0.9810 - val_dice_coef_metric_tumor: 0.3250 - val_loss: 0.4348 - val_mean_iou_all: 0.2578 - val_precision_tumor: 0.3689 - val_recall_tumor: 0.3717 - val_tumor_iou: 0.2157 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 61 lên WandB.\n\n--- Epoch 62/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9778 - dice_coef_metric_tumor: 0.4198 - loss: 0.3588 - mean_iou_all: 0.3350 - precision_tumor: 0.3971 - recall_tumor: 0.5331 - tumor_iou: 0.2945","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.36216 to 0.36636, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 472ms/step - acc: 0.9778 - dice_coef_metric_tumor: 0.4197 - loss: 0.3589 - mean_iou_all: 0.3353 - precision_tumor: 0.3970 - recall_tumor: 0.5331 - tumor_iou: 0.2944 - val_acc: 0.9827 - val_dice_coef_metric_tumor: 0.3664 - val_loss: 0.4109 - val_mean_iou_all: 0.2636 - val_precision_tumor: 0.4329 - val_recall_tumor: 0.3923 - val_tumor_iou: 0.2519 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 62 lên WandB.\n\n--- Epoch 63/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9788 - dice_coef_metric_tumor: 0.4074 - loss: 0.3590 - mean_iou_all: 0.3553 - precision_tumor: 0.3935 - recall_tumor: 0.5279 - tumor_iou: 0.2815","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.36636\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9788 - dice_coef_metric_tumor: 0.4074 - loss: 0.3590 - mean_iou_all: 0.3556 - precision_tumor: 0.3935 - recall_tumor: 0.5279 - tumor_iou: 0.2814 - val_acc: 0.9828 - val_dice_coef_metric_tumor: 0.3201 - val_loss: 0.4393 - val_mean_iou_all: 0.2548 - val_precision_tumor: 0.3980 - val_recall_tumor: 0.3320 - val_tumor_iou: 0.2149 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 63 lên WandB.\n\n--- Epoch 64/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9790 - dice_coef_metric_tumor: 0.4211 - loss: 0.3508 - mean_iou_all: 0.3661 - precision_tumor: 0.4220 - recall_tumor: 0.5363 - tumor_iou: 0.2952","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.36636\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9790 - dice_coef_metric_tumor: 0.4210 - loss: 0.3509 - mean_iou_all: 0.3664 - precision_tumor: 0.4219 - recall_tumor: 0.5363 - tumor_iou: 0.2952 - val_acc: 0.9805 - val_dice_coef_metric_tumor: 0.3332 - val_loss: 0.4315 - val_mean_iou_all: 0.2612 - val_precision_tumor: 0.4111 - val_recall_tumor: 0.3676 - val_tumor_iou: 0.2237 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 64 lên WandB.\n\n--- Epoch 65/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9784 - dice_coef_metric_tumor: 0.4256 - loss: 0.3529 - mean_iou_all: 0.3485 - precision_tumor: 0.4228 - recall_tumor: 0.5421 - tumor_iou: 0.2992","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.36636\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 465ms/step - acc: 0.9784 - dice_coef_metric_tumor: 0.4255 - loss: 0.3529 - mean_iou_all: 0.3487 - precision_tumor: 0.4227 - recall_tumor: 0.5420 - tumor_iou: 0.2992 - val_acc: 0.9729 - val_dice_coef_metric_tumor: 0.2945 - val_loss: 0.4575 - val_mean_iou_all: 0.2606 - val_precision_tumor: 0.2889 - val_recall_tumor: 0.3951 - val_tumor_iou: 0.1939 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 65 lên WandB.\n\n--- Epoch 66/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9781 - dice_coef_metric_tumor: 0.4245 - loss: 0.3499 - mean_iou_all: 0.3484 - precision_tumor: 0.4046 - recall_tumor: 0.5515 - tumor_iou: 0.2981","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.36636\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 465ms/step - acc: 0.9781 - dice_coef_metric_tumor: 0.4244 - loss: 0.3499 - mean_iou_all: 0.3486 - precision_tumor: 0.4046 - recall_tumor: 0.5515 - tumor_iou: 0.2981 - val_acc: 0.9807 - val_dice_coef_metric_tumor: 0.3539 - val_loss: 0.4186 - val_mean_iou_all: 0.2639 - val_precision_tumor: 0.3991 - val_recall_tumor: 0.4067 - val_tumor_iou: 0.2394 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 66 lên WandB.\n\n--- Epoch 67/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9789 - dice_coef_metric_tumor: 0.4365 - loss: 0.3480 - mean_iou_all: 0.3693 - precision_tumor: 0.4206 - recall_tumor: 0.5522 - tumor_iou: 0.3073","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.36636\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9789 - dice_coef_metric_tumor: 0.4364 - loss: 0.3480 - mean_iou_all: 0.3696 - precision_tumor: 0.4206 - recall_tumor: 0.5522 - tumor_iou: 0.3072 - val_acc: 0.9751 - val_dice_coef_metric_tumor: 0.3515 - val_loss: 0.4232 - val_mean_iou_all: 0.2529 - val_precision_tumor: 0.3109 - val_recall_tumor: 0.5048 - val_tumor_iou: 0.2333 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 67 lên WandB.\n\n--- Epoch 68/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9793 - dice_coef_metric_tumor: 0.4220 - loss: 0.3562 - mean_iou_all: 0.3643 - precision_tumor: 0.4131 - recall_tumor: 0.5318 - tumor_iou: 0.2941","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.36636 to 0.40513, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 472ms/step - acc: 0.9793 - dice_coef_metric_tumor: 0.4220 - loss: 0.3562 - mean_iou_all: 0.3646 - precision_tumor: 0.4130 - recall_tumor: 0.5318 - tumor_iou: 0.2941 - val_acc: 0.9801 - val_dice_coef_metric_tumor: 0.4051 - val_loss: 0.3883 - val_mean_iou_all: 0.2628 - val_precision_tumor: 0.4383 - val_recall_tumor: 0.4940 - val_tumor_iou: 0.2793 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 68 lên WandB.\n\n--- Epoch 69/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9788 - dice_coef_metric_tumor: 0.4335 - loss: 0.3530 - mean_iou_all: 0.3775 - precision_tumor: 0.4161 - recall_tumor: 0.5475 - tumor_iou: 0.3056","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.40513\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 465ms/step - acc: 0.9788 - dice_coef_metric_tumor: 0.4334 - loss: 0.3530 - mean_iou_all: 0.3777 - precision_tumor: 0.4160 - recall_tumor: 0.5475 - tumor_iou: 0.3055 - val_acc: 0.9837 - val_dice_coef_metric_tumor: 0.3787 - val_loss: 0.4043 - val_mean_iou_all: 0.3714 - val_precision_tumor: 0.4730 - val_recall_tumor: 0.3691 - val_tumor_iou: 0.2623 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 69 lên WandB.\n\n--- Epoch 70/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9793 - dice_coef_metric_tumor: 0.4332 - loss: 0.3496 - mean_iou_all: 0.3809 - precision_tumor: 0.4209 - recall_tumor: 0.5517 - tumor_iou: 0.3037","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.40513\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 465ms/step - acc: 0.9793 - dice_coef_metric_tumor: 0.4331 - loss: 0.3496 - mean_iou_all: 0.3812 - precision_tumor: 0.4208 - recall_tumor: 0.5517 - tumor_iou: 0.3036 - val_acc: 0.9811 - val_dice_coef_metric_tumor: 0.3971 - val_loss: 0.3932 - val_mean_iou_all: 0.2780 - val_precision_tumor: 0.4311 - val_recall_tumor: 0.4583 - val_tumor_iou: 0.2742 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 70 lên WandB.\n\n--- Epoch 71/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4264 - loss: 0.3530 - mean_iou_all: 0.3507 - precision_tumor: 0.4164 - recall_tumor: 0.5266 - tumor_iou: 0.2983","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.40513 to 0.41399, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 471ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4264 - loss: 0.3530 - mean_iou_all: 0.3510 - precision_tumor: 0.4163 - recall_tumor: 0.5266 - tumor_iou: 0.2983 - val_acc: 0.9810 - val_dice_coef_metric_tumor: 0.4140 - val_loss: 0.3836 - val_mean_iou_all: 0.2834 - val_precision_tumor: 0.4240 - val_recall_tumor: 0.4828 - val_tumor_iou: 0.2895 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 71 lên WandB.\n\n--- Epoch 72/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9793 - dice_coef_metric_tumor: 0.4310 - loss: 0.3498 - mean_iou_all: 0.3985 - precision_tumor: 0.4110 - recall_tumor: 0.5453 - tumor_iou: 0.3016","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41399\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9793 - dice_coef_metric_tumor: 0.4310 - loss: 0.3498 - mean_iou_all: 0.3988 - precision_tumor: 0.4110 - recall_tumor: 0.5453 - tumor_iou: 0.3015 - val_acc: 0.9736 - val_dice_coef_metric_tumor: 0.3638 - val_loss: 0.4165 - val_mean_iou_all: 0.2661 - val_precision_tumor: 0.3662 - val_recall_tumor: 0.4973 - val_tumor_iou: 0.2471 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 72 lên WandB.\n\n--- Epoch 73/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9770 - dice_coef_metric_tumor: 0.4249 - loss: 0.3617 - mean_iou_all: 0.4218 - precision_tumor: 0.3969 - recall_tumor: 0.5679 - tumor_iou: 0.2939","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41399\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9770 - dice_coef_metric_tumor: 0.4249 - loss: 0.3617 - mean_iou_all: 0.4221 - precision_tumor: 0.3969 - recall_tumor: 0.5679 - tumor_iou: 0.2939 - val_acc: 0.9813 - val_dice_coef_metric_tumor: 0.3860 - val_loss: 0.4005 - val_mean_iou_all: 0.2818 - val_precision_tumor: 0.4217 - val_recall_tumor: 0.4384 - val_tumor_iou: 0.2659 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 73 lên WandB.\n\n--- Epoch 74/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9810 - dice_coef_metric_tumor: 0.4562 - loss: 0.3348 - mean_iou_all: 0.3996 - precision_tumor: 0.4395 - recall_tumor: 0.5632 - tumor_iou: 0.3245","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41399\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9810 - dice_coef_metric_tumor: 0.4561 - loss: 0.3348 - mean_iou_all: 0.3998 - precision_tumor: 0.4395 - recall_tumor: 0.5631 - tumor_iou: 0.3244 - val_acc: 0.9829 - val_dice_coef_metric_tumor: 0.4090 - val_loss: 0.3867 - val_mean_iou_all: 0.2633 - val_precision_tumor: 0.4491 - val_recall_tumor: 0.4434 - val_tumor_iou: 0.2871 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 74 lên WandB.\n\n--- Epoch 75/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9803 - dice_coef_metric_tumor: 0.4522 - loss: 0.3397 - mean_iou_all: 0.4085 - precision_tumor: 0.4384 - recall_tumor: 0.5609 - tumor_iou: 0.3192","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41399\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9803 - dice_coef_metric_tumor: 0.4522 - loss: 0.3397 - mean_iou_all: 0.4087 - precision_tumor: 0.4384 - recall_tumor: 0.5609 - tumor_iou: 0.3192 - val_acc: 0.9846 - val_dice_coef_metric_tumor: 0.3937 - val_loss: 0.3956 - val_mean_iou_all: 0.2621 - val_precision_tumor: 0.4657 - val_recall_tumor: 0.4009 - val_tumor_iou: 0.2743 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 75 lên WandB.\n\n--- Epoch 76/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9805 - dice_coef_metric_tumor: 0.4506 - loss: 0.3353 - mean_iou_all: 0.3998 - precision_tumor: 0.4257 - recall_tumor: 0.5655 - tumor_iou: 0.3190","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41399\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9805 - dice_coef_metric_tumor: 0.4505 - loss: 0.3353 - mean_iou_all: 0.4001 - precision_tumor: 0.4257 - recall_tumor: 0.5654 - tumor_iou: 0.3189 - val_acc: 0.9757 - val_dice_coef_metric_tumor: 0.3979 - val_loss: 0.3966 - val_mean_iou_all: 0.3270 - val_precision_tumor: 0.3681 - val_recall_tumor: 0.5383 - val_tumor_iou: 0.2758 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 76 lên WandB.\n\n--- Epoch 77/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9800 - dice_coef_metric_tumor: 0.4456 - loss: 0.3419 - mean_iou_all: 0.4355 - precision_tumor: 0.4369 - recall_tumor: 0.5585 - tumor_iou: 0.3154","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41399\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9800 - dice_coef_metric_tumor: 0.4456 - loss: 0.3419 - mean_iou_all: 0.4357 - precision_tumor: 0.4369 - recall_tumor: 0.5585 - tumor_iou: 0.3153 - val_acc: 0.9740 - val_dice_coef_metric_tumor: 0.3965 - val_loss: 0.3970 - val_mean_iou_all: 0.2784 - val_precision_tumor: 0.3444 - val_recall_tumor: 0.6094 - val_tumor_iou: 0.2703 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 77 lên WandB.\n\n--- Epoch 78/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9814 - dice_coef_metric_tumor: 0.4709 - loss: 0.3231 - mean_iou_all: 0.4046 - precision_tumor: 0.4549 - recall_tumor: 0.5898 - tumor_iou: 0.3384","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41399\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9814 - dice_coef_metric_tumor: 0.4708 - loss: 0.3231 - mean_iou_all: 0.4049 - precision_tumor: 0.4548 - recall_tumor: 0.5898 - tumor_iou: 0.3384 - val_acc: 0.9716 - val_dice_coef_metric_tumor: 0.3683 - val_loss: 0.4161 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3558 - val_recall_tumor: 0.5432 - val_tumor_iou: 0.2502 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 78 lên WandB.\n\n--- Epoch 79/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9806 - dice_coef_metric_tumor: 0.4585 - loss: 0.3341 - mean_iou_all: 0.4325 - precision_tumor: 0.4427 - recall_tumor: 0.5754 - tumor_iou: 0.3265","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41399\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9806 - dice_coef_metric_tumor: 0.4584 - loss: 0.3341 - mean_iou_all: 0.4327 - precision_tumor: 0.4427 - recall_tumor: 0.5754 - tumor_iou: 0.3264 - val_acc: 0.9768 - val_dice_coef_metric_tumor: 0.3842 - val_loss: 0.4035 - val_mean_iou_all: 0.2835 - val_precision_tumor: 0.3500 - val_recall_tumor: 0.5293 - val_tumor_iou: 0.2635 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 79 lên WandB.\n\n--- Epoch 80/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9818 - dice_coef_metric_tumor: 0.4672 - loss: 0.3241 - mean_iou_all: 0.4315 - precision_tumor: 0.4561 - recall_tumor: 0.5737 - tumor_iou: 0.3327","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.41399 to 0.41425, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 472ms/step - acc: 0.9818 - dice_coef_metric_tumor: 0.4671 - loss: 0.3241 - mean_iou_all: 0.4317 - precision_tumor: 0.4560 - recall_tumor: 0.5736 - tumor_iou: 0.3327 - val_acc: 0.9788 - val_dice_coef_metric_tumor: 0.4143 - val_loss: 0.3854 - val_mean_iou_all: 0.2936 - val_precision_tumor: 0.3780 - val_recall_tumor: 0.5555 - val_tumor_iou: 0.2888 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 80 lên WandB.\n\n--- Epoch 81/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9822 - dice_coef_metric_tumor: 0.4612 - loss: 0.3283 - mean_iou_all: 0.4408 - precision_tumor: 0.4565 - recall_tumor: 0.5603 - tumor_iou: 0.3283","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41425\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9822 - dice_coef_metric_tumor: 0.4611 - loss: 0.3283 - mean_iou_all: 0.4409 - precision_tumor: 0.4564 - recall_tumor: 0.5603 - tumor_iou: 0.3282 - val_acc: 0.9821 - val_dice_coef_metric_tumor: 0.4117 - val_loss: 0.3852 - val_mean_iou_all: 0.4308 - val_precision_tumor: 0.4577 - val_recall_tumor: 0.4693 - val_tumor_iou: 0.2879 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 81 lên WandB.\n\n--- Epoch 82/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9806 - dice_coef_metric_tumor: 0.4430 - loss: 0.3423 - mean_iou_all: 0.4476 - precision_tumor: 0.4431 - recall_tumor: 0.5476 - tumor_iou: 0.3118","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41425\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9806 - dice_coef_metric_tumor: 0.4430 - loss: 0.3423 - mean_iou_all: 0.4478 - precision_tumor: 0.4430 - recall_tumor: 0.5476 - tumor_iou: 0.3118 - val_acc: 0.9744 - val_dice_coef_metric_tumor: 0.3906 - val_loss: 0.4004 - val_mean_iou_all: 0.4138 - val_precision_tumor: 0.3267 - val_recall_tumor: 0.6109 - val_tumor_iou: 0.2660 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 82 lên WandB.\n\n--- Epoch 83/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9811 - dice_coef_metric_tumor: 0.4655 - loss: 0.3322 - mean_iou_all: 0.4461 - precision_tumor: 0.4545 - recall_tumor: 0.5855 - tumor_iou: 0.3300","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.41425\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9811 - dice_coef_metric_tumor: 0.4654 - loss: 0.3322 - mean_iou_all: 0.4462 - precision_tumor: 0.4544 - recall_tumor: 0.5855 - tumor_iou: 0.3300 - val_acc: 0.9863 - val_dice_coef_metric_tumor: 0.3696 - val_loss: 0.4092 - val_mean_iou_all: 0.3059 - val_precision_tumor: 0.5195 - val_recall_tumor: 0.3375 - val_tumor_iou: 0.2592 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 83 lên WandB.\n\n--- Epoch 84/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9823 - dice_coef_metric_tumor: 0.4736 - loss: 0.3231 - mean_iou_all: 0.4420 - precision_tumor: 0.4605 - recall_tumor: 0.5758 - tumor_iou: 0.3384","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.41425 to 0.42077, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 473ms/step - acc: 0.9823 - dice_coef_metric_tumor: 0.4735 - loss: 0.3231 - mean_iou_all: 0.4422 - precision_tumor: 0.4605 - recall_tumor: 0.5757 - tumor_iou: 0.3384 - val_acc: 0.9818 - val_dice_coef_metric_tumor: 0.4208 - val_loss: 0.3807 - val_mean_iou_all: 0.3917 - val_precision_tumor: 0.4288 - val_recall_tumor: 0.5067 - val_tumor_iou: 0.2952 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 84 lên WandB.\n\n--- Epoch 85/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9819 - dice_coef_metric_tumor: 0.4653 - loss: 0.3349 - mean_iou_all: 0.4458 - precision_tumor: 0.4631 - recall_tumor: 0.5577 - tumor_iou: 0.3301","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42077\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9819 - dice_coef_metric_tumor: 0.4652 - loss: 0.3349 - mean_iou_all: 0.4459 - precision_tumor: 0.4631 - recall_tumor: 0.5577 - tumor_iou: 0.3301 - val_acc: 0.9738 - val_dice_coef_metric_tumor: 0.3951 - val_loss: 0.3995 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3600 - val_recall_tumor: 0.5619 - val_tumor_iou: 0.2732 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 85 lên WandB.\n\n--- Epoch 86/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9817 - dice_coef_metric_tumor: 0.4793 - loss: 0.3308 - mean_iou_all: 0.4658 - precision_tumor: 0.4726 - recall_tumor: 0.5761 - tumor_iou: 0.3439","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42077\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 465ms/step - acc: 0.9817 - dice_coef_metric_tumor: 0.4792 - loss: 0.3307 - mean_iou_all: 0.4659 - precision_tumor: 0.4726 - recall_tumor: 0.5760 - tumor_iou: 0.3438 - val_acc: 0.9693 - val_dice_coef_metric_tumor: 0.3592 - val_loss: 0.4232 - val_mean_iou_all: 0.3160 - val_precision_tumor: 0.2996 - val_recall_tumor: 0.5845 - val_tumor_iou: 0.2419 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 86 lên WandB.\n\n--- Epoch 87/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9828 - dice_coef_metric_tumor: 0.4849 - loss: 0.3131 - mean_iou_all: 0.4417 - precision_tumor: 0.4722 - recall_tumor: 0.5857 - tumor_iou: 0.3519","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.42077 to 0.42403, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 472ms/step - acc: 0.9828 - dice_coef_metric_tumor: 0.4848 - loss: 0.3132 - mean_iou_all: 0.4418 - precision_tumor: 0.4722 - recall_tumor: 0.5857 - tumor_iou: 0.3518 - val_acc: 0.9774 - val_dice_coef_metric_tumor: 0.4240 - val_loss: 0.3807 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3917 - val_recall_tumor: 0.5792 - val_tumor_iou: 0.2972 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 87 lên WandB.\n\n--- Epoch 88/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9822 - dice_coef_metric_tumor: 0.4828 - loss: 0.3197 - mean_iou_all: 0.4462 - precision_tumor: 0.4740 - recall_tumor: 0.5794 - tumor_iou: 0.3489","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42403\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9822 - dice_coef_metric_tumor: 0.4827 - loss: 0.3198 - mean_iou_all: 0.4464 - precision_tumor: 0.4740 - recall_tumor: 0.5793 - tumor_iou: 0.3488 - val_acc: 0.9749 - val_dice_coef_metric_tumor: 0.3960 - val_loss: 0.3985 - val_mean_iou_all: 0.4506 - val_precision_tumor: 0.3639 - val_recall_tumor: 0.5653 - val_tumor_iou: 0.2747 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 88 lên WandB.\n\n--- Epoch 89/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9819 - dice_coef_metric_tumor: 0.4673 - loss: 0.3314 - mean_iou_all: 0.4526 - precision_tumor: 0.4541 - recall_tumor: 0.5588 - tumor_iou: 0.3344","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42403\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9819 - dice_coef_metric_tumor: 0.4672 - loss: 0.3313 - mean_iou_all: 0.4528 - precision_tumor: 0.4541 - recall_tumor: 0.5588 - tumor_iou: 0.3344 - val_acc: 0.9863 - val_dice_coef_metric_tumor: 0.3447 - val_loss: 0.4271 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5600 - val_recall_tumor: 0.2888 - val_tumor_iou: 0.2406 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 89 lên WandB.\n\n--- Epoch 90/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9818 - dice_coef_metric_tumor: 0.4719 - loss: 0.3315 - mean_iou_all: 0.4568 - precision_tumor: 0.4612 - recall_tumor: 0.5720 - tumor_iou: 0.3376","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42403\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9818 - dice_coef_metric_tumor: 0.4719 - loss: 0.3315 - mean_iou_all: 0.4569 - precision_tumor: 0.4612 - recall_tumor: 0.5720 - tumor_iou: 0.3376 - val_acc: 0.9855 - val_dice_coef_metric_tumor: 0.2777 - val_loss: 0.4670 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4982 - val_recall_tumor: 0.2283 - val_tumor_iou: 0.1861 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 90 lên WandB.\n\n--- Epoch 91/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9814 - dice_coef_metric_tumor: 0.4669 - loss: 0.3361 - mean_iou_all: 0.4569 - precision_tumor: 0.4653 - recall_tumor: 0.5610 - tumor_iou: 0.3307","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42403\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9814 - dice_coef_metric_tumor: 0.4669 - loss: 0.3361 - mean_iou_all: 0.4570 - precision_tumor: 0.4653 - recall_tumor: 0.5610 - tumor_iou: 0.3307 - val_acc: 0.9811 - val_dice_coef_metric_tumor: 0.4074 - val_loss: 0.3898 - val_mean_iou_all: 0.3013 - val_precision_tumor: 0.4236 - val_recall_tumor: 0.4822 - val_tumor_iou: 0.2863 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 91 lên WandB.\n\n--- Epoch 92/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9825 - dice_coef_metric_tumor: 0.5003 - loss: 0.3155 - mean_iou_all: 0.4671 - precision_tumor: 0.4858 - recall_tumor: 0.6024 - tumor_iou: 0.3621","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.42403 to 0.43859, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 473ms/step - acc: 0.9825 - dice_coef_metric_tumor: 0.5002 - loss: 0.3155 - mean_iou_all: 0.4672 - precision_tumor: 0.4858 - recall_tumor: 0.6024 - tumor_iou: 0.3620 - val_acc: 0.9827 - val_dice_coef_metric_tumor: 0.4386 - val_loss: 0.3706 - val_mean_iou_all: 0.3175 - val_precision_tumor: 0.4519 - val_recall_tumor: 0.5066 - val_tumor_iou: 0.3085 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 92 lên WandB.\n\n--- Epoch 93/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.4991 - loss: 0.3099 - mean_iou_all: 0.4630 - precision_tumor: 0.4900 - recall_tumor: 0.6033 - tumor_iou: 0.3650","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.43859\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.4990 - loss: 0.3100 - mean_iou_all: 0.4631 - precision_tumor: 0.4899 - recall_tumor: 0.6033 - tumor_iou: 0.3649 - val_acc: 0.9821 - val_dice_coef_metric_tumor: 0.4164 - val_loss: 0.3847 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4139 - val_recall_tumor: 0.4934 - val_tumor_iou: 0.2928 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 93 lên WandB.\n\n--- Epoch 94/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9829 - dice_coef_metric_tumor: 0.4782 - loss: 0.3191 - mean_iou_all: 0.4741 - precision_tumor: 0.4782 - recall_tumor: 0.5863 - tumor_iou: 0.3446","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.43859\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9829 - dice_coef_metric_tumor: 0.4781 - loss: 0.3191 - mean_iou_all: 0.4741 - precision_tumor: 0.4782 - recall_tumor: 0.5863 - tumor_iou: 0.3446 - val_acc: 0.9855 - val_dice_coef_metric_tumor: 0.4222 - val_loss: 0.3800 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4902 - val_recall_tumor: 0.4395 - val_tumor_iou: 0.2977 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 94 lên WandB.\n\n--- Epoch 95/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.4880 - loss: 0.3259 - mean_iou_all: 0.4744 - precision_tumor: 0.4896 - recall_tumor: 0.5713 - tumor_iou: 0.3522","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.43859\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 467ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.4880 - loss: 0.3259 - mean_iou_all: 0.4745 - precision_tumor: 0.4896 - recall_tumor: 0.5713 - tumor_iou: 0.3521 - val_acc: 0.9744 - val_dice_coef_metric_tumor: 0.4164 - val_loss: 0.3875 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3572 - val_recall_tumor: 0.6558 - val_tumor_iou: 0.2878 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 95 lên WandB.\n\n--- Epoch 96/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - acc: 0.9843 - dice_coef_metric_tumor: 0.5089 - loss: 0.3033 - mean_iou_all: 0.4684 - precision_tumor: 0.5081 - recall_tumor: 0.5886 - tumor_iou: 0.3724","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.43859\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9843 - dice_coef_metric_tumor: 0.5088 - loss: 0.3033 - mean_iou_all: 0.4685 - precision_tumor: 0.5080 - recall_tumor: 0.5886 - tumor_iou: 0.3723 - val_acc: 0.9597 - val_dice_coef_metric_tumor: 0.3496 - val_loss: 0.4347 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.2549 - val_recall_tumor: 0.7613 - val_tumor_iou: 0.2314 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 96 lên WandB.\n\n--- Epoch 97/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9820 - dice_coef_metric_tumor: 0.4951 - loss: 0.3206 - mean_iou_all: 0.4700 - precision_tumor: 0.4743 - recall_tumor: 0.6028 - tumor_iou: 0.3619","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.43859\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9820 - dice_coef_metric_tumor: 0.4950 - loss: 0.3206 - mean_iou_all: 0.4701 - precision_tumor: 0.4742 - recall_tumor: 0.6027 - tumor_iou: 0.3618 - val_acc: 0.9824 - val_dice_coef_metric_tumor: 0.4350 - val_loss: 0.3730 - val_mean_iou_all: 0.3157 - val_precision_tumor: 0.4466 - val_recall_tumor: 0.5223 - val_tumor_iou: 0.3030 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 97 lên WandB.\n\n--- Epoch 98/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9833 - dice_coef_metric_tumor: 0.5073 - loss: 0.3080 - mean_iou_all: 0.4587 - precision_tumor: 0.4904 - recall_tumor: 0.6114 - tumor_iou: 0.3684","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.43859\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9833 - dice_coef_metric_tumor: 0.5072 - loss: 0.3080 - mean_iou_all: 0.4588 - precision_tumor: 0.4903 - recall_tumor: 0.6113 - tumor_iou: 0.3684 - val_acc: 0.9727 - val_dice_coef_metric_tumor: 0.4061 - val_loss: 0.3947 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3296 - val_recall_tumor: 0.6523 - val_tumor_iou: 0.2809 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 98 lên WandB.\n\n--- Epoch 99/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9818 - dice_coef_metric_tumor: 0.4933 - loss: 0.3228 - mean_iou_all: 0.4747 - precision_tumor: 0.4830 - recall_tumor: 0.5997 - tumor_iou: 0.3534","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.43859 to 0.46601, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 473ms/step - acc: 0.9818 - dice_coef_metric_tumor: 0.4933 - loss: 0.3227 - mean_iou_all: 0.4748 - precision_tumor: 0.4830 - recall_tumor: 0.5997 - tumor_iou: 0.3534 - val_acc: 0.9837 - val_dice_coef_metric_tumor: 0.4660 - val_loss: 0.3551 - val_mean_iou_all: 0.3938 - val_precision_tumor: 0.4582 - val_recall_tumor: 0.5411 - val_tumor_iou: 0.3330 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 99 lên WandB.\n\n--- Epoch 100/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.4818 - loss: 0.3195 - mean_iou_all: 0.4477 - precision_tumor: 0.4615 - recall_tumor: 0.5912 - tumor_iou: 0.3460","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46601\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.4818 - loss: 0.3195 - mean_iou_all: 0.4478 - precision_tumor: 0.4615 - recall_tumor: 0.5912 - tumor_iou: 0.3459 - val_acc: 0.9854 - val_dice_coef_metric_tumor: 0.4622 - val_loss: 0.3570 - val_mean_iou_all: 0.4104 - val_precision_tumor: 0.5433 - val_recall_tumor: 0.4790 - val_tumor_iou: 0.3303 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 100 lên WandB.\n\n--- Epoch 101/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.4982 - loss: 0.3123 - mean_iou_all: 0.4613 - precision_tumor: 0.4856 - recall_tumor: 0.6050 - tumor_iou: 0.3606","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46601\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.4982 - loss: 0.3123 - mean_iou_all: 0.4613 - precision_tumor: 0.4856 - recall_tumor: 0.6049 - tumor_iou: 0.3605 - val_acc: 0.9809 - val_dice_coef_metric_tumor: 0.4597 - val_loss: 0.3604 - val_mean_iou_all: 0.4442 - val_precision_tumor: 0.4163 - val_recall_tumor: 0.6316 - val_tumor_iou: 0.3257 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 101 lên WandB.\n\n--- Epoch 102/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9840 - dice_coef_metric_tumor: 0.5008 - loss: 0.3115 - mean_iou_all: 0.4653 - precision_tumor: 0.5063 - recall_tumor: 0.5854 - tumor_iou: 0.3627","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46601\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9840 - dice_coef_metric_tumor: 0.5008 - loss: 0.3115 - mean_iou_all: 0.4654 - precision_tumor: 0.5063 - recall_tumor: 0.5854 - tumor_iou: 0.3626 - val_acc: 0.9847 - val_dice_coef_metric_tumor: 0.4484 - val_loss: 0.3655 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4903 - val_recall_tumor: 0.4849 - val_tumor_iou: 0.3212 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 102 lên WandB.\n\n--- Epoch 103/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.5126 - loss: 0.3081 - mean_iou_all: 0.4657 - precision_tumor: 0.4995 - recall_tumor: 0.6079 - tumor_iou: 0.3778","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.46601 to 0.47232, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 474ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.5126 - loss: 0.3081 - mean_iou_all: 0.4657 - precision_tumor: 0.4994 - recall_tumor: 0.6079 - tumor_iou: 0.3778 - val_acc: 0.9838 - val_dice_coef_metric_tumor: 0.4723 - val_loss: 0.3505 - val_mean_iou_all: 0.3202 - val_precision_tumor: 0.4619 - val_recall_tumor: 0.5723 - val_tumor_iou: 0.3387 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 103 lên WandB.\n\n--- Epoch 104/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9846 - dice_coef_metric_tumor: 0.5169 - loss: 0.3033 - mean_iou_all: 0.4658 - precision_tumor: 0.5256 - recall_tumor: 0.5988 - tumor_iou: 0.3796","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47232\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 467ms/step - acc: 0.9846 - dice_coef_metric_tumor: 0.5168 - loss: 0.3033 - mean_iou_all: 0.4659 - precision_tumor: 0.5255 - recall_tumor: 0.5988 - tumor_iou: 0.3795 - val_acc: 0.9859 - val_dice_coef_metric_tumor: 0.4026 - val_loss: 0.3929 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5754 - val_recall_tumor: 0.3655 - val_tumor_iou: 0.2778 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 104 lên WandB.\n\n--- Epoch 105/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5207 - loss: 0.3055 - mean_iou_all: 0.4765 - precision_tumor: 0.5229 - recall_tumor: 0.5879 - tumor_iou: 0.3806","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47232\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5206 - loss: 0.3055 - mean_iou_all: 0.4766 - precision_tumor: 0.5229 - recall_tumor: 0.5879 - tumor_iou: 0.3805 - val_acc: 0.9815 - val_dice_coef_metric_tumor: 0.4488 - val_loss: 0.3673 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4273 - val_recall_tumor: 0.5809 - val_tumor_iou: 0.3228 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 105 lên WandB.\n\n--- Epoch 106/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5097 - loss: 0.3019 - mean_iou_all: 0.4736 - precision_tumor: 0.5122 - recall_tumor: 0.5878 - tumor_iou: 0.3731","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47232\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5097 - loss: 0.3019 - mean_iou_all: 0.4736 - precision_tumor: 0.5122 - recall_tumor: 0.5878 - tumor_iou: 0.3731 - val_acc: 0.9846 - val_dice_coef_metric_tumor: 0.4476 - val_loss: 0.3670 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4720 - val_recall_tumor: 0.4986 - val_tumor_iou: 0.3151 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 106 lên WandB.\n\n--- Epoch 107/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9834 - dice_coef_metric_tumor: 0.4999 - loss: 0.3133 - mean_iou_all: 0.4754 - precision_tumor: 0.4809 - recall_tumor: 0.6115 - tumor_iou: 0.3606","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47232\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9834 - dice_coef_metric_tumor: 0.4999 - loss: 0.3133 - mean_iou_all: 0.4754 - precision_tumor: 0.4809 - recall_tumor: 0.6115 - tumor_iou: 0.3606 - val_acc: 0.9780 - val_dice_coef_metric_tumor: 0.4124 - val_loss: 0.3901 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3832 - val_recall_tumor: 0.5559 - val_tumor_iou: 0.2883 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 107 lên WandB.\n\n--- Epoch 108/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9848 - dice_coef_metric_tumor: 0.5194 - loss: 0.3027 - mean_iou_all: 0.4700 - precision_tumor: 0.5247 - recall_tumor: 0.6041 - tumor_iou: 0.3804","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47232\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9848 - dice_coef_metric_tumor: 0.5193 - loss: 0.3027 - mean_iou_all: 0.4700 - precision_tumor: 0.5246 - recall_tumor: 0.6041 - tumor_iou: 0.3804 - val_acc: 0.9849 - val_dice_coef_metric_tumor: 0.4233 - val_loss: 0.3811 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5033 - val_recall_tumor: 0.4297 - val_tumor_iou: 0.2973 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 108 lên WandB.\n\n--- Epoch 109/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9838 - dice_coef_metric_tumor: 0.5020 - loss: 0.3076 - mean_iou_all: 0.4755 - precision_tumor: 0.4926 - recall_tumor: 0.6144 - tumor_iou: 0.3675","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47232\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9838 - dice_coef_metric_tumor: 0.5020 - loss: 0.3076 - mean_iou_all: 0.4756 - precision_tumor: 0.4926 - recall_tumor: 0.6144 - tumor_iou: 0.3675 - val_acc: 0.9761 - val_dice_coef_metric_tumor: 0.4163 - val_loss: 0.3887 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3632 - val_recall_tumor: 0.6228 - val_tumor_iou: 0.2883 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 109 lên WandB.\n\n--- Epoch 110/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - acc: 0.9832 - dice_coef_metric_tumor: 0.4972 - loss: 0.3144 - mean_iou_all: 0.4770 - precision_tumor: 0.4809 - recall_tumor: 0.5918 - tumor_iou: 0.3585","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47232\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9832 - dice_coef_metric_tumor: 0.4972 - loss: 0.3144 - mean_iou_all: 0.4770 - precision_tumor: 0.4809 - recall_tumor: 0.5917 - tumor_iou: 0.3585 - val_acc: 0.9762 - val_dice_coef_metric_tumor: 0.4436 - val_loss: 0.3738 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3590 - val_recall_tumor: 0.6996 - val_tumor_iou: 0.3107 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 110 lên WandB.\n\n--- Epoch 111/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.5099 - loss: 0.3091 - mean_iou_all: 0.4725 - precision_tumor: 0.5048 - recall_tumor: 0.5999 - tumor_iou: 0.3718","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47232\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.5099 - loss: 0.3091 - mean_iou_all: 0.4726 - precision_tumor: 0.5048 - recall_tumor: 0.5999 - tumor_iou: 0.3718 - val_acc: 0.9805 - val_dice_coef_metric_tumor: 0.4693 - val_loss: 0.3558 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4289 - val_recall_tumor: 0.6349 - val_tumor_iou: 0.3331 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 111 lên WandB.\n\n--- Epoch 112/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9837 - dice_coef_metric_tumor: 0.5215 - loss: 0.2993 - mean_iou_all: 0.4663 - precision_tumor: 0.5093 - recall_tumor: 0.6306 - tumor_iou: 0.3849","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47232\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9837 - dice_coef_metric_tumor: 0.5215 - loss: 0.2993 - mean_iou_all: 0.4663 - precision_tumor: 0.5092 - recall_tumor: 0.6305 - tumor_iou: 0.3848 - val_acc: 0.9827 - val_dice_coef_metric_tumor: 0.4486 - val_loss: 0.3670 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4224 - val_recall_tumor: 0.5746 - val_tumor_iou: 0.3160 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 112 lên WandB.\n\n--- Epoch 113/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9842 - dice_coef_metric_tumor: 0.5225 - loss: 0.2981 - mean_iou_all: 0.4766 - precision_tumor: 0.5160 - recall_tumor: 0.6177 - tumor_iou: 0.3841","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47232\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9842 - dice_coef_metric_tumor: 0.5225 - loss: 0.2982 - mean_iou_all: 0.4767 - precision_tumor: 0.5160 - recall_tumor: 0.6176 - tumor_iou: 0.3840 - val_acc: 0.9867 - val_dice_coef_metric_tumor: 0.4547 - val_loss: 0.3621 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5698 - val_recall_tumor: 0.4409 - val_tumor_iou: 0.3294 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 113 lên WandB.\n\n--- Epoch 114/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9855 - dice_coef_metric_tumor: 0.5244 - loss: 0.2963 - mean_iou_all: 0.4744 - precision_tumor: 0.5337 - recall_tumor: 0.5921 - tumor_iou: 0.3879","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47232\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9855 - dice_coef_metric_tumor: 0.5244 - loss: 0.2963 - mean_iou_all: 0.4744 - precision_tumor: 0.5336 - recall_tumor: 0.5921 - tumor_iou: 0.3879 - val_acc: 0.9836 - val_dice_coef_metric_tumor: 0.4600 - val_loss: 0.3601 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4638 - val_recall_tumor: 0.5306 - val_tumor_iou: 0.3295 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 114 lên WandB.\n\n--- Epoch 115/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9844 - dice_coef_metric_tumor: 0.5145 - loss: 0.3081 - mean_iou_all: 0.4727 - precision_tumor: 0.5128 - recall_tumor: 0.5910 - tumor_iou: 0.3794","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.47232 to 0.48446, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 473ms/step - acc: 0.9844 - dice_coef_metric_tumor: 0.5145 - loss: 0.3081 - mean_iou_all: 0.4727 - precision_tumor: 0.5127 - recall_tumor: 0.5910 - tumor_iou: 0.3793 - val_acc: 0.9862 - val_dice_coef_metric_tumor: 0.4845 - val_loss: 0.3450 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5228 - val_recall_tumor: 0.5111 - val_tumor_iou: 0.3519 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 115 lên WandB.\n\n--- Epoch 116/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5343 - loss: 0.2912 - mean_iou_all: 0.4633 - precision_tumor: 0.5377 - recall_tumor: 0.6039 - tumor_iou: 0.3927","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48446\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5343 - loss: 0.2912 - mean_iou_all: 0.4633 - precision_tumor: 0.5377 - recall_tumor: 0.6039 - tumor_iou: 0.3926 - val_acc: 0.9817 - val_dice_coef_metric_tumor: 0.4605 - val_loss: 0.3606 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4150 - val_recall_tumor: 0.6166 - val_tumor_iou: 0.3276 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 116 lên WandB.\n\n--- Epoch 117/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9842 - dice_coef_metric_tumor: 0.5207 - loss: 0.3035 - mean_iou_all: 0.4608 - precision_tumor: 0.5164 - recall_tumor: 0.6106 - tumor_iou: 0.3809","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48446\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 467ms/step - acc: 0.9842 - dice_coef_metric_tumor: 0.5206 - loss: 0.3035 - mean_iou_all: 0.4607 - precision_tumor: 0.5163 - recall_tumor: 0.6106 - tumor_iou: 0.3809 - val_acc: 0.9807 - val_dice_coef_metric_tumor: 0.4641 - val_loss: 0.3591 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4203 - val_recall_tumor: 0.6292 - val_tumor_iou: 0.3286 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 117 lên WandB.\n\n--- Epoch 118/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9846 - dice_coef_metric_tumor: 0.5170 - loss: 0.3011 - mean_iou_all: 0.4758 - precision_tumor: 0.5104 - recall_tumor: 0.6069 - tumor_iou: 0.3770","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48446\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9846 - dice_coef_metric_tumor: 0.5170 - loss: 0.3011 - mean_iou_all: 0.4758 - precision_tumor: 0.5103 - recall_tumor: 0.6069 - tumor_iou: 0.3770 - val_acc: 0.9838 - val_dice_coef_metric_tumor: 0.4753 - val_loss: 0.3516 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4574 - val_recall_tumor: 0.5788 - val_tumor_iou: 0.3417 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 118 lên WandB.\n\n--- Epoch 119/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5330 - loss: 0.2926 - mean_iou_all: 0.4684 - precision_tumor: 0.5311 - recall_tumor: 0.6099 - tumor_iou: 0.3933","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48446\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5330 - loss: 0.2926 - mean_iou_all: 0.4684 - precision_tumor: 0.5311 - recall_tumor: 0.6098 - tumor_iou: 0.3932 - val_acc: 0.9865 - val_dice_coef_metric_tumor: 0.4789 - val_loss: 0.3487 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5388 - val_recall_tumor: 0.5071 - val_tumor_iou: 0.3450 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 119 lên WandB.\n\n--- Epoch 120/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9844 - dice_coef_metric_tumor: 0.5263 - loss: 0.3057 - mean_iou_all: 0.4696 - precision_tumor: 0.5288 - recall_tumor: 0.6139 - tumor_iou: 0.3867","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.48446 to 0.51450, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 474ms/step - acc: 0.9844 - dice_coef_metric_tumor: 0.5263 - loss: 0.3057 - mean_iou_all: 0.4697 - precision_tumor: 0.5287 - recall_tumor: 0.6139 - tumor_iou: 0.3867 - val_acc: 0.9864 - val_dice_coef_metric_tumor: 0.5145 - val_loss: 0.3272 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5282 - val_recall_tumor: 0.5668 - val_tumor_iou: 0.3805 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 120 lên WandB.\n\n--- Epoch 121/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9852 - dice_coef_metric_tumor: 0.5417 - loss: 0.2910 - mean_iou_all: 0.4837 - precision_tumor: 0.5420 - recall_tumor: 0.6204 - tumor_iou: 0.4004","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9852 - dice_coef_metric_tumor: 0.5417 - loss: 0.2910 - mean_iou_all: 0.4837 - precision_tumor: 0.5420 - recall_tumor: 0.6204 - tumor_iou: 0.4004 - val_acc: 0.9811 - val_dice_coef_metric_tumor: 0.4696 - val_loss: 0.3564 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4090 - val_recall_tumor: 0.6602 - val_tumor_iou: 0.3356 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 121 lên WandB.\n\n--- Epoch 122/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9842 - dice_coef_metric_tumor: 0.5242 - loss: 0.2984 - mean_iou_all: 0.4753 - precision_tumor: 0.5211 - recall_tumor: 0.6134 - tumor_iou: 0.3864","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 467ms/step - acc: 0.9842 - dice_coef_metric_tumor: 0.5242 - loss: 0.2983 - mean_iou_all: 0.4753 - precision_tumor: 0.5211 - recall_tumor: 0.6134 - tumor_iou: 0.3864 - val_acc: 0.9839 - val_dice_coef_metric_tumor: 0.4475 - val_loss: 0.3691 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5222 - val_recall_tumor: 0.4660 - val_tumor_iou: 0.3179 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 122 lên WandB.\n\n--- Epoch 123/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5438 - loss: 0.2881 - mean_iou_all: 0.4789 - precision_tumor: 0.5401 - recall_tumor: 0.6232 - tumor_iou: 0.4033","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 467ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5437 - loss: 0.2881 - mean_iou_all: 0.4789 - precision_tumor: 0.5401 - recall_tumor: 0.6232 - tumor_iou: 0.4033 - val_acc: 0.9674 - val_dice_coef_metric_tumor: 0.4101 - val_loss: 0.3984 - val_mean_iou_all: 0.4658 - val_precision_tumor: 0.3046 - val_recall_tumor: 0.7990 - val_tumor_iou: 0.2816 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 123 lên WandB.\n\n--- Epoch 124/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5322 - loss: 0.2949 - mean_iou_all: 0.4716 - precision_tumor: 0.5428 - recall_tumor: 0.5975 - tumor_iou: 0.3947","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 467ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5322 - loss: 0.2949 - mean_iou_all: 0.4716 - precision_tumor: 0.5427 - recall_tumor: 0.5975 - tumor_iou: 0.3946 - val_acc: 0.9837 - val_dice_coef_metric_tumor: 0.4807 - val_loss: 0.3491 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4725 - val_recall_tumor: 0.5750 - val_tumor_iou: 0.3493 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 124 lên WandB.\n\n--- Epoch 125/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5475 - loss: 0.2849 - mean_iou_all: 0.4851 - precision_tumor: 0.5464 - recall_tumor: 0.6328 - tumor_iou: 0.4089","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 467ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5475 - loss: 0.2849 - mean_iou_all: 0.4851 - precision_tumor: 0.5463 - recall_tumor: 0.6327 - tumor_iou: 0.4088 - val_acc: 0.9823 - val_dice_coef_metric_tumor: 0.4570 - val_loss: 0.3644 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4455 - val_recall_tumor: 0.5687 - val_tumor_iou: 0.3222 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 125 lên WandB.\n\n--- Epoch 126/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5327 - loss: 0.2960 - mean_iou_all: 0.4824 - precision_tumor: 0.5419 - recall_tumor: 0.6041 - tumor_iou: 0.3928","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 468ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5327 - loss: 0.2960 - mean_iou_all: 0.4824 - precision_tumor: 0.5419 - recall_tumor: 0.6041 - tumor_iou: 0.3927 - val_acc: 0.9815 - val_dice_coef_metric_tumor: 0.4749 - val_loss: 0.3539 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4289 - val_recall_tumor: 0.6332 - val_tumor_iou: 0.3403 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 126 lên WandB.\n\n--- Epoch 127/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.5740 - loss: 0.2720 - mean_iou_all: 0.4842 - precision_tumor: 0.5780 - recall_tumor: 0.6418 - tumor_iou: 0.4334","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.5739 - loss: 0.2721 - mean_iou_all: 0.4842 - precision_tumor: 0.5779 - recall_tumor: 0.6418 - tumor_iou: 0.4333 - val_acc: 0.9795 - val_dice_coef_metric_tumor: 0.4499 - val_loss: 0.3700 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3758 - val_recall_tumor: 0.6808 - val_tumor_iou: 0.3192 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 127 lên WandB.\n\n--- Epoch 128/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5410 - loss: 0.2927 - mean_iou_all: 0.4782 - precision_tumor: 0.5339 - recall_tumor: 0.6122 - tumor_iou: 0.4029","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5410 - loss: 0.2927 - mean_iou_all: 0.4782 - precision_tumor: 0.5339 - recall_tumor: 0.6122 - tumor_iou: 0.4029 - val_acc: 0.9836 - val_dice_coef_metric_tumor: 0.4633 - val_loss: 0.3596 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4715 - val_recall_tumor: 0.5405 - val_tumor_iou: 0.3327 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 128 lên WandB.\n\n--- Epoch 129/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5616 - loss: 0.2845 - mean_iou_all: 0.4741 - precision_tumor: 0.5684 - recall_tumor: 0.6307 - tumor_iou: 0.4212","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5615 - loss: 0.2845 - mean_iou_all: 0.4741 - precision_tumor: 0.5683 - recall_tumor: 0.6307 - tumor_iou: 0.4211 - val_acc: 0.9857 - val_dice_coef_metric_tumor: 0.5112 - val_loss: 0.3303 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5133 - val_recall_tumor: 0.5764 - val_tumor_iou: 0.3738 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 129 lên WandB.\n\n--- Epoch 130/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5634 - loss: 0.2820 - mean_iou_all: 0.4785 - precision_tumor: 0.5607 - recall_tumor: 0.6442 - tumor_iou: 0.4227","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5634 - loss: 0.2820 - mean_iou_all: 0.4785 - precision_tumor: 0.5607 - recall_tumor: 0.6442 - tumor_iou: 0.4227 - val_acc: 0.9849 - val_dice_coef_metric_tumor: 0.4237 - val_loss: 0.3838 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5387 - val_recall_tumor: 0.4215 - val_tumor_iou: 0.2992 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 130 lên WandB.\n\n--- Epoch 131/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5552 - loss: 0.2810 - mean_iou_all: 0.4778 - precision_tumor: 0.5510 - recall_tumor: 0.6304 - tumor_iou: 0.4179","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5551 - loss: 0.2810 - mean_iou_all: 0.4778 - precision_tumor: 0.5509 - recall_tumor: 0.6304 - tumor_iou: 0.4179 - val_acc: 0.9841 - val_dice_coef_metric_tumor: 0.4509 - val_loss: 0.3677 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5346 - val_recall_tumor: 0.4684 - val_tumor_iou: 0.3214 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 131 lên WandB.\n\n--- Epoch 132/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5651 - loss: 0.2800 - mean_iou_all: 0.4859 - precision_tumor: 0.5664 - recall_tumor: 0.6434 - tumor_iou: 0.4258","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5650 - loss: 0.2801 - mean_iou_all: 0.4859 - precision_tumor: 0.5664 - recall_tumor: 0.6434 - tumor_iou: 0.4258 - val_acc: 0.9871 - val_dice_coef_metric_tumor: 0.4150 - val_loss: 0.3889 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6122 - val_recall_tumor: 0.3651 - val_tumor_iou: 0.2905 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 132 lên WandB.\n\n--- Epoch 133/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9855 - dice_coef_metric_tumor: 0.5498 - loss: 0.2870 - mean_iou_all: 0.4835 - precision_tumor: 0.5447 - recall_tumor: 0.6351 - tumor_iou: 0.4081","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9855 - dice_coef_metric_tumor: 0.5498 - loss: 0.2870 - mean_iou_all: 0.4835 - precision_tumor: 0.5447 - recall_tumor: 0.6351 - tumor_iou: 0.4081 - val_acc: 0.9849 - val_dice_coef_metric_tumor: 0.4904 - val_loss: 0.3441 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4834 - val_recall_tumor: 0.5714 - val_tumor_iou: 0.3615 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 133 lên WandB.\n\n--- Epoch 134/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5452 - loss: 0.2867 - mean_iou_all: 0.4837 - precision_tumor: 0.5708 - recall_tumor: 0.6001 - tumor_iou: 0.4069","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5452 - loss: 0.2867 - mean_iou_all: 0.4837 - precision_tumor: 0.5708 - recall_tumor: 0.6001 - tumor_iou: 0.4069 - val_acc: 0.9871 - val_dice_coef_metric_tumor: 0.4954 - val_loss: 0.3405 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5473 - val_recall_tumor: 0.5152 - val_tumor_iou: 0.3598 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 134 lên WandB.\n\n--- Epoch 135/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5657 - loss: 0.2758 - mean_iou_all: 0.4799 - precision_tumor: 0.5752 - recall_tumor: 0.6199 - tumor_iou: 0.4274","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 466ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5656 - loss: 0.2759 - mean_iou_all: 0.4799 - precision_tumor: 0.5751 - recall_tumor: 0.6199 - tumor_iou: 0.4273 - val_acc: 0.9869 - val_dice_coef_metric_tumor: 0.4301 - val_loss: 0.3796 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6220 - val_recall_tumor: 0.3827 - val_tumor_iou: 0.3068 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 135 lên WandB.\n\n--- Epoch 136/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5632 - loss: 0.2870 - mean_iou_all: 0.4802 - precision_tumor: 0.5705 - recall_tumor: 0.6194 - tumor_iou: 0.4181","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 467ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5632 - loss: 0.2870 - mean_iou_all: 0.4802 - precision_tumor: 0.5705 - recall_tumor: 0.6194 - tumor_iou: 0.4181 - val_acc: 0.9877 - val_dice_coef_metric_tumor: 0.5012 - val_loss: 0.3364 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6007 - val_recall_tumor: 0.4844 - val_tumor_iou: 0.3672 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 136 lên WandB.\n\n--- Epoch 137/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9852 - dice_coef_metric_tumor: 0.5442 - loss: 0.2944 - mean_iou_all: 0.4801 - precision_tumor: 0.5381 - recall_tumor: 0.6310 - tumor_iou: 0.4074","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51450\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9852 - dice_coef_metric_tumor: 0.5441 - loss: 0.2944 - mean_iou_all: 0.4801 - precision_tumor: 0.5381 - recall_tumor: 0.6309 - tumor_iou: 0.4074 - val_acc: 0.9850 - val_dice_coef_metric_tumor: 0.5064 - val_loss: 0.3348 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4829 - val_recall_tumor: 0.6065 - val_tumor_iou: 0.3674 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 137 lên WandB.\n\n--- Epoch 138/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5563 - loss: 0.2864 - mean_iou_all: 0.4761 - precision_tumor: 0.5588 - recall_tumor: 0.6243 - tumor_iou: 0.4158","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.51450 to 0.52364, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 473ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5563 - loss: 0.2864 - mean_iou_all: 0.4760 - precision_tumor: 0.5587 - recall_tumor: 0.6243 - tumor_iou: 0.4158 - val_acc: 0.9854 - val_dice_coef_metric_tumor: 0.5236 - val_loss: 0.3243 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4940 - val_recall_tumor: 0.6298 - val_tumor_iou: 0.3892 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 138 lên WandB.\n\n--- Epoch 139/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5657 - loss: 0.2767 - mean_iou_all: 0.4842 - precision_tumor: 0.5614 - recall_tumor: 0.6429 - tumor_iou: 0.4245","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52364\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5657 - loss: 0.2767 - mean_iou_all: 0.4842 - precision_tumor: 0.5613 - recall_tumor: 0.6429 - tumor_iou: 0.4245 - val_acc: 0.9838 - val_dice_coef_metric_tumor: 0.4938 - val_loss: 0.3429 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4602 - val_recall_tumor: 0.6251 - val_tumor_iou: 0.3599 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 139 lên WandB.\n\n--- Epoch 140/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9855 - dice_coef_metric_tumor: 0.5495 - loss: 0.2914 - mean_iou_all: 0.4766 - precision_tumor: 0.5468 - recall_tumor: 0.6212 - tumor_iou: 0.4110","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52364\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9855 - dice_coef_metric_tumor: 0.5495 - loss: 0.2914 - mean_iou_all: 0.4766 - precision_tumor: 0.5468 - recall_tumor: 0.6212 - tumor_iou: 0.4110 - val_acc: 0.9797 - val_dice_coef_metric_tumor: 0.4742 - val_loss: 0.3565 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4017 - val_recall_tumor: 0.6804 - val_tumor_iou: 0.3420 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 140 lên WandB.\n\n--- Epoch 141/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5586 - loss: 0.2843 - mean_iou_all: 0.4795 - precision_tumor: 0.5490 - recall_tumor: 0.6499 - tumor_iou: 0.4169","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52364\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5585 - loss: 0.2843 - mean_iou_all: 0.4795 - precision_tumor: 0.5490 - recall_tumor: 0.6499 - tumor_iou: 0.4169 - val_acc: 0.9870 - val_dice_coef_metric_tumor: 0.5097 - val_loss: 0.3318 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5334 - val_recall_tumor: 0.5564 - val_tumor_iou: 0.3758 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 141 lên WandB.\n\n--- Epoch 142/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5529 - loss: 0.2881 - mean_iou_all: 0.4807 - precision_tumor: 0.5692 - recall_tumor: 0.6073 - tumor_iou: 0.4126","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52364\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5529 - loss: 0.2881 - mean_iou_all: 0.4807 - precision_tumor: 0.5691 - recall_tumor: 0.6073 - tumor_iou: 0.4126 - val_acc: 0.9819 - val_dice_coef_metric_tumor: 0.4974 - val_loss: 0.3423 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4533 - val_recall_tumor: 0.6539 - val_tumor_iou: 0.3628 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 142 lên WandB.\n\n--- Epoch 143/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9852 - dice_coef_metric_tumor: 0.5657 - loss: 0.2837 - mean_iou_all: 0.4655 - precision_tumor: 0.5524 - recall_tumor: 0.6445 - tumor_iou: 0.4254","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52364\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9852 - dice_coef_metric_tumor: 0.5657 - loss: 0.2837 - mean_iou_all: 0.4654 - precision_tumor: 0.5524 - recall_tumor: 0.6445 - tumor_iou: 0.4254 - val_acc: 0.9874 - val_dice_coef_metric_tumor: 0.5029 - val_loss: 0.3366 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5527 - val_recall_tumor: 0.5221 - val_tumor_iou: 0.3707 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 143 lên WandB.\n\n--- Epoch 144/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5497 - loss: 0.2831 - mean_iou_all: 0.4590 - precision_tumor: 0.5403 - recall_tumor: 0.6402 - tumor_iou: 0.4095","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52364\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5497 - loss: 0.2831 - mean_iou_all: 0.4590 - precision_tumor: 0.5403 - recall_tumor: 0.6402 - tumor_iou: 0.4094 - val_acc: 0.9859 - val_dice_coef_metric_tumor: 0.5002 - val_loss: 0.3384 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5029 - val_recall_tumor: 0.5725 - val_tumor_iou: 0.3665 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 144 lên WandB.\n\n--- Epoch 145/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5692 - loss: 0.2881 - mean_iou_all: 0.4641 - precision_tumor: 0.5685 - recall_tumor: 0.6432 - tumor_iou: 0.4223","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.52364 to 0.52552, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 474ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5692 - loss: 0.2880 - mean_iou_all: 0.4640 - precision_tumor: 0.5685 - recall_tumor: 0.6432 - tumor_iou: 0.4222 - val_acc: 0.9871 - val_dice_coef_metric_tumor: 0.5255 - val_loss: 0.3232 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5560 - val_recall_tumor: 0.5568 - val_tumor_iou: 0.3880 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 145 lên WandB.\n\n--- Epoch 146/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5557 - loss: 0.2931 - mean_iou_all: 0.4800 - precision_tumor: 0.5673 - recall_tumor: 0.6271 - tumor_iou: 0.4152","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52552\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5557 - loss: 0.2931 - mean_iou_all: 0.4800 - precision_tumor: 0.5673 - recall_tumor: 0.6271 - tumor_iou: 0.4152 - val_acc: 0.9859 - val_dice_coef_metric_tumor: 0.5087 - val_loss: 0.3341 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5074 - val_recall_tumor: 0.5712 - val_tumor_iou: 0.3752 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 146 lên WandB.\n\n--- Epoch 147/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.5601 - loss: 0.2784 - mean_iou_all: 0.4732 - precision_tumor: 0.5638 - recall_tumor: 0.6278 - tumor_iou: 0.4240","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52552\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.5600 - loss: 0.2784 - mean_iou_all: 0.4731 - precision_tumor: 0.5637 - recall_tumor: 0.6278 - tumor_iou: 0.4239 - val_acc: 0.9826 - val_dice_coef_metric_tumor: 0.4818 - val_loss: 0.3509 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4594 - val_recall_tumor: 0.6001 - val_tumor_iou: 0.3505 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 147 lên WandB.\n\n--- Epoch 148/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9865 - dice_coef_metric_tumor: 0.5690 - loss: 0.2772 - mean_iou_all: 0.4713 - precision_tumor: 0.5685 - recall_tumor: 0.6390 - tumor_iou: 0.4278","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52552\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9865 - dice_coef_metric_tumor: 0.5690 - loss: 0.2772 - mean_iou_all: 0.4713 - precision_tumor: 0.5685 - recall_tumor: 0.6390 - tumor_iou: 0.4278 - val_acc: 0.9829 - val_dice_coef_metric_tumor: 0.4888 - val_loss: 0.3470 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4629 - val_recall_tumor: 0.6064 - val_tumor_iou: 0.3569 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 148 lên WandB.\n\n--- Epoch 149/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5743 - loss: 0.2763 - mean_iou_all: 0.4559 - precision_tumor: 0.5783 - recall_tumor: 0.6367 - tumor_iou: 0.4328","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52552\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5742 - loss: 0.2763 - mean_iou_all: 0.4558 - precision_tumor: 0.5783 - recall_tumor: 0.6367 - tumor_iou: 0.4327 - val_acc: 0.9870 - val_dice_coef_metric_tumor: 0.5118 - val_loss: 0.3321 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5386 - val_recall_tumor: 0.5488 - val_tumor_iou: 0.3726 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 149 lên WandB.\n\n--- Epoch 150/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9857 - dice_coef_metric_tumor: 0.5565 - loss: 0.2830 - mean_iou_all: 0.4774 - precision_tumor: 0.5434 - recall_tumor: 0.6499 - tumor_iou: 0.4192","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52552\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9857 - dice_coef_metric_tumor: 0.5565 - loss: 0.2829 - mean_iou_all: 0.4774 - precision_tumor: 0.5434 - recall_tumor: 0.6499 - tumor_iou: 0.4192 - val_acc: 0.9865 - val_dice_coef_metric_tumor: 0.5122 - val_loss: 0.3321 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5517 - val_recall_tumor: 0.5436 - val_tumor_iou: 0.3792 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 150 lên WandB.\n\n--- Epoch 151/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5665 - loss: 0.2839 - mean_iou_all: 0.4735 - precision_tumor: 0.5659 - recall_tumor: 0.6383 - tumor_iou: 0.4239","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52552\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 467ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5665 - loss: 0.2839 - mean_iou_all: 0.4735 - precision_tumor: 0.5658 - recall_tumor: 0.6383 - tumor_iou: 0.4239 - val_acc: 0.9860 - val_dice_coef_metric_tumor: 0.5121 - val_loss: 0.3321 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5318 - val_recall_tumor: 0.5745 - val_tumor_iou: 0.3777 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 151 lên WandB.\n\n--- Epoch 152/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5792 - loss: 0.2741 - mean_iou_all: 0.4700 - precision_tumor: 0.5787 - recall_tumor: 0.6559 - tumor_iou: 0.4377","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52552\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 467ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5791 - loss: 0.2741 - mean_iou_all: 0.4700 - precision_tumor: 0.5787 - recall_tumor: 0.6559 - tumor_iou: 0.4377 - val_acc: 0.9803 - val_dice_coef_metric_tumor: 0.4839 - val_loss: 0.3514 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4252 - val_recall_tumor: 0.6785 - val_tumor_iou: 0.3489 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 152 lên WandB.\n\n--- Epoch 153/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5593 - loss: 0.2783 - mean_iou_all: 0.4781 - precision_tumor: 0.5473 - recall_tumor: 0.6413 - tumor_iou: 0.4214","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52552\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5593 - loss: 0.2783 - mean_iou_all: 0.4780 - precision_tumor: 0.5472 - recall_tumor: 0.6413 - tumor_iou: 0.4214 - val_acc: 0.9868 - val_dice_coef_metric_tumor: 0.5126 - val_loss: 0.3321 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5390 - val_recall_tumor: 0.5484 - val_tumor_iou: 0.3776 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 153 lên WandB.\n\n--- Epoch 154/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.5683 - loss: 0.2759 - mean_iou_all: 0.4757 - precision_tumor: 0.5678 - recall_tumor: 0.6405 - tumor_iou: 0.4302","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.52552 to 0.52721, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 474ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.5682 - loss: 0.2759 - mean_iou_all: 0.4757 - precision_tumor: 0.5678 - recall_tumor: 0.6405 - tumor_iou: 0.4301 - val_acc: 0.9874 - val_dice_coef_metric_tumor: 0.5272 - val_loss: 0.3231 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5429 - val_recall_tumor: 0.5710 - val_tumor_iou: 0.3923 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 154 lên WandB.\n\n--- Epoch 155/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5584 - loss: 0.2823 - mean_iou_all: 0.4802 - precision_tumor: 0.5515 - recall_tumor: 0.6398 - tumor_iou: 0.4205","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52721\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5584 - loss: 0.2822 - mean_iou_all: 0.4801 - precision_tumor: 0.5515 - recall_tumor: 0.6398 - tumor_iou: 0.4205 - val_acc: 0.9880 - val_dice_coef_metric_tumor: 0.5131 - val_loss: 0.3318 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5916 - val_recall_tumor: 0.5137 - val_tumor_iou: 0.3777 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 155 lên WandB.\n\n--- Epoch 156/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5713 - loss: 0.2780 - mean_iou_all: 0.4737 - precision_tumor: 0.5781 - recall_tumor: 0.6364 - tumor_iou: 0.4287","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52721\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5713 - loss: 0.2780 - mean_iou_all: 0.4737 - precision_tumor: 0.5781 - recall_tumor: 0.6364 - tumor_iou: 0.4286 - val_acc: 0.9878 - val_dice_coef_metric_tumor: 0.5065 - val_loss: 0.3355 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6024 - val_recall_tumor: 0.4912 - val_tumor_iou: 0.3740 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 156 lên WandB.\n\n--- Epoch 157/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.5957 - loss: 0.2640 - mean_iou_all: 0.4876 - precision_tumor: 0.5857 - recall_tumor: 0.6660 - tumor_iou: 0.4560","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.52721 to 0.53699, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 475ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.5956 - loss: 0.2640 - mean_iou_all: 0.4876 - precision_tumor: 0.5857 - recall_tumor: 0.6659 - tumor_iou: 0.4559 - val_acc: 0.9850 - val_dice_coef_metric_tumor: 0.5370 - val_loss: 0.3181 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4964 - val_recall_tumor: 0.6692 - val_tumor_iou: 0.4009 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 157 lên WandB.\n\n--- Epoch 158/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5590 - loss: 0.2836 - mean_iou_all: 0.4878 - precision_tumor: 0.5613 - recall_tumor: 0.6337 - tumor_iou: 0.4209","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53699\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5590 - loss: 0.2835 - mean_iou_all: 0.4878 - precision_tumor: 0.5613 - recall_tumor: 0.6337 - tumor_iou: 0.4209 - val_acc: 0.9881 - val_dice_coef_metric_tumor: 0.5176 - val_loss: 0.3291 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5914 - val_recall_tumor: 0.5196 - val_tumor_iou: 0.3858 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 158 lên WandB.\n\n--- Epoch 159/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5758 - loss: 0.2719 - mean_iou_all: 0.4797 - precision_tumor: 0.5723 - recall_tumor: 0.6486 - tumor_iou: 0.4360","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53699\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 468ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5758 - loss: 0.2719 - mean_iou_all: 0.4796 - precision_tumor: 0.5723 - recall_tumor: 0.6486 - tumor_iou: 0.4360 - val_acc: 0.9856 - val_dice_coef_metric_tumor: 0.5265 - val_loss: 0.3250 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5011 - val_recall_tumor: 0.6237 - val_tumor_iou: 0.3871 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 159 lên WandB.\n\n--- Epoch 160/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5587 - loss: 0.2894 - mean_iou_all: 0.4769 - precision_tumor: 0.5559 - recall_tumor: 0.6353 - tumor_iou: 0.4208","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53699\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5587 - loss: 0.2894 - mean_iou_all: 0.4768 - precision_tumor: 0.5559 - recall_tumor: 0.6353 - tumor_iou: 0.4207 - val_acc: 0.9862 - val_dice_coef_metric_tumor: 0.5035 - val_loss: 0.3381 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5456 - val_recall_tumor: 0.5419 - val_tumor_iou: 0.3752 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 160 lên WandB.\n\n--- Epoch 161/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5858 - loss: 0.2738 - mean_iou_all: 0.4797 - precision_tumor: 0.5986 - recall_tumor: 0.6435 - tumor_iou: 0.4444","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53699\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5857 - loss: 0.2738 - mean_iou_all: 0.4797 - precision_tumor: 0.5985 - recall_tumor: 0.6434 - tumor_iou: 0.4444 - val_acc: 0.9858 - val_dice_coef_metric_tumor: 0.5308 - val_loss: 0.3221 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5062 - val_recall_tumor: 0.6297 - val_tumor_iou: 0.3946 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 161 lên WandB.\n\n--- Epoch 162/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5885 - loss: 0.2748 - mean_iou_all: 0.4846 - precision_tumor: 0.5877 - recall_tumor: 0.6668 - tumor_iou: 0.4461","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53699\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5885 - loss: 0.2748 - mean_iou_all: 0.4845 - precision_tumor: 0.5877 - recall_tumor: 0.6667 - tumor_iou: 0.4461 - val_acc: 0.9881 - val_dice_coef_metric_tumor: 0.5240 - val_loss: 0.3251 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5995 - val_recall_tumor: 0.5157 - val_tumor_iou: 0.3891 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 162 lên WandB.\n\n--- Epoch 163/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9874 - dice_coef_metric_tumor: 0.5767 - loss: 0.2718 - mean_iou_all: 0.4886 - precision_tumor: 0.5838 - recall_tumor: 0.6414 - tumor_iou: 0.4360","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53699\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9874 - dice_coef_metric_tumor: 0.5767 - loss: 0.2718 - mean_iou_all: 0.4886 - precision_tumor: 0.5838 - recall_tumor: 0.6414 - tumor_iou: 0.4360 - val_acc: 0.9883 - val_dice_coef_metric_tumor: 0.5308 - val_loss: 0.3218 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6063 - val_recall_tumor: 0.5260 - val_tumor_iou: 0.3951 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 163 lên WandB.\n\n--- Epoch 164/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.5919 - loss: 0.2711 - mean_iou_all: 0.4759 - precision_tumor: 0.6020 - recall_tumor: 0.6533 - tumor_iou: 0.4460","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53699\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.5919 - loss: 0.2710 - mean_iou_all: 0.4758 - precision_tumor: 0.6020 - recall_tumor: 0.6533 - tumor_iou: 0.4460 - val_acc: 0.9869 - val_dice_coef_metric_tumor: 0.5267 - val_loss: 0.3241 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5440 - val_recall_tumor: 0.5887 - val_tumor_iou: 0.3942 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 164 lên WandB.\n\n--- Epoch 165/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.5763 - loss: 0.2714 - mean_iou_all: 0.4807 - precision_tumor: 0.5793 - recall_tumor: 0.6444 - tumor_iou: 0.4372","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53699\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.5763 - loss: 0.2714 - mean_iou_all: 0.4807 - precision_tumor: 0.5793 - recall_tumor: 0.6444 - tumor_iou: 0.4372 - val_acc: 0.9802 - val_dice_coef_metric_tumor: 0.5039 - val_loss: 0.3411 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4138 - val_recall_tumor: 0.7491 - val_tumor_iou: 0.3665 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 165 lên WandB.\n\n--- Epoch 166/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.5973 - loss: 0.2613 - mean_iou_all: 0.4796 - precision_tumor: 0.5937 - recall_tumor: 0.6631 - tumor_iou: 0.4566","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53699\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.5973 - loss: 0.2613 - mean_iou_all: 0.4795 - precision_tumor: 0.5937 - recall_tumor: 0.6631 - tumor_iou: 0.4565 - val_acc: 0.9882 - val_dice_coef_metric_tumor: 0.5274 - val_loss: 0.3236 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5960 - val_recall_tumor: 0.5326 - val_tumor_iou: 0.3938 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 166 lên WandB.\n\n--- Epoch 167/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5795 - loss: 0.2712 - mean_iou_all: 0.4605 - precision_tumor: 0.5808 - recall_tumor: 0.6521 - tumor_iou: 0.4396","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53699\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5795 - loss: 0.2712 - mean_iou_all: 0.4604 - precision_tumor: 0.5807 - recall_tumor: 0.6521 - tumor_iou: 0.4396 - val_acc: 0.9825 - val_dice_coef_metric_tumor: 0.4946 - val_loss: 0.3458 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4339 - val_recall_tumor: 0.6632 - val_tumor_iou: 0.3596 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 167 lên WandB.\n\n--- Epoch 168/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.5998 - loss: 0.2656 - mean_iou_all: 0.4833 - precision_tumor: 0.6054 - recall_tumor: 0.6521 - tumor_iou: 0.4552","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.53699 to 0.54871, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 475ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.5998 - loss: 0.2656 - mean_iou_all: 0.4833 - precision_tumor: 0.6054 - recall_tumor: 0.6520 - tumor_iou: 0.4552 - val_acc: 0.9878 - val_dice_coef_metric_tumor: 0.5487 - val_loss: 0.3117 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5588 - val_recall_tumor: 0.6014 - val_tumor_iou: 0.4143 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 168 lên WandB.\n\n--- Epoch 169/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5797 - loss: 0.2755 - mean_iou_all: 0.4813 - precision_tumor: 0.5817 - recall_tumor: 0.6524 - tumor_iou: 0.4388","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54871\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 470ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5797 - loss: 0.2755 - mean_iou_all: 0.4812 - precision_tumor: 0.5817 - recall_tumor: 0.6524 - tumor_iou: 0.4388 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5420 - val_loss: 0.3149 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5773 - val_recall_tumor: 0.5681 - val_tumor_iou: 0.4090 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 169 lên WandB.\n\n--- Epoch 170/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.6036 - loss: 0.2617 - mean_iou_all: 0.4781 - precision_tumor: 0.6012 - recall_tumor: 0.6702 - tumor_iou: 0.4593","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54871\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.6035 - loss: 0.2617 - mean_iou_all: 0.4781 - precision_tumor: 0.6012 - recall_tumor: 0.6702 - tumor_iou: 0.4593 - val_acc: 0.9878 - val_dice_coef_metric_tumor: 0.4836 - val_loss: 0.3512 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5945 - val_recall_tumor: 0.4695 - val_tumor_iou: 0.3520 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 170 lên WandB.\n\n--- Epoch 171/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9874 - dice_coef_metric_tumor: 0.5943 - loss: 0.2651 - mean_iou_all: 0.4749 - precision_tumor: 0.5867 - recall_tumor: 0.6645 - tumor_iou: 0.4511","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54871\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9874 - dice_coef_metric_tumor: 0.5943 - loss: 0.2651 - mean_iou_all: 0.4749 - precision_tumor: 0.5867 - recall_tumor: 0.6645 - tumor_iou: 0.4511 - val_acc: 0.9872 - val_dice_coef_metric_tumor: 0.5283 - val_loss: 0.3241 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5695 - val_recall_tumor: 0.5576 - val_tumor_iou: 0.3949 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 171 lên WandB.\n\n--- Epoch 172/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.5776 - loss: 0.2695 - mean_iou_all: 0.4721 - precision_tumor: 0.5932 - recall_tumor: 0.6320 - tumor_iou: 0.4389","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54871\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.5776 - loss: 0.2694 - mean_iou_all: 0.4721 - precision_tumor: 0.5932 - recall_tumor: 0.6320 - tumor_iou: 0.4389 - val_acc: 0.9860 - val_dice_coef_metric_tumor: 0.4930 - val_loss: 0.3460 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5422 - val_recall_tumor: 0.5231 - val_tumor_iou: 0.3623 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 172 lên WandB.\n\n--- Epoch 173/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6026 - loss: 0.2577 - mean_iou_all: 0.4760 - precision_tumor: 0.6203 - recall_tumor: 0.6537 - tumor_iou: 0.4631","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54871\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6025 - loss: 0.2577 - mean_iou_all: 0.4759 - precision_tumor: 0.6202 - recall_tumor: 0.6537 - tumor_iou: 0.4631 - val_acc: 0.9878 - val_dice_coef_metric_tumor: 0.5370 - val_loss: 0.3187 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5770 - val_recall_tumor: 0.5649 - val_tumor_iou: 0.4017 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 173 lên WandB.\n\n--- Epoch 174/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6067 - loss: 0.2602 - mean_iou_all: 0.4698 - precision_tumor: 0.6168 - recall_tumor: 0.6534 - tumor_iou: 0.4636","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54871\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6067 - loss: 0.2602 - mean_iou_all: 0.4697 - precision_tumor: 0.6167 - recall_tumor: 0.6534 - tumor_iou: 0.4636 - val_acc: 0.9850 - val_dice_coef_metric_tumor: 0.5175 - val_loss: 0.3318 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4656 - val_recall_tumor: 0.6699 - val_tumor_iou: 0.3791 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 174 lên WandB.\n\n--- Epoch 175/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5856 - loss: 0.2720 - mean_iou_all: 0.4401 - precision_tumor: 0.5859 - recall_tumor: 0.6666 - tumor_iou: 0.4439","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54871\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5855 - loss: 0.2720 - mean_iou_all: 0.4400 - precision_tumor: 0.5858 - recall_tumor: 0.6666 - tumor_iou: 0.4439 - val_acc: 0.9844 - val_dice_coef_metric_tumor: 0.5245 - val_loss: 0.3276 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4935 - val_recall_tumor: 0.6507 - val_tumor_iou: 0.3928 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 175 lên WandB.\n\n--- Epoch 176/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6041 - loss: 0.2586 - mean_iou_all: 0.4630 - precision_tumor: 0.6026 - recall_tumor: 0.6810 - tumor_iou: 0.4658","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54871\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6041 - loss: 0.2587 - mean_iou_all: 0.4630 - precision_tumor: 0.6026 - recall_tumor: 0.6809 - tumor_iou: 0.4658 - val_acc: 0.9871 - val_dice_coef_metric_tumor: 0.5341 - val_loss: 0.3210 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5343 - val_recall_tumor: 0.5996 - val_tumor_iou: 0.4043 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 176 lên WandB.\n\n--- Epoch 177/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.5984 - loss: 0.2598 - mean_iou_all: 0.4759 - precision_tumor: 0.5873 - recall_tumor: 0.6820 - tumor_iou: 0.4566","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54871\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.5983 - loss: 0.2599 - mean_iou_all: 0.4759 - precision_tumor: 0.5873 - recall_tumor: 0.6820 - tumor_iou: 0.4566 - val_acc: 0.9858 - val_dice_coef_metric_tumor: 0.4924 - val_loss: 0.3468 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5653 - val_recall_tumor: 0.5374 - val_tumor_iou: 0.3629 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 177 lên WandB.\n\n--- Epoch 178/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5825 - loss: 0.2736 - mean_iou_all: 0.4681 - precision_tumor: 0.5740 - recall_tumor: 0.6573 - tumor_iou: 0.4409","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54871\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5825 - loss: 0.2736 - mean_iou_all: 0.4680 - precision_tumor: 0.5740 - recall_tumor: 0.6573 - tumor_iou: 0.4409 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5181 - val_loss: 0.3305 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6272 - val_recall_tumor: 0.5042 - val_tumor_iou: 0.3854 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 178 lên WandB.\n\n--- Epoch 179/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6095 - loss: 0.2568 - mean_iou_all: 0.4664 - precision_tumor: 0.6225 - recall_tumor: 0.6626 - tumor_iou: 0.4662","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.54871 to 0.55799, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 475ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6095 - loss: 0.2568 - mean_iou_all: 0.4663 - precision_tumor: 0.6225 - recall_tumor: 0.6626 - tumor_iou: 0.4662 - val_acc: 0.9883 - val_dice_coef_metric_tumor: 0.5580 - val_loss: 0.3066 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5954 - val_recall_tumor: 0.5821 - val_tumor_iou: 0.4214 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 179 lên WandB.\n\n--- Epoch 180/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6118 - loss: 0.2574 - mean_iou_all: 0.4811 - precision_tumor: 0.6164 - recall_tumor: 0.6661 - tumor_iou: 0.4694","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55799\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6118 - loss: 0.2574 - mean_iou_all: 0.4811 - precision_tumor: 0.6164 - recall_tumor: 0.6660 - tumor_iou: 0.4694 - val_acc: 0.9883 - val_dice_coef_metric_tumor: 0.5372 - val_loss: 0.3196 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6047 - val_recall_tumor: 0.5316 - val_tumor_iou: 0.4012 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 180 lên WandB.\n\n--- Epoch 181/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6213 - loss: 0.2581 - mean_iou_all: 0.4780 - precision_tumor: 0.6445 - recall_tumor: 0.6592 - tumor_iou: 0.4786","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55799\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6212 - loss: 0.2581 - mean_iou_all: 0.4779 - precision_tumor: 0.6444 - recall_tumor: 0.6591 - tumor_iou: 0.4785 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.5570 - val_loss: 0.3075 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5702 - val_recall_tumor: 0.5939 - val_tumor_iou: 0.4257 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 181 lên WandB.\n\n--- Epoch 182/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.6043 - loss: 0.2607 - mean_iou_all: 0.4748 - precision_tumor: 0.6060 - recall_tumor: 0.6621 - tumor_iou: 0.4625","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55799\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.6043 - loss: 0.2607 - mean_iou_all: 0.4748 - precision_tumor: 0.6060 - recall_tumor: 0.6621 - tumor_iou: 0.4625 - val_acc: 0.9874 - val_dice_coef_metric_tumor: 0.5215 - val_loss: 0.3298 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5657 - val_recall_tumor: 0.5484 - val_tumor_iou: 0.3884 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 182 lên WandB.\n\n--- Epoch 183/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6169 - loss: 0.2515 - mean_iou_all: 0.4725 - precision_tumor: 0.6175 - recall_tumor: 0.6861 - tumor_iou: 0.4775","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55799\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6168 - loss: 0.2515 - mean_iou_all: 0.4725 - precision_tumor: 0.6175 - recall_tumor: 0.6860 - tumor_iou: 0.4775 - val_acc: 0.9873 - val_dice_coef_metric_tumor: 0.5275 - val_loss: 0.3255 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5795 - val_recall_tumor: 0.5587 - val_tumor_iou: 0.3975 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 183 lên WandB.\n\n--- Epoch 184/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6030 - loss: 0.2629 - mean_iou_all: 0.4567 - precision_tumor: 0.6239 - recall_tumor: 0.6521 - tumor_iou: 0.4619","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55799\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6030 - loss: 0.2629 - mean_iou_all: 0.4566 - precision_tumor: 0.6238 - recall_tumor: 0.6520 - tumor_iou: 0.4619 - val_acc: 0.9883 - val_dice_coef_metric_tumor: 0.5257 - val_loss: 0.3268 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6290 - val_recall_tumor: 0.5119 - val_tumor_iou: 0.3920 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 184 lên WandB.\n\n--- Epoch 185/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6275 - loss: 0.2501 - mean_iou_all: 0.4496 - precision_tumor: 0.6397 - recall_tumor: 0.6734 - tumor_iou: 0.4848","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55799\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6275 - loss: 0.2501 - mean_iou_all: 0.4495 - precision_tumor: 0.6396 - recall_tumor: 0.6734 - tumor_iou: 0.4848 - val_acc: 0.9872 - val_dice_coef_metric_tumor: 0.5277 - val_loss: 0.3256 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5652 - val_recall_tumor: 0.5568 - val_tumor_iou: 0.3974 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 185 lên WandB.\n\n--- Epoch 186/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6153 - loss: 0.2560 - mean_iou_all: 0.4605 - precision_tumor: 0.6310 - recall_tumor: 0.6577 - tumor_iou: 0.4750","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.55799 to 0.56227, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 475ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6152 - loss: 0.2560 - mean_iou_all: 0.4604 - precision_tumor: 0.6309 - recall_tumor: 0.6577 - tumor_iou: 0.4749 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.5623 - val_loss: 0.3043 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6325 - val_recall_tumor: 0.5694 - val_tumor_iou: 0.4289 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 186 lên WandB.\n\n--- Epoch 187/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6176 - loss: 0.2552 - mean_iou_all: 0.4777 - precision_tumor: 0.6277 - recall_tumor: 0.6582 - tumor_iou: 0.4733","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56227\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6175 - loss: 0.2552 - mean_iou_all: 0.4776 - precision_tumor: 0.6277 - recall_tumor: 0.6582 - tumor_iou: 0.4733 - val_acc: 0.9811 - val_dice_coef_metric_tumor: 0.5077 - val_loss: 0.3400 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4525 - val_recall_tumor: 0.6968 - val_tumor_iou: 0.3748 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 187 lên WandB.\n\n--- Epoch 188/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9874 - dice_coef_metric_tumor: 0.6044 - loss: 0.2653 - mean_iou_all: 0.4789 - precision_tumor: 0.6046 - recall_tumor: 0.6709 - tumor_iou: 0.4595","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56227\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9874 - dice_coef_metric_tumor: 0.6044 - loss: 0.2653 - mean_iou_all: 0.4788 - precision_tumor: 0.6046 - recall_tumor: 0.6709 - tumor_iou: 0.4595 - val_acc: 0.9882 - val_dice_coef_metric_tumor: 0.5146 - val_loss: 0.3336 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6149 - val_recall_tumor: 0.5123 - val_tumor_iou: 0.3870 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 188 lên WandB.\n\n--- Epoch 189/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6092 - loss: 0.2586 - mean_iou_all: 0.4728 - precision_tumor: 0.6153 - recall_tumor: 0.6606 - tumor_iou: 0.4697","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56227\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6092 - loss: 0.2586 - mean_iou_all: 0.4727 - precision_tumor: 0.6153 - recall_tumor: 0.6606 - tumor_iou: 0.4697 - val_acc: 0.9835 - val_dice_coef_metric_tumor: 0.4936 - val_loss: 0.3495 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5297 - val_recall_tumor: 0.5342 - val_tumor_iou: 0.3663 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 189 lên WandB.\n\n--- Epoch 190/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6145 - loss: 0.2564 - mean_iou_all: 0.4772 - precision_tumor: 0.6244 - recall_tumor: 0.6681 - tumor_iou: 0.4703","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56227\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6145 - loss: 0.2564 - mean_iou_all: 0.4771 - precision_tumor: 0.6243 - recall_tumor: 0.6680 - tumor_iou: 0.4703 - val_acc: 0.9852 - val_dice_coef_metric_tumor: 0.5075 - val_loss: 0.3401 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4794 - val_recall_tumor: 0.6085 - val_tumor_iou: 0.3714 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 190 lên WandB.\n\n--- Epoch 191/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6250 - loss: 0.2498 - mean_iou_all: 0.4712 - precision_tumor: 0.6266 - recall_tumor: 0.6861 - tumor_iou: 0.4859","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56227\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6249 - loss: 0.2498 - mean_iou_all: 0.4711 - precision_tumor: 0.6265 - recall_tumor: 0.6860 - tumor_iou: 0.4858 - val_acc: 0.9858 - val_dice_coef_metric_tumor: 0.4886 - val_loss: 0.3507 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5480 - val_recall_tumor: 0.5066 - val_tumor_iou: 0.3596 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 191 lên WandB.\n\n--- Epoch 192/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.5968 - loss: 0.2607 - mean_iou_all: 0.4762 - precision_tumor: 0.5971 - recall_tumor: 0.6700 - tumor_iou: 0.4580","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56227\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.5967 - loss: 0.2607 - mean_iou_all: 0.4762 - precision_tumor: 0.5971 - recall_tumor: 0.6700 - tumor_iou: 0.4579 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5423 - val_loss: 0.3179 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6328 - val_recall_tumor: 0.5251 - val_tumor_iou: 0.4041 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 201 lên WandB.\n\n--- Epoch 202/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6209 - loss: 0.2523 - mean_iou_all: 0.4758 - precision_tumor: 0.6247 - recall_tumor: 0.6802 - tumor_iou: 0.4786","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56227\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6209 - loss: 0.2523 - mean_iou_all: 0.4758 - precision_tumor: 0.6247 - recall_tumor: 0.6801 - tumor_iou: 0.4786 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.5388 - val_loss: 0.3204 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5805 - val_recall_tumor: 0.5653 - val_tumor_iou: 0.4079 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 202 lên WandB.\n\n--- Epoch 203/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6196 - loss: 0.2548 - mean_iou_all: 0.4582 - precision_tumor: 0.6275 - recall_tumor: 0.6677 - tumor_iou: 0.4778","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56227\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6196 - loss: 0.2548 - mean_iou_all: 0.4580 - precision_tumor: 0.6275 - recall_tumor: 0.6677 - tumor_iou: 0.4778 - val_acc: 0.9882 - val_dice_coef_metric_tumor: 0.5315 - val_loss: 0.3250 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5867 - val_recall_tumor: 0.5458 - val_tumor_iou: 0.4007 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 203 lên WandB.\n\n--- Epoch 204/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6229 - loss: 0.2458 - mean_iou_all: 0.4658 - precision_tumor: 0.6300 - recall_tumor: 0.6751 - tumor_iou: 0.4832","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56227\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6229 - loss: 0.2458 - mean_iou_all: 0.4657 - precision_tumor: 0.6300 - recall_tumor: 0.6751 - tumor_iou: 0.4831 - val_acc: 0.9886 - val_dice_coef_metric_tumor: 0.5223 - val_loss: 0.3306 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6150 - val_recall_tumor: 0.5113 - val_tumor_iou: 0.3923 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 204 lên WandB.\n\n--- Epoch 205/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6193 - loss: 0.2583 - mean_iou_all: 0.4808 - precision_tumor: 0.6545 - recall_tumor: 0.6460 - tumor_iou: 0.4784","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.56227 to 0.56716, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 474ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6193 - loss: 0.2583 - mean_iou_all: 0.4808 - precision_tumor: 0.6544 - recall_tumor: 0.6460 - tumor_iou: 0.4784 - val_acc: 0.9888 - val_dice_coef_metric_tumor: 0.5672 - val_loss: 0.3031 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6100 - val_recall_tumor: 0.5850 - val_tumor_iou: 0.4324 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 205 lên WandB.\n\n--- Epoch 206/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6295 - loss: 0.2456 - mean_iou_all: 0.4773 - precision_tumor: 0.6404 - recall_tumor: 0.6703 - tumor_iou: 0.4864","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56716\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6294 - loss: 0.2456 - mean_iou_all: 0.4772 - precision_tumor: 0.6404 - recall_tumor: 0.6703 - tumor_iou: 0.4863 - val_acc: 0.9847 - val_dice_coef_metric_tumor: 0.5345 - val_loss: 0.3250 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4945 - val_recall_tumor: 0.6784 - val_tumor_iou: 0.3982 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 206 lên WandB.\n\n--- Epoch 207/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6325 - loss: 0.2486 - mean_iou_all: 0.4716 - precision_tumor: 0.6436 - recall_tumor: 0.6933 - tumor_iou: 0.4903","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56716\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6325 - loss: 0.2486 - mean_iou_all: 0.4715 - precision_tumor: 0.6436 - recall_tumor: 0.6932 - tumor_iou: 0.4903 - val_acc: 0.9875 - val_dice_coef_metric_tumor: 0.5436 - val_loss: 0.3182 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5370 - val_recall_tumor: 0.6060 - val_tumor_iou: 0.4097 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 207 lên WandB.\n\n--- Epoch 208/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6004 - loss: 0.2611 - mean_iou_all: 0.4663 - precision_tumor: 0.6008 - recall_tumor: 0.6584 - tumor_iou: 0.4617","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56716\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6004 - loss: 0.2611 - mean_iou_all: 0.4661 - precision_tumor: 0.6008 - recall_tumor: 0.6584 - tumor_iou: 0.4617 - val_acc: 0.9882 - val_dice_coef_metric_tumor: 0.5564 - val_loss: 0.3099 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5737 - val_recall_tumor: 0.6007 - val_tumor_iou: 0.4221 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 208 lên WandB.\n\n--- Epoch 209/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6399 - loss: 0.2417 - mean_iou_all: 0.4578 - precision_tumor: 0.6558 - recall_tumor: 0.6837 - tumor_iou: 0.4981","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56716\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6399 - loss: 0.2417 - mean_iou_all: 0.4577 - precision_tumor: 0.6557 - recall_tumor: 0.6837 - tumor_iou: 0.4980 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5504 - val_loss: 0.3138 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6015 - val_recall_tumor: 0.5651 - val_tumor_iou: 0.4190 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 209 lên WandB.\n\n--- Epoch 210/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6292 - loss: 0.2448 - mean_iou_all: 0.4356 - precision_tumor: 0.6383 - recall_tumor: 0.6724 - tumor_iou: 0.4915","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56716\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6292 - loss: 0.2448 - mean_iou_all: 0.4355 - precision_tumor: 0.6383 - recall_tumor: 0.6724 - tumor_iou: 0.4915 - val_acc: 0.9863 - val_dice_coef_metric_tumor: 0.5524 - val_loss: 0.3136 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5093 - val_recall_tumor: 0.6755 - val_tumor_iou: 0.4169 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 210 lên WandB.\n\n--- Epoch 211/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6242 - loss: 0.2525 - mean_iou_all: 0.4479 - precision_tumor: 0.6356 - recall_tumor: 0.6684 - tumor_iou: 0.4828","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56716\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6242 - loss: 0.2525 - mean_iou_all: 0.4478 - precision_tumor: 0.6356 - recall_tumor: 0.6684 - tumor_iou: 0.4828 - val_acc: 0.9873 - val_dice_coef_metric_tumor: 0.5548 - val_loss: 0.3118 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5333 - val_recall_tumor: 0.6448 - val_tumor_iou: 0.4163 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 211 lên WandB.\n\n--- Epoch 212/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6119 - loss: 0.2591 - mean_iou_all: 0.4610 - precision_tumor: 0.6217 - recall_tumor: 0.6598 - tumor_iou: 0.4693","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56716\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6119 - loss: 0.2591 - mean_iou_all: 0.4608 - precision_tumor: 0.6217 - recall_tumor: 0.6598 - tumor_iou: 0.4693 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.5619 - val_loss: 0.3069 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5972 - val_recall_tumor: 0.5808 - val_tumor_iou: 0.4295 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 212 lên WandB.\n\n--- Epoch 213/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6335 - loss: 0.2436 - mean_iou_all: 0.4750 - precision_tumor: 0.6470 - recall_tumor: 0.6833 - tumor_iou: 0.4945","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56716\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6335 - loss: 0.2436 - mean_iou_all: 0.4749 - precision_tumor: 0.6470 - recall_tumor: 0.6832 - tumor_iou: 0.4945 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.5422 - val_loss: 0.3187 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6458 - val_recall_tumor: 0.5193 - val_tumor_iou: 0.4094 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 213 lên WandB.\n\n--- Epoch 214/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6098 - loss: 0.2597 - mean_iou_all: 0.4815 - precision_tumor: 0.6361 - recall_tumor: 0.6539 - tumor_iou: 0.4710","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56716\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6097 - loss: 0.2597 - mean_iou_all: 0.4815 - precision_tumor: 0.6360 - recall_tumor: 0.6539 - tumor_iou: 0.4709 - val_acc: 0.9837 - val_dice_coef_metric_tumor: 0.5286 - val_loss: 0.3294 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4686 - val_recall_tumor: 0.6967 - val_tumor_iou: 0.3915 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 214 lên WandB.\n\n--- Epoch 215/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6412 - loss: 0.2432 - mean_iou_all: 0.4749 - precision_tumor: 0.6574 - recall_tumor: 0.6784 - tumor_iou: 0.5009","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56716\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6412 - loss: 0.2432 - mean_iou_all: 0.4748 - precision_tumor: 0.6574 - recall_tumor: 0.6784 - tumor_iou: 0.5008 - val_acc: 0.9869 - val_dice_coef_metric_tumor: 0.5526 - val_loss: 0.3138 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5355 - val_recall_tumor: 0.6339 - val_tumor_iou: 0.4151 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 215 lên WandB.\n\n--- Epoch 216/300 ---\n\u001b[1m328/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 415ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6466 - loss: 0.2451 - mean_iou_all: 0.4717 - precision_tumor: 0.6634 - recall_tumor: 0.6877 - tumor_iou: 0.5040\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56716\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6461 - loss: 0.2449 - mean_iou_all: 0.4710 - precision_tumor: 0.6629 - recall_tumor: 0.6876 - tumor_iou: 0.5036 - val_acc: 0.9887 - val_dice_coef_metric_tumor: 0.5264 - val_loss: 0.3290 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6361 - val_recall_tumor: 0.5015 - val_tumor_iou: 0.3978 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 216 lên WandB.\n\n--- Epoch 217/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6351 - loss: 0.2461 - mean_iou_all: 0.4700 - precision_tumor: 0.6558 - recall_tumor: 0.6802 - tumor_iou: 0.4940","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56716\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6350 - loss: 0.2461 - mean_iou_all: 0.4699 - precision_tumor: 0.6557 - recall_tumor: 0.6802 - tumor_iou: 0.4939 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.4846 - val_loss: 0.3554 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7436 - val_recall_tumor: 0.4001 - val_tumor_iou: 0.3582 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 217 lên WandB.\n\n--- Epoch 218/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6238 - loss: 0.2479 - mean_iou_all: 0.4627 - precision_tumor: 0.6371 - recall_tumor: 0.6848 - tumor_iou: 0.4862","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56716\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6238 - loss: 0.2479 - mean_iou_all: 0.4627 - precision_tumor: 0.6371 - recall_tumor: 0.6848 - tumor_iou: 0.4862 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.5563 - val_loss: 0.3104 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6409 - val_recall_tumor: 0.5445 - val_tumor_iou: 0.4204 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 218 lên WandB.\n\n--- Epoch 219/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6325 - loss: 0.2438 - mean_iou_all: 0.4592 - precision_tumor: 0.6249 - recall_tumor: 0.7008 - tumor_iou: 0.4949","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.56716 to 0.58173, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 475ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6324 - loss: 0.2437 - mean_iou_all: 0.4591 - precision_tumor: 0.6249 - recall_tumor: 0.7008 - tumor_iou: 0.4949 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5817 - val_loss: 0.2955 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5898 - val_recall_tumor: 0.6369 - val_tumor_iou: 0.4467 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 219 lên WandB.\n\n--- Epoch 220/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6199 - loss: 0.2518 - mean_iou_all: 0.4566 - precision_tumor: 0.6286 - recall_tumor: 0.6787 - tumor_iou: 0.4798","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58173\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6199 - loss: 0.2518 - mean_iou_all: 0.4565 - precision_tumor: 0.6285 - recall_tumor: 0.6786 - tumor_iou: 0.4798 - val_acc: 0.9854 - val_dice_coef_metric_tumor: 0.5085 - val_loss: 0.3413 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5106 - val_recall_tumor: 0.5851 - val_tumor_iou: 0.3746 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 220 lên WandB.\n\n--- Epoch 221/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6314 - loss: 0.2447 - mean_iou_all: 0.4519 - precision_tumor: 0.6396 - recall_tumor: 0.6753 - tumor_iou: 0.4907","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58173\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6313 - loss: 0.2447 - mean_iou_all: 0.4518 - precision_tumor: 0.6395 - recall_tumor: 0.6754 - tumor_iou: 0.4907 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5604 - val_loss: 0.3086 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6123 - val_recall_tumor: 0.5675 - val_tumor_iou: 0.4265 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 221 lên WandB.\n\n--- Epoch 222/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6269 - loss: 0.2540 - mean_iou_all: 0.4524 - precision_tumor: 0.6404 - recall_tumor: 0.6752 - tumor_iou: 0.4834","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58173\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6269 - loss: 0.2539 - mean_iou_all: 0.4523 - precision_tumor: 0.6404 - recall_tumor: 0.6752 - tumor_iou: 0.4835 - val_acc: 0.9886 - val_dice_coef_metric_tumor: 0.5720 - val_loss: 0.3020 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5881 - val_recall_tumor: 0.6230 - val_tumor_iou: 0.4373 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 222 lên WandB.\n\n--- Epoch 223/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6517 - loss: 0.2367 - mean_iou_all: 0.4674 - precision_tumor: 0.6619 - recall_tumor: 0.6927 - tumor_iou: 0.5128","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58173\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6516 - loss: 0.2367 - mean_iou_all: 0.4672 - precision_tumor: 0.6619 - recall_tumor: 0.6926 - tumor_iou: 0.5127 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.5518 - val_loss: 0.3137 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6180 - val_recall_tumor: 0.5632 - val_tumor_iou: 0.4178 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 223 lên WandB.\n\n--- Epoch 224/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6244 - loss: 0.2512 - mean_iou_all: 0.4500 - precision_tumor: 0.6379 - recall_tumor: 0.6774 - tumor_iou: 0.4839","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58173\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6244 - loss: 0.2512 - mean_iou_all: 0.4499 - precision_tumor: 0.6379 - recall_tumor: 0.6773 - tumor_iou: 0.4839 - val_acc: 0.9866 - val_dice_coef_metric_tumor: 0.5585 - val_loss: 0.3107 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5322 - val_recall_tumor: 0.6545 - val_tumor_iou: 0.4239 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 224 lên WandB.\n\n--- Epoch 225/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6370 - loss: 0.2489 - mean_iou_all: 0.4577 - precision_tumor: 0.6528 - recall_tumor: 0.6734 - tumor_iou: 0.4981","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58173\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6370 - loss: 0.2489 - mean_iou_all: 0.4576 - precision_tumor: 0.6528 - recall_tumor: 0.6734 - tumor_iou: 0.4980 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5644 - val_loss: 0.3064 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5850 - val_recall_tumor: 0.5955 - val_tumor_iou: 0.4289 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 225 lên WandB.\n\n--- Epoch 226/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6408 - loss: 0.2435 - mean_iou_all: 0.4720 - precision_tumor: 0.6534 - recall_tumor: 0.6853 - tumor_iou: 0.4978","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58173\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6408 - loss: 0.2435 - mean_iou_all: 0.4719 - precision_tumor: 0.6535 - recall_tumor: 0.6853 - tumor_iou: 0.4978 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5541 - val_loss: 0.3127 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6784 - val_recall_tumor: 0.5251 - val_tumor_iou: 0.4185 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 226 lên WandB.\n\n--- Epoch 227/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6340 - loss: 0.2476 - mean_iou_all: 0.4381 - precision_tumor: 0.6500 - recall_tumor: 0.6759 - tumor_iou: 0.4911","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58173\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6340 - loss: 0.2476 - mean_iou_all: 0.4380 - precision_tumor: 0.6500 - recall_tumor: 0.6758 - tumor_iou: 0.4910 - val_acc: 0.9895 - val_dice_coef_metric_tumor: 0.5482 - val_loss: 0.3162 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6716 - val_recall_tumor: 0.5115 - val_tumor_iou: 0.4132 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 227 lên WandB.\n\n--- Epoch 228/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6278 - loss: 0.2503 - mean_iou_all: 0.4635 - precision_tumor: 0.6322 - recall_tumor: 0.6834 - tumor_iou: 0.4866","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58173\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6278 - loss: 0.2503 - mean_iou_all: 0.4633 - precision_tumor: 0.6322 - recall_tumor: 0.6834 - tumor_iou: 0.4866 - val_acc: 0.9881 - val_dice_coef_metric_tumor: 0.5494 - val_loss: 0.3163 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5602 - val_recall_tumor: 0.5898 - val_tumor_iou: 0.4160 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 228 lên WandB.\n\n--- Epoch 229/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6373 - loss: 0.2437 - mean_iou_all: 0.4601 - precision_tumor: 0.6555 - recall_tumor: 0.6783 - tumor_iou: 0.4978","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58173\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6372 - loss: 0.2437 - mean_iou_all: 0.4600 - precision_tumor: 0.6554 - recall_tumor: 0.6783 - tumor_iou: 0.4977 - val_acc: 0.9895 - val_dice_coef_metric_tumor: 0.5760 - val_loss: 0.2999 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6495 - val_recall_tumor: 0.5695 - val_tumor_iou: 0.4406 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 229 lên WandB.\n\n--- Epoch 230/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6330 - loss: 0.2473 - mean_iou_all: 0.4641 - precision_tumor: 0.6481 - recall_tumor: 0.6711 - tumor_iou: 0.4939","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58173\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6330 - loss: 0.2472 - mean_iou_all: 0.4640 - precision_tumor: 0.6481 - recall_tumor: 0.6711 - tumor_iou: 0.4939 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5562 - val_loss: 0.3120 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6011 - val_recall_tumor: 0.5702 - val_tumor_iou: 0.4240 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 230 lên WandB.\n\n--- Epoch 231/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6554 - loss: 0.2386 - mean_iou_all: 0.4599 - precision_tumor: 0.6700 - recall_tumor: 0.6987 - tumor_iou: 0.5135","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58173\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6553 - loss: 0.2386 - mean_iou_all: 0.4598 - precision_tumor: 0.6700 - recall_tumor: 0.6987 - tumor_iou: 0.5134 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5312 - val_loss: 0.3269 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6352 - val_recall_tumor: 0.5285 - val_tumor_iou: 0.3972 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 231 lên WandB.\n\n--- Epoch 232/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6442 - loss: 0.2415 - mean_iou_all: 0.4571 - precision_tumor: 0.6568 - recall_tumor: 0.6860 - tumor_iou: 0.5046","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58173\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6442 - loss: 0.2415 - mean_iou_all: 0.4570 - precision_tumor: 0.6568 - recall_tumor: 0.6860 - tumor_iou: 0.5046 - val_acc: 0.9886 - val_dice_coef_metric_tumor: 0.5422 - val_loss: 0.3212 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6323 - val_recall_tumor: 0.5279 - val_tumor_iou: 0.4060 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 232 lên WandB.\n\n--- Epoch 233/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6349 - loss: 0.2449 - mean_iou_all: 0.4528 - precision_tumor: 0.6434 - recall_tumor: 0.6940 - tumor_iou: 0.4980","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58173\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6349 - loss: 0.2449 - mean_iou_all: 0.4527 - precision_tumor: 0.6434 - recall_tumor: 0.6939 - tumor_iou: 0.4980 - val_acc: 0.9871 - val_dice_coef_metric_tumor: 0.5474 - val_loss: 0.3177 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5497 - val_recall_tumor: 0.6186 - val_tumor_iou: 0.4117 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 233 lên WandB.\n\n--- Epoch 234/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6418 - loss: 0.2417 - mean_iou_all: 0.4572 - precision_tumor: 0.6540 - recall_tumor: 0.6882 - tumor_iou: 0.5005","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor improved from 0.58173 to 0.58889, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_22052025_094709.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 475ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6417 - loss: 0.2417 - mean_iou_all: 0.4571 - precision_tumor: 0.6540 - recall_tumor: 0.6882 - tumor_iou: 0.5005 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.5889 - val_loss: 0.2923 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6091 - val_recall_tumor: 0.6242 - val_tumor_iou: 0.4499 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 234 lên WandB.\n\n--- Epoch 235/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6476 - loss: 0.2387 - mean_iou_all: 0.4619 - precision_tumor: 0.6485 - recall_tumor: 0.6984 - tumor_iou: 0.5101","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58889\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6476 - loss: 0.2387 - mean_iou_all: 0.4618 - precision_tumor: 0.6485 - recall_tumor: 0.6983 - tumor_iou: 0.5101 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.5442 - val_loss: 0.3191 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6758 - val_recall_tumor: 0.5099 - val_tumor_iou: 0.4116 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 235 lên WandB.\n\n--- Epoch 236/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6407 - loss: 0.2426 - mean_iou_all: 0.4470 - precision_tumor: 0.6567 - recall_tumor: 0.6808 - tumor_iou: 0.5022","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58889\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6407 - loss: 0.2426 - mean_iou_all: 0.4469 - precision_tumor: 0.6566 - recall_tumor: 0.6808 - tumor_iou: 0.5022 - val_acc: 0.9888 - val_dice_coef_metric_tumor: 0.5719 - val_loss: 0.3028 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5985 - val_recall_tumor: 0.6004 - val_tumor_iou: 0.4326 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 236 lên WandB.\n\n--- Epoch 237/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6363 - loss: 0.2466 - mean_iou_all: 0.4671 - precision_tumor: 0.6426 - recall_tumor: 0.6848 - tumor_iou: 0.4976","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58889\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6363 - loss: 0.2466 - mean_iou_all: 0.4670 - precision_tumor: 0.6426 - recall_tumor: 0.6848 - tumor_iou: 0.4976 - val_acc: 0.9888 - val_dice_coef_metric_tumor: 0.5633 - val_loss: 0.3079 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6105 - val_recall_tumor: 0.5792 - val_tumor_iou: 0.4296 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 237 lên WandB.\n\n--- Epoch 238/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6588 - loss: 0.2371 - mean_iou_all: 0.4310 - precision_tumor: 0.6732 - recall_tumor: 0.6985 - tumor_iou: 0.5162","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58889\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6587 - loss: 0.2371 - mean_iou_all: 0.4308 - precision_tumor: 0.6732 - recall_tumor: 0.6985 - tumor_iou: 0.5162 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5877 - val_loss: 0.2936 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5954 - val_recall_tumor: 0.6323 - val_tumor_iou: 0.4515 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 238 lên WandB.\n\n--- Epoch 239/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6457 - loss: 0.2414 - mean_iou_all: 0.4446 - precision_tumor: 0.6488 - recall_tumor: 0.6987 - tumor_iou: 0.5091","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58889\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 468ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6457 - loss: 0.2414 - mean_iou_all: 0.4444 - precision_tumor: 0.6488 - recall_tumor: 0.6987 - tumor_iou: 0.5090 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5627 - val_loss: 0.3087 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6365 - val_recall_tumor: 0.5532 - val_tumor_iou: 0.4290 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 239 lên WandB.\n\n--- Epoch 240/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6401 - loss: 0.2421 - mean_iou_all: 0.4412 - precision_tumor: 0.6491 - recall_tumor: 0.6883 - tumor_iou: 0.5070","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58889\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6401 - loss: 0.2421 - mean_iou_all: 0.4411 - precision_tumor: 0.6491 - recall_tumor: 0.6883 - tumor_iou: 0.5069 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.5736 - val_loss: 0.3027 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6386 - val_recall_tumor: 0.5668 - val_tumor_iou: 0.4357 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 240 lên WandB.\n\n--- Epoch 241/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6492 - loss: 0.2404 - mean_iou_all: 0.4747 - precision_tumor: 0.6595 - recall_tumor: 0.6955 - tumor_iou: 0.5079","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58889\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6491 - loss: 0.2404 - mean_iou_all: 0.4747 - precision_tumor: 0.6595 - recall_tumor: 0.6955 - tumor_iou: 0.5079 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.5469 - val_loss: 0.3188 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6082 - val_recall_tumor: 0.5460 - val_tumor_iou: 0.4170 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Đã log metrics cho epoch 241 lên WandB.\n\n--- Epoch 242/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6355 - loss: 0.2502 - mean_iou_all: 0.4713 - precision_tumor: 0.6375 - recall_tumor: 0.6979 - tumor_iou: 0.4956","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58889\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 467ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6355 - loss: 0.2502 - mean_iou_all: 0.4712 - precision_tumor: 0.6376 - recall_tumor: 0.6979 - tumor_iou: 0.4956 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.5853 - val_loss: 0.2948 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6180 - val_recall_tumor: 0.6046 - val_tumor_iou: 0.4495 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 242 lên WandB.\n\n--- Epoch 243/300 ---\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  7/336\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:20\u001b[0m 428ms/step - acc: 0.9826 - dice_coef_metric_tumor: 0.7582 - loss: 0.2749 - mean_iou_all: 0.5507 - precision_tumor: 0.7864 - recall_tumor: 0.7550 - tumor_iou: 0.6206","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"bản cũ bị xung đột phiên bản (wandb callback)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wandb login 2b7e633df37247dd52582a893eecab6314151a62","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:03:36.581875Z","iopub.execute_input":"2025-05-22T02:03:36.582261Z","iopub.status.idle":"2025-05-22T02:03:37.816382Z","shell.execute_reply.started":"2025-05-22T02:03:36.582220Z","shell.execute_reply":"2025-05-22T02:03:37.815300Z"}},"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"!export WANDB_API_KEY=\"2b7e633df37247dd52582a893eecab6314151a62\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:03:39.990023Z","iopub.execute_input":"2025-05-22T02:03:39.990348Z","iopub.status.idle":"2025-05-22T02:03:40.159660Z","shell.execute_reply.started":"2025-05-22T02:03:39.990320Z","shell.execute_reply":"2025-05-22T02:03:40.158657Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"!ping api.wandb.ai\n!curl https://api.wandb.ai/status","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:03:42.062239Z","iopub.execute_input":"2025-05-22T02:03:42.062586Z","iopub.status.idle":"2025-05-22T02:03:42.671926Z","shell.execute_reply.started":"2025-05-22T02:03:42.062559Z","shell.execute_reply":"2025-05-22T02:03:42.671115Z"}},"outputs":[{"name":"stdout","text":"/bin/bash: line 1: ping: command not found\n404 page not found\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom PIL import Image, ImageDraw\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom typing import Optional, Tuple\n\nimport wandb # <<< THÊM DÒNG NÀY\nfrom wandb.integration.keras import WandbCallback","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:11:04.537216Z","iopub.execute_input":"2025-05-22T02:11:04.537614Z","iopub.status.idle":"2025-05-22T02:11:04.544046Z","shell.execute_reply.started":"2025-05-22T02:11:04.537533Z","shell.execute_reply":"2025-05-22T02:11:04.543124Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# --- Cấu hình ---\nINPUT_DATA_ROOT = '/kaggle/input/btxrd-data' # THAY ĐỔI NẾU MÔI TRƯỜNG CỦA BẠN KHÁC\nBASE_DATA_DIR = os.path.join(INPUT_DATA_ROOT, 'btxrd-v2.1')\nCLASSIFICATION_FILE = os.path.join(INPUT_DATA_ROOT, 'classification.xlsx')\nIMAGE_SUBDIR_NAME = 'images'\nANNOTATION_SUBDIR_NAME = 'annotations'\n\n# Tham số Model & Huấn luyện\nTARGET_SIZE = 512\nN_CLASSES = 2 # 2 lớp: 0 (nền), 1 (khối u)\nBATCH_SIZE = 4\nBUFFER_SIZE = 100\nEPOCHS = 300 # Tăng epochs, EarlyStopping sẽ xử lý\nLEARNING_RATE = 1e-4\nL2_REG_FACTOR = 1e-5\nDROPOUT_RATE = 0.3\n\n# --- Cải tiến để tăng IoU ---\nUSE_COMBINED_LOSS = True\nDICE_LOSS_WEIGHT = 0.6 # Ưu tiên Dice hơn một chút, hoặc giữ 0.5\nUSE_FOCAL_LOSS_IN_COMBINED = True # **MẶC ĐỊNH SỬ DỤNG FOCAL LOSS**\nFOCAL_LOSS_ALPHA = 0.25 # Alpha cho Focal Loss\nFOCAL_LOSS_GAMMA = 2.0  # Gamma cho Focal Loss\n\nUSE_ATTENTION_UNET = False # Thử nghiệm bật/tắt sau\n# USE_ALBUMENTATIONS = False # Tạm thời không dùng để giữ code đơn giản\n\nAPPLY_POST_PROCESSING = True\nPOST_PROCESSING_KERNEL_SIZE = (5,5)\nMIN_AREA_POST_PROCESSING = 30\n\nMODEL_CHECKPOINT_BASENAME = \"unet_model\"\nTENSORBOARD_LOG_DIR = \"./logs_unet_iou_focused\"\n\n# --- Các hằng số cho callback ---\nPATIENCE_EARLY_STOPPING = 35 # Tăng patience\nPATIENCE_REDUCE_LR = 12  # Tăng patience\n\n# --- Cấu hình WandB ---\nWANDB_PROJECT_NAME = \"btxrd-project\" # Đặt tên project của bạn trên WandB\nWANDB_ENTITY = \"nganltt2333\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:11:06.370802Z","iopub.execute_input":"2025-05-22T02:11:06.371144Z","iopub.status.idle":"2025-05-22T02:11:06.378710Z","shell.execute_reply.started":"2025-05-22T02:11:06.371117Z","shell.execute_reply":"2025-05-22T02:11:06.377768Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"def get_valid_paths(base_dir: str, split_type: str, img_filename_with_ext: str) -> Optional[Tuple[str, str]]:\n    split_dir = os.path.join(base_dir, split_type); image_dir_path = os.path.join(split_dir, IMAGE_SUBDIR_NAME); annotation_dir_path = os.path.join(split_dir, ANNOTATION_SUBDIR_NAME)\n    img_path = os.path.join(image_dir_path, img_filename_with_ext); base_name = os.path.splitext(img_filename_with_ext)[0]; json_filename = base_name + '.json'\n    json_path = os.path.join(annotation_dir_path, json_filename)\n    if os.path.exists(img_path) and os.path.exists(json_path): return img_path, json_path\n    return None\n\ndef create_mask_pil(mask_size: Tuple[int, int], json_path: str) -> Image.Image:\n    if not os.path.exists(json_path): return Image.new('L', (mask_size[1], mask_size[0]), 0)\n    mask = Image.new('L', (mask_size[1], mask_size[0]), 0)\n    try:\n        with open(json_path, 'r') as f: data = json.load(f)\n        if 'shapes' not in data or not isinstance(data['shapes'], list) or not data['shapes']: return mask\n        for shape in data['shapes']:\n             if 'points' in shape and isinstance(shape['points'], list):\n                  polygon = [tuple(point) for point in shape['points']]\n                  if len(polygon) >= 3: ImageDraw.Draw(mask).polygon(polygon, outline=255, fill=255)\n    except (json.JSONDecodeError, Exception): return Image.new('L', (mask_size[1], mask_size[0]), 0)\n    return mask\n\ndef plot_image(ax: plt.Axes, image_data: np.ndarray, title: str, cmap='gray'):\n    if image_data.ndim == 2 or (image_data.ndim == 3 and image_data.shape[2] == 1): ax.imshow(image_data.squeeze(), cmap=cmap)\n    else: ax.imshow(image_data)\n    ax.set_title(title, fontsize=10); ax.axis('off')\n\nall_image_paths = []; all_mask_paths = []; all_types = []\ntry:\n    if not os.path.exists(CLASSIFICATION_FILE): raise FileNotFoundError(f\"Không tìm thấy file phân loại tại {CLASSIFICATION_FILE}\")\n    if not os.path.isdir(BASE_DATA_DIR): raise FileNotFoundError(f\"Không tìm thấy thư mục dữ liệu cơ sở: {BASE_DATA_DIR}\")\n    df_classification = pd.read_excel(CLASSIFICATION_FILE)\n    required_cols = ['image_filename', 'type']\n    if not all(col in df_classification.columns for col in required_cols): raise ValueError(f\"File Excel phải chứa các cột: {required_cols}\")\n    for index, row in tqdm(df_classification.iterrows(), total=len(df_classification), desc=\"Kiểm tra file\"):\n        img_filename_with_ext = row['image_filename']; file_type = row['type']\n        if pd.isna(img_filename_with_ext) or pd.isna(file_type) or file_type not in ['train', 'val', 'test']: continue\n        paths = get_valid_paths(BASE_DATA_DIR, str(file_type).lower(), str(img_filename_with_ext))\n        if paths: img_path, json_path = paths; all_image_paths.append(img_path); all_mask_paths.append(json_path); all_types.append(str(file_type).lower())\n    if not all_image_paths: print(\"\\nLỗi: Không tìm thấy cặp ảnh-chú thích hợp lệ nào.\"); exit()\n    df_paths = pd.DataFrame({'image_path': all_image_paths, 'mask_path': all_mask_paths, 'type': all_types})\n    df_train = df_paths[df_paths['type'] == 'train'].reset_index(drop=True); df_val = df_paths[df_paths['type'] == 'val'].reset_index(drop=True); df_test = df_paths[df_paths['type'] == 'test'].reset_index(drop=True)\n    train_image_paths = df_train['image_path'].tolist(); train_mask_paths = df_train['mask_path'].tolist()\n    val_image_paths = df_val['image_path'].tolist(); val_mask_paths = df_val['mask_path'].tolist()\n    test_image_paths = df_test['image_path'].tolist(); test_mask_paths = df_test['mask_path'].tolist()\n    print(f\"\\nPhân chia dữ liệu: Train({len(train_image_paths)}), Val({len(val_image_paths)}), Test({len(test_image_paths)})\")\n    if not train_image_paths: print(\"Cảnh báo: Tập huấn luyện rỗng!\"); exit()\nexcept Exception as e: print(f\"Lỗi khi tải siêu dữ liệu: {e}\"); import traceback; traceback.print_exc(); exit()\n\n# Tính toán Mean/Std\nmean_pixel = 0.5; std_pixel = 0.1\nnum_train_images = len(train_image_paths)\nif num_train_images > 0:\n    print(\"Đang tính toán Mean/Std...\")\n    pixel_sum = 0.0; pixel_sum_sq = 0.0; total_pixels_calculated = 0; processed_count = 0\n    sample_size_for_stats = min(num_train_images, 250) # Tăng nhẹ sample size\n    sampled_train_paths = np.random.choice(train_image_paths, size=sample_size_for_stats, replace=False)\n    for img_path in tqdm(sampled_train_paths, desc=\"Tính Mean/Std\"):\n        try:\n            img_bytes = tf.io.read_file(img_path); img = tf.io.decode_image(img_bytes, channels=1, expand_animations=False, dtype=tf.float32)\n            img = tf.image.resize(img, [TARGET_SIZE, TARGET_SIZE])\n            pixel_sum += tf.reduce_sum(img).numpy(); pixel_sum_sq += tf.reduce_sum(tf.square(img)).numpy()\n            total_pixels_calculated += (TARGET_SIZE * TARGET_SIZE); processed_count += 1\n        except Exception: pass\n    if processed_count > 0 and total_pixels_calculated > 0:\n        mean_pixel = pixel_sum / total_pixels_calculated; variance = (pixel_sum_sq / total_pixels_calculated) - (mean_pixel ** 2)\n        std_pixel = np.sqrt(max(variance, 1e-7)); print(f\"Mean: {mean_pixel:.4f}, Std Dev: {std_pixel:.4f}\")\n        if std_pixel < 1e-4: std_pixel = 0.1; print(\"Std Dev quá thấp, dùng mặc định 0.1.\")\n    else: print(f\"Cảnh báo: Không tính được mean/std, dùng mặc định.\")\nstd_pixel = max(std_pixel, 1e-7)\n\n# Pipeline Dữ liệu TensorFlow\ndef load_mask_from_json_py(json_path_bytes):\n    json_path = json_path_bytes.numpy().decode('utf-8'); pil_mask = create_mask_pil((TARGET_SIZE, TARGET_SIZE), json_path)\n    mask_np = np.array(pil_mask, dtype=np.uint8); mask_np = (mask_np > 128).astype(np.uint8)\n    return mask_np\n\n@tf.function\ndef load_and_preprocess(image_path, mask_json_path):\n    img_bytes = tf.io.read_file(image_path)\n    try: img = tf.io.decode_image(img_bytes, channels=1, expand_animations=False, dtype=tf.float32)\n    except tf.errors.InvalidArgumentError:\n        try: img = tf.image.decode_png(img_bytes, channels=1, dtype=tf.uint8); img = tf.cast(img, tf.float32) / 255.0\n        except tf.errors.InvalidArgumentError: img = tf.image.decode_jpeg(img_bytes, channels=1); img = tf.cast(img, tf.float32) / 255.0\n    img = tf.image.resize(img, [TARGET_SIZE, TARGET_SIZE]); img.set_shape([TARGET_SIZE, TARGET_SIZE, 1])\n    mask_np_binary = tf.py_function(func=load_mask_from_json_py, inp=[mask_json_path], Tout=tf.uint8)\n    mask_np_binary.set_shape([TARGET_SIZE, TARGET_SIZE])\n    mask_onehot = tf.one_hot(tf.cast(mask_np_binary, tf.int32), depth=N_CLASSES, dtype=tf.float32)\n    mask_onehot.set_shape([TARGET_SIZE, TARGET_SIZE, N_CLASSES])\n    img = (img - mean_pixel) / std_pixel\n    return img, mask_onehot\n\n@tf.function\ndef augment_data_tf(image, mask_onehot):\n    combined = tf.concat([image, tf.cast(mask_onehot, image.dtype)], axis=-1) # Nối image và mask (đã cast về dtype của image)\n    if tf.random.uniform(()) > 0.5: combined = tf.image.flip_left_right(combined)\n    if tf.random.uniform(()) > 0.5: combined = tf.image.flip_up_down(combined)\n    k_rot = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n    combined = tf.image.rot90(combined, k=k_rot)\n    img_aug = combined[..., :1]\n    mask_aug = tf.cast(combined[..., 1:], tf.float32)\n    img_aug = tf.image.random_brightness(img_aug, max_delta=0.25)\n    img_aug = tf.image.random_contrast(img_aug, lower=0.7, upper=1.3)\n    if tf.random.uniform(()) > 0.3:\n        scale = tf.random.uniform((), 0.8, 1.2)\n        new_height = tf.cast(TARGET_SIZE * scale, tf.int32)\n        new_width = tf.cast(TARGET_SIZE * scale, tf.int32)\n        img_scaled = tf.image.resize(img_aug, [new_height, new_width], method=tf.image.ResizeMethod.BILINEAR)\n        mask_scaled = tf.image.resize(mask_aug, [new_height, new_width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        img_aug = tf.image.resize_with_crop_or_pad(img_scaled, TARGET_SIZE, TARGET_SIZE)\n        mask_aug = tf.image.resize_with_crop_or_pad(mask_scaled, TARGET_SIZE, TARGET_SIZE)\n    img_aug = tf.clip_by_value(img_aug, -3.0, 3.0)\n    img_aug.set_shape([TARGET_SIZE, TARGET_SIZE, 1])\n    mask_aug.set_shape([TARGET_SIZE, TARGET_SIZE, N_CLASSES])\n    return img_aug, mask_aug\n\ndef create_dataset(image_paths, mask_paths, is_training=True):\n    if not image_paths or not mask_paths: return tf.data.Dataset.from_tensor_slices(([], [])).batch(BATCH_SIZE)\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n    if is_training: dataset = dataset.shuffle(buffer_size=min(BUFFER_SIZE, len(image_paths)), reshuffle_each_iteration=True)\n    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n    if is_training: dataset = dataset.map(augment_data_tf, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=(is_training if len(image_paths) >= BATCH_SIZE else False))\n    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return dataset\n\ntrain_ds = create_dataset(train_image_paths, train_mask_paths, is_training=True)\nval_ds = create_dataset(val_image_paths, val_mask_paths, is_training=False)\ntest_ds = create_dataset(test_image_paths, test_mask_paths, is_training=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:11:08.055289Z","iopub.execute_input":"2025-05-22T02:11:08.055628Z","iopub.status.idle":"2025-05-22T02:11:14.814765Z","shell.execute_reply.started":"2025-05-22T02:11:08.055602Z","shell.execute_reply":"2025-05-22T02:11:14.813893Z"}},"outputs":[{"name":"stderr","text":"Kiểm tra file: 100%|██████████| 3746/3746 [00:04<00:00, 928.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nPhân chia dữ liệu: Train(1344), Val(336), Test(187)\nĐang tính toán Mean/Std...\n","output_type":"stream"},{"name":"stderr","text":"Tính Mean/Std: 100%|██████████| 250/250 [00:01<00:00, 150.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Mean: 0.1980, Std Dev: 0.2364\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# UNET\nclass AttentionGate(layers.Layer):\n    def __init__(self, F_g, F_l, F_int, **kwargs): super(AttentionGate, self).__init__(**kwargs); self.W_g = layers.Conv2D(F_int, 1, padding='same', kernel_initializer='he_normal'); self.W_x = layers.Conv2D(F_int, 1, padding='same', kernel_initializer='he_normal'); self.psi = layers.Conv2D(1, 1, padding='same', kernel_initializer='he_normal', activation='sigmoid'); self.relu = layers.Activation('relu')\n    def call(self, g, x): g1 = self.W_g(g); x1 = self.W_x(x); psi_input = self.relu(g1 + x1); alpha = self.psi(psi_input); return x * alpha\ndef conv_block(inputs, num_filters, l2_reg, dropout):\n    x = layers.Conv2D(num_filters, 3, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(inputs); x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n    if dropout > 0: x = layers.Dropout(dropout)(x)\n    x = layers.Conv2D(num_filters, 3, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x); x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n    return x\ndef encoder_block(inputs, num_filters, l2_reg, dropout, pool=True): c = conv_block(inputs, num_filters, l2_reg, dropout); p = layers.MaxPooling2D(2)(c) if pool else None; return c, p\ndef decoder_block(inputs, skip_features, num_filters, l2_reg, dropout, use_attention):\n    x = layers.Conv2DTranspose(num_filters, 2, strides=2, padding='same')(inputs)\n    if use_attention and skip_features is not None: att_gate = AttentionGate(num_filters, skip_features.shape[-1], max(1, skip_features.shape[-1] // 2) ); skip_features = att_gate(g=x, x=skip_features)\n    if skip_features is not None: x = layers.Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters, l2_reg, dropout); return x\ndef build_unet(input_shape, n_classes=N_CLASSES, l2_reg=L2_REG_FACTOR, dropout=DROPOUT_RATE, use_attention=USE_ATTENTION_UNET):\n    filters = [64, 128, 256, 512, 1024]\n    inputs = keras.Input(shape=input_shape); skips = []; x = inputs\n    for f in filters[:-1]: s, p = encoder_block(x, f, l2_reg, dropout, pool=True); skips.append(s); x = p\n    x, _ = encoder_block(x, filters[-1], l2_reg, dropout*1.3, pool=False)\n    for i, f in reversed(list(enumerate(filters[:-1]))): x = decoder_block(x, skips[i], f, l2_reg, dropout, use_attention)\n    outputs = layers.Conv2D(n_classes, 1, padding='same', activation='softmax')(x)\n    return keras.Model(inputs, outputs, name=f\"{'Attention' if use_attention else ''}UNet_filters{filters[0]}\")\n\n# --- HÀM MẤT MÁT (LOSS FUNCTIONS) ---\nSMOOTH = 1e-6\ndef dice_coef(y_true_one_hot, y_pred_softmax):\n    y_true_f = tf.keras.backend.flatten(y_true_one_hot)\n    y_pred_f = tf.keras.backend.flatten(y_pred_softmax)\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    return (2. * intersection + SMOOTH) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + SMOOTH)\n\ndef dice_coef_metric_tumor(y_true, y_pred):\n    # y_true: (batch, H, W, N_CLASSES), y_pred: (batch, H, W, N_CLASSES)\n    return dice_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\ndice_coef_metric_tumor.__name__ = 'dice_coef_metric_tumor' # Khớp với `metrics_to_plot`\n\ndef dice_loss_tumor(y_true, y_pred):\n    return 1.0 - dice_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\n\ndef iou_coef(y_true_one_hot, y_pred_softmax):\n    y_true_f = tf.keras.backend.flatten(y_true_one_hot)\n    y_pred_f = tf.keras.backend.flatten(y_pred_softmax)\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n    return (intersection + SMOOTH) / (union + SMOOTH)\n\ndef iou_metric_tumor(y_true, y_pred):\n    return iou_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\niou_metric_tumor.__name__ = 'tumor_iou' # Khớp với `metrics_to_plot`\n\n# --- CÁC METRICS MỚI CHO LỚP TUMOR ---\ndef precision_recall_tumor_base(y_true, y_pred, metric_type):\n    if N_CLASSES < 2:\n        return tf.constant(0.0, dtype=tf.float32)\n\n    # Lấy kênh của lớp tumor (giả sử lớp 1 là tumor)\n    y_true_tumor = y_true[..., 1] # Ground truth cho lớp tumor (0 hoặc 1)\n    \n    # Chuyển đổi y_pred (softmax probabilities) thành dự đoán nhãn cứng (0 hoặc 1) cho lớp tumor\n    # Cách 1: Dựa trên xác suất cao nhất (argmax)\n    y_pred_labels = tf.argmax(y_pred, axis=-1) # Shape: (batch, H, W)\n    y_pred_tumor_binary = tf.cast(tf.equal(y_pred_labels, 1), tf.float32) # 1 nếu dự đoán là tumor (lớp 1), 0 nếu khác\n\n    # Cách 2: (Nếu chỉ có 2 lớp, có thể dùng ngưỡng 0.5 cho xác suất lớp tumor)\n    # y_pred_tumor_binary = tf.cast(y_pred[..., 1] > 0.5, tf.float32) # Chỉ phù hợp nếu N_CLASSES=2 và lớp 1 là tumor\n\n    # Flatten để tính toán\n    y_true_tumor_flat = tf.keras.backend.flatten(y_true_tumor)\n    y_pred_tumor_binary_flat = tf.keras.backend.flatten(y_pred_tumor_binary)\n\n    true_positives = tf.keras.backend.sum(y_true_tumor_flat * y_pred_tumor_binary_flat)\n    \n    if metric_type == 'precision':\n        predicted_positives = tf.keras.backend.sum(y_pred_tumor_binary_flat)\n        value = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n    elif metric_type == 'recall':\n        possible_positives = tf.keras.backend.sum(y_true_tumor_flat)\n        value = true_positives / (possible_positives + tf.keras.backend.epsilon())\n    else:\n        value = tf.constant(0.0, dtype=tf.float32)\n        \n    return value\n\ndef precision_tumor_metric(y_true, y_pred):\n    return precision_recall_tumor_base(y_true, y_pred, 'precision')\nprecision_tumor_metric.__name__ = 'precision_tumor' # Khớp với `metrics_to_plot`\n\ndef recall_tumor_metric(y_true, y_pred):\n    return precision_recall_tumor_base(y_true, y_pred, 'recall')\nrecall_tumor_metric.__name__ = 'recall_tumor' # Khớp với `metrics_to_plot`\n# --- KẾT THÚC METRICS MỚI ---\n\ndef categorical_focal_loss_wrapper(alpha=FOCAL_LOSS_ALPHA, gamma=FOCAL_LOSS_GAMMA):\n    def focal_loss_fn(y_true, y_pred):\n        epsilon = tf.keras.backend.epsilon(); y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n        cross_entropy = -y_true * tf.math.log(y_pred)\n        loss = alpha * tf.pow(1 - y_pred, gamma) * cross_entropy\n        return tf.reduce_mean(tf.reduce_sum(loss, axis=-1))\n    focal_loss_fn.__name__ = f'focal_loss_alpha{alpha}_gamma{gamma}'\n    return focal_loss_fn\n\ndef combined_loss_fn(y_true, y_pred, dice_w=DICE_LOSS_WEIGHT):\n    d_loss = dice_loss_tumor(y_true, y_pred)\n    if USE_FOCAL_LOSS_IN_COMBINED: ce_or_focal_loss = categorical_focal_loss_wrapper()(y_true, y_pred)\n    else: ce_or_focal_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true, y_pred))\n    return (dice_w * d_loss) + ((1.0 - dice_w) * ce_or_focal_loss)\ncombined_loss_fn.__name__ = f'combined_dice{DICE_LOSS_WEIGHT}_{\"focal\" if USE_FOCAL_LOSS_IN_COMBINED else \"cce\"}'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:11:19.088956Z","iopub.execute_input":"2025-05-22T02:11:19.089270Z","iopub.status.idle":"2025-05-22T02:11:19.111864Z","shell.execute_reply.started":"2025-05-22T02:11:19.089243Z","shell.execute_reply":"2025-05-22T02:11:19.110850Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"model = build_unet((TARGET_SIZE, TARGET_SIZE, 1))\noptimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n\n# --- Chọn và Compile Model với loss function ---\nif USE_COMBINED_LOSS:\n    loss_to_use = combined_loss_fn\nelse:\n    if USE_FOCAL_LOSS_IN_COMBINED:\n        loss_to_use = categorical_focal_loss_wrapper(alpha=FOCAL_LOSS_ALPHA, gamma=FOCAL_LOSS_GAMMA)\n    else:\n        loss_to_use = tf.keras.losses.CategoricalCrossentropy()\n        loss_to_use.__name__ = \"categorical_crossentropy\"\n\nloss_name_str = loss_to_use.__name__ if hasattr(loss_to_use, '__name__') else \"custom_loss\"\n\n# --- Định nghĩa danh sách metrics cho model.compile() ---\nmetrics_to_use = [\n    dice_coef_metric_tumor,  # Tên: 'dice_coef_metric_tumor'\n    iou_metric_tumor,        # Tên: 'tumor_iou'\n    precision_tumor_metric,  # Tên: 'precision_tumor'\n    recall_tumor_metric,     # Tên: 'recall_tumor'\n    tf.keras.metrics.MeanIoU(num_classes=N_CLASSES, name='mean_iou_all'), # Tên: 'mean_iou_all'\n    tf.keras.metrics.CategoricalAccuracy(name='acc') # Tên: 'acc' (pixel-wise accuracy)\n]\n# Lưu ý: Keras sẽ tự động tạo các phiên bản 'val_...' cho tập validation.\n\nmodel.compile(optimizer=optimizer, loss=loss_to_use, metrics=metrics_to_use)\nmodel.summary()\n\n\n# --- KHỞI TẠO WEIGHTS & BIASES ---\n# ... (phần wandb.init() và config giữ nguyên như trước) ...\n# Đảm bảo bạn đã đăng nhập wandb qua CLI hoặc đặt WANDB_API_KEY\n\nMONITOR_METRIC_CB = 'val_dice_coef_metric_tumor'\n\nwandb_config = {\n    \"TARGET_SIZE\": TARGET_SIZE,\n    \"N_CLASSES\": N_CLASSES,\n    \"BATCH_SIZE\": BATCH_SIZE,\n    \"EPOCHS\": EPOCHS,\n    \"LEARNING_RATE\": LEARNING_RATE,\n    \"L2_REG_FACTOR\": L2_REG_FACTOR,\n    \"DROPOUT_RATE\": DROPOUT_RATE,\n    \"USE_COMBINED_LOSS\": USE_COMBINED_LOSS,\n    \"DICE_LOSS_WEIGHT\": DICE_LOSS_WEIGHT,\n    \"USE_FOCAL_LOSS_IN_COMBINED\": USE_FOCAL_LOSS_IN_COMBINED,\n    \"FOCAL_LOSS_ALPHA\": FOCAL_LOSS_ALPHA,\n    \"FOCAL_LOSS_GAMMA\": FOCAL_LOSS_GAMMA,\n    \"USE_ATTENTION_UNET\": USE_ATTENTION_UNET,\n    \"PATIENCE_EARLY_STOPPING\": PATIENCE_EARLY_STOPPING,\n    \"PATIENCE_REDUCE_LR\": PATIENCE_REDUCE_LR,\n    \"MODEL_ARCHITECTURE\": model.name,\n    \"OPTIMIZER\": type(optimizer).__name__,\n    \"LOSS_FUNCTION\": loss_name_str,\n    \"MONITOR_METRIC_CB\": MONITOR_METRIC_CB,\n    \"MEAN_PIXEL_TRAIN\": mean_pixel,\n    \"STD_PIXEL_TRAIN\": std_pixel\n}\n\nrun_name_wandb = f\"{MODEL_CHECKPOINT_BASENAME}_{loss_name_str}_attn{USE_ATTENTION_UNET}_lr{LEARNING_RATE}_bs{BATCH_SIZE}\"\n\nwandb.init(\n    project=WANDB_PROJECT_NAME,\n    entity=WANDB_ENTITY,\n    config=wandb_config,\n    name=run_name_wandb,\n    sync_tensorboard=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:11:22.325911Z","iopub.execute_input":"2025-05-22T02:11:22.326257Z","iopub.status.idle":"2025-05-22T02:11:22.752809Z","shell.execute_reply.started":"2025-05-22T02:11:22.326227Z","shell.execute_reply":"2025-05-22T02:11:22.752150Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"UNet_filters64\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"UNet_filters64\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_57 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m640\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_54    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_54             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_58 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ dropout_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_55    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_55             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_59 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_56    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_56             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_60 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ dropout_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_57    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_57             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_61 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_58    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_58             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_62 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m590,080\u001b[0m │ dropout_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_59    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_59             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_63 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_60    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_60             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_64 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ dropout_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_61    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_61             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_65 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │      \u001b[38;5;34m4,719,616\u001b[0m │ max_pooling2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_62    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_62             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_66 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │      \u001b[38;5;34m9,438,208\u001b[0m │ dropout_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_63    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_63             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_12       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,097,664\u001b[0m │ activation_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_12            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_12[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_67 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m4,719,104\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_64    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_64             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_68 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ dropout_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_65    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_65             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_13       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m524,544\u001b[0m │ activation_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_13            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_13[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_69 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │      \u001b[38;5;34m1,179,904\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_66    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_66             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_70 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m590,080\u001b[0m │ dropout_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_67    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_67             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_14       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m131,200\u001b[0m │ activation_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_14            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_14[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_71 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m295,040\u001b[0m │ concatenate_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_68    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_68             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_34 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_72 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ dropout_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_69    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_72[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_69             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_15       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m32,832\u001b[0m │ activation_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_15            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_15[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_73 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m73,792\u001b[0m │ concatenate_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_70    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_73[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_70             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_35 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_74 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ dropout_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_71    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_74[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_71             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_75 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m2\u001b[0m)    │            \u001b[38;5;34m130\u001b[0m │ activation_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_54    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_54             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ dropout_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_55    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_55             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_56    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_56             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_57    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_57             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_58    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_58             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ dropout_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_59    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_59             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_60    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_60             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ dropout_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_61    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_61             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> │ max_pooling2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_62    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_62             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span> │ dropout_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_63    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_63             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_12       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ activation_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_12            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_64    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_64             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ dropout_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_65    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_65             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_13       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ activation_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_13            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_66    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_66             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ dropout_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_67    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_67             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_14       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ activation_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_14            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_68    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_68             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_69    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_69             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_15       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ activation_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_15            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_70    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_70             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ dropout_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_71    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_71             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ activation_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,054,210\u001b[0m (118.46 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,054,210</span> (118.46 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,042,434\u001b[0m (118.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,042,434</span> (118.42 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m11,776\u001b[0m (46.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,776</span> (46.00 KB)\n</pre>\n"},"metadata":{}},{"execution_count":41,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nganltt2333/btxrd-project/runs/f0ny5wue?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x782a34cb6560>"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"# Callbacks\ncheckpoint_path = f\"{MODEL_CHECKPOINT_BASENAME}_{loss_name_str}_attn{USE_ATTENTION_UNET}.keras\"\n\n# Định nghĩa nhãn lớp cho WandB (quan trọng cho segmentation masks)\nclass_labels_for_wandb = {0: \"background\", 1: \"tumor\"} # Điều chỉnh nếu N_CLASSES khác\n\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\n        checkpoint_path,\n        save_best_only=True,\n        monitor=MONITOR_METRIC_CB,\n        mode='max', # Quan trọng: 'max' vì dice/iou càng cao càng tốt\n        verbose=1\n    ),\n    tf.keras.callbacks.EarlyStopping(\n        monitor=MONITOR_METRIC_CB,\n        patience=PATIENCE_EARLY_STOPPING,\n        mode='max', # Quan trọng: 'max'\n        restore_best_weights=True,\n        verbose=1\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor=MONITOR_METRIC_CB,\n        factor=0.3,\n        patience=PATIENCE_REDUCE_LR,\n        mode='max', # Quan trọng: 'max'\n        min_lr=1e-7,\n        verbose=1\n    ),\n    tf.keras.callbacks.TensorBoard(\n        log_dir=TENSORBOARD_LOG_DIR, # WandB có thể sync từ đây\n        histogram_freq=1\n    ),\n    # <<< THÊM WANDBCALLBACK >>>\n    WandbCallback(\n        monitor=MONITOR_METRIC_CB,\n        mode='max', # Phải khớp với ModelCheckpoint và EarlyStopping\n        save_model=False, # ModelCheckpoint đã xử lý việc lưu model tốt nhất\n        log_weights=False, # Đặt True nếu muốn log trọng số model (tốn dung lượng)\n        log_gradients=False, # Đặt True nếu muốn log gradient (tốn dung lượng, dùng khi debug)\n        log_evaluation=True if val_ds else False, # Bật để log các dự đoán trên tập validation\n        validation_data=val_ds if val_ds else None, # Cung cấp val_ds để log ảnh\n        data_type=\"image\", # Cho WandB biết đây là dữ liệu ảnh\n        labels=class_labels_for_wandb, # Nhãn lớp cho segmentation mask\n        predictions=min(16, BATCH_SIZE * 2, len(val_image_paths) if val_image_paths else 16) if val_ds else 0, # Số lượng mẫu validation để log (ảnh + mask + prediction)\n        log_batch_frequency=None, # Log metrics mỗi N batch, ví dụ: 100. Mặc định là cuối mỗi epoch.\n                                  # (len(train_ds)//10) if train_ds and len(train_ds) > 0 else None\n    )\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:11:28.540705Z","iopub.execute_input":"2025-05-22T02:11:28.541037Z","iopub.status.idle":"2025-05-22T02:11:28.587910Z","shell.execute_reply.started":"2025-05-22T02:11:28.541011Z","shell.execute_reply":"2025-05-22T02:11:28.587262Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"#Class Weights\npix_cls0 = 0; pix_cls1 = 0\nfor mask_p in tqdm(train_mask_paths, desc=\"Đếm pixels\"):\n    try: m = create_mask_pil((TARGET_SIZE, TARGET_SIZE), mask_p); m_np = (np.array(m) > 128).astype(np.uint8); pix_cls0 += np.sum(m_np == 0); pix_cls1 += np.sum(m_np == 1)\n    except: continue\nclass_weights = None\nif pix_cls1 > 0 and pix_cls0 > 0:\n    total_pix = float(pix_cls0 + pix_cls1)\n    w0 = (total_pix / (N_CLASSES * float(pix_cls0)))\n    w1 = (total_pix / (N_CLASSES * float(pix_cls1)))\n    class_weights = {0: w0, 1: w1}\n    print(f\"Class weights đã tính: Lớp 0: {w0:.4f}, Lớp 1: {w1:.4f}\")\n    if w1 < w0 : print(\"Cảnh báo: Trọng số lớp khối u (1) nhỏ hơn lớp nền (0). Kiểm tra lại số lượng pixel hoặc dữ liệu.\")\n    # Log class weights lên WandB nếu được tính\n    if wandb.run: # Kiểm tra xem run đã được khởi tạo chưa\n        wandb.config.update({\"class_weight_0\": w0, \"class_weight_1\": w1})\nelse: print(\"Không tính được class weights (số pixel lớp 0 hoặc 1 bằng 0). Sử dụng None.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:11:32.966643Z","iopub.execute_input":"2025-05-22T02:11:32.966947Z","iopub.status.idle":"2025-05-22T02:11:35.517122Z","shell.execute_reply.started":"2025-05-22T02:11:32.966925Z","shell.execute_reply":"2025-05-22T02:11:35.516220Z"}},"outputs":[{"name":"stderr","text":"Đếm pixels: 100%|██████████| 1344/1344 [00:02<00:00, 529.69it/s]","output_type":"stream"},{"name":"stdout","text":"Class weights đã tính: Lớp 0: 0.5089, Lớp 1: 28.6592\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# Huấn luyện Model\nhistory = None\nif train_ds and (not val_image_paths or val_ds): # Đảm bảo val_ds tồn tại nếu val_image_paths có\n    history = model.fit(\n        train_ds,\n        epochs=EPOCHS,\n        validation_data=val_ds if val_image_paths else None,\n        callbacks=callbacks, # Danh sách callbacks đã bao gồm WandbCallback\n        class_weight=class_weights\n    )\n    print(\"\\nHuấn luyện hoàn tất.\")\n    if wandb.run: # Đánh dấu run là hoàn thành\n        wandb.finish()\nelse:\n    print(\"Dữ liệu không hợp lệ hoặc tập huấn luyện rỗng.\")\n    if wandb.run: # Đóng run nếu có lỗi trước khi huấn luyện\n        wandb.finish(exit_code=1) # exit_code=1 báo hiệu run thất bại","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:11:36.607760Z","iopub.execute_input":"2025-05-22T02:11:36.608085Z","iopub.status.idle":"2025-05-22T02:12:04.679823Z","shell.execute_reply.started":"2025-05-22T02:11:36.608059Z","shell.execute_reply":"2025-05-22T02:12:04.678624Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Error initializing ValidationDataLogger in WandbCallback. Skipping logging validation data. Error: '_PrefetchDataset' object is not subscriptable\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/300\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-41705b02b636>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain_ds\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mval_image_paths\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Đảm bảo val_ds tồn tại nếu val_image_paths có\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_graph\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_rendered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m             \u001b[0;31m# Couldn't do this in train_begin because keras may still not be built\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m             \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"graph\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_rendered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/data_types/graph.py\u001b[0m in \u001b[0;36mfrom_keras\u001b[0;34m(cls, model)\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Node' object has no attribute 'inbound_layers'"],"ename":"AttributeError","evalue":"'Node' object has no attribute 'inbound_layers'","output_type":"error"}],"execution_count":44},{"cell_type":"code","source":"import keras\nprint(f\"Keras version (from standalone import): {keras.__version__}\")\n# TensorFlow 2.16+ sẽ sử dụng Keras 3.x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:09:00.437571Z","iopub.execute_input":"2025-05-22T02:09:00.437937Z","iopub.status.idle":"2025-05-22T02:09:00.444074Z","shell.execute_reply.started":"2025-05-22T02:09:00.437909Z","shell.execute_reply":"2025-05-22T02:09:00.443324Z"}},"outputs":[{"name":"stdout","text":"Keras version (from standalone import): 3.5.0\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"!pip install wandb==0.18.0  # Thay 0.18.0 bằng phiên bản bạn muốn thử","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:10:18.482966Z","iopub.execute_input":"2025-05-22T02:10:18.483289Z","iopub.status.idle":"2025-05-22T02:10:33.793493Z","shell.execute_reply.started":"2025-05-22T02:10:18.483267Z","shell.execute_reply":"2025-05-22T02:10:33.792698Z"}},"outputs":[{"name":"stdout","text":"Collecting wandb==0.18.0\n  Downloading wandb-0.18.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb==0.18.0) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.18.0) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.18.0) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb==0.18.0) (4.3.6)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.18.0) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.18.0) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb==0.18.0) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.18.0) (2.32.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.18.0) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb==0.18.0) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb==0.18.0) (75.1.0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb==0.18.0) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb==0.18.0) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.18.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.18.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.18.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.18.0) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb==0.18.0) (5.0.1)\nDownloading wandb-0.18.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: wandb\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.19.1\n    Uninstalling wandb-0.19.1:\n      Successfully uninstalled wandb-0.19.1\nSuccessfully installed wandb-0.18.0\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"import tensorflow as tf\nimport wandb\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"WandB version: {wandb.__version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:00:08.437502Z","iopub.execute_input":"2025-05-22T02:00:08.437932Z","iopub.status.idle":"2025-05-22T02:00:08.444826Z","shell.execute_reply.started":"2025-05-22T02:00:08.437907Z","shell.execute_reply":"2025-05-22T02:00:08.443950Z"}},"outputs":[{"name":"stdout","text":"TensorFlow version: 2.17.1\nWandB version: 0.19.1\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"!pip install tensorflow==2.16.1 # Ví dụ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:01:33.023917Z","iopub.execute_input":"2025-05-22T02:01:33.024255Z","iopub.status.idle":"2025-05-22T02:03:28.533340Z","shell.execute_reply.started":"2025-05-22T02:01:33.024230Z","shell.execute_reply":"2025-05-22T02:03:28.532232Z"}},"outputs":[{"name":"stdout","text":"Collecting tensorflow==2.16.1\n  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.12.1)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (18.1.1)\nCollecting ml-dtypes~=0.3.1 (from tensorflow==2.16.1)\n  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.17.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.68.1)\nCollecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.1)\n  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.5.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.37.1)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.1) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (13.9.4)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2025.1.31)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1) (0.1.2)\nDownloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:03\u001b[0mmm\n\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, tensorflow\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.4.1\n    Uninstalling ml-dtypes-0.4.1:\n      Successfully uninstalled ml-dtypes-0.4.1\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.17.1\n    Uninstalling tensorboard-2.17.1:\n      Successfully uninstalled tensorboard-2.17.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.17.1\n    Uninstalling tensorflow-2.17.1:\n      Successfully uninstalled tensorflow-2.17.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.16.1 which is incompatible.\ntensorflow-text 2.17.0 requires tensorflow<2.18,>=2.17.0, but you have tensorflow 2.16.1 which is incompatible.\ntf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ml-dtypes-0.3.2 tensorboard-2.16.2 tensorflow-2.16.1\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"bản cũ ko dùng wandb","metadata":{}},{"cell_type":"code","source":"# --- Cấu hình ---\nINPUT_DATA_ROOT = '/kaggle/input/btxrd-data' # THAY ĐỔI NẾU MÔI TRƯỜNG CỦA BẠN KHÁC\nBASE_DATA_DIR = os.path.join(INPUT_DATA_ROOT, 'btxrd-v2.1')\nCLASSIFICATION_FILE = os.path.join(INPUT_DATA_ROOT, 'classification.xlsx')\nIMAGE_SUBDIR_NAME = 'images'\nANNOTATION_SUBDIR_NAME = 'annotations'\n\n# Tham số Model & Huấn luyện\nTARGET_SIZE = 512\nN_CLASSES = 2 # 2 lớp: 0 (nền), 1 (khối u)\nBATCH_SIZE = 4\nBUFFER_SIZE = 100\nEPOCHS = 300 # Tăng epochs, EarlyStopping sẽ xử lý\nLEARNING_RATE = 3e-5 # Giữ LR nhỏ hoặc thử 5e-5\nL2_REG_FACTOR = 1e-5\nDROPOUT_RATE = 0.3\n\n# --- Cải tiến để tăng IoU ---\nUSE_COMBINED_LOSS = True\nDICE_LOSS_WEIGHT = 0.6 # Ưu tiên Dice hơn một chút, hoặc giữ 0.5\nUSE_FOCAL_LOSS_IN_COMBINED = True # **MẶC ĐỊNH SỬ DỤNG FOCAL LOSS**\nFOCAL_LOSS_ALPHA = 0.25 # Alpha cho Focal Loss\nFOCAL_LOSS_GAMMA = 2.0  # Gamma cho Focal Loss\n\nUSE_ATTENTION_UNET = False # Thử nghiệm bật/tắt sau\n# USE_ALBUMENTATIONS = False # Tạm thời không dùng để giữ code đơn giản\n\nAPPLY_POST_PROCESSING = True\nPOST_PROCESSING_KERNEL_SIZE = (5,5)\nMIN_AREA_POST_PROCESSING = 30\n\nMODEL_CHECKPOINT_BASENAME = \"best_unet_model_iou_focused\"\nTENSORBOARD_LOG_DIR = \"./logs_unet_iou_focused\"\n\n# --- Các hằng số cho callback ---\nPATIENCE_EARLY_STOPPING = 35 # Tăng patience\nPATIENCE_REDUCE_LR = 12  # Tăng patience","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:55:58.382700Z","iopub.execute_input":"2025-05-13T01:55:58.383079Z","iopub.status.idle":"2025-05-13T01:55:58.391002Z","shell.execute_reply.started":"2025-05-13T01:55:58.383051Z","shell.execute_reply":"2025-05-13T01:55:58.389448Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def get_valid_paths(base_dir: str, split_type: str, img_filename_with_ext: str) -> Optional[Tuple[str, str]]:\n    split_dir = os.path.join(base_dir, split_type); image_dir_path = os.path.join(split_dir, IMAGE_SUBDIR_NAME); annotation_dir_path = os.path.join(split_dir, ANNOTATION_SUBDIR_NAME)\n    img_path = os.path.join(image_dir_path, img_filename_with_ext); base_name = os.path.splitext(img_filename_with_ext)[0]; json_filename = base_name + '.json'\n    json_path = os.path.join(annotation_dir_path, json_filename)\n    if os.path.exists(img_path) and os.path.exists(json_path): return img_path, json_path\n    return None\n\ndef create_mask_pil(mask_size: Tuple[int, int], json_path: str) -> Image.Image:\n    if not os.path.exists(json_path): return Image.new('L', (mask_size[1], mask_size[0]), 0)\n    mask = Image.new('L', (mask_size[1], mask_size[0]), 0)\n    try:\n        with open(json_path, 'r') as f: data = json.load(f)\n        if 'shapes' not in data or not isinstance(data['shapes'], list) or not data['shapes']: return mask\n        for shape in data['shapes']:\n             if 'points' in shape and isinstance(shape['points'], list):\n                  polygon = [tuple(point) for point in shape['points']]\n                  if len(polygon) >= 3: ImageDraw.Draw(mask).polygon(polygon, outline=255, fill=255)\n    except (json.JSONDecodeError, Exception): return Image.new('L', (mask_size[1], mask_size[0]), 0)\n    return mask\n\ndef plot_image(ax: plt.Axes, image_data: np.ndarray, title: str, cmap='gray'):\n    if image_data.ndim == 2 or (image_data.ndim == 3 and image_data.shape[2] == 1): ax.imshow(image_data.squeeze(), cmap=cmap)\n    else: ax.imshow(image_data)\n    ax.set_title(title, fontsize=10); ax.axis('off')\n\nall_image_paths = []; all_mask_paths = []; all_types = []\ntry:\n    if not os.path.exists(CLASSIFICATION_FILE): raise FileNotFoundError(f\"Không tìm thấy file phân loại tại {CLASSIFICATION_FILE}\")\n    if not os.path.isdir(BASE_DATA_DIR): raise FileNotFoundError(f\"Không tìm thấy thư mục dữ liệu cơ sở: {BASE_DATA_DIR}\")\n    df_classification = pd.read_excel(CLASSIFICATION_FILE)\n    required_cols = ['image_filename', 'type']\n    if not all(col in df_classification.columns for col in required_cols): raise ValueError(f\"File Excel phải chứa các cột: {required_cols}\")\n    for index, row in tqdm(df_classification.iterrows(), total=len(df_classification), desc=\"Kiểm tra file\"):\n        img_filename_with_ext = row['image_filename']; file_type = row['type']\n        if pd.isna(img_filename_with_ext) or pd.isna(file_type) or file_type not in ['train', 'val', 'test']: continue\n        paths = get_valid_paths(BASE_DATA_DIR, str(file_type).lower(), str(img_filename_with_ext))\n        if paths: img_path, json_path = paths; all_image_paths.append(img_path); all_mask_paths.append(json_path); all_types.append(str(file_type).lower())\n    if not all_image_paths: print(\"\\nLỗi: Không tìm thấy cặp ảnh-chú thích hợp lệ nào.\"); exit()\n    df_paths = pd.DataFrame({'image_path': all_image_paths, 'mask_path': all_mask_paths, 'type': all_types})\n    df_train = df_paths[df_paths['type'] == 'train'].reset_index(drop=True); df_val = df_paths[df_paths['type'] == 'val'].reset_index(drop=True); df_test = df_paths[df_paths['type'] == 'test'].reset_index(drop=True)\n    train_image_paths = df_train['image_path'].tolist(); train_mask_paths = df_train['mask_path'].tolist()\n    val_image_paths = df_val['image_path'].tolist(); val_mask_paths = df_val['mask_path'].tolist()\n    test_image_paths = df_test['image_path'].tolist(); test_mask_paths = df_test['mask_path'].tolist()\n    print(f\"\\nPhân chia dữ liệu: Train({len(train_image_paths)}), Val({len(val_image_paths)}), Test({len(test_image_paths)})\")\n    if not train_image_paths: print(\"Cảnh báo: Tập huấn luyện rỗng!\"); exit()\nexcept Exception as e: print(f\"Lỗi khi tải siêu dữ liệu: {e}\"); import traceback; traceback.print_exc(); exit()\n\n# Tính toán Mean/Std\nmean_pixel = 0.5; std_pixel = 0.1\nnum_train_images = len(train_image_paths)\nif num_train_images > 0:\n    print(\"Đang tính toán Mean/Std...\")\n    pixel_sum = 0.0; pixel_sum_sq = 0.0; total_pixels_calculated = 0; processed_count = 0\n    sample_size_for_stats = min(num_train_images, 250) # Tăng nhẹ sample size\n    sampled_train_paths = np.random.choice(train_image_paths, size=sample_size_for_stats, replace=False)\n    for img_path in tqdm(sampled_train_paths, desc=\"Tính Mean/Std\"):\n        try:\n            img_bytes = tf.io.read_file(img_path); img = tf.io.decode_image(img_bytes, channels=1, expand_animations=False, dtype=tf.float32)\n            img = tf.image.resize(img, [TARGET_SIZE, TARGET_SIZE])\n            pixel_sum += tf.reduce_sum(img).numpy(); pixel_sum_sq += tf.reduce_sum(tf.square(img)).numpy()\n            total_pixels_calculated += (TARGET_SIZE * TARGET_SIZE); processed_count += 1\n        except Exception: pass\n    if processed_count > 0 and total_pixels_calculated > 0:\n        mean_pixel = pixel_sum / total_pixels_calculated; variance = (pixel_sum_sq / total_pixels_calculated) - (mean_pixel ** 2)\n        std_pixel = np.sqrt(max(variance, 1e-7)); print(f\"Mean: {mean_pixel:.4f}, Std Dev: {std_pixel:.4f}\")\n        if std_pixel < 1e-4: std_pixel = 0.1; print(\"Std Dev quá thấp, dùng mặc định 0.1.\")\n    else: print(f\"Cảnh báo: Không tính được mean/std, dùng mặc định.\")\nstd_pixel = max(std_pixel, 1e-7)\n\n# Pipeline Dữ liệu TensorFlow\ndef load_mask_from_json_py(json_path_bytes):\n    json_path = json_path_bytes.numpy().decode('utf-8'); pil_mask = create_mask_pil((TARGET_SIZE, TARGET_SIZE), json_path)\n    mask_np = np.array(pil_mask, dtype=np.uint8); mask_np = (mask_np > 128).astype(np.uint8)\n    return mask_np\n\n@tf.function\ndef load_and_preprocess(image_path, mask_json_path):\n    img_bytes = tf.io.read_file(image_path)\n    try: img = tf.io.decode_image(img_bytes, channels=1, expand_animations=False, dtype=tf.float32)\n    except tf.errors.InvalidArgumentError:\n        try: img = tf.image.decode_png(img_bytes, channels=1, dtype=tf.uint8); img = tf.cast(img, tf.float32) / 255.0\n        except tf.errors.InvalidArgumentError: img = tf.image.decode_jpeg(img_bytes, channels=1); img = tf.cast(img, tf.float32) / 255.0\n    img = tf.image.resize(img, [TARGET_SIZE, TARGET_SIZE]); img.set_shape([TARGET_SIZE, TARGET_SIZE, 1])\n    mask_np_binary = tf.py_function(func=load_mask_from_json_py, inp=[mask_json_path], Tout=tf.uint8)\n    mask_np_binary.set_shape([TARGET_SIZE, TARGET_SIZE])\n    mask_onehot = tf.one_hot(tf.cast(mask_np_binary, tf.int32), depth=N_CLASSES, dtype=tf.float32)\n    mask_onehot.set_shape([TARGET_SIZE, TARGET_SIZE, N_CLASSES])\n    img = (img - mean_pixel) / std_pixel\n    return img, mask_onehot\n\n@tf.function\ndef augment_data_tf(image, mask_onehot):\n    combined = tf.concat([image, tf.cast(mask_onehot, image.dtype)], axis=-1) # Nối image và mask (đã cast về dtype của image)\n    # Augmentations mạnh hơn một chút\n    if tf.random.uniform(()) > 0.5: combined = tf.image.flip_left_right(combined)\n    if tf.random.uniform(()) > 0.5: combined = tf.image.flip_up_down(combined)\n    \n    k_rot = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32) # Xoay 0, 90, 180, 270 độ\n    combined = tf.image.rot90(combined, k=k_rot)\n    \n    # Tách lại\n    img_aug = combined[..., :1]\n    mask_aug = tf.cast(combined[..., 1:], tf.float32) # Đảm bảo mask là float32\n    \n    img_aug = tf.image.random_brightness(img_aug, max_delta=0.25) # Tăng dải brightness\n    img_aug = tf.image.random_contrast(img_aug, lower=0.7, upper=1.3) # Tăng dải contrast\n    \n    # Thêm random zoom (cần resize lại sau đó)\n    if tf.random.uniform(()) > 0.3: # Áp dụng zoom với xác suất 30%\n        scale = tf.random.uniform((), 0.8, 1.2) # Zoom từ 80% đến 120%\n        new_height = tf.cast(TARGET_SIZE * scale, tf.int32)\n        new_width = tf.cast(TARGET_SIZE * scale, tf.int32)\n        \n        # Phải augment cả image và mask cùng một cách\n        img_scaled = tf.image.resize(img_aug, [new_height, new_width], method=tf.image.ResizeMethod.BILINEAR)\n        mask_scaled = tf.image.resize(mask_aug, [new_height, new_width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR) # Dùng NEAREST cho mask\n        \n        # Crop hoặc pad về TARGET_SIZE\n        img_aug = tf.image.resize_with_crop_or_pad(img_scaled, TARGET_SIZE, TARGET_SIZE)\n        mask_aug = tf.image.resize_with_crop_or_pad(mask_scaled, TARGET_SIZE, TARGET_SIZE)\n\n    img_aug = tf.clip_by_value(img_aug, -3.0, 3.0) # Clip giá trị sau chuẩn hóa và augment\n    img_aug.set_shape([TARGET_SIZE, TARGET_SIZE, 1])\n    mask_aug.set_shape([TARGET_SIZE, TARGET_SIZE, N_CLASSES])\n    return img_aug, mask_aug\n\ndef create_dataset(image_paths, mask_paths, is_training=True):\n    if not image_paths or not mask_paths: return tf.data.Dataset.from_tensor_slices(([], [])).batch(BATCH_SIZE)\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n    if is_training: dataset = dataset.shuffle(buffer_size=min(BUFFER_SIZE, len(image_paths)), reshuffle_each_iteration=True)\n    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n    if is_training: dataset = dataset.map(augment_data_tf, num_parallel_calls=tf.data.AUTOTUNE) # Sử dụng augment_data_tf\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=(is_training if len(image_paths) >= BATCH_SIZE else False))\n    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return dataset\n\ntrain_ds = create_dataset(train_image_paths, train_mask_paths, is_training=True)\nval_ds = create_dataset(val_image_paths, val_mask_paths, is_training=False)\ntest_ds = create_dataset(test_image_paths, test_mask_paths, is_training=False)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:56:02.440241Z","iopub.execute_input":"2025-05-13T01:56:02.440621Z","iopub.status.idle":"2025-05-13T01:56:26.650986Z","shell.execute_reply.started":"2025-05-13T01:56:02.440585Z","shell.execute_reply":"2025-05-13T01:56:26.649880Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Kiểm tra file:   0%|          | 0/3746 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3883343cef1844699779ca577c4cb4ed"}},"metadata":{}},{"name":"stdout","text":"\nPhân chia dữ liệu: Train(1344), Val(336), Test(187)\nĐang tính toán Mean/Std...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Tính Mean/Std:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d6b77be277d40ad84a4bf61133f15a7"}},"metadata":{}},{"name":"stdout","text":"Mean: 0.1986, Std Dev: 0.2389\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# UNET\nclass AttentionGate(layers.Layer):\n    def __init__(self, F_g, F_l, F_int, **kwargs): super(AttentionGate, self).__init__(**kwargs); self.W_g = layers.Conv2D(F_int, 1, padding='same', kernel_initializer='he_normal'); self.W_x = layers.Conv2D(F_int, 1, padding='same', kernel_initializer='he_normal'); self.psi = layers.Conv2D(1, 1, padding='same', kernel_initializer='he_normal', activation='sigmoid'); self.relu = layers.Activation('relu')\n    def call(self, g, x): g1 = self.W_g(g); x1 = self.W_x(x); psi_input = self.relu(g1 + x1); alpha = self.psi(psi_input); return x * alpha\ndef conv_block(inputs, num_filters, l2_reg, dropout):\n    x = layers.Conv2D(num_filters, 3, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(inputs); x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n    if dropout > 0: x = layers.Dropout(dropout)(x)\n    x = layers.Conv2D(num_filters, 3, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x); x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n    return x\ndef encoder_block(inputs, num_filters, l2_reg, dropout, pool=True): c = conv_block(inputs, num_filters, l2_reg, dropout); p = layers.MaxPooling2D(2)(c) if pool else None; return c, p\ndef decoder_block(inputs, skip_features, num_filters, l2_reg, dropout, use_attention):\n    x = layers.Conv2DTranspose(num_filters, 2, strides=2, padding='same')(inputs)\n    if use_attention and skip_features is not None: att_gate = AttentionGate(num_filters, skip_features.shape[-1], max(1, skip_features.shape[-1] // 2) ); skip_features = att_gate(g=x, x=skip_features)\n    if skip_features is not None: x = layers.Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters, l2_reg, dropout); return x\ndef build_unet(input_shape, n_classes=N_CLASSES, l2_reg=L2_REG_FACTOR, dropout=DROPOUT_RATE, use_attention=USE_ATTENTION_UNET):\n    filters = [64, 128, 256, 512, 1024] # Giữ nguyên số filter\n    inputs = keras.Input(shape=input_shape); skips = []; x = inputs\n    for f in filters[:-1]: s, p = encoder_block(x, f, l2_reg, dropout, pool=True); skips.append(s); x = p\n    x, _ = encoder_block(x, filters[-1], l2_reg, dropout*1.3, pool=False) # Tăng nhẹ dropout ở bottleneck\n    for i, f in reversed(list(enumerate(filters[:-1]))): x = decoder_block(x, skips[i], f, l2_reg, dropout, use_attention)\n    outputs = layers.Conv2D(n_classes, 1, padding='same', activation='softmax')(x)\n    return keras.Model(inputs, outputs, name=f\"{'Attention' if use_attention else ''}UNet_filters{filters[0]}\")\n\n# --- HÀM MẤT MÁT (LOSS FUNCTIONS) ---\nSMOOTH = 1e-6\ndef dice_coef(y_true_one_hot, y_pred_softmax): y_true_f = tf.keras.backend.flatten(y_true_one_hot); y_pred_f = tf.keras.backend.flatten(y_pred_softmax); intersection = tf.keras.backend.sum(y_true_f * y_pred_f); return (2. * intersection + SMOOTH) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + SMOOTH)\ndef dice_coef_metric_tumor(y_true, y_pred): return dice_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\ndef dice_loss_tumor(y_true, y_pred): return 1.0 - dice_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\n\ndef categorical_focal_loss_wrapper(alpha=FOCAL_LOSS_ALPHA, gamma=FOCAL_LOSS_GAMMA): # Đổi tên để tránh xung đột\n    def focal_loss_fn(y_true, y_pred): # y_true one-hot, y_pred softmax\n        epsilon = tf.keras.backend.epsilon(); y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n        cross_entropy = -y_true * tf.math.log(y_pred)\n        loss = alpha * tf.pow(1 - y_pred, gamma) * cross_entropy\n        return tf.reduce_mean(tf.reduce_sum(loss, axis=-1)) # Mean over batch & spatial\n    focal_loss_fn.__name__ = f'focal_loss_alpha{alpha}_gamma{gamma}' # Đặt tên cho hàm loss\n    return focal_loss_fn\n\ndef combined_loss_fn(y_true, y_pred, dice_w=DICE_LOSS_WEIGHT):\n    d_loss = dice_loss_tumor(y_true, y_pred)\n    if USE_FOCAL_LOSS_IN_COMBINED: ce_or_focal_loss = categorical_focal_loss_wrapper()(y_true, y_pred)\n    else: ce_or_focal_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true, y_pred)) # CCE cần reduce_mean\n    return (dice_w * d_loss) + ((1.0 - dice_w) * ce_or_focal_loss)\ncombined_loss_fn.__name__ = f'combined_dice{DICE_LOSS_WEIGHT}_{\"focal\" if USE_FOCAL_LOSS_IN_COMBINED else \"cce\"}'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:57:35.233036Z","iopub.execute_input":"2025-05-13T01:57:35.233400Z","iopub.status.idle":"2025-05-13T01:57:35.254612Z","shell.execute_reply.started":"2025-05-13T01:57:35.233373Z","shell.execute_reply":"2025-05-13T01:57:35.253249Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"model = build_unet((TARGET_SIZE, TARGET_SIZE, 1))\nmodel.summary()\noptimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:57:39.976220Z","iopub.execute_input":"2025-05-13T01:57:39.976675Z","iopub.status.idle":"2025-05-13T01:57:40.995770Z","shell.execute_reply.started":"2025-05-13T01:57:39.976637Z","shell.execute_reply":"2025-05-13T01:57:40.994625Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"UNet_filters64\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"UNet_filters64\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m640\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_2 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_3 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_4 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m590,080\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_5 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_6 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_7 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │      \u001b[38;5;34m4,719,616\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_8 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │      \u001b[38;5;34m9,438,208\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_9 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,097,664\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                           │                        │                │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m4,719,104\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m524,544\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │      \u001b[38;5;34m1,179,904\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_12             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m590,080\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_13             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m131,200\u001b[0m │ activation_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_2[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m295,040\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_14             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_15             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m32,832\u001b[0m │ activation_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_3[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m73,792\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_16             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_17             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m2\u001b[0m)    │            \u001b[38;5;34m130\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                           │                        │                │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_12             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_13             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_14             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_15             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_16             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_17             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,054,210\u001b[0m (118.46 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,054,210</span> (118.46 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,042,434\u001b[0m (118.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,042,434</span> (118.42 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m11,776\u001b[0m (46.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,776</span> (46.00 KB)\n</pre>\n"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"loss_to_use_obj = combined_loss_fn if USE_COMBINED_LOSS else \\\n                  (categorical_focal_loss_wrapper() if USE_FOCAL_LOSS_IN_COMBINED else tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0.01)) # Thêm label smoothing cho CCE nếu dùng riêng\nloss_name_str = getattr(loss_to_use_obj, '__name__', 'UnknownLoss')\nprint(f\"Sử dụng Loss: {loss_name_str}\")\n\ntumor_iou_metric = tf.keras.metrics.OneHotIoU(num_classes=N_CLASSES, target_class_ids=[1], name='tumor_iou')\nmean_iou_all_metric = tf.keras.metrics.MeanIoU(num_classes=N_CLASSES, name='mean_iou_all')\nmetrics_list = [tf.keras.metrics.CategoricalAccuracy(name='acc'), mean_iou_all_metric, tumor_iou_metric, dice_coef_metric_tumor,\n                tf.keras.metrics.Precision(class_id=1, name='precision_tumor'), tf.keras.metrics.Recall(class_id=1, name='recall_tumor')]\nmodel.compile(optimizer=optimizer, loss=loss_to_use_obj, metrics=metrics_list)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:57:43.707863Z","iopub.execute_input":"2025-05-13T01:57:43.708221Z","iopub.status.idle":"2025-05-13T01:57:43.738244Z","shell.execute_reply.started":"2025-05-13T01:57:43.708193Z","shell.execute_reply":"2025-05-13T01:57:43.737017Z"}},"outputs":[{"name":"stdout","text":"Sử dụng Loss: combined_dice0.6_focal\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Callbacks\nMONITOR_METRIC_CB = 'val_dice_coef_metric_tumor' # Hoặc 'val_tumor_iou'\ncheckpoint_path = f\"{MODEL_CHECKPOINT_BASENAME}_{loss_name_str}_attn{USE_ATTENTION_UNET}.keras\"\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True, monitor=MONITOR_METRIC_CB, mode='max', verbose=1),\n    tf.keras.callbacks.EarlyStopping(monitor=MONITOR_METRIC_CB, patience=PATIENCE_EARLY_STOPPING, mode='max', restore_best_weights=True, verbose=1),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor=MONITOR_METRIC_CB, factor=0.3, patience=PATIENCE_REDUCE_LR, mode='max', min_lr=1e-7, verbose=1),\n    tf.keras.callbacks.TensorBoard(log_dir=TENSORBOARD_LOG_DIR, histogram_freq=1)\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:57:47.680482Z","iopub.execute_input":"2025-05-13T01:57:47.680916Z","iopub.status.idle":"2025-05-13T01:57:47.687056Z","shell.execute_reply.started":"2025-05-13T01:57:47.680885Z","shell.execute_reply":"2025-05-13T01:57:47.685827Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"#Class Weights\npix_cls0 = 0; pix_cls1 = 0\nfor mask_p in tqdm(train_mask_paths, desc=\"Đếm pixels\"):\n    try: m = create_mask_pil((TARGET_SIZE, TARGET_SIZE), mask_p); m_np = (np.array(m) > 128).astype(np.uint8); pix_cls0 += np.sum(m_np == 0); pix_cls1 += np.sum(m_np == 1)\n    except: continue\nclass_weights = None\nif pix_cls1 > 0 and pix_cls0 > 0:\n    total_pix = float(pix_cls0 + pix_cls1) # Đảm bảo float division\n    # Công thức: scaling_factor / count. Scaling_factor có thể là total_samples / num_classes\n    # Hoặc đơn giản là tổng số pixel chia cho số pixel của lớp đó, rồi chuẩn hóa nhẹ.\n    # Weight cao hơn cho lớp ít pixel hơn.\n    w0 = (total_pix / (N_CLASSES * float(pix_cls0)))\n    w1 = (total_pix / (N_CLASSES * float(pix_cls1)))\n    \n    # Chuẩn hóa lại để tổng weight không quá lớn, giữ cho loss ở mức hợp lý\n    # scale_factor = 1.0 / (w0 + w1) # Hoặc một hằng số khác\n    # w0 *= scale_factor * N_CLASSES\n    # w1 *= scale_factor * N_CLASSES\n    \n    class_weights = {0: w0, 1: w1}\n    print(f\"Class weights đã tính: Lớp 0: {w0:.4f}, Lớp 1: {w1:.4f}\")\n    if w1 < w0 : print(\"Trọng số lớp khối u (1) nhỏ hơn lớp nền (0). Kiểm tra lại số lượng pixel hoặc dữ liệu.\")\nelse: print(\"Không tính được class weights (số pixel lớp 0 hoặc 1 bằng 0). Sử dụng None.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:57:51.024421Z","iopub.execute_input":"2025-05-13T01:57:51.024855Z","iopub.status.idle":"2025-05-13T01:58:05.293268Z","shell.execute_reply.started":"2025-05-13T01:57:51.024824Z","shell.execute_reply":"2025-05-13T01:58:05.291824Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Đếm pixels:   0%|          | 0/1344 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20aee42033564a05ba92e42423491154"}},"metadata":{}},{"name":"stdout","text":"Class weights đã tính: Lớp 0: 0.5089, Lớp 1: 28.6592\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Huấn luyện Model \nhistory = None\nif train_ds and (not val_image_paths or val_ds):\n    history = model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds if val_image_paths else None, callbacks=callbacks, class_weight=class_weights) # **SỬ DỤNG CLASS_WEIGHTS**\n    print(\"\\nHuấn luyện hoàn tất.\")\nelse: print(\"Dữ liệu không hợp lệ.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:58:06.609607Z","iopub.execute_input":"2025-05-13T01:58:06.610013Z","execution_failed":"2025-05-13T02:23:16.423Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/300\n\u001b[1m 23/336\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:31:02\u001b[0m 63s/step - acc: 0.0767 - dice_coef_metric_tumor: 0.0733 - loss: 1.1804 - mean_iou_all: 0.2620 - precision_tumor: 0.0342 - recall_tumor: 0.9935 - tumor_iou: 0.0342","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.463677Z","iopub.status.idle":"2025-05-13T01:54:09.464500Z","shell.execute_reply.started":"2025-05-13T01:54:09.463847Z","shell.execute_reply":"2025-05-13T01:54:09.463889Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # --- Vẽ biểu đồ (Giữ nguyên) ---\n# if history:\n#     print(\"Vẽ biểu đồ lịch sử huấn luyện...\"); plt.figure(figsize=(20, 12))\n    # metrics_to_plot = {'Loss': ('loss', 'val_loss'), 'Accuracy': ('acc', 'val_acc'), 'Mean IoU (All)': ('mean_iou_all', 'val_mean_iou_all'),\n    #                    'Tumor IoU': ('tumor_iou', 'val_tumor_iou'), 'Dice Coef (Tumor)': ('dice_coef_metric_tumor', 'val_dice_coef_metric_tumor'),\n    #                    'Precision (Tumor)': ('precision_tumor', 'val_precision_tumor'), 'Recall (Tumor)': ('recall_tumor', 'val_recall_tumor')}\n#     for i, (title, (train_key, val_key)) in enumerate(metrics_to_plot.items()):\n#         plt.subplot(3, 3, i + 1)\n#         if train_key in history.history: plt.plot(history.history[train_key], label=f'Train {title}')\n#         if val_key in history.history: plt.plot(history.history[val_key], label=f'Val {title}')\n#         plt.title(title); plt.legend(); plt.grid(True)\n#     plt.tight_layout(); plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.465629Z","iopub.status.idle":"2025-05-13T01:54:09.466168Z","shell.execute_reply.started":"2025-05-13T01:54:09.465772Z","shell.execute_reply":"2025-05-13T01:54:09.465810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Post-processing\n# def apply_post_processing_mask(mask_np_binary: np.ndarray, kernel_size: Tuple[int, int] = POST_PROCESSING_KERNEL_SIZE, min_area_threshold: Optional[int] = MIN_AREA_POST_PROCESSING) -> np.ndarray:\n#     processed_mask = mask_np_binary.astype(np.uint8); kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, kernel_size)\n#     processed_mask = cv2.morphologyEx(processed_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n#     processed_mask = cv2.morphologyEx(processed_mask, cv2.MORPH_CLOSE, kernel, iterations=1)\n#     if min_area_threshold and min_area_threshold > 0:\n#         num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(processed_mask, connectivity=8)\n#         output_mask = np.zeros_like(processed_mask);\n#         for i in range(1, num_labels):\n#             if stats[i, cv2.CC_STAT_AREA] >= min_area_threshold: output_mask[labels == i] = 1\n#         processed_mask = output_mask\n#     return processed_mask.astype(np.uint8)\n\n# # Đánh giá trên tập test\n# if os.path.exists(checkpoint_path) and test_ds and test_image_paths:\n#     print(f\"Tải model tốt nhất từ: {checkpoint_path}\")\n#     try:\n#         custom_objects_load = {'dice_coef_metric_tumor': dice_coef_metric_tumor, 'tumor_iou': tumor_iou_metric, 'mean_iou_all': mean_iou_all_metric}\n#         # Thêm hàm loss đã được sử dụng vào custom_objects\n#         # Cần đảm bảo tên hàm và các tham số (alpha, gamma cho focal) là giống hệt lúc compile\n#         if USE_COMBINED_LOSS:\n#             # Cần một cách để reconstruct combined_loss_fn với đúng các tham số nếu nó không được Keras tự động serialize\n#             # Cách đơn giản là định nghĩa lại nó hoặc nếu hàm loss có __name__ và Keras lưu theo tên.\n#             # Nếu loss_to_use_obj là một hàm, Keras có thể lưu theo tên.\n#             custom_objects_load[loss_name_str] = loss_to_use_obj # Thử thêm đối tượng hàm loss trực tiếp\n#         elif USE_FOCAL_LOSS_IN_COMBINED: # Trường hợp này đã được bao gồm ở trên nếu USE_COMBINED_LOSS=True\n#              custom_objects_load[loss_name_str] = categorical_focal_loss_wrapper(alpha=FOCAL_LOSS_ALPHA, gamma=FOCAL_LOSS_GAMMA)\n#         # Nếu chỉ dùng CCE, thường không cần thêm vào custom_objects trừ khi có tùy chỉnh đặc biệt\n\n#         if USE_ATTENTION_UNET: custom_objects_load['AttentionGate'] = AttentionGate\n\n#         best_model = tf.keras.models.load_model(checkpoint_path, custom_objects=custom_objects_load, compile=True) # compile=True rất quan trọng\n#         eval_results = best_model.evaluate(test_ds, verbose=1)\n#         print(\"\\n--- KẾT QUẢ ĐÁNH GIÁ TRÊN TẬP TEST ---\")\n#         results_dict = dict(zip(best_model.metrics_names, eval_results))\n#         for name, val in results_dict.items(): print(f\" - Test {name}: {val:.4f}\")\n#         if 'precision_tumor' in results_dict and 'recall_tumor' in results_dict:\n#             p, r = results_dict['precision_tumor'], results_dict['recall_tumor']\n#             f1 = 2 * (p * r) / (p + r + SMOOTH) if (p + r) > 0 else 0.0; print(f\" - Test F1-Score (Tumor): {f1:.4f}\")\n#         print(\"--------------------------------------\")\n#         # (Phần trực quan hóa giữ nguyên như trước)\n#         print(\"\\nTrực quan hóa dự đoán...\")\n#         num_viz = min(6, len(test_image_paths));\n#         if num_viz > 0:\n#             cols_viz = 4; title_pad = 1.5\n#             if APPLY_POST_PROCESSING: cols_viz += 1; title_pad = 2.0\n#             plt.figure(figsize=(cols_viz * 4, num_viz * 4)); test_iter = iter(test_ds.unbatch().take(num_viz))\n#             for i in range(num_viz):\n#                 try: img_tensor, mask_onehot_tensor = next(test_iter)\n#                 except StopIteration: break\n#                 img_np = img_tensor.numpy(); pred_probs = best_model.predict(np.expand_dims(img_np, axis=0))[0]\n#                 pred_labels = np.argmax(pred_probs, axis=-1).astype(np.uint8); true_labels = np.argmax(mask_onehot_tensor.numpy(), axis=-1).astype(np.uint8)\n#                 tumor_prob_map = pred_probs[..., 1]; img_display = np.clip((img_np * std_pixel) + mean_pixel, 0.0, 1.0)\n#                 plot_idx = i * cols_viz\n#                 plt.subplot(num_viz, cols_viz, plot_idx + 1); plot_image(plt.gca(), img_display, f\"Test {i+1}\")\n#                 plt.subplot(num_viz, cols_viz, plot_idx + 2); plot_image(plt.gca(), true_labels, \"Mask Thực tế\")\n#                 ax_prob = plt.subplot(num_viz, cols_viz, plot_idx + 3); im_prob = ax_prob.imshow(tumor_prob_map, cmap='viridis', vmin=0, vmax=1); ax_prob.set_title(\"Xác suất Khối u\", fontsize=10); ax_prob.axis('off'); plt.colorbar(im_prob, ax=ax_prob, fraction=0.046, pad=0.04)\n#                 plt.subplot(num_viz, cols_viz, plot_idx + 4); plot_image(plt.gca(), pred_labels, \"Mask Dự đoán (Raw)\")\n#                 if APPLY_POST_PROCESSING: post_pred = apply_post_processing_mask(pred_labels); plt.subplot(num_viz, cols_viz, plot_idx + 5); plot_image(plt.gca(), post_pred, \"Mask (Post-processed)\")\n#             plt.tight_layout(pad=title_pad); plt.show()\n#     except Exception as e: print(f\"Lỗi khi tải model/trực quan hóa: {e}\"); traceback.print_exc()\n# elif not os.path.exists(checkpoint_path): print(f\"Checkpoint '{checkpoint_path}' không tìm thấy.\")\n# else: print(\"Dataset test rỗng hoặc không hợp lệ.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.467249Z","iopub.status.idle":"2025-05-13T01:54:09.467784Z","shell.execute_reply.started":"2025-05-13T01:54:09.467451Z","shell.execute_reply":"2025-05-13T01:54:09.467493Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Chuẩn bị tập dữ liệu**","metadata":{}},{"cell_type":"markdown","source":"# **Xây dựng mô hình CNN**","metadata":{}},{"cell_type":"markdown","source":"# **Compile**","metadata":{}},{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"code","source":"a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.469189Z","iopub.status.idle":"2025-05-13T01:54:09.469756Z","shell.execute_reply.started":"2025-05-13T01:54:09.469339Z","shell.execute_reply":"2025-05-13T01:54:09.469379Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"nháp từ đây tới dưới","metadata":{}},{"cell_type":"code","source":"# # Build U-Net model\n# def unet_model():\n#     inputs = layers.Input((*IMG_SIZE, 1))\n\n#     x = layers.Conv2D(32, (3, 3), strides=2, padding='same', activation='relu')(inputs)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n#     x = layers.BatchNormalization()(x)\n#     skip1 = x\n\n#     x = layers.Conv2D(64, (3, 3), strides=2, padding='same', activation='relu')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n#     x = layers.BatchNormalization()(x)\n#     skip2 = x\n\n#     x = layers.Conv2D(128, (3, 3), strides=2, padding='same', activation='relu')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n#     x = layers.BatchNormalization()(x)\n#     skip3 = x\n\n#     x = layers.Conv2D(256, (3, 3), strides=2, padding='same', activation='relu')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n#     x = layers.BatchNormalization()(x)\n\n#     x = layers.Conv2DTranspose(128, (3, 3), strides=2, padding='same', activation='relu')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Resizing(skip3.shape[1], skip3.shape[2])(x)\n#     x = layers.Concatenate()([x, skip3])\n#     x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n#     x = layers.BatchNormalization()(x)\n\n#     x = layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same', activation='relu')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Resizing(skip2.shape[1], skip2.shape[2])(x)\n#     x = layers.Concatenate()([x, skip2])\n#     x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n#     x = layers.BatchNormalization()(x)\n\n#     x = layers.Conv2DTranspose(32, (3, 3), strides=2, padding='same', activation='relu')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Resizing(skip1.shape[1], skip1.shape[2])(x)\n#     x = layers.Concatenate()([x, skip1])\n#     x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n#     x = layers.BatchNormalization()(x)\n\n#     x = layers.Conv2DTranspose(32, (3, 3), strides=2, padding='same', activation='relu')(x)\n#     x = layers.BatchNormalization()(x)\n#     outputs = layers.Conv2D(N_CLASSES, (1, 1), activation='softmax')(x)\n\n#     return models.Model(inputs, outputs)\n\n# model = unet_model()\n# # model.compile(optimizer='adam', loss=dice_loss, metrics=['accuracy', dice_coef, iou_coef])\n# model.compile(optimizer='adam', loss=combined_loss, metrics=['accuracy', dice_coef, iou_coef])\n\n# model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.471118Z","iopub.status.idle":"2025-05-13T01:54:09.472078Z","shell.execute_reply.started":"2025-05-13T01:54:09.471284Z","shell.execute_reply":"2025-05-13T01:54:09.471330Z"}},"outputs":[],"execution_count":null}]}