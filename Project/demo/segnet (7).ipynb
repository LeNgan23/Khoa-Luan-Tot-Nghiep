{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11709306,"sourceType":"datasetVersion","datasetId":6711261}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"ver 8 (6), v10","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n# Keras được tích hợp trong TensorFlow dưới dạng tf.keras\nkeras_version_from_tf = tf.keras.__version__\nprint(f\"Phiên bản Keras API (thông qua tf.keras): {keras_version_from_tf}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:05:09.857798Z","iopub.execute_input":"2025-05-22T19:05:09.858222Z","iopub.status.idle":"2025-05-22T19:05:21.492621Z","shell.execute_reply.started":"2025-05-22T19:05:09.858182Z","shell.execute_reply":"2025-05-22T19:05:21.491905Z"}},"outputs":[{"name":"stdout","text":"Phiên bản Keras API (thông qua tf.keras): 3.5.0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!cat /proc/cpuinfo | grep \"model name\" | uniq \n# Hoặc để xem số core\n!nproc ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:59:33.535913Z","iopub.execute_input":"2025-05-22T18:59:33.536271Z","iopub.status.idle":"2025-05-22T18:59:33.773679Z","shell.execute_reply.started":"2025-05-22T18:59:33.536241Z","shell.execute_reply":"2025-05-22T18:59:33.772865Z"}},"outputs":[{"name":"stdout","text":"model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n4\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!free -h \n# Hoặc chi tiết hơn\n!cat /proc/meminfo | grep MemTotal","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:00:22.805424Z","iopub.execute_input":"2025-05-22T19:00:22.805756Z","iopub.status.idle":"2025-05-22T19:00:23.085306Z","shell.execute_reply.started":"2025-05-22T19:00:22.805729Z","shell.execute_reply":"2025-05-22T19:00:23.084541Z"}},"outputs":[{"name":"stdout","text":"               total        used        free      shared  buff/cache   available\nMem:            31Gi       836Mi        23Gi       1.0Mi       6.9Gi        30Gi\nSwap:             0B          0B          0B\nMemTotal:       32873392 kB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:58:04.760970Z","iopub.execute_input":"2025-05-22T18:58:04.761387Z","iopub.status.idle":"2025-05-22T18:58:04.933902Z","shell.execute_reply.started":"2025-05-22T18:58:04.761350Z","shell.execute_reply":"2025-05-22T18:58:04.932229Z"}},"outputs":[{"name":"stdout","text":"Thu May 22 18:58:04 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   31C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport json\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw\nfrom typing import Tuple\n\nimport cv2\nimport json\nfrom tqdm.notebook import tqdm\n\n\nimport pandas as pd\nimport glob\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\nimport shutil \n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom typing import List, Tuple, Optional","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T15:16:37.699155Z","iopub.execute_input":"2025-05-31T15:16:37.699492Z","iopub.status.idle":"2025-05-31T15:16:50.694599Z","shell.execute_reply.started":"2025-05-31T15:16:37.699455Z","shell.execute_reply":"2025-05-31T15:16:50.693672Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"base_input_dir = \"/kaggle/input/btxrd-data/BTXRD/BTXRD\" \nimage_dir = os.path.join(base_input_dir, \"images\")\nannotation_dir = os.path.join(base_input_dir, \"Annotations\")\nexcel_path = \"/kaggle/input/btxrd-data/classification.xlsx\"\n\n\n# output_dir = \"/kaggle/working/btxrd-v2.2\"\n# output_image_dir = os.path.join(output_dir, \"images\")\n# output_anno_dir = os.path.join(output_dir, \"Annotations\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.430179Z","iopub.status.idle":"2025-05-13T01:54:09.431135Z","shell.execute_reply.started":"2025-05-13T01:54:09.430368Z","shell.execute_reply":"2025-05-13T01:54:09.430415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Đọc file Excel\n# file_path = '/kaggle/input/btxrd-data/classification.xlsx'\ndf = pd.read_excel(excel_path)\n\n# Hiển thị 10 dòng đầu tiên\ndf.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.432391Z","iopub.status.idle":"2025-05-13T01:54:09.433268Z","shell.execute_reply.started":"2025-05-13T01:54:09.432557Z","shell.execute_reply":"2025-05-13T01:54:09.432619Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Xử lý ảnh**","metadata":{}},{"cell_type":"code","source":"# in 30 ảnh trước xử lý\nnum_images_to_show = 30\nimages_per_row = 5  # Số ảnh mỗi hàng\nmask_color = [255, 0, 0]  # Red\n\ndef create_mask(img_size: Tuple[int, int], ann_path: str) -> np.ndarray:\n    mask = Image.new('L', img_size, 0)\n    if os.path.exists(ann_path):\n        try:\n            with open(ann_path, 'r') as f:\n                data = json.load(f)\n                for shape in data.get('shapes', []):\n                    points = shape.get('points', [])\n                    polygon_points = [(int(x), int(y)) for x, y in points]\n                    if polygon_points:\n                        ImageDraw.Draw(mask).polygon(polygon_points, outline=1, fill=1)\n        except Exception as e:\n            print(f\"Lỗi annotation {ann_path}: {e}\")\n    return np.array(mask)\n\n# Lấy danh sách tất cả ảnh trong thư mục\nall_filenames = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# Chọn ngẫu nhiên 30 ảnh\nselected_filenames = random.sample(all_filenames, min(num_images_to_show, len(all_filenames)))\n\n# Plot ảnh với mask\nplt.figure(figsize=(18, 18))  # Tăng kích thước ảnh\nfor i, fname in enumerate(selected_filenames):\n    img_path = os.path.join(image_dir, fname)\n    ann_fname = os.path.splitext(fname)[0] + '.json'\n    ann_path = os.path.join(annotation_dir, ann_fname)\n\n    try:\n        img_pil = Image.open(img_path).convert('L')\n        img_np = np.array(img_pil)\n\n        mask_np = create_mask(img_pil.size, ann_path)\n        color_img = np.stack([img_np] * 3, axis=-1)\n        color_img[mask_np == 1] = mask_color\n\n        # Chia bố cục thành 6 hàng và 5 cột (số ảnh mỗi hàng là 5)\n        plt.subplot(6, 5, i + 1)\n        plt.imshow(color_img)\n        plt.axis('off')  # Tắt trục\n    except Exception as e:\n        print(f\"Lỗi khi xử lý {fname}: {e}\")\n        continue\n\n# Loại bỏ khoảng trống giữa các ảnh\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.434296Z","iopub.status.idle":"2025-05-13T01:54:09.435136Z","shell.execute_reply.started":"2025-05-13T01:54:09.434455Z","shell.execute_reply":"2025-05-13T01:54:09.434496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nTARGET_SIZE = 512\n\n# base_input_dir = \"/kaggle/input/btxrd-data/BTXRD/BTXRD\" # Đường dẫn gốc chứa ảnh và annotation\n# image_dir = os.path.join(base_input_dir, \"images\")      # Thư mục chứa ảnh gốc\n# annotation_dir = os.path.join(base_input_dir, \"Annotations\") # Thư mục chứa annotation gốc\n\noutput_dir = \"/kaggle/working/btxrd-v2.2\"\noutput_image_dir = os.path.join(output_dir, \"images\")\noutput_anno_dir = os.path.join(output_dir, \"annotations\")\n\nos.makedirs(output_image_dir, exist_ok=True)\nos.makedirs(output_anno_dir, exist_ok=True)\n\nMAX_VISUALIZATIONS = 5 # Số lượng ảnh tối đa để trực quan hóa\nvisualized_count = 0\n\n\ndef get_bounding_box(points):\n    if not points:\n        return None\n    points_array = np.array(points)\n    xmin = int(np.min(points_array[:, 0]))\n    ymin = int(np.min(points_array[:, 1]))\n    xmax = int(np.max(points_array[:, 0]))\n    ymax = int(np.max(points_array[:, 1]))\n    # Đảm bảo tọa độ không âm\n    xmin = max(0, xmin)\n    ymin = max(0, ymin)\n    return (xmin, ymin, xmax, ymax)\n\ntry:\n    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg'))]\n    total_images = len(image_files)\n    if total_images == 0:\n        print(f\"Không tìm thấy file ảnh nào trong: {image_dir}\")\n        exit()\n    print(f\"Tìm thấy {total_images} ảnh để xử lý.\")\nexcept FileNotFoundError:\n    print(f\"Không tìm thấy thư mục ảnh: {image_dir}\")\n    exit()\n\nprint(f\"Bắt đầu xử lý ảnh và lưu vào: {output_dir}\")\n# Sử dụng tqdm để hiển thị thanh tiến trình\nfor file in tqdm(image_files, desc=\"Processing Images\"):\n    img_path = os.path.join(image_dir, file)\n    anno_filename = file.rsplit('.', 1)[0] + '.json'\n    anno_path = os.path.join(annotation_dir, anno_filename)\n\n    # Đọc ảnh gốc\n    img_orig = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    if img_orig is None:\n        # print(f\"Không thể đọc ảnh: {file}\"\n        continue\n    orig_height, orig_width = img_orig.shape[:2]\n\n    # Đọc annotation gốc \n    annotation_orig = None\n    has_annotation = os.path.exists(anno_path)\n    if has_annotation:\n        try:\n            with open(anno_path, \"r\", encoding=\"utf-8\") as f:\n                annotation_orig = json.load(f)\n        except Exception as e:\n            # print(f\"Lỗi khi đọc annotation {anno_filename}: {e}\")\n            has_annotation = False # Coi như không có nếu đọc lỗi\n\n    img_to_draw_orig = None\n    img_to_draw_padded = None\n    original_bboxes = []\n    transformed_bboxes = []\n\n    should_visualize = has_annotation and (visualized_count < MAX_VISUALIZATIONS)\n\n    if should_visualize:\n        img_to_draw_orig = cv2.cvtColor(img_orig, cv2.COLOR_GRAY2BGR) # Chuyển sang BGR để vẽ màu\n        if annotation_orig and \"shapes\" in annotation_orig:\n             for shape in annotation_orig[\"shapes\"]:\n                if shape.get(\"shape_type\") == \"rectangle\" and \"points\" in shape and len(shape[\"points\"]) == 2:\n                     # LabelMe rectangle format uses [top-left, bottom-right]\n                     p1 = shape[\"points\"][0]\n                     p2 = shape[\"points\"][1]\n                     xmin = int(min(p1[0], p2[0]))\n                     ymin = int(min(p1[1], p2[1]))\n                     xmax = int(max(p1[0], p2[0]))\n                     ymax = int(max(p1[1], p2[1]))\n                     bbox = (max(0, xmin), max(0, ymin), xmax, ymax)\n                     original_bboxes.append(bbox)\n                     cv2.rectangle(img_to_draw_orig, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 2) # Vẽ màu đỏ (BGR)\n                elif shape.get(\"shape_type\") in [\"polygon\", \"linestrip\", \"point\"] and \"points\" in shape and shape[\"points\"]:\n                     # Lấy bounding box bao quanh các loại shape khác\n                     bbox = get_bounding_box(shape[\"points\"])\n                     if bbox:\n                        original_bboxes.append(bbox)\n                        cv2.rectangle(img_to_draw_orig, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 2) # Red\n\n    # Resize ảnh với padding để giữ tỉ lệ\n    # Tính tỉ lệ resize để cạnh dài nhất bằng TARGET_SIZE\n    scale = TARGET_SIZE / max(orig_height, orig_width)\n    new_width = int(orig_width * scale)\n    new_height = int(orig_height * scale)\n\n    # Đảm bảo kích thước mới không lớn hơn TARGET_SIZE\n    new_width = min(new_width, TARGET_SIZE)\n    new_height = min(new_height, TARGET_SIZE)\n\n    # Resize ảnh\n    img_resized = cv2.resize(img_orig, (new_width, new_height), interpolation=cv2.INTER_AREA)\n\n    # Tính toán padding\n    pad_h = TARGET_SIZE - new_height\n    pad_w = TARGET_SIZE - new_width\n    top = pad_h // 2\n    bottom = pad_h - top\n    left = pad_w // 2\n    right = pad_w - left\n\n    # Thêm padding\n    # Sử dụng giá trị 0 (màu đen) cho padding vì ảnh là grayscale\n    padded_img = cv2.copyMakeBorder(img_resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n\n    # Lưu ảnh đã xử lý\n    output_img_path = os.path.join(output_image_dir, file)\n    try:\n        # Đảm bảo kích thước cuối cùng đúng là TARGET_SIZE x TARGET_SIZE\n        if padded_img.shape[0] != TARGET_SIZE or padded_img.shape[1] != TARGET_SIZE:\n             # Nếu có sai lệch nhỏ do làm tròn, resize lại lần cuối\n             padded_img = cv2.resize(padded_img, (TARGET_SIZE, TARGET_SIZE), interpolation=cv2.INTER_AREA)\n             # print(f\"Final resize needed for {file}. Original: ({orig_width}x{orig_height}), Resized: ({new_width}x{new_height}), Padded: {padded_img.shape[:2]}\")\n\n\n        cv2.imwrite(output_img_path, padded_img)\n    except Exception as e:\n        # print(f\"Lỗi khi lưu ảnh {output_img_path}: {e}\") # Bỏ comment nếu cần debug\n        continue # Bỏ qua ảnh này nếu không lưu được\n\n    # Xử lý và lưu annotation\n    if has_annotation and annotation_orig:\n        # Tạo bản sao sâu để không ảnh hưởng annotation gốc\n        annotation_new = json.loads(json.dumps(annotation_orig))\n\n        if \"shapes\" in annotation_new:\n            new_shapes = [] # Tạo list mới để chứa các shape đã chuyển đổi\n            for shape in annotation_new[\"shapes\"]:\n                if \"points\" in shape and shape[\"points\"]:\n                    original_points = shape[\"points\"]\n                    new_points_transformed = []\n                    valid_shape = True\n                    for x, y in original_points:\n                        # Áp dụng tỉ lệ resize\n                        new_x = x * scale\n                        new_y = y * scale\n                        # Áp dụng padding offset\n                        new_x += left\n                        new_y += top\n\n                        # Kiểm tra xem điểm có nằm trong ảnh mới không\n                        # new_x = max(0, min(TARGET_SIZE - 1, new_x))\n                        # new_y = max(0, min(TARGET_SIZE - 1, new_y))\n                        new_points_transformed.append([new_x, new_y])\n\n                    # Cập nhật điểm trong shape\n                    shape[\"points\"] = new_points_transformed\n                    new_shapes.append(shape) # Thêm shape đã chuyển đổi vào list mới\n\n                    # Tính bbox mới để trực quan hóa\n                    if should_visualize:\n                        new_bbox = get_bounding_box(new_points_transformed)\n                        if new_bbox:\n                            # Đảm bảo bbox không vượt ra ngoài TARGET_SIZE\n                            xmin = max(0, min(TARGET_SIZE - 1, new_bbox[0]))\n                            ymin = max(0, min(TARGET_SIZE - 1, new_bbox[1]))\n                            xmax = max(0, min(TARGET_SIZE - 1, new_bbox[2]))\n                            ymax = max(0, min(TARGET_SIZE - 1, new_bbox[3]))\n                            # Chỉ thêm vào nếu bbox hợp lệ\n                            if xmax > xmin and ymax > ymin:\n                                transformed_bboxes.append((xmin, ymin, xmax, ymax))\n\n            # Cập nhật lại danh sách shapes và kích thước ảnh trong annotation\n            annotation_new[\"shapes\"] = new_shapes\n            annotation_new[\"imagePath\"] = file # Cập nhật tên file ảnh mới\n            annotation_new[\"imageWidth\"] = TARGET_SIZE\n            annotation_new[\"imageHeight\"] = TARGET_SIZE\n            \n            if \"imageData\" in annotation_new:\n                annotation_new[\"imageData\"] = None\n\n            # Lưu file annotation mới\n            output_annotation_path = os.path.join(output_anno_dir, anno_filename)\n            try:\n                with open(output_annotation_path, \"w\", encoding=\"utf-8\") as f:\n                    json.dump(annotation_new, f, indent=4, ensure_ascii=False)\n            except Exception as e:\n                # print(f\"Lỗi khi lưu annotation {anno_filename}: {e}\") # Bỏ comment nếu cần debug\n                pass # Bỏ qua nếu lưu lỗi\n\n            if should_visualize and img_to_draw_orig is not None:\n                # Chuyển ảnh đã padding sang BGR để vẽ màu\n                img_to_draw_padded = cv2.cvtColor(padded_img, cv2.COLOR_GRAY2BGR)\n                # Vẽ các bounding box đã biến đổi\n                for bbox in transformed_bboxes:\n                     # Đảm bảo tọa độ là số nguyên để vẽ\n                     pt1 = (int(bbox[0]), int(bbox[1]))\n                     pt2 = (int(bbox[2]), int(bbox[3]))\n                     cv2.rectangle(img_to_draw_padded, pt1, pt2, (0, 255, 0), 2) # Vẽ màu xanh lá (BGR)\n\n                # Hiển thị ảnh gốc và ảnh đã xử lý\n                fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\n                # Ảnh gốc với bbox gốc (màu đỏ)\n                axes[0].imshow(cv2.cvtColor(img_to_draw_orig, cv2.COLOR_BGR2RGB)) # Chuyển BGR sang RGB cho matplotlib\n                axes[0].set_title(f'Original: {file}\\nSize: {orig_width}x{orig_height}')\n                axes[0].axis('off')\n\n                # Ảnh đã xử lý với bbox mới (màu xanh)\n                axes[1].imshow(cv2.cvtColor(img_to_draw_padded, cv2.COLOR_BGR2RGB)) # Chuyển BGR sang RGB\n                axes[1].set_title(f'Processed (Resized & Padded)\\nSize: {TARGET_SIZE}x{TARGET_SIZE}')\n                axes[1].axis('off')\n\n                plt.suptitle(f\"Visualization {visualized_count + 1}/{MAX_VISUALIZATIONS}\")\n                plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Điều chỉnh layout để tiêu đề không bị che\n                plt.show()\n\n                visualized_count += 1\n\nprint(f\"Xử lý {total_images} ảnh.\")\nif visualized_count > 0:\n    print(f\"Hiển thị {visualized_count} ảnh trực quan hóa.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.436168Z","iopub.status.idle":"2025-05-13T01:54:09.436694Z","shell.execute_reply.started":"2025-05-13T01:54:09.436347Z","shell.execute_reply":"2025-05-13T01:54:09.436393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hiển thị random 30 hình sau khi xử lý ảnh\n\n\n# Cấu hình\nimage_dir_test = '/kaggle/working/btxrd-v2.2/images'\nannotation_dir_test = '/kaggle/working/btxrd-v2.2/annotations'\n# Cấu hình\nnum_images_to_show = 30\nimages_per_row = 5  # Số ảnh mỗi hàng\nmask_color = [255, 0, 0]  # Red\n\ndef create_mask(img_size: Tuple[int, int], ann_path: str) -> np.ndarray:\n    mask = Image.new('L', img_size, 0)\n    if os.path.exists(ann_path):\n        try:\n            with open(ann_path, 'r') as f:\n                data = json.load(f)\n                for shape in data.get('shapes', []):\n                    points = shape.get('points', [])\n                    polygon_points = [(int(x), int(y)) for x, y in points]\n                    if polygon_points:\n                        ImageDraw.Draw(mask).polygon(polygon_points, outline=1, fill=1)\n        except Exception as e:\n            print(f\"Lỗi annotation {ann_path}: {e}\")\n    return np.array(mask)\n\n# Lấy danh sách tất cả ảnh trong thư mục\nall_filenames = [f for f in os.listdir(image_dir_test) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# Chọn ngẫu nhiên 30 ảnh\nselected_filenames = random.sample(all_filenames, min(num_images_to_show, len(all_filenames)))\n\n# Plot ảnh với mask\nplt.figure(figsize=(18, 18))  # Tăng kích thước ảnh\nfor i, fname in enumerate(selected_filenames):\n    img_path = os.path.join(image_dir_test, fname)\n    ann_fname = os.path.splitext(fname)[0] + '.json'\n    ann_path = os.path.join(annotation_dir_test, ann_fname)\n\n    try:\n        img_pil = Image.open(img_path).convert('L')\n        img_np = np.array(img_pil)\n\n        mask_np = create_mask(img_pil.size, ann_path)\n        color_img = np.stack([img_np] * 3, axis=-1)\n        color_img[mask_np == 1] = mask_color\n\n        # Chia bố cục thành 6 hàng và 5 cột (số ảnh mỗi hàng là 5)\n        plt.subplot(6, 5, i + 1)\n        plt.imshow(color_img)\n        plt.axis('off')  # Tắt trục\n    except Exception as e:\n        print(f\"Lỗi khi xử lý {fname}: {e}\")\n        continue\n\n# Loại bỏ khoảng trống giữa các ảnh\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.437653Z","iopub.status.idle":"2025-05-13T01:54:09.438769Z","shell.execute_reply.started":"2025-05-13T01:54:09.437797Z","shell.execute_reply":"2025-05-13T01:54:09.437838Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Chia tập dữ liệu**","metadata":{}},{"cell_type":"code","source":"output_split_dir = \"/kaggle/working/btxrd-v2.1\"\n\nANNOTATION_EXTENSION = \".json\"\n\nVAL_SIZE = 0.20   # 20% cho tập validation\nTRAIN_SIZE = 0.70 # 70% cho tập train\nTEST_SIZE = 1.0 - VAL_SIZE - TRAIN_SIZE\n\nRANDOM_STATE = 42","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.439717Z","iopub.status.idle":"2025-05-13T01:54:09.440264Z","shell.execute_reply.started":"2025-05-13T01:54:09.439865Z","shell.execute_reply":"2025-05-13T01:54:09.439927Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Đọc Dữ liệu Phân loại từ Excel\ntry:\n    df_classification = pd.read_excel(excel_path)\n    required_columns = ['image_id', 'tumor_type', 'image_filename']\n    if not all(col in df_classification.columns for col in required_columns):\n        missing = [col for col in required_columns if col not in df_classification.columns]\n        raise ValueError(f\"File Excel thiếu các cột bắt buộc: {missing}\")\n\n    df_classification['image_id'] = df_classification['image_id'].astype(str).str.strip()\n    df_classification['image_filename'] = df_classification['image_filename'].astype(str).str.strip()\n\n    print(f\"Đọc thành công {len(df_classification)} dòng\")\n    print(df_classification['tumor_type'].value_counts())\nexcept FileNotFoundError:\n    print(f\"Không tìm thấy file Excel tại {excel_path}\")\n    exit()\nexcept ValueError as ve:\n    print(f\"Lỗi dữ liệu trong file Excel: {ve}\")\n    exit()\nexcept Exception as e:\n    print(f\"không xác định khi đọc file Excel: {e}\")\n    exit()\n\ntry:\n    all_image_files = glob.glob(os.path.join(image_dir_test, \"*.*\"))\n    annotation_files = glob.glob(os.path.join(annotation_dir_test, f\"*{ANNOTATION_EXTENSION}\"))\n\n    image_basenames_actual = set(os.path.splitext(os.path.basename(f))[0] for f in all_image_files)\n    annotation_basenames_actual = set(os.path.splitext(os.path.basename(f))[0] for f in annotation_files)\n\n    print(f\"Tìm thấy {len(all_image_files)} tệp\")\n    print(f\"Tìm thấy {len(annotation_files)} tệp annotation\")\nexcept Exception as e:\n    print(f\"Lỗi khi quét thư mục ảnh hoặc annotation: {e}\")\n    exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.441610Z","iopub.status.idle":"2025-05-13T01:54:09.442492Z","shell.execute_reply.started":"2025-05-13T01:54:09.442254Z","shell.execute_reply":"2025-05-13T01:54:09.442305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"excel_image_ids = set(df_classification['image_id'])\nvalid_ids = list(excel_image_ids.intersection(image_basenames_actual).intersection(annotation_basenames_actual))\n\nif not valid_ids:\n    print(\"Không tìm thấy dữ liệu hợp lệ nào.\")\n    exit()\ndf_filtered = df_classification[df_classification['image_id'].isin(valid_ids)].copy()\ndf_filtered = df_filtered.drop_duplicates(subset=['image_id'])\nfilename_map = pd.Series(df_filtered.image_filename.values, index=df_filtered.image_id).to_dict()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.443533Z","iopub.status.idle":"2025-05-13T01:54:09.444176Z","shell.execute_reply.started":"2025-05-13T01:54:09.443693Z","shell.execute_reply":"2025-05-13T01:54:09.443733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Chuẩn bị dữ liệu (X=IDs, y=Labels) cho việc chia\nX = df_filtered['image_id'].tolist() # Danh sách ID ảnh \ny = df_filtered['tumor_type'].tolist() # Danh sách nhãn tương ứng\n\n# Chia Lần 1 (Train+Val / Test)\nX_train_val, X_test, y_train_val, y_test = [], [], [], []\nif len(X) < 2:\n    print(\"Không đủ mẫu dữ liệu (< 2) để thực hiện chia.\")\n    exit()\nif TEST_SIZE <= 0 or TEST_SIZE >= 1:\n     print(f\"Tỷ lệ Test ({TEST_SIZE:.2f}) không hợp lệ. Toàn bộ dữ liệu sẽ là Train+Val.\")\n     X_train_val, y_train_val = X, y\nelse:\n    try:\n        unique_classes_total, counts_total = np.unique(y, return_counts=True)\n        stratify_option_1 = y\n        if len(unique_classes_total) < 2:\n            print(\"Chỉ có 1 lớp. Chia ngẫu nhiên cho Test.\")\n            stratify_option_1 = None\n        elif np.any(counts_total < 2):\n             print(f\"Có lớp < 2 mẫu. Chia ngẫu nhiên cho Test.\")\n             stratify_option_1 = None\n\n        X_train_val, X_test, y_train_val, y_test = train_test_split(\n            X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=stratify_option_1\n        )\n        print(f\"Chia lần 1: {len(X_train_val)} Train+Val, {len(X_test)} Test.\")\n        print(\"Phân phối 'tumor_type' trong Test:\", sorted(Counter(y_test).items()))\n    except ValueError as e:\n         print(f\"Lỗi khi chia lần 1 (Test): {e}. Thoát.\")\n         exit()\n\n\n# Chia lần 2 (Train / Validation)\nX_train, X_val, y_train, y_val = [], [], [], []\nif not X_train_val:\n     print(\"Tập Train+Val rỗng.\")\nelif len(X_train_val) == 1:\n     print(\"Tập Train+Val chỉ có 1 mẫu -> vào Train.\")\n     X_train, y_train = X_train_val, y_train_val\nelif VAL_SIZE <= 0 or VAL_SIZE >= 1:\n     print(f\"Tỷ lệ Val ({VAL_SIZE:.4f}) không hợp lệ. Toàn bộ Train+Val -> Train.\")\n     X_train, y_train = X_train_val, y_train_val\nelse:\n    try:\n        unique_classes_tv, counts_tv = np.unique(y_train_val, return_counts=True)\n        stratify_option_2 = y_train_val\n        if len(unique_classes_tv) < 2:\n            print(\"Train+Val chỉ còn 1 lớp. Chia ngẫu nhiên cho Val.\")\n            stratify_option_2 = None\n        elif np.any(counts_tv < 2):\n             print(f\"Có lớp < 2 mẫu trong Train+Val. Chia ngẫu nhiên cho Val.\")\n             stratify_option_2 = None\n\n        X_train, X_val, y_train, y_val = train_test_split(\n            X_train_val, y_train_val, test_size=VAL_SIZE,\n            random_state=RANDOM_STATE, stratify=stratify_option_2\n        )\n        print(f\"Chia lần 2: {len(X_train)} Train, {len(X_val)} Validation.\")\n        print(\"Phân phối 'tumor_type' trong Train:\", sorted(Counter(y_train).items()))\n        print(\"Phân phối 'tumor_type' trong Validation:\", sorted(Counter(y_val).items()))\n    except ValueError as e:\n        print(f\"Lỗi khi chia lần 2 (Validation): {e}. Toàn bộ Train+Val -> Train.\")\n        X_train, y_train = X_train_val, y_train_val # Gán lại vào Train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.445355Z","iopub.status.idle":"2025-05-13T01:54:09.445873Z","shell.execute_reply.started":"2025-05-13T01:54:09.445521Z","shell.execute_reply":"2025-05-13T01:54:09.445564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# kết quả sau khi chia\ntotal_ids_split = len(X_train) + len(X_val) + len(X_test)\noriginal_valid_count = len(df_filtered)\n\nprint(f\"Tổng số mẫu hợp lệ ban đầu: {original_valid_count}\")\nprint(f\"Tổng số IDs được chia vào các tập: {total_ids_split}\")\nif total_ids_split != original_valid_count:\n     print(f\"Số ID được chia ({total_ids_split}) không khớp số ID hợp lệ ({original_valid_count}). Kiểm tra logic chia.\")\n\nprint(f\"Train set IDs:      {len(X_train):>5}\")\nprint(f\"Validation set IDs: {len(X_val):>5}\")\nprint(f\"Test set IDs:       {len(X_test):>5}\")\n\nif total_ids_split > 0:\n    print(f\"\\nTỷ lệ thực tế (dựa trên IDs):\")\n    print(f\"  Train: {len(X_train) / total_ids_split * 100:>6.1f}%\")\n    print(f\"  Val:   {len(X_val) / total_ids_split * 100:>6.1f}%\")\n    print(f\"  Test:  {len(X_test) / total_ids_split * 100:>6.1f}%\")\n\nprint(\"\\nPhân phối 'tumor_type' cuối cùng (dựa trên IDs đã chia):\")\nprint(f\"Train:      {sorted(Counter(y_train).items())}\")\nprint(f\"Validation: {sorted(Counter(y_val).items())}\")\nprint(f\"Test:       {sorted(Counter(y_test).items())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.447098Z","iopub.status.idle":"2025-05-13T01:54:09.447781Z","shell.execute_reply.started":"2025-05-13T01:54:09.447359Z","shell.execute_reply":"2025-05-13T01:54:09.447402Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Huấn luyện mô hình**","metadata":{}},{"cell_type":"code","source":"!pip install wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T00:26:42.422684Z","iopub.execute_input":"2025-05-22T00:26:42.422966Z","iopub.status.idle":"2025-05-22T00:26:49.207863Z","shell.execute_reply.started":"2025-05-22T00:26:42.422940Z","shell.execute_reply":"2025-05-22T00:26:49.206145Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.11.0a2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.29.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# --- Cấu hình ---\nimport os # Thêm import os nếu chưa có\nimport numpy as np # Thêm import numpy nếu dùng trong tính mean/std\nimport pandas as pd # Thêm import pandas nếu dùng trong tải metadata\nfrom tqdm import tqdm # Thêm import tqdm\nimport tensorflow as tf # Thêm import tensorflow\nfrom PIL import Image, ImageDraw # Thêm import PIL\nimport json # Thêm import json\nimport matplotlib.pyplot as plt # Thêm import matplotlib nếu dùng plot_image\n\nINPUT_DATA_ROOT = '/kaggle/input/btxrd-data' # THAY ĐỔI NẾU MÔI TRƯỜNG CỦA BẠN KHÁC\nBASE_DATA_DIR = os.path.join(INPUT_DATA_ROOT, 'btxrd-v2.1')\nCLASSIFICATION_FILE = os.path.join(INPUT_DATA_ROOT, 'classification.xlsx')\nIMAGE_SUBDIR_NAME = 'images'\nANNOTATION_SUBDIR_NAME = 'annotations'\n\n# Tham số Model & Huấn luyện\nTARGET_SIZE = 512\nN_CLASSES = 2 # 2 lớp: 0 (nền), 1 (khối u)\nBATCH_SIZE = 4 # Sẽ được dùng trong config wandb\nBUFFER_SIZE = 100 # Dùng cho dataset.shuffle\nEPOCHS = 300 # Sẽ được dùng trong config wandb và vòng lặp for\nLEARNING_RATE = 1e-4 # Sẽ được dùng trong config wandb\nL2_REG_FACTOR = 1e-5\nDROPOUT_RATE = 0.3\n\n# --- Cải tiến để tăng IoU ---\nUSE_COMBINED_LOSS = True\nDICE_LOSS_WEIGHT = 0.6\nUSE_FOCAL_LOSS_IN_COMBINED = True\nFOCAL_LOSS_ALPHA = 0.25\nFOCAL_LOSS_GAMMA = 2.0\n\nUSE_ATTENTION_UNET = False\n\n# APPLY_POST_PROCESSING, POST_PROCESSING_KERNEL_SIZE, MIN_AREA_POST_PROCESSING\n# thường dùng sau huấn luyện, không trực tiếp ảnh hưởng đến vòng lặp huấn luyện này\n\nMODEL_CHECKPOINT_BASENAME = \"unet_model\"\nTENSORBOARD_LOG_DIR = \"./logs_unet_iou_focused\"\n\n# --- Các hằng số cho callback Keras tiêu chuẩn ---\nPATIENCE_EARLY_STOPPING = 35\nPATIENCE_REDUCE_LR = 12\nMONITOR_METRIC_CB = 'val_dice_coef_metric_tumor' # QUAN TRỌNG: Phải khớp với key trong history.history\n\n# --- Cấu hình WandB ---\nWANDB_PROJECT_NAME = \"btxrd-project\" # Đặt tên project của bạn trên WandB\nWANDB_ENTITY = \"nganltt2333\" # Đặt entity của bạn\nWANDB_API_KEY = \"2b7e633df37247dd52582a893eecab6314151a62\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T15:16:57.622010Z","iopub.execute_input":"2025-05-31T15:16:57.622289Z","iopub.status.idle":"2025-05-31T15:16:57.629524Z","shell.execute_reply.started":"2025-05-31T15:16:57.622268Z","shell.execute_reply":"2025-05-31T15:16:57.628806Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def get_valid_paths(base_dir: str, split_type: str, img_filename_with_ext: str) -> Optional[Tuple[str, str]]:\n    split_dir = os.path.join(base_dir, split_type); image_dir_path = os.path.join(split_dir, IMAGE_SUBDIR_NAME); annotation_dir_path = os.path.join(split_dir, ANNOTATION_SUBDIR_NAME)\n    img_path = os.path.join(image_dir_path, img_filename_with_ext); base_name = os.path.splitext(img_filename_with_ext)[0]; json_filename = base_name + '.json'\n    json_path = os.path.join(annotation_dir_path, json_filename)\n    if os.path.exists(img_path) and os.path.exists(json_path): return img_path, json_path\n    return None\n\ndef create_mask_pil(mask_size: Tuple[int, int], json_path: str) -> Image.Image:\n    if not os.path.exists(json_path): return Image.new('L', (mask_size[1], mask_size[0]), 0)\n    mask = Image.new('L', (mask_size[1], mask_size[0]), 0)\n    try:\n        with open(json_path, 'r') as f: data = json.load(f)\n        if 'shapes' not in data or not isinstance(data['shapes'], list) or not data['shapes']: return mask\n        for shape in data['shapes']:\n             if 'points' in shape and isinstance(shape['points'], list):\n                  polygon = [tuple(point) for point in shape['points']]\n                  if len(polygon) >= 3: ImageDraw.Draw(mask).polygon(polygon, outline=255, fill=255)\n    except (json.JSONDecodeError, Exception): return Image.new('L', (mask_size[1], mask_size[0]), 0)\n    return mask\n\ndef plot_image(ax: plt.Axes, image_data: np.ndarray, title: str, cmap='gray'):\n    if image_data.ndim == 2 or (image_data.ndim == 3 and image_data.shape[2] == 1): ax.imshow(image_data.squeeze(), cmap=cmap)\n    else: ax.imshow(image_data)\n    ax.set_title(title, fontsize=10); ax.axis('off')\n\nall_image_paths = []; all_mask_paths = []; all_types = []\ntry:\n    if not os.path.exists(CLASSIFICATION_FILE): raise FileNotFoundError(f\"Không tìm thấy file phân loại tại {CLASSIFICATION_FILE}\")\n    if not os.path.isdir(BASE_DATA_DIR): raise FileNotFoundError(f\"Không tìm thấy thư mục dữ liệu cơ sở: {BASE_DATA_DIR}\")\n    df_classification = pd.read_excel(CLASSIFICATION_FILE)\n    required_cols = ['image_filename', 'type']\n    if not all(col in df_classification.columns for col in required_cols): raise ValueError(f\"File Excel phải chứa các cột: {required_cols}\")\n    for index, row in tqdm(df_classification.iterrows(), total=len(df_classification), desc=\"Kiểm tra file\"):\n        img_filename_with_ext = row['image_filename']; file_type = row['type']\n        if pd.isna(img_filename_with_ext) or pd.isna(file_type) or file_type not in ['train', 'val', 'test']: continue\n        paths = get_valid_paths(BASE_DATA_DIR, str(file_type).lower(), str(img_filename_with_ext))\n        if paths: img_path, json_path = paths; all_image_paths.append(img_path); all_mask_paths.append(json_path); all_types.append(str(file_type).lower())\n    if not all_image_paths: print(\"\\nLỗi: Không tìm thấy cặp ảnh-chú thích hợp lệ nào.\"); exit()\n    df_paths = pd.DataFrame({'image_path': all_image_paths, 'mask_path': all_mask_paths, 'type': all_types})\n    df_train = df_paths[df_paths['type'] == 'train'].reset_index(drop=True); df_val = df_paths[df_paths['type'] == 'val'].reset_index(drop=True); df_test = df_paths[df_paths['type'] == 'test'].reset_index(drop=True)\n    train_image_paths = df_train['image_path'].tolist(); train_mask_paths = df_train['mask_path'].tolist()\n    val_image_paths = df_val['image_path'].tolist(); val_mask_paths = df_val['mask_path'].tolist()\n    test_image_paths = df_test['image_path'].tolist(); test_mask_paths = df_test['mask_path'].tolist()\n    print(f\"\\nPhân chia dữ liệu: Train({len(train_image_paths)}), Val({len(val_image_paths)}), Test({len(test_image_paths)})\")\n    if not train_image_paths: print(\"Cảnh báo: Tập huấn luyện rỗng!\"); exit()\nexcept Exception as e: print(f\"Lỗi khi tải siêu dữ liệu: {e}\"); import traceback; traceback.print_exc(); exit()\n\n# Tính toán Mean/Std\nmean_pixel = 0.5; std_pixel = 0.1\nnum_train_images = len(train_image_paths)\nif num_train_images > 0:\n    print(\"Đang tính toán Mean/Std...\")\n    pixel_sum = 0.0; pixel_sum_sq = 0.0; total_pixels_calculated = 0; processed_count = 0\n    sample_size_for_stats = min(num_train_images, 250) # Tăng nhẹ sample size\n    sampled_train_paths = np.random.choice(train_image_paths, size=sample_size_for_stats, replace=False)\n    for img_path in tqdm(sampled_train_paths, desc=\"Tính Mean/Std\"):\n        try:\n            img_bytes = tf.io.read_file(img_path); img = tf.io.decode_image(img_bytes, channels=1, expand_animations=False, dtype=tf.float32)\n            img = tf.image.resize(img, [TARGET_SIZE, TARGET_SIZE])\n            pixel_sum += tf.reduce_sum(img).numpy(); pixel_sum_sq += tf.reduce_sum(tf.square(img)).numpy()\n            total_pixels_calculated += (TARGET_SIZE * TARGET_SIZE); processed_count += 1\n        except Exception: pass\n    if processed_count > 0 and total_pixels_calculated > 0:\n        mean_pixel = pixel_sum / total_pixels_calculated; variance = (pixel_sum_sq / total_pixels_calculated) - (mean_pixel ** 2)\n        std_pixel = np.sqrt(max(variance, 1e-7)); print(f\"Mean: {mean_pixel:.4f}, Std Dev: {std_pixel:.4f}\")\n        if std_pixel < 1e-4: std_pixel = 0.1; print(\"Std Dev quá thấp, dùng mặc định 0.1.\")\n    else: print(f\"Cảnh báo: Không tính được mean/std, dùng mặc định.\")\nstd_pixel = max(std_pixel, 1e-7)\n\n# Pipeline Dữ liệu TensorFlow\ndef load_mask_from_json_py(json_path_bytes):\n    json_path = json_path_bytes.numpy().decode('utf-8'); pil_mask = create_mask_pil((TARGET_SIZE, TARGET_SIZE), json_path)\n    mask_np = np.array(pil_mask, dtype=np.uint8); mask_np = (mask_np > 128).astype(np.uint8)\n    return mask_np\n\n@tf.function\ndef load_and_preprocess(image_path, mask_json_path):\n    img_bytes = tf.io.read_file(image_path)\n    try: img = tf.io.decode_image(img_bytes, channels=1, expand_animations=False, dtype=tf.float32)\n    except tf.errors.InvalidArgumentError:\n        try: img = tf.image.decode_png(img_bytes, channels=1, dtype=tf.uint8); img = tf.cast(img, tf.float32) / 255.0\n        except tf.errors.InvalidArgumentError: img = tf.image.decode_jpeg(img_bytes, channels=1); img = tf.cast(img, tf.float32) / 255.0\n    img = tf.image.resize(img, [TARGET_SIZE, TARGET_SIZE]); img.set_shape([TARGET_SIZE, TARGET_SIZE, 1])\n    mask_np_binary = tf.py_function(func=load_mask_from_json_py, inp=[mask_json_path], Tout=tf.uint8)\n    mask_np_binary.set_shape([TARGET_SIZE, TARGET_SIZE])\n    mask_onehot = tf.one_hot(tf.cast(mask_np_binary, tf.int32), depth=N_CLASSES, dtype=tf.float32)\n    mask_onehot.set_shape([TARGET_SIZE, TARGET_SIZE, N_CLASSES])\n    img = (img - mean_pixel) / std_pixel\n    return img, mask_onehot\n\n@tf.function\ndef augment_data_tf(image, mask_onehot):\n    combined = tf.concat([image, tf.cast(mask_onehot, image.dtype)], axis=-1) # Nối image và mask (đã cast về dtype của image)\n    if tf.random.uniform(()) > 0.5: combined = tf.image.flip_left_right(combined)\n    if tf.random.uniform(()) > 0.5: combined = tf.image.flip_up_down(combined)\n    k_rot = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n    combined = tf.image.rot90(combined, k=k_rot)\n    img_aug = combined[..., :1]\n    mask_aug = tf.cast(combined[..., 1:], tf.float32)\n    img_aug = tf.image.random_brightness(img_aug, max_delta=0.25)\n    img_aug = tf.image.random_contrast(img_aug, lower=0.7, upper=1.3)\n    if tf.random.uniform(()) > 0.3:\n        scale = tf.random.uniform((), 0.8, 1.2)\n        new_height = tf.cast(TARGET_SIZE * scale, tf.int32)\n        new_width = tf.cast(TARGET_SIZE * scale, tf.int32)\n        img_scaled = tf.image.resize(img_aug, [new_height, new_width], method=tf.image.ResizeMethod.BILINEAR)\n        mask_scaled = tf.image.resize(mask_aug, [new_height, new_width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        img_aug = tf.image.resize_with_crop_or_pad(img_scaled, TARGET_SIZE, TARGET_SIZE)\n        mask_aug = tf.image.resize_with_crop_or_pad(mask_scaled, TARGET_SIZE, TARGET_SIZE)\n    img_aug = tf.clip_by_value(img_aug, -3.0, 3.0)\n    img_aug.set_shape([TARGET_SIZE, TARGET_SIZE, 1])\n    mask_aug.set_shape([TARGET_SIZE, TARGET_SIZE, N_CLASSES])\n    return img_aug, mask_aug\n\ndef create_dataset(image_paths, mask_paths, is_training=True):\n    if not image_paths or not mask_paths: return tf.data.Dataset.from_tensor_slices(([], [])).batch(BATCH_SIZE)\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n    if is_training: dataset = dataset.shuffle(buffer_size=min(BUFFER_SIZE, len(image_paths)), reshuffle_each_iteration=True)\n    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n    if is_training: dataset = dataset.map(augment_data_tf, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=(is_training if len(image_paths) >= BATCH_SIZE else False))\n    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return dataset\n\ntrain_ds = create_dataset(train_image_paths, train_mask_paths, is_training=True)\nval_ds = create_dataset(val_image_paths, val_mask_paths, is_training=False)\ntest_ds = create_dataset(test_image_paths, test_mask_paths, is_training=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T15:17:00.005024Z","iopub.execute_input":"2025-05-31T15:17:00.005372Z","iopub.status.idle":"2025-05-31T15:17:14.284229Z","shell.execute_reply.started":"2025-05-31T15:17:00.005344Z","shell.execute_reply":"2025-05-31T15:17:14.283516Z"}},"outputs":[{"name":"stderr","text":"Kiểm tra file: 100%|██████████| 3746/3746 [00:09<00:00, 413.20it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nPhân chia dữ liệu: Train(1344), Val(336), Test(187)\nĐang tính toán Mean/Std...\n","output_type":"stream"},{"name":"stderr","text":"Tính Mean/Std: 100%|██████████| 250/250 [00:03<00:00, 78.07it/s] \n","output_type":"stream"},{"name":"stdout","text":"Mean: 0.1915, Std Dev: 0.2355\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# UNET\nclass AttentionGate(layers.Layer):\n    def __init__(self, F_g, F_l, F_int, **kwargs): super(AttentionGate, self).__init__(**kwargs); self.W_g = layers.Conv2D(F_int, 1, padding='same', kernel_initializer='he_normal'); self.W_x = layers.Conv2D(F_int, 1, padding='same', kernel_initializer='he_normal'); self.psi = layers.Conv2D(1, 1, padding='same', kernel_initializer='he_normal', activation='sigmoid'); self.relu = layers.Activation('relu')\n    def call(self, g, x): g1 = self.W_g(g); x1 = self.W_x(x); psi_input = self.relu(g1 + x1); alpha = self.psi(psi_input); return x * alpha\ndef conv_block(inputs, num_filters, l2_reg, dropout):\n    x = layers.Conv2D(num_filters, 3, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(inputs); x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n    if dropout > 0: x = layers.Dropout(dropout)(x)\n    x = layers.Conv2D(num_filters, 3, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x); x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n    return x\ndef encoder_block(inputs, num_filters, l2_reg, dropout, pool=True): c = conv_block(inputs, num_filters, l2_reg, dropout); p = layers.MaxPooling2D(2)(c) if pool else None; return c, p\ndef decoder_block(inputs, skip_features, num_filters, l2_reg, dropout, use_attention):\n    x = layers.Conv2DTranspose(num_filters, 2, strides=2, padding='same')(inputs)\n    if use_attention and skip_features is not None: att_gate = AttentionGate(num_filters, skip_features.shape[-1], max(1, skip_features.shape[-1] // 2) ); skip_features = att_gate(g=x, x=skip_features)\n    if skip_features is not None: x = layers.Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters, l2_reg, dropout); return x\ndef build_unet(input_shape, n_classes=N_CLASSES, l2_reg=L2_REG_FACTOR, dropout=DROPOUT_RATE, use_attention=USE_ATTENTION_UNET):\n    filters = [64, 128, 256, 512, 1024]\n    inputs = keras.Input(shape=input_shape); skips = []; x = inputs\n    for f in filters[:-1]: s, p = encoder_block(x, f, l2_reg, dropout, pool=True); skips.append(s); x = p\n    x, _ = encoder_block(x, filters[-1], l2_reg, dropout*1.3, pool=False)\n    for i, f in reversed(list(enumerate(filters[:-1]))): x = decoder_block(x, skips[i], f, l2_reg, dropout, use_attention)\n    outputs = layers.Conv2D(n_classes, 1, padding='same', activation='softmax')(x)\n    return keras.Model(inputs, outputs, name=f\"{'Attention' if use_attention else ''}UNet_filters{filters[0]}\")\n\n# --- HÀM MẤT MÁT (LOSS FUNCTIONS) ---\nSMOOTH = 1e-6\ndef dice_coef(y_true_one_hot, y_pred_softmax):\n    y_true_f = tf.keras.backend.flatten(y_true_one_hot)\n    y_pred_f = tf.keras.backend.flatten(y_pred_softmax)\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    return (2. * intersection + SMOOTH) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + SMOOTH)\n\ndef dice_coef_metric_tumor(y_true, y_pred):\n    # y_true: (batch, H, W, N_CLASSES), y_pred: (batch, H, W, N_CLASSES)\n    return dice_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\ndice_coef_metric_tumor.__name__ = 'dice_coef_metric_tumor' # Khớp với `metrics_to_plot`\n\ndef dice_loss_tumor(y_true, y_pred):\n    return 1.0 - dice_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\n\ndef iou_coef(y_true_one_hot, y_pred_softmax):\n    y_true_f = tf.keras.backend.flatten(y_true_one_hot)\n    y_pred_f = tf.keras.backend.flatten(y_pred_softmax)\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n    return (intersection + SMOOTH) / (union + SMOOTH)\n\ndef iou_metric_tumor(y_true, y_pred):\n    return iou_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\niou_metric_tumor.__name__ = 'tumor_iou' # Khớp với `metrics_to_plot`\n\n# --- CÁC METRICS MỚI CHO LỚP TUMOR ---\ndef precision_recall_tumor_base(y_true, y_pred, metric_type):\n    if N_CLASSES < 2:\n        return tf.constant(0.0, dtype=tf.float32)\n\n    # Lấy kênh của lớp tumor (giả sử lớp 1 là tumor)\n    y_true_tumor = y_true[..., 1] # Ground truth cho lớp tumor (0 hoặc 1)\n    \n    # Chuyển đổi y_pred (softmax probabilities) thành dự đoán nhãn cứng (0 hoặc 1) cho lớp tumor\n    # Cách 1: Dựa trên xác suất cao nhất (argmax)\n    y_pred_labels = tf.argmax(y_pred, axis=-1) # Shape: (batch, H, W)\n    y_pred_tumor_binary = tf.cast(tf.equal(y_pred_labels, 1), tf.float32) # 1 nếu dự đoán là tumor (lớp 1), 0 nếu khác\n\n    # Cách 2: (Nếu chỉ có 2 lớp, có thể dùng ngưỡng 0.5 cho xác suất lớp tumor)\n    # y_pred_tumor_binary = tf.cast(y_pred[..., 1] > 0.5, tf.float32) # Chỉ phù hợp nếu N_CLASSES=2 và lớp 1 là tumor\n\n    # Flatten để tính toán\n    y_true_tumor_flat = tf.keras.backend.flatten(y_true_tumor)\n    y_pred_tumor_binary_flat = tf.keras.backend.flatten(y_pred_tumor_binary)\n\n    true_positives = tf.keras.backend.sum(y_true_tumor_flat * y_pred_tumor_binary_flat)\n    \n    if metric_type == 'precision':\n        predicted_positives = tf.keras.backend.sum(y_pred_tumor_binary_flat)\n        value = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n    elif metric_type == 'recall':\n        possible_positives = tf.keras.backend.sum(y_true_tumor_flat)\n        value = true_positives / (possible_positives + tf.keras.backend.epsilon())\n    else:\n        value = tf.constant(0.0, dtype=tf.float32)\n        \n    return value\n\ndef precision_tumor_metric(y_true, y_pred):\n    return precision_recall_tumor_base(y_true, y_pred, 'precision')\nprecision_tumor_metric.__name__ = 'precision_tumor' # Khớp với `metrics_to_plot`\n\ndef recall_tumor_metric(y_true, y_pred):\n    return precision_recall_tumor_base(y_true, y_pred, 'recall')\nrecall_tumor_metric.__name__ = 'recall_tumor' # Khớp với `metrics_to_plot`\n# --- KẾT THÚC METRICS MỚI ---\n\ndef categorical_focal_loss_wrapper(alpha=FOCAL_LOSS_ALPHA, gamma=FOCAL_LOSS_GAMMA):\n    def focal_loss_fn(y_true, y_pred):\n        epsilon = tf.keras.backend.epsilon(); y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n        cross_entropy = -y_true * tf.math.log(y_pred)\n        loss = alpha * tf.pow(1 - y_pred, gamma) * cross_entropy\n        return tf.reduce_mean(tf.reduce_sum(loss, axis=-1))\n    focal_loss_fn.__name__ = f'focal_loss_alpha{alpha}_gamma{gamma}'\n    return focal_loss_fn\n\ndef combined_loss_fn(y_true, y_pred, dice_w=DICE_LOSS_WEIGHT):\n    d_loss = dice_loss_tumor(y_true, y_pred)\n    if USE_FOCAL_LOSS_IN_COMBINED: ce_or_focal_loss = categorical_focal_loss_wrapper()(y_true, y_pred)\n    else: ce_or_focal_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true, y_pred))\n    return (dice_w * d_loss) + ((1.0 - dice_w) * ce_or_focal_loss)\ncombined_loss_fn.__name__ = f'combined_dice{DICE_LOSS_WEIGHT}_{\"focal\" if USE_FOCAL_LOSS_IN_COMBINED else \"cce\"}'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T15:17:43.149497Z","iopub.execute_input":"2025-05-31T15:17:43.150010Z","iopub.status.idle":"2025-05-31T15:17:43.172126Z","shell.execute_reply.started":"2025-05-31T15:17:43.149964Z","shell.execute_reply":"2025-05-31T15:17:43.171220Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import wandb # Đảm bảo wandb đã được import\nfrom datetime import datetime, timedelta # Để tạo tên run\n\n# --- Build và Compile Model ---\nmodel = build_unet((TARGET_SIZE, TARGET_SIZE, 1), N_CLASSES, L2_REG_FACTOR, DROPOUT_RATE, USE_ATTENTION_UNET)\noptimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n\nif USE_COMBINED_LOSS:\n    loss_to_use = combined_loss_fn\nelse:\n    if USE_FOCAL_LOSS_IN_COMBINED:\n        loss_to_use = categorical_focal_loss_wrapper(alpha=FOCAL_LOSS_ALPHA, gamma=FOCAL_LOSS_GAMMA)\n    else:\n        loss_to_use = tf.keras.losses.CategoricalCrossentropy()\n        loss_to_use.__name__ = \"categorical_crossentropy\" # Đặt tên nếu là object\n\nloss_name_str = loss_to_use.__name__ if hasattr(loss_to_use, '__name__') else \"custom_loss\"\n\n# --- Định nghĩa danh sách metrics cho model.compile() ---\n# Đảm bảo các tên này sẽ xuất hiện trong history.history\nmetrics_to_compile = [ # Đổi tên biến để tránh nhầm lẫn với list dùng để log\n    dice_coef_metric_tumor,\n    iou_metric_tumor,\n    precision_tumor_metric,\n    recall_tumor_metric,\n    tf.keras.metrics.MeanIoU(num_classes=N_CLASSES, name='mean_iou_all'),\n    tf.keras.metrics.CategoricalAccuracy(name='acc') # Keras có thể trả về 'acc' hoặc 'categorical_accuracy'\n]\n# Tạo list các tên metric thực tế sẽ dùng để log (từ history.history)\n# Điều này quan trọng để đảm bảo key khớp khi log thủ công\n# Keras trả về tên của hàm/object metric, hoặc tên bạn đặt trong tf.keras.metrics.Metric(name='...')\n# Nếu metric là một hàm, history.history sẽ dùng tên hàm.\n# Nếu là một object tf.keras.metrics.Metric, nó sẽ dùng thuộc tính .name\n# Đối với CategoricalAccuracy, Keras có thể dùng 'acc' hoặc 'categorical_accuracy'.\n# Chúng ta sẽ xử lý điều này linh hoạt hơn trong vòng lặp log.\n\n# Các tên metric cơ bản mà chúng ta muốn log, không bao gồm 'loss' và 'val_loss' (vì chúng luôn có)\n# và 'acc'/'val_acc' (sẽ xử lý riêng)\nmetric_names_to_log_manually = []\nfor m in metrics_to_compile:\n    if hasattr(m, 'name'):\n        metric_names_to_log_manually.append(m.name)\n    elif hasattr(m, '__name__'):\n        metric_names_to_log_manually.append(m.__name__)\n# Loại bỏ 'acc' nếu có, vì sẽ xử lý riêng\nif 'acc' in metric_names_to_log_manually:\n    metric_names_to_log_manually.remove('acc')\nif 'categorical_accuracy' in metric_names_to_log_manually:\n     metric_names_to_log_manually.remove('categorical_accuracy')\n\n\nmodel.compile(optimizer=optimizer, loss=loss_to_use, metrics=metrics_to_compile)\nmodel.summary()\n\n# --- KHỞI TẠO WEIGHTS & BIASES ---\nif WANDB_API_KEY:\n    wandb.login(key=WANDB_API_KEY)\nelse:\n    try:\n        wandb.login() # Thử đăng nhập tương tác nếu không có key\n    except Exception as e:\n        print(f\"Lỗi khi đăng nhập WandB: {e}. Vui lòng đảm bảo bạn đã đăng nhập WandB.\")\n        # Có thể exit() ở đây nếu WandB là bắt buộc\n\n# Lấy giờ VN cho tên run\nnow_vn = datetime.utcnow() + timedelta(hours=7)\n# Chỉnh sửa format tên run để không có ký tự '/' không hợp lệ cho tên file/directory\nrun_name_wandb = f\"{MODEL_CHECKPOINT_BASENAME}_{loss_name_str}_attn{USE_ATTENTION_UNET}_\" + now_vn.strftime(\"%d%m%Y_%H%M%S\")\n\nwandb_config = {\n    \"epochs\": EPOCHS,\n    \"batch_size\": BATCH_SIZE,\n    \"learning_rate\": LEARNING_RATE,\n    \"target_size\": TARGET_SIZE,\n    \"n_classes\": N_CLASSES,\n    \"l2_reg_factor\": L2_REG_FACTOR,\n    \"dropout_rate\": DROPOUT_RATE,\n    \"use_combined_loss\": USE_COMBINED_LOSS,\n    \"dice_loss_weight\": DICE_LOSS_WEIGHT,\n    \"use_focal_loss_in_combined\": USE_FOCAL_LOSS_IN_COMBINED,\n    \"focal_loss_alpha\": FOCAL_LOSS_ALPHA,\n    \"focal_loss_gamma\": FOCAL_LOSS_GAMMA,\n    \"use_attention_unet\": USE_ATTENTION_UNET,\n    \"architecture\": model.name,\n    \"optimizer\": type(optimizer).__name__,\n    \"loss_function\": loss_name_str,\n    \"mean_pixel_train\": mean_pixel, # Giả sử mean_pixel, std_pixel đã được tính\n    \"std_pixel_train\": std_pixel,\n    \"monitor_metric_callbacks\": MONITOR_METRIC_CB # Metric cho các Keras callback\n}\n\nwandb.init(\n    project=WANDB_PROJECT_NAME,\n    entity=WANDB_ENTITY,\n    name=run_name_wandb,\n    config=wandb_config\n    # sync_tensorboard=True # Vẫn có thể dùng nếu bạn có TensorBoard callback\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T15:17:47.663286Z","iopub.execute_input":"2025-05-31T15:17:47.663574Z","iopub.status.idle":"2025-05-31T15:18:04.723034Z","shell.execute_reply.started":"2025-05-31T15:17:47.663552Z","shell.execute_reply":"2025-05-31T15:18:04.722233Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"UNet_filters64\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"UNet_filters64\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m640\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_2 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_3 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_4 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m590,080\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_5 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_6 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_7 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │      \u001b[38;5;34m4,719,616\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_8 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │      \u001b[38;5;34m9,438,208\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_9 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,097,664\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                           │                        │                │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m4,719,104\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m524,544\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │      \u001b[38;5;34m1,179,904\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_12             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m590,080\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_13             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m131,200\u001b[0m │ activation_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_2[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m295,040\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_14             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_15             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m32,832\u001b[0m │ activation_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_3[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m73,792\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_16             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_17             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m2\u001b[0m)    │            \u001b[38;5;34m130\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                           │                        │                │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_12             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_13             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_14             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_15             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_16             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_17             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,054,210\u001b[0m (118.46 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,054,210</span> (118.46 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,042,434\u001b[0m (118.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,042,434</span> (118.42 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m11,776\u001b[0m (46.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,776</span> (46.00 KB)\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnganltt23\u001b[0m (\u001b[33mnganltt2333\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250531_151757-3x2dug9c</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nganltt2333/btxrd-project/runs/3x2dug9c' target=\"_blank\">unet_model_combined_dice0.6_focal_attnFalse_31052025_221757</a></strong> to <a href='https://wandb.ai/nganltt2333/btxrd-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nganltt2333/btxrd-project' target=\"_blank\">https://wandb.ai/nganltt2333/btxrd-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nganltt2333/btxrd-project/runs/3x2dug9c' target=\"_blank\">https://wandb.ai/nganltt2333/btxrd-project/runs/3x2dug9c</a>"},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nganltt2333/btxrd-project/runs/3x2dug9c?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7b50708848b0>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Callbacks Keras tiêu chuẩn (KHÔNG BAO GỒM WandbCallback)\n\n# Đường dẫn lưu checkpoint\ncheckpoint_path = f\"{MODEL_CHECKPOINT_BASENAME}_{run_name_wandb}.keras\" # Dùng run_name_wandb để duy nhất\n\n# MONITOR_METRIC_CB ('val_dice_coef_metric_tumor') phải là một key có trong history.history khi val_ds được dùng\nkeras_callbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_path, # Đổi tên tham số cho rõ ràng\n        save_best_only=True,\n        monitor=MONITOR_METRIC_CB,\n        mode='max',\n        verbose=1\n    ),\n    tf.keras.callbacks.EarlyStopping(\n        monitor=MONITOR_METRIC_CB,\n        patience=PATIENCE_EARLY_STOPPING,\n        mode='max',\n        restore_best_weights=True,\n        verbose=1\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor=MONITOR_METRIC_CB,\n        factor=0.3,\n        patience=PATIENCE_REDUCE_LR,\n        mode='max',\n        min_lr=1e-7,\n        verbose=1\n    ),\n    tf.keras.callbacks.TensorBoard(\n        log_dir=TENSORBOARD_LOG_DIR, # WandB có thể sync từ đây nếu sync_tensorboard=True trong init\n        histogram_freq=1 # Có thể gây chậm, cân nhắc\n    )\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T15:18:06.835549Z","iopub.execute_input":"2025-05-31T15:18:06.835877Z","iopub.status.idle":"2025-05-31T15:18:06.841845Z","shell.execute_reply.started":"2025-05-31T15:18:06.835853Z","shell.execute_reply":"2025-05-31T15:18:06.841004Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Class Weights\npix_cls0 = 0; pix_cls1 = 0\n# Giả sử train_mask_paths đã được tạo ở Đoạn 2\nif 'train_mask_paths' in locals() and train_mask_paths: # Kiểm tra biến tồn tại\n    for mask_p in tqdm(train_mask_paths, desc=\"Đếm pixels cho class weights\"):\n        try:\n            m = create_mask_pil((TARGET_SIZE, TARGET_SIZE), mask_p)\n            m_np = (np.array(m) > 128).astype(np.uint8)\n            pix_cls0 += np.sum(m_np == 0)\n            pix_cls1 += np.sum(m_np == 1)\n        except Exception as e:\n            print(f\"Lỗi khi xử lý mask {mask_p} cho class weights: {e}\")\n            continue\nelse:\n    print(\"Cảnh báo: train_mask_paths không tồn tại hoặc rỗng, không thể tính class weights.\")\n\nclass_weights = None # Khởi tạo class_weights\nif pix_cls1 > 0 and pix_cls0 > 0:\n    total_pix = float(pix_cls0 + pix_cls1)\n    w0 = (total_pix / (N_CLASSES * float(pix_cls0)))\n    w1 = (total_pix / (N_CLASSES * float(pix_cls1)))\n    class_weights = {0: w0, 1: w1} # Gán giá trị cho class_weights\n    print(f\"Class weights đã tính: Lớp 0: {w0:.4f}, Lớp 1: {w1:.4f}\")\n    if w1 < w0 :\n        print(\"Cảnh báo: Trọng số lớp khối u (1) nhỏ hơn lớp nền (0). Kiểm tra lại số lượng pixel hoặc dữ liệu.\")\n    if wandb.run:\n        wandb.config.update({\"class_weight_0\": w0, \"class_weight_1\": w1, \"calculated_class_weights\": True})\nelse:\n    print(\"Không tính được class weights (số pixel lớp 0 hoặc 1 bằng 0 hoặc train_mask_paths rỗng). Sử dụng None.\")\n    if wandb.run:\n        wandb.config.update({\"calculated_class_weights\": False})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T15:18:10.376021Z","iopub.execute_input":"2025-05-31T15:18:10.376341Z","iopub.status.idle":"2025-05-31T15:18:15.759592Z","shell.execute_reply.started":"2025-05-31T15:18:10.376317Z","shell.execute_reply":"2025-05-31T15:18:15.758688Z"}},"outputs":[{"name":"stderr","text":"Đếm pixels cho class weights: 100%|██████████| 1344/1344 [00:05<00:00, 250.28it/s]","output_type":"stream"},{"name":"stdout","text":"Class weights đã tính: Lớp 0: 0.5089, Lớp 1: 28.6592\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Huấn luyện Model với vòng lặp thủ công và log thủ công lên WandB\n\n# Kiểm tra sự tồn tại của train_ds và val_ds (nếu val_image_paths có)\nif 'train_ds' not in locals() or not train_ds:\n    print(\"Lỗi: Tập huấn luyện (train_ds) chưa được tạo hoặc rỗng.\")\n    if wandb.run: wandb.finish(exit_code=1)\n    exit()\n\nuse_validation = 'val_image_paths' in locals() and val_image_paths and 'val_ds' in locals() and val_ds\nif 'val_image_paths' in locals() and val_image_paths and ('val_ds' not in locals() or not val_ds):\n    print(\"Lỗi: Có val_image_paths nhưng tập validation (val_ds) chưa được tạo hoặc rỗng.\")\n    if wandb.run: wandb.finish(exit_code=1)\n    exit()\n\nprint(f\"\\nBắt đầu huấn luyện cho {EPOCHS} epochs...\")\n\nfor epoch in range(EPOCHS):\n    print(f\"\\n--- Epoch {epoch + 1}/{EPOCHS} ---\")\n\n    history = model.fit(\n        train_ds,\n        validation_data=val_ds if use_validation else None,\n        epochs=1, # CHỈ HUẤN LUYỆN 1 EPOCH MỖI LẦN GỌI FIT\n        class_weight=class_weights, # Từ Đoạn 6\n        callbacks=keras_callbacks, # Callbacks Keras tiêu chuẩn từ Đoạn 5\n        verbose=1\n    )\n\n    current_logs = history.history\n    if not current_logs:\n        print(f\"Cảnh báo: Không có logs nào được trả về từ model.fit() ở epoch {epoch + 1}.\")\n        continue\n\n    # --- Ghi log thủ công cho W&B ---\n    log_data_to_wandb = {\"epoch\": epoch + 1}\n\n    # Metrics huấn luyện\n    log_data_to_wandb[\"loss\"] = current_logs.get(\"loss\", [None])[0]\n    # Xử lý 'acc' hoặc 'categorical_accuracy' cho training\n    train_acc_key = None\n    if \"acc\" in current_logs:\n        train_acc_key = \"acc\"\n    elif \"categorical_accuracy\" in current_logs:\n        train_acc_key = \"categorical_accuracy\"\n    if train_acc_key:\n        log_data_to_wandb[train_acc_key] = current_logs.get(train_acc_key, [None])[0]\n\n    # Log các metrics tùy chỉnh khác cho training\n    for metric_name in metric_names_to_log_manually: # Từ Đoạn 4\n        if metric_name in current_logs:\n            log_data_to_wandb[metric_name] = current_logs.get(metric_name, [None])[0]\n\n\n    # Metrics validation (nếu có)\n    if use_validation:\n        log_data_to_wandb[\"val_loss\"] = current_logs.get(\"val_loss\", [None])[0]\n        # Xử lý 'val_acc' hoặc 'val_categorical_accuracy'\n        val_acc_key = None\n        if \"val_acc\" in current_logs:\n            val_acc_key = \"val_acc\"\n        elif \"val_categorical_accuracy\" in current_logs:\n            val_acc_key = \"val_categorical_accuracy\"\n        if val_acc_key:\n            log_data_to_wandb[val_acc_key] = current_logs.get(val_acc_key, [None])[0]\n\n        # Log các metrics tùy chỉnh khác cho validation\n        for metric_name in metric_names_to_log_manually: # Từ Đoạn 4\n            val_metric_key = f\"val_{metric_name}\"\n            if val_metric_key in current_logs:\n                log_data_to_wandb[val_metric_key] = current_logs.get(val_metric_key, [None])[0]\n\n    wandb.log(log_data_to_wandb)\n    print(f\"Đã log metrics cho epoch {epoch + 1} lên WandB.\")\n\n    # Kiểm tra điều kiện dừng sớm từ EarlyStopping callback\n    if model.stop_training:\n        print(f\"Huấn luyện dừng sớm bởi EarlyStopping callback sau epoch {epoch + 1}.\")\n        break\n\nprint(\"\\nHuấn luyện hoàn tất (hoặc dừng sớm)!\")\n\n# Kết thúc run WandB\nif wandb.run:\n    # (Tùy chọn) Log model tốt nhất như một artifact\n    # Giả sử ModelCheckpoint đã lưu model tốt nhất vào checkpoint_path\n    if os.path.exists(checkpoint_path):\n        print(f\"Đang log model tốt nhất từ: {checkpoint_path}\")\n        best_model_artifact = wandb.Artifact(\n            f'{MODEL_CHECKPOINT_BASENAME}-best_model',\n            type='model',\n            description=f'Best model based on {MONITOR_METRIC_CB} from run {run_name_wandb}',\n            metadata=dict(wandb.config) # Lưu config của run vào metadata artifact\n        )\n        best_model_artifact.add_file(checkpoint_path)\n        wandb.log_artifact(best_model_artifact)\n        print(\"Đã log model tốt nhất lên WandB Artifacts.\")\n    else:\n        print(f\"Không tìm thấy model checkpoint tại: {checkpoint_path} để log artifact.\")\n\n    wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T15:18:17.645279Z","iopub.execute_input":"2025-05-31T15:18:17.645566Z","execution_failed":"2025-06-01T03:16:15.863Z"}},"outputs":[{"name":"stdout","text":"\nBắt đầu huấn luyện cho 300 epochs...\n\n--- Epoch 1/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.8005 - dice_coef_metric_tumor: 0.0652 - loss: 0.6923 - mean_iou_all: 0.2516 - precision_tumor: 0.0583 - recall_tumor: 0.6086 - tumor_iou: 0.0344\nEpoch 1: val_dice_coef_metric_tumor improved from -inf to 0.08014, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 483ms/step - acc: 0.8006 - dice_coef_metric_tumor: 0.0653 - loss: 0.6922 - mean_iou_all: 0.2516 - precision_tumor: 0.0583 - recall_tumor: 0.6085 - tumor_iou: 0.0344 - val_acc: 0.9001 - val_dice_coef_metric_tumor: 0.0801 - val_loss: 0.6192 - val_mean_iou_all: 0.2487 - val_precision_tumor: 0.0561 - val_recall_tumor: 0.3082 - val_tumor_iou: 0.0431 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 1 lên WandB.\n\n--- Epoch 2/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.8839 - dice_coef_metric_tumor: 0.1132 - loss: 0.5908 - mean_iou_all: 0.2524 - precision_tumor: 0.0886 - recall_tumor: 0.5499 - tumor_iou: 0.0626\nEpoch 1: val_dice_coef_metric_tumor improved from 0.08014 to 0.09066, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.8839 - dice_coef_metric_tumor: 0.1132 - loss: 0.5908 - mean_iou_all: 0.2524 - precision_tumor: 0.0886 - recall_tumor: 0.5498 - tumor_iou: 0.0626 - val_acc: 0.9179 - val_dice_coef_metric_tumor: 0.0907 - val_loss: 0.5978 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0668 - val_recall_tumor: 0.3075 - val_tumor_iou: 0.0491 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 2 lên WandB.\n\n--- Epoch 3/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9228 - dice_coef_metric_tumor: 0.1424 - loss: 0.5532 - mean_iou_all: 0.2515 - precision_tumor: 0.1217 - recall_tumor: 0.4845 - tumor_iou: 0.0813\nEpoch 1: val_dice_coef_metric_tumor improved from 0.09066 to 0.11409, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9228 - dice_coef_metric_tumor: 0.1424 - loss: 0.5531 - mean_iou_all: 0.2515 - precision_tumor: 0.1217 - recall_tumor: 0.4845 - tumor_iou: 0.0813 - val_acc: 0.8386 - val_dice_coef_metric_tumor: 0.1141 - val_loss: 0.5850 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0736 - val_recall_tumor: 0.7662 - val_tumor_iou: 0.0630 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 3 lên WandB.\n\n--- Epoch 4/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9378 - dice_coef_metric_tumor: 0.1767 - loss: 0.5368 - mean_iou_all: 0.2518 - precision_tumor: 0.1480 - recall_tumor: 0.4384 - tumor_iou: 0.1036\nEpoch 1: val_dice_coef_metric_tumor improved from 0.11409 to 0.14456, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9378 - dice_coef_metric_tumor: 0.1767 - loss: 0.5367 - mean_iou_all: 0.2518 - precision_tumor: 0.1479 - recall_tumor: 0.4384 - tumor_iou: 0.1035 - val_acc: 0.9253 - val_dice_coef_metric_tumor: 0.1446 - val_loss: 0.5593 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1042 - val_recall_tumor: 0.4714 - val_tumor_iou: 0.0824 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 4 lên WandB.\n\n--- Epoch 5/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9385 - dice_coef_metric_tumor: 0.1841 - loss: 0.5212 - mean_iou_all: 0.2521 - precision_tumor: 0.1460 - recall_tumor: 0.4443 - tumor_iou: 0.1088\nEpoch 1: val_dice_coef_metric_tumor improved from 0.14456 to 0.15636, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9385 - dice_coef_metric_tumor: 0.1841 - loss: 0.5212 - mean_iou_all: 0.2521 - precision_tumor: 0.1459 - recall_tumor: 0.4443 - tumor_iou: 0.1087 - val_acc: 0.9313 - val_dice_coef_metric_tumor: 0.1564 - val_loss: 0.5514 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1147 - val_recall_tumor: 0.4688 - val_tumor_iou: 0.0902 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 5 lên WandB.\n\n--- Epoch 6/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9392 - dice_coef_metric_tumor: 0.1977 - loss: 0.5205 - mean_iou_all: 0.2519 - precision_tumor: 0.1585 - recall_tumor: 0.4513 - tumor_iou: 0.1192\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.15636\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9392 - dice_coef_metric_tumor: 0.1976 - loss: 0.5204 - mean_iou_all: 0.2519 - precision_tumor: 0.1585 - recall_tumor: 0.4513 - tumor_iou: 0.1192 - val_acc: 0.9549 - val_dice_coef_metric_tumor: 0.1450 - val_loss: 0.5523 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1348 - val_recall_tumor: 0.3042 - val_tumor_iou: 0.0834 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 6 lên WandB.\n\n--- Epoch 7/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9488 - dice_coef_metric_tumor: 0.1994 - loss: 0.5106 - mean_iou_all: 0.2521 - precision_tumor: 0.1688 - recall_tumor: 0.4020 - tumor_iou: 0.1201\nEpoch 1: val_dice_coef_metric_tumor improved from 0.15636 to 0.16352, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9488 - dice_coef_metric_tumor: 0.1993 - loss: 0.5106 - mean_iou_all: 0.2521 - precision_tumor: 0.1688 - recall_tumor: 0.4020 - tumor_iou: 0.1201 - val_acc: 0.9548 - val_dice_coef_metric_tumor: 0.1635 - val_loss: 0.5386 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1481 - val_recall_tumor: 0.3481 - val_tumor_iou: 0.0958 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 7 lên WandB.\n\n--- Epoch 8/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9432 - dice_coef_metric_tumor: 0.2014 - loss: 0.5109 - mean_iou_all: 0.2533 - precision_tumor: 0.1542 - recall_tumor: 0.4597 - tumor_iou: 0.1201\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.16352\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9432 - dice_coef_metric_tumor: 0.2014 - loss: 0.5109 - mean_iou_all: 0.2533 - precision_tumor: 0.1542 - recall_tumor: 0.4597 - tumor_iou: 0.1200 - val_acc: 0.9504 - val_dice_coef_metric_tumor: 0.1522 - val_loss: 0.5474 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1331 - val_recall_tumor: 0.3324 - val_tumor_iou: 0.0894 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 8 lên WandB.\n\n--- Epoch 9/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9476 - dice_coef_metric_tumor: 0.2072 - loss: 0.5045 - mean_iou_all: 0.2552 - precision_tumor: 0.1653 - recall_tumor: 0.4372 - tumor_iou: 0.1257\nEpoch 1: val_dice_coef_metric_tumor improved from 0.16352 to 0.17113, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9476 - dice_coef_metric_tumor: 0.2071 - loss: 0.5045 - mean_iou_all: 0.2553 - precision_tumor: 0.1653 - recall_tumor: 0.4371 - tumor_iou: 0.1257 - val_acc: 0.9452 - val_dice_coef_metric_tumor: 0.1711 - val_loss: 0.5353 - val_mean_iou_all: 0.2593 - val_precision_tumor: 0.1361 - val_recall_tumor: 0.4109 - val_tumor_iou: 0.1008 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 9 lên WandB.\n\n--- Epoch 10/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9466 - dice_coef_metric_tumor: 0.2163 - loss: 0.5003 - mean_iou_all: 0.2576 - precision_tumor: 0.1710 - recall_tumor: 0.4620 - tumor_iou: 0.1314\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.17113\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9466 - dice_coef_metric_tumor: 0.2162 - loss: 0.5002 - mean_iou_all: 0.2576 - precision_tumor: 0.1710 - recall_tumor: 0.4619 - tumor_iou: 0.1314 - val_acc: 0.9572 - val_dice_coef_metric_tumor: 0.1556 - val_loss: 0.5440 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1464 - val_recall_tumor: 0.2876 - val_tumor_iou: 0.0935 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 10 lên WandB.\n\n--- Epoch 11/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9474 - dice_coef_metric_tumor: 0.2114 - loss: 0.4974 - mean_iou_all: 0.2534 - precision_tumor: 0.1667 - recall_tumor: 0.4444 - tumor_iou: 0.1279\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.17113\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9474 - dice_coef_metric_tumor: 0.2113 - loss: 0.4973 - mean_iou_all: 0.2534 - precision_tumor: 0.1666 - recall_tumor: 0.4444 - tumor_iou: 0.1278 - val_acc: 0.9705 - val_dice_coef_metric_tumor: 0.1370 - val_loss: 0.5521 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1778 - val_recall_tumor: 0.1855 - val_tumor_iou: 0.0813 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 11 lên WandB.\n\n--- Epoch 12/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9511 - dice_coef_metric_tumor: 0.2127 - loss: 0.5026 - mean_iou_all: 0.2539 - precision_tumor: 0.1718 - recall_tumor: 0.4139 - tumor_iou: 0.1292\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.17113\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9511 - dice_coef_metric_tumor: 0.2127 - loss: 0.5026 - mean_iou_all: 0.2539 - precision_tumor: 0.1718 - recall_tumor: 0.4139 - tumor_iou: 0.1292 - val_acc: 0.9820 - val_dice_coef_metric_tumor: 0.0389 - val_loss: 0.6129 - val_mean_iou_all: 0.2501 - val_precision_tumor: 0.1638 - val_recall_tumor: 0.0231 - val_tumor_iou: 0.0212 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 12 lên WandB.\n\n--- Epoch 13/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9500 - dice_coef_metric_tumor: 0.2121 - loss: 0.4925 - mean_iou_all: 0.2547 - precision_tumor: 0.1693 - recall_tumor: 0.4136 - tumor_iou: 0.1289\nEpoch 1: val_dice_coef_metric_tumor improved from 0.17113 to 0.17588, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9500 - dice_coef_metric_tumor: 0.2121 - loss: 0.4925 - mean_iou_all: 0.2547 - precision_tumor: 0.1693 - recall_tumor: 0.4135 - tumor_iou: 0.1289 - val_acc: 0.9584 - val_dice_coef_metric_tumor: 0.1759 - val_loss: 0.5310 - val_mean_iou_all: 0.2515 - val_precision_tumor: 0.1580 - val_recall_tumor: 0.3235 - val_tumor_iou: 0.1054 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 13 lên WandB.\n\n--- Epoch 14/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9555 - dice_coef_metric_tumor: 0.2322 - loss: 0.4757 - mean_iou_all: 0.2568 - precision_tumor: 0.1888 - recall_tumor: 0.4329 - tumor_iou: 0.1419\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.17588\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9555 - dice_coef_metric_tumor: 0.2321 - loss: 0.4757 - mean_iou_all: 0.2568 - precision_tumor: 0.1888 - recall_tumor: 0.4329 - tumor_iou: 0.1419 - val_acc: 0.9573 - val_dice_coef_metric_tumor: 0.1536 - val_loss: 0.5435 - val_mean_iou_all: 0.2502 - val_precision_tumor: 0.1478 - val_recall_tumor: 0.2902 - val_tumor_iou: 0.0910 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 14 lên WandB.\n\n--- Epoch 15/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9535 - dice_coef_metric_tumor: 0.2387 - loss: 0.4883 - mean_iou_all: 0.2581 - precision_tumor: 0.1978 - recall_tumor: 0.4409 - tumor_iou: 0.1473\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.17588\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9535 - dice_coef_metric_tumor: 0.2387 - loss: 0.4883 - mean_iou_all: 0.2581 - precision_tumor: 0.1977 - recall_tumor: 0.4408 - tumor_iou: 0.1473 - val_acc: 0.9689 - val_dice_coef_metric_tumor: 0.1524 - val_loss: 0.5419 - val_mean_iou_all: 0.2501 - val_precision_tumor: 0.1740 - val_recall_tumor: 0.1992 - val_tumor_iou: 0.0925 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 15 lên WandB.\n\n--- Epoch 16/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9569 - dice_coef_metric_tumor: 0.2460 - loss: 0.4692 - mean_iou_all: 0.2538 - precision_tumor: 0.2038 - recall_tumor: 0.4404 - tumor_iou: 0.1542\nEpoch 1: val_dice_coef_metric_tumor improved from 0.17588 to 0.18968, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9569 - dice_coef_metric_tumor: 0.2459 - loss: 0.4692 - mean_iou_all: 0.2538 - precision_tumor: 0.2037 - recall_tumor: 0.4403 - tumor_iou: 0.1542 - val_acc: 0.9226 - val_dice_coef_metric_tumor: 0.1897 - val_loss: 0.5296 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1279 - val_recall_tumor: 0.5976 - val_tumor_iou: 0.1139 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 16 lên WandB.\n\n--- Epoch 17/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9548 - dice_coef_metric_tumor: 0.2382 - loss: 0.4777 - mean_iou_all: 0.2537 - precision_tumor: 0.1905 - recall_tumor: 0.4541 - tumor_iou: 0.1456\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18968\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9548 - dice_coef_metric_tumor: 0.2381 - loss: 0.4777 - mean_iou_all: 0.2537 - precision_tumor: 0.1905 - recall_tumor: 0.4541 - tumor_iou: 0.1456 - val_acc: 0.9686 - val_dice_coef_metric_tumor: 0.1618 - val_loss: 0.5372 - val_mean_iou_all: 0.2501 - val_precision_tumor: 0.1845 - val_recall_tumor: 0.2279 - val_tumor_iou: 0.0998 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 17 lên WandB.\n\n--- Epoch 18/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9570 - dice_coef_metric_tumor: 0.2349 - loss: 0.4831 - mean_iou_all: 0.2543 - precision_tumor: 0.2016 - recall_tumor: 0.4134 - tumor_iou: 0.1457\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18968\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9570 - dice_coef_metric_tumor: 0.2349 - loss: 0.4831 - mean_iou_all: 0.2543 - precision_tumor: 0.2015 - recall_tumor: 0.4134 - tumor_iou: 0.1456 - val_acc: 0.8853 - val_dice_coef_metric_tumor: 0.1690 - val_loss: 0.5581 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1024 - val_recall_tumor: 0.7492 - val_tumor_iou: 0.0984 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 18 lên WandB.\n\n--- Epoch 19/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9566 - dice_coef_metric_tumor: 0.2433 - loss: 0.4689 - mean_iou_all: 0.2585 - precision_tumor: 0.2022 - recall_tumor: 0.4191 - tumor_iou: 0.1518\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18968\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9566 - dice_coef_metric_tumor: 0.2433 - loss: 0.4689 - mean_iou_all: 0.2585 - precision_tumor: 0.2022 - recall_tumor: 0.4191 - tumor_iou: 0.1518 - val_acc: 0.9709 - val_dice_coef_metric_tumor: 0.1660 - val_loss: 0.5323 - val_mean_iou_all: 0.2535 - val_precision_tumor: 0.2110 - val_recall_tumor: 0.2186 - val_tumor_iou: 0.1014 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 19 lên WandB.\n\n--- Epoch 20/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9593 - dice_coef_metric_tumor: 0.2528 - loss: 0.4695 - mean_iou_all: 0.2628 - precision_tumor: 0.2161 - recall_tumor: 0.4381 - tumor_iou: 0.1576\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18968\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9593 - dice_coef_metric_tumor: 0.2528 - loss: 0.4695 - mean_iou_all: 0.2628 - precision_tumor: 0.2161 - recall_tumor: 0.4381 - tumor_iou: 0.1576 - val_acc: 0.9281 - val_dice_coef_metric_tumor: 0.1783 - val_loss: 0.5365 - val_mean_iou_all: 0.2546 - val_precision_tumor: 0.1275 - val_recall_tumor: 0.5096 - val_tumor_iou: 0.1058 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 20 lên WandB.\n\n--- Epoch 21/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9597 - dice_coef_metric_tumor: 0.2582 - loss: 0.4632 - mean_iou_all: 0.2621 - precision_tumor: 0.2256 - recall_tumor: 0.4215 - tumor_iou: 0.1631\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18968\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9596 - dice_coef_metric_tumor: 0.2581 - loss: 0.4631 - mean_iou_all: 0.2621 - precision_tumor: 0.2256 - recall_tumor: 0.4216 - tumor_iou: 0.1631 - val_acc: 0.9120 - val_dice_coef_metric_tumor: 0.1878 - val_loss: 0.5331 - val_mean_iou_all: 0.2600 - val_precision_tumor: 0.1221 - val_recall_tumor: 0.6592 - val_tumor_iou: 0.1117 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 21 lên WandB.\n\n--- Epoch 22/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9607 - dice_coef_metric_tumor: 0.2441 - loss: 0.4591 - mean_iou_all: 0.2613 - precision_tumor: 0.2047 - recall_tumor: 0.4082 - tumor_iou: 0.1537\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18968\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9607 - dice_coef_metric_tumor: 0.2441 - loss: 0.4591 - mean_iou_all: 0.2613 - precision_tumor: 0.2047 - recall_tumor: 0.4082 - tumor_iou: 0.1536 - val_acc: 0.9297 - val_dice_coef_metric_tumor: 0.1747 - val_loss: 0.5363 - val_mean_iou_all: 0.2518 - val_precision_tumor: 0.1274 - val_recall_tumor: 0.5122 - val_tumor_iou: 0.1030 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 22 lên WandB.\n\n--- Epoch 23/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9614 - dice_coef_metric_tumor: 0.2581 - loss: 0.4556 - mean_iou_all: 0.2580 - precision_tumor: 0.2268 - recall_tumor: 0.4168 - tumor_iou: 0.1641\nEpoch 1: val_dice_coef_metric_tumor improved from 0.18968 to 0.20701, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9614 - dice_coef_metric_tumor: 0.2581 - loss: 0.4556 - mean_iou_all: 0.2580 - precision_tumor: 0.2268 - recall_tumor: 0.4168 - tumor_iou: 0.1641 - val_acc: 0.9526 - val_dice_coef_metric_tumor: 0.2070 - val_loss: 0.5110 - val_mean_iou_all: 0.2548 - val_precision_tumor: 0.1689 - val_recall_tumor: 0.4049 - val_tumor_iou: 0.1263 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 23 lên WandB.\n\n--- Epoch 24/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9630 - dice_coef_metric_tumor: 0.2667 - loss: 0.4508 - mean_iou_all: 0.2610 - precision_tumor: 0.2295 - recall_tumor: 0.4462 - tumor_iou: 0.1692\nEpoch 1: val_dice_coef_metric_tumor improved from 0.20701 to 0.21553, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 470ms/step - acc: 0.9630 - dice_coef_metric_tumor: 0.2667 - loss: 0.4508 - mean_iou_all: 0.2611 - precision_tumor: 0.2295 - recall_tumor: 0.4461 - tumor_iou: 0.1692 - val_acc: 0.9414 - val_dice_coef_metric_tumor: 0.2155 - val_loss: 0.5133 - val_mean_iou_all: 0.2529 - val_precision_tumor: 0.1598 - val_recall_tumor: 0.5339 - val_tumor_iou: 0.1320 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 24 lên WandB.\n\n--- Epoch 25/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9633 - dice_coef_metric_tumor: 0.2693 - loss: 0.4550 - mean_iou_all: 0.2601 - precision_tumor: 0.2326 - recall_tumor: 0.4246 - tumor_iou: 0.1707\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.21553\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9633 - dice_coef_metric_tumor: 0.2693 - loss: 0.4550 - mean_iou_all: 0.2602 - precision_tumor: 0.2325 - recall_tumor: 0.4246 - tumor_iou: 0.1707 - val_acc: 0.9830 - val_dice_coef_metric_tumor: 0.1245 - val_loss: 0.5564 - val_mean_iou_all: 0.2528 - val_precision_tumor: 0.3331 - val_recall_tumor: 0.0894 - val_tumor_iou: 0.0743 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 25 lên WandB.\n\n--- Epoch 26/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9650 - dice_coef_metric_tumor: 0.2752 - loss: 0.4470 - mean_iou_all: 0.2598 - precision_tumor: 0.2435 - recall_tumor: 0.4324 - tumor_iou: 0.1752\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.21553\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9650 - dice_coef_metric_tumor: 0.2751 - loss: 0.4470 - mean_iou_all: 0.2598 - precision_tumor: 0.2435 - recall_tumor: 0.4323 - tumor_iou: 0.1752 - val_acc: 0.9104 - val_dice_coef_metric_tumor: 0.1847 - val_loss: 0.5459 - val_mean_iou_all: 0.2534 - val_precision_tumor: 0.1194 - val_recall_tumor: 0.6477 - val_tumor_iou: 0.1102 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 26 lên WandB.\n\n--- Epoch 27/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9649 - dice_coef_metric_tumor: 0.2892 - loss: 0.4393 - mean_iou_all: 0.2661 - precision_tumor: 0.2564 - recall_tumor: 0.4476 - tumor_iou: 0.1869\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.21553\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9649 - dice_coef_metric_tumor: 0.2892 - loss: 0.4393 - mean_iou_all: 0.2662 - precision_tumor: 0.2564 - recall_tumor: 0.4475 - tumor_iou: 0.1869 - val_acc: 0.9040 - val_dice_coef_metric_tumor: 0.1841 - val_loss: 0.5504 - val_mean_iou_all: 0.2588 - val_precision_tumor: 0.1154 - val_recall_tumor: 0.7101 - val_tumor_iou: 0.1087 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 27 lên WandB.\n\n--- Epoch 28/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9610 - dice_coef_metric_tumor: 0.2759 - loss: 0.4524 - mean_iou_all: 0.2637 - precision_tumor: 0.2328 - recall_tumor: 0.4677 - tumor_iou: 0.1755\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.21553\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9611 - dice_coef_metric_tumor: 0.2759 - loss: 0.4524 - mean_iou_all: 0.2637 - precision_tumor: 0.2328 - recall_tumor: 0.4677 - tumor_iou: 0.1755 - val_acc: 0.9793 - val_dice_coef_metric_tumor: 0.1653 - val_loss: 0.5336 - val_mean_iou_all: 0.2718 - val_precision_tumor: 0.2454 - val_recall_tumor: 0.1606 - val_tumor_iou: 0.1050 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 28 lên WandB.\n\n--- Epoch 29/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9671 - dice_coef_metric_tumor: 0.2969 - loss: 0.4310 - mean_iou_all: 0.2772 - precision_tumor: 0.2685 - recall_tumor: 0.4497 - tumor_iou: 0.1922\nEpoch 1: val_dice_coef_metric_tumor improved from 0.21553 to 0.22517, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9671 - dice_coef_metric_tumor: 0.2968 - loss: 0.4310 - mean_iou_all: 0.2772 - precision_tumor: 0.2684 - recall_tumor: 0.4497 - tumor_iou: 0.1922 - val_acc: 0.9668 - val_dice_coef_metric_tumor: 0.2252 - val_loss: 0.4984 - val_mean_iou_all: 0.2636 - val_precision_tumor: 0.2196 - val_recall_tumor: 0.3413 - val_tumor_iou: 0.1426 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 29 lên WandB.\n\n--- Epoch 30/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9697 - dice_coef_metric_tumor: 0.3114 - loss: 0.4248 - mean_iou_all: 0.2697 - precision_tumor: 0.2940 - recall_tumor: 0.4436 - tumor_iou: 0.2026\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.22517\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9697 - dice_coef_metric_tumor: 0.3114 - loss: 0.4248 - mean_iou_all: 0.2697 - precision_tumor: 0.2940 - recall_tumor: 0.4436 - tumor_iou: 0.2026 - val_acc: 0.9380 - val_dice_coef_metric_tumor: 0.2160 - val_loss: 0.5139 - val_mean_iou_all: 0.2639 - val_precision_tumor: 0.1571 - val_recall_tumor: 0.5565 - val_tumor_iou: 0.1315 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 30 lên WandB.\n\n--- Epoch 31/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9683 - dice_coef_metric_tumor: 0.3085 - loss: 0.4304 - mean_iou_all: 0.2689 - precision_tumor: 0.2775 - recall_tumor: 0.4568 - tumor_iou: 0.2011\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.22517\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9683 - dice_coef_metric_tumor: 0.3085 - loss: 0.4304 - mean_iou_all: 0.2690 - precision_tumor: 0.2775 - recall_tumor: 0.4568 - tumor_iou: 0.2011 - val_acc: 0.9689 - val_dice_coef_metric_tumor: 0.2130 - val_loss: 0.5061 - val_mean_iou_all: 0.2600 - val_precision_tumor: 0.2389 - val_recall_tumor: 0.3006 - val_tumor_iou: 0.1351 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 31 lên WandB.\n\n--- Epoch 32/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9700 - dice_coef_metric_tumor: 0.3102 - loss: 0.4292 - mean_iou_all: 0.2677 - precision_tumor: 0.2841 - recall_tumor: 0.4487 - tumor_iou: 0.2022\nEpoch 1: val_dice_coef_metric_tumor improved from 0.22517 to 0.22941, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9700 - dice_coef_metric_tumor: 0.3102 - loss: 0.4292 - mean_iou_all: 0.2677 - precision_tumor: 0.2840 - recall_tumor: 0.4487 - tumor_iou: 0.2022 - val_acc: 0.9693 - val_dice_coef_metric_tumor: 0.2294 - val_loss: 0.4964 - val_mean_iou_all: 0.2601 - val_precision_tumor: 0.2392 - val_recall_tumor: 0.3367 - val_tumor_iou: 0.1448 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 32 lên WandB.\n\n--- Epoch 33/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9698 - dice_coef_metric_tumor: 0.3266 - loss: 0.4190 - mean_iou_all: 0.2699 - precision_tumor: 0.2954 - recall_tumor: 0.4789 - tumor_iou: 0.2144\nEpoch 1: val_dice_coef_metric_tumor improved from 0.22941 to 0.26779, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9698 - dice_coef_metric_tumor: 0.3266 - loss: 0.4190 - mean_iou_all: 0.2700 - precision_tumor: 0.2954 - recall_tumor: 0.4788 - tumor_iou: 0.2144 - val_acc: 0.9628 - val_dice_coef_metric_tumor: 0.2678 - val_loss: 0.4750 - val_mean_iou_all: 0.2545 - val_precision_tumor: 0.2208 - val_recall_tumor: 0.4697 - val_tumor_iou: 0.1709 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 33 lên WandB.\n\n--- Epoch 34/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9719 - dice_coef_metric_tumor: 0.3425 - loss: 0.4078 - mean_iou_all: 0.2690 - precision_tumor: 0.3288 - recall_tumor: 0.4708 - tumor_iou: 0.2289\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.26779\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9719 - dice_coef_metric_tumor: 0.3424 - loss: 0.4079 - mean_iou_all: 0.2691 - precision_tumor: 0.3287 - recall_tumor: 0.4708 - tumor_iou: 0.2289 - val_acc: 0.9777 - val_dice_coef_metric_tumor: 0.1997 - val_loss: 0.5127 - val_mean_iou_all: 0.2529 - val_precision_tumor: 0.2891 - val_recall_tumor: 0.2119 - val_tumor_iou: 0.1267 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 34 lên WandB.\n\n--- Epoch 35/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9716 - dice_coef_metric_tumor: 0.3249 - loss: 0.4169 - mean_iou_all: 0.2718 - precision_tumor: 0.3200 - recall_tumor: 0.4555 - tumor_iou: 0.2120\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.26779\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9716 - dice_coef_metric_tumor: 0.3249 - loss: 0.4169 - mean_iou_all: 0.2719 - precision_tumor: 0.3199 - recall_tumor: 0.4556 - tumor_iou: 0.2120 - val_acc: 0.9565 - val_dice_coef_metric_tumor: 0.2438 - val_loss: 0.4924 - val_mean_iou_all: 0.2608 - val_precision_tumor: 0.2000 - val_recall_tumor: 0.4759 - val_tumor_iou: 0.1536 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 35 lên WandB.\n\n--- Epoch 36/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9709 - dice_coef_metric_tumor: 0.3504 - loss: 0.4070 - mean_iou_all: 0.2919 - precision_tumor: 0.3227 - recall_tumor: 0.4945 - tumor_iou: 0.2339\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.26779\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9709 - dice_coef_metric_tumor: 0.3503 - loss: 0.4070 - mean_iou_all: 0.2920 - precision_tumor: 0.3226 - recall_tumor: 0.4944 - tumor_iou: 0.2338 - val_acc: 0.9716 - val_dice_coef_metric_tumor: 0.2303 - val_loss: 0.4955 - val_mean_iou_all: 0.2535 - val_precision_tumor: 0.2609 - val_recall_tumor: 0.3041 - val_tumor_iou: 0.1476 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 36 lên WandB.\n\n--- Epoch 37/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9725 - dice_coef_metric_tumor: 0.3423 - loss: 0.4067 - mean_iou_all: 0.2822 - precision_tumor: 0.3131 - recall_tumor: 0.4680 - tumor_iou: 0.2285\nEpoch 1: val_dice_coef_metric_tumor improved from 0.26779 to 0.28636, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 470ms/step - acc: 0.9725 - dice_coef_metric_tumor: 0.3423 - loss: 0.4067 - mean_iou_all: 0.2823 - precision_tumor: 0.3130 - recall_tumor: 0.4680 - tumor_iou: 0.2285 - val_acc: 0.9781 - val_dice_coef_metric_tumor: 0.2864 - val_loss: 0.4591 - val_mean_iou_all: 0.2601 - val_precision_tumor: 0.3230 - val_recall_tumor: 0.3367 - val_tumor_iou: 0.1882 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 37 lên WandB.\n\n--- Epoch 38/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9700 - dice_coef_metric_tumor: 0.3360 - loss: 0.4094 - mean_iou_all: 0.2869 - precision_tumor: 0.3088 - recall_tumor: 0.4882 - tumor_iou: 0.2222\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.28636\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 464ms/step - acc: 0.9700 - dice_coef_metric_tumor: 0.3360 - loss: 0.4094 - mean_iou_all: 0.2870 - precision_tumor: 0.3087 - recall_tumor: 0.4881 - tumor_iou: 0.2221 - val_acc: 0.9733 - val_dice_coef_metric_tumor: 0.2659 - val_loss: 0.4729 - val_mean_iou_all: 0.2625 - val_precision_tumor: 0.2776 - val_recall_tumor: 0.3573 - val_tumor_iou: 0.1711 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 38 lên WandB.\n\n--- Epoch 39/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9734 - dice_coef_metric_tumor: 0.3468 - loss: 0.3977 - mean_iou_all: 0.2822 - precision_tumor: 0.3236 - recall_tumor: 0.4824 - tumor_iou: 0.2344\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.28636\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9734 - dice_coef_metric_tumor: 0.3467 - loss: 0.3977 - mean_iou_all: 0.2823 - precision_tumor: 0.3236 - recall_tumor: 0.4824 - tumor_iou: 0.2343 - val_acc: 0.9819 - val_dice_coef_metric_tumor: 0.2695 - val_loss: 0.4692 - val_mean_iou_all: 0.2662 - val_precision_tumor: 0.3848 - val_recall_tumor: 0.2602 - val_tumor_iou: 0.1747 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 39 lên WandB.\n\n--- Epoch 40/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9744 - dice_coef_metric_tumor: 0.3463 - loss: 0.4004 - mean_iou_all: 0.2831 - precision_tumor: 0.3239 - recall_tumor: 0.4618 - tumor_iou: 0.2311\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.28636\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9744 - dice_coef_metric_tumor: 0.3462 - loss: 0.4005 - mean_iou_all: 0.2832 - precision_tumor: 0.3238 - recall_tumor: 0.4618 - tumor_iou: 0.2310 - val_acc: 0.9771 - val_dice_coef_metric_tumor: 0.2846 - val_loss: 0.4612 - val_mean_iou_all: 0.2610 - val_precision_tumor: 0.3015 - val_recall_tumor: 0.3446 - val_tumor_iou: 0.1852 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 40 lên WandB.\n\n--- Epoch 41/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9745 - dice_coef_metric_tumor: 0.3682 - loss: 0.3994 - mean_iou_all: 0.2836 - precision_tumor: 0.3434 - recall_tumor: 0.4892 - tumor_iou: 0.2470\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.28636\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9745 - dice_coef_metric_tumor: 0.3682 - loss: 0.3994 - mean_iou_all: 0.2837 - precision_tumor: 0.3434 - recall_tumor: 0.4891 - tumor_iou: 0.2470 - val_acc: 0.9825 - val_dice_coef_metric_tumor: 0.1912 - val_loss: 0.5179 - val_mean_iou_all: 0.2620 - val_precision_tumor: 0.3314 - val_recall_tumor: 0.1592 - val_tumor_iou: 0.1221 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 41 lên WandB.\n\n--- Epoch 42/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9751 - dice_coef_metric_tumor: 0.3606 - loss: 0.3988 - mean_iou_all: 0.2784 - precision_tumor: 0.3444 - recall_tumor: 0.4590 - tumor_iou: 0.2423\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.28636\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9751 - dice_coef_metric_tumor: 0.3605 - loss: 0.3988 - mean_iou_all: 0.2785 - precision_tumor: 0.3444 - recall_tumor: 0.4590 - tumor_iou: 0.2423 - val_acc: 0.9775 - val_dice_coef_metric_tumor: 0.2535 - val_loss: 0.4799 - val_mean_iou_all: 0.2548 - val_precision_tumor: 0.3044 - val_recall_tumor: 0.2920 - val_tumor_iou: 0.1653 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 42 lên WandB.\n\n--- Epoch 43/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9748 - dice_coef_metric_tumor: 0.3660 - loss: 0.3926 - mean_iou_all: 0.2758 - precision_tumor: 0.3475 - recall_tumor: 0.4916 - tumor_iou: 0.2459\nEpoch 1: val_dice_coef_metric_tumor improved from 0.28636 to 0.30917, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9748 - dice_coef_metric_tumor: 0.3660 - loss: 0.3926 - mean_iou_all: 0.2759 - precision_tumor: 0.3474 - recall_tumor: 0.4916 - tumor_iou: 0.2458 - val_acc: 0.9680 - val_dice_coef_metric_tumor: 0.3092 - val_loss: 0.4496 - val_mean_iou_all: 0.2548 - val_precision_tumor: 0.2641 - val_recall_tumor: 0.5171 - val_tumor_iou: 0.2007 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 43 lên WandB.\n\n--- Epoch 44/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9746 - dice_coef_metric_tumor: 0.3652 - loss: 0.3955 - mean_iou_all: 0.2863 - precision_tumor: 0.3445 - recall_tumor: 0.4901 - tumor_iou: 0.2453\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.30917\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9746 - dice_coef_metric_tumor: 0.3652 - loss: 0.3955 - mean_iou_all: 0.2864 - precision_tumor: 0.3445 - recall_tumor: 0.4902 - tumor_iou: 0.2453 - val_acc: 0.9656 - val_dice_coef_metric_tumor: 0.2619 - val_loss: 0.4784 - val_mean_iou_all: 0.2587 - val_precision_tumor: 0.2355 - val_recall_tumor: 0.4313 - val_tumor_iou: 0.1685 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 44 lên WandB.\n\n--- Epoch 45/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9746 - dice_coef_metric_tumor: 0.3839 - loss: 0.3854 - mean_iou_all: 0.2787 - precision_tumor: 0.3622 - recall_tumor: 0.5043 - tumor_iou: 0.2602\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.30917\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9746 - dice_coef_metric_tumor: 0.3838 - loss: 0.3854 - mean_iou_all: 0.2788 - precision_tumor: 0.3621 - recall_tumor: 0.5042 - tumor_iou: 0.2602 - val_acc: 0.9715 - val_dice_coef_metric_tumor: 0.2893 - val_loss: 0.4609 - val_mean_iou_all: 0.2563 - val_precision_tumor: 0.2932 - val_recall_tumor: 0.4009 - val_tumor_iou: 0.1892 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 45 lên WandB.\n\n--- Epoch 46/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9754 - dice_coef_metric_tumor: 0.3670 - loss: 0.3850 - mean_iou_all: 0.2779 - precision_tumor: 0.3524 - recall_tumor: 0.4870 - tumor_iou: 0.2498\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.30917\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 466ms/step - acc: 0.9754 - dice_coef_metric_tumor: 0.3670 - loss: 0.3850 - mean_iou_all: 0.2781 - precision_tumor: 0.3523 - recall_tumor: 0.4870 - tumor_iou: 0.2497 - val_acc: 0.9799 - val_dice_coef_metric_tumor: 0.2838 - val_loss: 0.4622 - val_mean_iou_all: 0.2659 - val_precision_tumor: 0.3531 - val_recall_tumor: 0.3157 - val_tumor_iou: 0.1869 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 46 lên WandB.\n\n--- Epoch 47/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9759 - dice_coef_metric_tumor: 0.3842 - loss: 0.3834 - mean_iou_all: 0.2921 - precision_tumor: 0.3602 - recall_tumor: 0.5110 - tumor_iou: 0.2596\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.30917\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9759 - dice_coef_metric_tumor: 0.3841 - loss: 0.3834 - mean_iou_all: 0.2922 - precision_tumor: 0.3601 - recall_tumor: 0.5110 - tumor_iou: 0.2595 - val_acc: 0.9729 - val_dice_coef_metric_tumor: 0.2710 - val_loss: 0.4718 - val_mean_iou_all: 0.2591 - val_precision_tumor: 0.2961 - val_recall_tumor: 0.3540 - val_tumor_iou: 0.1742 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 47 lên WandB.\n\n--- Epoch 48/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9743 - dice_coef_metric_tumor: 0.3769 - loss: 0.3873 - mean_iou_all: 0.2851 - precision_tumor: 0.3529 - recall_tumor: 0.5172 - tumor_iou: 0.2531\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.30917\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9743 - dice_coef_metric_tumor: 0.3769 - loss: 0.3873 - mean_iou_all: 0.2852 - precision_tumor: 0.3529 - recall_tumor: 0.5172 - tumor_iou: 0.2530 - val_acc: 0.9807 - val_dice_coef_metric_tumor: 0.2866 - val_loss: 0.4593 - val_mean_iou_all: 0.2612 - val_precision_tumor: 0.3655 - val_recall_tumor: 0.3112 - val_tumor_iou: 0.1909 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 48 lên WandB.\n\n--- Epoch 49/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9762 - dice_coef_metric_tumor: 0.3853 - loss: 0.3765 - mean_iou_all: 0.2910 - precision_tumor: 0.3613 - recall_tumor: 0.5077 - tumor_iou: 0.2629\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.30917\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9762 - dice_coef_metric_tumor: 0.3852 - loss: 0.3765 - mean_iou_all: 0.2912 - precision_tumor: 0.3612 - recall_tumor: 0.5077 - tumor_iou: 0.2628 - val_acc: 0.9786 - val_dice_coef_metric_tumor: 0.2764 - val_loss: 0.4671 - val_mean_iou_all: 0.2655 - val_precision_tumor: 0.3650 - val_recall_tumor: 0.3051 - val_tumor_iou: 0.1785 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 49 lên WandB.\n\n--- Epoch 50/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9745 - dice_coef_metric_tumor: 0.3763 - loss: 0.3872 - mean_iou_all: 0.3106 - precision_tumor: 0.3492 - recall_tumor: 0.5211 - tumor_iou: 0.2546\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.30917\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9745 - dice_coef_metric_tumor: 0.3763 - loss: 0.3872 - mean_iou_all: 0.3107 - precision_tumor: 0.3492 - recall_tumor: 0.5211 - tumor_iou: 0.2546 - val_acc: 0.9813 - val_dice_coef_metric_tumor: 0.2929 - val_loss: 0.4565 - val_mean_iou_all: 0.2651 - val_precision_tumor: 0.3903 - val_recall_tumor: 0.2883 - val_tumor_iou: 0.1943 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 50 lên WandB.\n\n--- Epoch 51/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9766 - dice_coef_metric_tumor: 0.3796 - loss: 0.3960 - mean_iou_all: 0.3258 - precision_tumor: 0.3674 - recall_tumor: 0.4898 - tumor_iou: 0.2558\nEpoch 1: val_dice_coef_metric_tumor improved from 0.30917 to 0.32415, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9766 - dice_coef_metric_tumor: 0.3795 - loss: 0.3960 - mean_iou_all: 0.3260 - precision_tumor: 0.3673 - recall_tumor: 0.4898 - tumor_iou: 0.2558 - val_acc: 0.9687 - val_dice_coef_metric_tumor: 0.3242 - val_loss: 0.4419 - val_mean_iou_all: 0.2594 - val_precision_tumor: 0.2980 - val_recall_tumor: 0.5145 - val_tumor_iou: 0.2129 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 51 lên WandB.\n\n--- Epoch 52/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9760 - dice_coef_metric_tumor: 0.3862 - loss: 0.3766 - mean_iou_all: 0.3204 - precision_tumor: 0.3668 - recall_tumor: 0.5076 - tumor_iou: 0.2655\nEpoch 1: val_dice_coef_metric_tumor improved from 0.32415 to 0.34891, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9760 - dice_coef_metric_tumor: 0.3861 - loss: 0.3766 - mean_iou_all: 0.3205 - precision_tumor: 0.3667 - recall_tumor: 0.5076 - tumor_iou: 0.2655 - val_acc: 0.9789 - val_dice_coef_metric_tumor: 0.3489 - val_loss: 0.4230 - val_mean_iou_all: 0.2570 - val_precision_tumor: 0.3581 - val_recall_tumor: 0.4331 - val_tumor_iou: 0.2331 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 52 lên WandB.\n\n--- Epoch 53/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9753 - dice_coef_metric_tumor: 0.3951 - loss: 0.3771 - mean_iou_all: 0.3242 - precision_tumor: 0.3713 - recall_tumor: 0.5358 - tumor_iou: 0.2703\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34891\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9754 - dice_coef_metric_tumor: 0.3950 - loss: 0.3771 - mean_iou_all: 0.3243 - precision_tumor: 0.3712 - recall_tumor: 0.5358 - tumor_iou: 0.2702 - val_acc: 0.9826 - val_dice_coef_metric_tumor: 0.3013 - val_loss: 0.4514 - val_mean_iou_all: 0.2567 - val_precision_tumor: 0.4297 - val_recall_tumor: 0.2898 - val_tumor_iou: 0.1994 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 53 lên WandB.\n\n--- Epoch 54/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9771 - dice_coef_metric_tumor: 0.3957 - loss: 0.3737 - mean_iou_all: 0.3389 - precision_tumor: 0.3773 - recall_tumor: 0.5085 - tumor_iou: 0.2710\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34891\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9771 - dice_coef_metric_tumor: 0.3957 - loss: 0.3737 - mean_iou_all: 0.3391 - precision_tumor: 0.3773 - recall_tumor: 0.5085 - tumor_iou: 0.2710 - val_acc: 0.9602 - val_dice_coef_metric_tumor: 0.2810 - val_loss: 0.4719 - val_mean_iou_all: 0.2602 - val_precision_tumor: 0.2315 - val_recall_tumor: 0.5184 - val_tumor_iou: 0.1798 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 54 lên WandB.\n\n--- Epoch 55/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9756 - dice_coef_metric_tumor: 0.4025 - loss: 0.3711 - mean_iou_all: 0.3113 - precision_tumor: 0.3742 - recall_tumor: 0.5486 - tumor_iou: 0.2740\nEpoch 1: val_dice_coef_metric_tumor improved from 0.34891 to 0.34935, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9756 - dice_coef_metric_tumor: 0.4024 - loss: 0.3711 - mean_iou_all: 0.3114 - precision_tumor: 0.3742 - recall_tumor: 0.5486 - tumor_iou: 0.2740 - val_acc: 0.9723 - val_dice_coef_metric_tumor: 0.3494 - val_loss: 0.4246 - val_mean_iou_all: 0.2576 - val_precision_tumor: 0.3008 - val_recall_tumor: 0.5426 - val_tumor_iou: 0.2306 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 55 lên WandB.\n\n--- Epoch 56/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9760 - dice_coef_metric_tumor: 0.3960 - loss: 0.3732 - mean_iou_all: 0.3024 - precision_tumor: 0.3722 - recall_tumor: 0.5320 - tumor_iou: 0.2736\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.34935\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9760 - dice_coef_metric_tumor: 0.3960 - loss: 0.3732 - mean_iou_all: 0.3025 - precision_tumor: 0.3722 - recall_tumor: 0.5320 - tumor_iou: 0.2736 - val_acc: 0.9843 - val_dice_coef_metric_tumor: 0.2750 - val_loss: 0.4674 - val_mean_iou_all: 0.2563 - val_precision_tumor: 0.4734 - val_recall_tumor: 0.2343 - val_tumor_iou: 0.1831 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 56 lên WandB.\n\n--- Epoch 57/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9787 - dice_coef_metric_tumor: 0.4167 - loss: 0.3618 - mean_iou_all: 0.2897 - precision_tumor: 0.4059 - recall_tumor: 0.5236 - tumor_iou: 0.2887\nEpoch 1: val_dice_coef_metric_tumor improved from 0.34935 to 0.37321, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9787 - dice_coef_metric_tumor: 0.4167 - loss: 0.3618 - mean_iou_all: 0.2898 - precision_tumor: 0.4058 - recall_tumor: 0.5236 - tumor_iou: 0.2886 - val_acc: 0.9824 - val_dice_coef_metric_tumor: 0.3732 - val_loss: 0.4090 - val_mean_iou_all: 0.2658 - val_precision_tumor: 0.4394 - val_recall_tumor: 0.3755 - val_tumor_iou: 0.2561 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 57 lên WandB.\n\n--- Epoch 58/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9782 - dice_coef_metric_tumor: 0.4128 - loss: 0.3641 - mean_iou_all: 0.3111 - precision_tumor: 0.3887 - recall_tumor: 0.5357 - tumor_iou: 0.2848\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.37321\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9782 - dice_coef_metric_tumor: 0.4127 - loss: 0.3641 - mean_iou_all: 0.3113 - precision_tumor: 0.3886 - recall_tumor: 0.5357 - tumor_iou: 0.2847 - val_acc: 0.9699 - val_dice_coef_metric_tumor: 0.2993 - val_loss: 0.4568 - val_mean_iou_all: 0.2591 - val_precision_tumor: 0.2831 - val_recall_tumor: 0.4560 - val_tumor_iou: 0.1951 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 58 lên WandB.\n\n--- Epoch 59/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9775 - dice_coef_metric_tumor: 0.4101 - loss: 0.3608 - mean_iou_all: 0.3154 - precision_tumor: 0.3840 - recall_tumor: 0.5403 - tumor_iou: 0.2849\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.37321\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9775 - dice_coef_metric_tumor: 0.4100 - loss: 0.3608 - mean_iou_all: 0.3156 - precision_tumor: 0.3840 - recall_tumor: 0.5403 - tumor_iou: 0.2848 - val_acc: 0.9721 - val_dice_coef_metric_tumor: 0.3056 - val_loss: 0.4523 - val_mean_iou_all: 0.3491 - val_precision_tumor: 0.3070 - val_recall_tumor: 0.4396 - val_tumor_iou: 0.1996 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 59 lên WandB.\n\n--- Epoch 60/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9768 - dice_coef_metric_tumor: 0.4112 - loss: 0.3691 - mean_iou_all: 0.3964 - precision_tumor: 0.3859 - recall_tumor: 0.5410 - tumor_iou: 0.2811\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.37321\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9768 - dice_coef_metric_tumor: 0.4112 - loss: 0.3691 - mean_iou_all: 0.3966 - precision_tumor: 0.3858 - recall_tumor: 0.5410 - tumor_iou: 0.2811 - val_acc: 0.9724 - val_dice_coef_metric_tumor: 0.3469 - val_loss: 0.4280 - val_mean_iou_all: 0.2975 - val_precision_tumor: 0.3165 - val_recall_tumor: 0.4886 - val_tumor_iou: 0.2322 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 60 lên WandB.\n\n--- Epoch 61/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9776 - dice_coef_metric_tumor: 0.4157 - loss: 0.3623 - mean_iou_all: 0.3804 - precision_tumor: 0.3955 - recall_tumor: 0.5416 - tumor_iou: 0.2888\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.37321\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9776 - dice_coef_metric_tumor: 0.4157 - loss: 0.3623 - mean_iou_all: 0.3807 - precision_tumor: 0.3954 - recall_tumor: 0.5416 - tumor_iou: 0.2888 - val_acc: 0.9819 - val_dice_coef_metric_tumor: 0.3241 - val_loss: 0.4378 - val_mean_iou_all: 0.2679 - val_precision_tumor: 0.4093 - val_recall_tumor: 0.3339 - val_tumor_iou: 0.2152 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 61 lên WandB.\n\n--- Epoch 62/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9778 - dice_coef_metric_tumor: 0.4058 - loss: 0.3667 - mean_iou_all: 0.3935 - precision_tumor: 0.3909 - recall_tumor: 0.5216 - tumor_iou: 0.2819\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.37321\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9778 - dice_coef_metric_tumor: 0.4057 - loss: 0.3667 - mean_iou_all: 0.3937 - precision_tumor: 0.3909 - recall_tumor: 0.5216 - tumor_iou: 0.2819 - val_acc: 0.9831 - val_dice_coef_metric_tumor: 0.2540 - val_loss: 0.4804 - val_mean_iou_all: 0.2789 - val_precision_tumor: 0.3797 - val_recall_tumor: 0.2366 - val_tumor_iou: 0.1659 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 62 lên WandB.\n\n--- Epoch 63/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9771 - dice_coef_metric_tumor: 0.4213 - loss: 0.3564 - mean_iou_all: 0.4038 - precision_tumor: 0.3952 - recall_tumor: 0.5752 - tumor_iou: 0.2937\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.37321\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 466ms/step - acc: 0.9771 - dice_coef_metric_tumor: 0.4213 - loss: 0.3564 - mean_iou_all: 0.4040 - precision_tumor: 0.3951 - recall_tumor: 0.5752 - tumor_iou: 0.2936 - val_acc: 0.9761 - val_dice_coef_metric_tumor: 0.3479 - val_loss: 0.4255 - val_mean_iou_all: 0.2579 - val_precision_tumor: 0.3443 - val_recall_tumor: 0.4566 - val_tumor_iou: 0.2316 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 63 lên WandB.\n\n--- Epoch 64/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9784 - dice_coef_metric_tumor: 0.4164 - loss: 0.3635 - mean_iou_all: 0.3840 - precision_tumor: 0.4023 - recall_tumor: 0.5510 - tumor_iou: 0.2883\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.37321\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 466ms/step - acc: 0.9784 - dice_coef_metric_tumor: 0.4164 - loss: 0.3635 - mean_iou_all: 0.3843 - precision_tumor: 0.4023 - recall_tumor: 0.5510 - tumor_iou: 0.2883 - val_acc: 0.9809 - val_dice_coef_metric_tumor: 0.3263 - val_loss: 0.4374 - val_mean_iou_all: 0.2572 - val_precision_tumor: 0.3730 - val_recall_tumor: 0.3639 - val_tumor_iou: 0.2182 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 64 lên WandB.\n\n--- Epoch 65/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9806 - dice_coef_metric_tumor: 0.4296 - loss: 0.3469 - mean_iou_all: 0.3988 - precision_tumor: 0.4235 - recall_tumor: 0.5338 - tumor_iou: 0.2990\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.37321\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 466ms/step - acc: 0.9806 - dice_coef_metric_tumor: 0.4296 - loss: 0.3469 - mean_iou_all: 0.3991 - precision_tumor: 0.4234 - recall_tumor: 0.5338 - tumor_iou: 0.2990 - val_acc: 0.9773 - val_dice_coef_metric_tumor: 0.3135 - val_loss: 0.4462 - val_mean_iou_all: 0.2600 - val_precision_tumor: 0.3260 - val_recall_tumor: 0.3901 - val_tumor_iou: 0.2086 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 65 lên WandB.\n\n--- Epoch 66/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9788 - dice_coef_metric_tumor: 0.4257 - loss: 0.3536 - mean_iou_all: 0.4088 - precision_tumor: 0.4238 - recall_tumor: 0.5166 - tumor_iou: 0.2983\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.37321\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9788 - dice_coef_metric_tumor: 0.4257 - loss: 0.3536 - mean_iou_all: 0.4091 - precision_tumor: 0.4237 - recall_tumor: 0.5166 - tumor_iou: 0.2983 - val_acc: 0.9779 - val_dice_coef_metric_tumor: 0.3558 - val_loss: 0.4201 - val_mean_iou_all: 0.3041 - val_precision_tumor: 0.3500 - val_recall_tumor: 0.4683 - val_tumor_iou: 0.2399 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 66 lên WandB.\n\n--- Epoch 67/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4302 - loss: 0.3504 - mean_iou_all: 0.4136 - precision_tumor: 0.4191 - recall_tumor: 0.5355 - tumor_iou: 0.3019\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.37321\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4302 - loss: 0.3504 - mean_iou_all: 0.4138 - precision_tumor: 0.4190 - recall_tumor: 0.5355 - tumor_iou: 0.3019 - val_acc: 0.9761 - val_dice_coef_metric_tumor: 0.3550 - val_loss: 0.4214 - val_mean_iou_all: 0.3296 - val_precision_tumor: 0.3397 - val_recall_tumor: 0.4835 - val_tumor_iou: 0.2391 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 67 lên WandB.\n\n--- Epoch 68/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9792 - dice_coef_metric_tumor: 0.4377 - loss: 0.3466 - mean_iou_all: 0.4235 - precision_tumor: 0.4149 - recall_tumor: 0.5523 - tumor_iou: 0.3095\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.37321\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9792 - dice_coef_metric_tumor: 0.4376 - loss: 0.3466 - mean_iou_all: 0.4237 - precision_tumor: 0.4149 - recall_tumor: 0.5523 - tumor_iou: 0.3094 - val_acc: 0.9785 - val_dice_coef_metric_tumor: 0.3431 - val_loss: 0.4284 - val_mean_iou_all: 0.3915 - val_precision_tumor: 0.3558 - val_recall_tumor: 0.4132 - val_tumor_iou: 0.2298 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 68 lên WandB.\n\n--- Epoch 69/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9797 - dice_coef_metric_tumor: 0.4223 - loss: 0.3522 - mean_iou_all: 0.4228 - precision_tumor: 0.4065 - recall_tumor: 0.5338 - tumor_iou: 0.2933\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.37321\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9797 - dice_coef_metric_tumor: 0.4223 - loss: 0.3522 - mean_iou_all: 0.4230 - precision_tumor: 0.4065 - recall_tumor: 0.5338 - tumor_iou: 0.2933 - val_acc: 0.9842 - val_dice_coef_metric_tumor: 0.3141 - val_loss: 0.4440 - val_mean_iou_all: 0.2582 - val_precision_tumor: 0.4570 - val_recall_tumor: 0.2877 - val_tumor_iou: 0.2106 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 69 lên WandB.\n\n--- Epoch 70/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9787 - dice_coef_metric_tumor: 0.4302 - loss: 0.3565 - mean_iou_all: 0.4099 - precision_tumor: 0.4150 - recall_tumor: 0.5571 - tumor_iou: 0.3007\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.37321\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9787 - dice_coef_metric_tumor: 0.4302 - loss: 0.3564 - mean_iou_all: 0.4101 - precision_tumor: 0.4149 - recall_tumor: 0.5571 - tumor_iou: 0.3006 - val_acc: 0.9735 - val_dice_coef_metric_tumor: 0.3363 - val_loss: 0.4350 - val_mean_iou_all: 0.3493 - val_precision_tumor: 0.3307 - val_recall_tumor: 0.4848 - val_tumor_iou: 0.2254 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 70 lên WandB.\n\n--- Epoch 71/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9777 - dice_coef_metric_tumor: 0.4332 - loss: 0.3497 - mean_iou_all: 0.4215 - precision_tumor: 0.3970 - recall_tumor: 0.5774 - tumor_iou: 0.3034\nEpoch 1: val_dice_coef_metric_tumor improved from 0.37321 to 0.39800, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9777 - dice_coef_metric_tumor: 0.4332 - loss: 0.3497 - mean_iou_all: 0.4217 - precision_tumor: 0.3970 - recall_tumor: 0.5774 - tumor_iou: 0.3033 - val_acc: 0.9803 - val_dice_coef_metric_tumor: 0.3980 - val_loss: 0.3941 - val_mean_iou_all: 0.2610 - val_precision_tumor: 0.3932 - val_recall_tumor: 0.4994 - val_tumor_iou: 0.2758 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 71 lên WandB.\n\n--- Epoch 72/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9806 - dice_coef_metric_tumor: 0.4415 - loss: 0.3448 - mean_iou_all: 0.4244 - precision_tumor: 0.4327 - recall_tumor: 0.5355 - tumor_iou: 0.3126\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.39800\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9806 - dice_coef_metric_tumor: 0.4415 - loss: 0.3448 - mean_iou_all: 0.4246 - precision_tumor: 0.4327 - recall_tumor: 0.5354 - tumor_iou: 0.3126 - val_acc: 0.9820 - val_dice_coef_metric_tumor: 0.3790 - val_loss: 0.4063 - val_mean_iou_all: 0.2705 - val_precision_tumor: 0.4093 - val_recall_tumor: 0.4189 - val_tumor_iou: 0.2592 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 72 lên WandB.\n\n--- Epoch 73/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9810 - dice_coef_metric_tumor: 0.4535 - loss: 0.3352 - mean_iou_all: 0.4014 - precision_tumor: 0.4401 - recall_tumor: 0.5664 - tumor_iou: 0.3222\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.39800\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9810 - dice_coef_metric_tumor: 0.4534 - loss: 0.3352 - mean_iou_all: 0.4016 - precision_tumor: 0.4400 - recall_tumor: 0.5663 - tumor_iou: 0.3221 - val_acc: 0.9797 - val_dice_coef_metric_tumor: 0.3514 - val_loss: 0.4243 - val_mean_iou_all: 0.4132 - val_precision_tumor: 0.3628 - val_recall_tumor: 0.4084 - val_tumor_iou: 0.2376 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 73 lên WandB.\n\n--- Epoch 74/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9801 - dice_coef_metric_tumor: 0.4309 - loss: 0.3492 - mean_iou_all: 0.4126 - precision_tumor: 0.4218 - recall_tumor: 0.5393 - tumor_iou: 0.3037\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.39800\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9801 - dice_coef_metric_tumor: 0.4308 - loss: 0.3492 - mean_iou_all: 0.4128 - precision_tumor: 0.4217 - recall_tumor: 0.5393 - tumor_iou: 0.3036 - val_acc: 0.9779 - val_dice_coef_metric_tumor: 0.3098 - val_loss: 0.4501 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3727 - val_recall_tumor: 0.3585 - val_tumor_iou: 0.2074 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 74 lên WandB.\n\n--- Epoch 75/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9796 - dice_coef_metric_tumor: 0.4383 - loss: 0.3438 - mean_iou_all: 0.4328 - precision_tumor: 0.4127 - recall_tumor: 0.5554 - tumor_iou: 0.3088\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.39800\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9796 - dice_coef_metric_tumor: 0.4382 - loss: 0.3438 - mean_iou_all: 0.4330 - precision_tumor: 0.4127 - recall_tumor: 0.5553 - tumor_iou: 0.3088 - val_acc: 0.9773 - val_dice_coef_metric_tumor: 0.3615 - val_loss: 0.4180 - val_mean_iou_all: 0.3071 - val_precision_tumor: 0.3444 - val_recall_tumor: 0.4948 - val_tumor_iou: 0.2444 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 75 lên WandB.\n\n--- Epoch 76/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9791 - dice_coef_metric_tumor: 0.4241 - loss: 0.3531 - mean_iou_all: 0.4433 - precision_tumor: 0.4028 - recall_tumor: 0.5531 - tumor_iou: 0.2968\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.39800\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9791 - dice_coef_metric_tumor: 0.4241 - loss: 0.3531 - mean_iou_all: 0.4434 - precision_tumor: 0.4027 - recall_tumor: 0.5531 - tumor_iou: 0.2967 - val_acc: 0.9776 - val_dice_coef_metric_tumor: 0.3491 - val_loss: 0.4252 - val_mean_iou_all: 0.3383 - val_precision_tumor: 0.3525 - val_recall_tumor: 0.4293 - val_tumor_iou: 0.2355 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 76 lên WandB.\n\n--- Epoch 77/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9809 - dice_coef_metric_tumor: 0.4500 - loss: 0.3382 - mean_iou_all: 0.4357 - precision_tumor: 0.4479 - recall_tumor: 0.5532 - tumor_iou: 0.3196\nEpoch 1: val_dice_coef_metric_tumor improved from 0.39800 to 0.40769, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9809 - dice_coef_metric_tumor: 0.4499 - loss: 0.3382 - mean_iou_all: 0.4359 - precision_tumor: 0.4478 - recall_tumor: 0.5532 - tumor_iou: 0.3196 - val_acc: 0.9829 - val_dice_coef_metric_tumor: 0.4077 - val_loss: 0.3887 - val_mean_iou_all: 0.2661 - val_precision_tumor: 0.4314 - val_recall_tumor: 0.4572 - val_tumor_iou: 0.2849 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 77 lên WandB.\n\n--- Epoch 78/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9802 - dice_coef_metric_tumor: 0.4418 - loss: 0.3554 - mean_iou_all: 0.4299 - precision_tumor: 0.4346 - recall_tumor: 0.5526 - tumor_iou: 0.3078\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.40769\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9802 - dice_coef_metric_tumor: 0.4418 - loss: 0.3554 - mean_iou_all: 0.4301 - precision_tumor: 0.4346 - recall_tumor: 0.5526 - tumor_iou: 0.3078 - val_acc: 0.9783 - val_dice_coef_metric_tumor: 0.3382 - val_loss: 0.4324 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3657 - val_recall_tumor: 0.4214 - val_tumor_iou: 0.2278 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 78 lên WandB.\n\n--- Epoch 79/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9800 - dice_coef_metric_tumor: 0.4454 - loss: 0.3403 - mean_iou_all: 0.4381 - precision_tumor: 0.4253 - recall_tumor: 0.5631 - tumor_iou: 0.3142\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.40769\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9800 - dice_coef_metric_tumor: 0.4454 - loss: 0.3403 - mean_iou_all: 0.4382 - precision_tumor: 0.4252 - recall_tumor: 0.5631 - tumor_iou: 0.3142 - val_acc: 0.9819 - val_dice_coef_metric_tumor: 0.3741 - val_loss: 0.4099 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4048 - val_recall_tumor: 0.4308 - val_tumor_iou: 0.2546 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 79 lên WandB.\n\n--- Epoch 80/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4424 - loss: 0.3543 - mean_iou_all: 0.4460 - precision_tumor: 0.4258 - recall_tumor: 0.5544 - tumor_iou: 0.3094\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.40769\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4424 - loss: 0.3543 - mean_iou_all: 0.4461 - precision_tumor: 0.4258 - recall_tumor: 0.5543 - tumor_iou: 0.3094 - val_acc: 0.9690 - val_dice_coef_metric_tumor: 0.3669 - val_loss: 0.4181 - val_mean_iou_all: 0.4770 - val_precision_tumor: 0.2974 - val_recall_tumor: 0.6581 - val_tumor_iou: 0.2467 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 80 lên WandB.\n\n--- Epoch 81/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9796 - dice_coef_metric_tumor: 0.4479 - loss: 0.3464 - mean_iou_all: 0.4358 - precision_tumor: 0.4205 - recall_tumor: 0.5688 - tumor_iou: 0.3150\nEpoch 1: val_dice_coef_metric_tumor improved from 0.40769 to 0.42955, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 471ms/step - acc: 0.9796 - dice_coef_metric_tumor: 0.4479 - loss: 0.3464 - mean_iou_all: 0.4360 - precision_tumor: 0.4205 - recall_tumor: 0.5688 - tumor_iou: 0.3150 - val_acc: 0.9851 - val_dice_coef_metric_tumor: 0.4295 - val_loss: 0.3755 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4881 - val_recall_tumor: 0.4481 - val_tumor_iou: 0.3047 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 81 lên WandB.\n\n--- Epoch 82/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9808 - dice_coef_metric_tumor: 0.4573 - loss: 0.3396 - mean_iou_all: 0.4490 - precision_tumor: 0.4552 - recall_tumor: 0.5496 - tumor_iou: 0.3263\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42955\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9808 - dice_coef_metric_tumor: 0.4572 - loss: 0.3396 - mean_iou_all: 0.4491 - precision_tumor: 0.4551 - recall_tumor: 0.5496 - tumor_iou: 0.3263 - val_acc: 0.9772 - val_dice_coef_metric_tumor: 0.3725 - val_loss: 0.4126 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3719 - val_recall_tumor: 0.4801 - val_tumor_iou: 0.2538 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 82 lên WandB.\n\n--- Epoch 83/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9772 - dice_coef_metric_tumor: 0.4425 - loss: 0.3498 - mean_iou_all: 0.4441 - precision_tumor: 0.4200 - recall_tumor: 0.5883 - tumor_iou: 0.3113\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42955\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9772 - dice_coef_metric_tumor: 0.4424 - loss: 0.3499 - mean_iou_all: 0.4442 - precision_tumor: 0.4199 - recall_tumor: 0.5883 - tumor_iou: 0.3112 - val_acc: 0.9833 - val_dice_coef_metric_tumor: 0.3932 - val_loss: 0.3975 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4208 - val_recall_tumor: 0.4357 - val_tumor_iou: 0.2687 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 83 lên WandB.\n\n--- Epoch 84/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9822 - dice_coef_metric_tumor: 0.4722 - loss: 0.3312 - mean_iou_all: 0.4435 - precision_tumor: 0.4714 - recall_tumor: 0.5533 - tumor_iou: 0.3375\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42955\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9822 - dice_coef_metric_tumor: 0.4721 - loss: 0.3312 - mean_iou_all: 0.4436 - precision_tumor: 0.4714 - recall_tumor: 0.5532 - tumor_iou: 0.3375 - val_acc: 0.9797 - val_dice_coef_metric_tumor: 0.3918 - val_loss: 0.3999 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3779 - val_recall_tumor: 0.5222 - val_tumor_iou: 0.2648 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 84 lên WandB.\n\n--- Epoch 85/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9808 - dice_coef_metric_tumor: 0.4686 - loss: 0.3354 - mean_iou_all: 0.4524 - precision_tumor: 0.4556 - recall_tumor: 0.5745 - tumor_iou: 0.3333\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42955\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9808 - dice_coef_metric_tumor: 0.4686 - loss: 0.3354 - mean_iou_all: 0.4525 - precision_tumor: 0.4556 - recall_tumor: 0.5744 - tumor_iou: 0.3333 - val_acc: 0.9757 - val_dice_coef_metric_tumor: 0.3868 - val_loss: 0.4050 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3438 - val_recall_tumor: 0.5423 - val_tumor_iou: 0.2643 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 85 lên WandB.\n\n--- Epoch 86/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9828 - dice_coef_metric_tumor: 0.4771 - loss: 0.3285 - mean_iou_all: 0.4562 - precision_tumor: 0.4895 - recall_tumor: 0.5703 - tumor_iou: 0.3424\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42955\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9828 - dice_coef_metric_tumor: 0.4771 - loss: 0.3285 - mean_iou_all: 0.4563 - precision_tumor: 0.4894 - recall_tumor: 0.5702 - tumor_iou: 0.3424 - val_acc: 0.9848 - val_dice_coef_metric_tumor: 0.4020 - val_loss: 0.3927 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4870 - val_recall_tumor: 0.4098 - val_tumor_iou: 0.2796 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 86 lên WandB.\n\n--- Epoch 87/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9801 - dice_coef_metric_tumor: 0.4423 - loss: 0.3455 - mean_iou_all: 0.4611 - precision_tumor: 0.4242 - recall_tumor: 0.5597 - tumor_iou: 0.3126\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42955\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9801 - dice_coef_metric_tumor: 0.4423 - loss: 0.3455 - mean_iou_all: 0.4612 - precision_tumor: 0.4242 - recall_tumor: 0.5596 - tumor_iou: 0.3126 - val_acc: 0.9803 - val_dice_coef_metric_tumor: 0.3960 - val_loss: 0.3977 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3894 - val_recall_tumor: 0.4953 - val_tumor_iou: 0.2714 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 87 lên WandB.\n\n--- Epoch 88/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9813 - dice_coef_metric_tumor: 0.4653 - loss: 0.3299 - mean_iou_all: 0.4562 - precision_tumor: 0.4478 - recall_tumor: 0.5896 - tumor_iou: 0.3327\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42955\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9813 - dice_coef_metric_tumor: 0.4652 - loss: 0.3299 - mean_iou_all: 0.4563 - precision_tumor: 0.4478 - recall_tumor: 0.5896 - tumor_iou: 0.3327 - val_acc: 0.9763 - val_dice_coef_metric_tumor: 0.3623 - val_loss: 0.4196 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3552 - val_recall_tumor: 0.4815 - val_tumor_iou: 0.2420 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 88 lên WandB.\n\n--- Epoch 89/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9808 - dice_coef_metric_tumor: 0.4655 - loss: 0.3368 - mean_iou_all: 0.4493 - precision_tumor: 0.4486 - recall_tumor: 0.5889 - tumor_iou: 0.3310\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42955\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9808 - dice_coef_metric_tumor: 0.4655 - loss: 0.3368 - mean_iou_all: 0.4494 - precision_tumor: 0.4486 - recall_tumor: 0.5889 - tumor_iou: 0.3310 - val_acc: 0.9734 - val_dice_coef_metric_tumor: 0.3902 - val_loss: 0.4046 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3711 - val_recall_tumor: 0.5400 - val_tumor_iou: 0.2686 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 89 lên WandB.\n\n--- Epoch 90/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9813 - dice_coef_metric_tumor: 0.4717 - loss: 0.3297 - mean_iou_all: 0.4649 - precision_tumor: 0.4618 - recall_tumor: 0.5844 - tumor_iou: 0.3377\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42955\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9813 - dice_coef_metric_tumor: 0.4717 - loss: 0.3297 - mean_iou_all: 0.4650 - precision_tumor: 0.4618 - recall_tumor: 0.5844 - tumor_iou: 0.3377 - val_acc: 0.9852 - val_dice_coef_metric_tumor: 0.2666 - val_loss: 0.4755 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4964 - val_recall_tumor: 0.2178 - val_tumor_iou: 0.1772 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 90 lên WandB.\n\n--- Epoch 91/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9825 - dice_coef_metric_tumor: 0.4825 - loss: 0.3290 - mean_iou_all: 0.4644 - precision_tumor: 0.4766 - recall_tumor: 0.5687 - tumor_iou: 0.3438\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42955\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9825 - dice_coef_metric_tumor: 0.4824 - loss: 0.3290 - mean_iou_all: 0.4645 - precision_tumor: 0.4765 - recall_tumor: 0.5687 - tumor_iou: 0.3438 - val_acc: 0.9795 - val_dice_coef_metric_tumor: 0.4033 - val_loss: 0.3944 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3856 - val_recall_tumor: 0.5236 - val_tumor_iou: 0.2783 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 91 lên WandB.\n\n--- Epoch 92/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9807 - dice_coef_metric_tumor: 0.4720 - loss: 0.3332 - mean_iou_all: 0.4485 - precision_tumor: 0.4548 - recall_tumor: 0.5799 - tumor_iou: 0.3381\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42955\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9807 - dice_coef_metric_tumor: 0.4720 - loss: 0.3331 - mean_iou_all: 0.4486 - precision_tumor: 0.4547 - recall_tumor: 0.5799 - tumor_iou: 0.3381 - val_acc: 0.9829 - val_dice_coef_metric_tumor: 0.3815 - val_loss: 0.4051 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4644 - val_recall_tumor: 0.3994 - val_tumor_iou: 0.2626 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 92 lên WandB.\n\n--- Epoch 93/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9838 - dice_coef_metric_tumor: 0.5009 - loss: 0.3138 - mean_iou_all: 0.4599 - precision_tumor: 0.5027 - recall_tumor: 0.5831 - tumor_iou: 0.3614\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42955\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9838 - dice_coef_metric_tumor: 0.5008 - loss: 0.3138 - mean_iou_all: 0.4600 - precision_tumor: 0.5026 - recall_tumor: 0.5830 - tumor_iou: 0.3613 - val_acc: 0.9830 - val_dice_coef_metric_tumor: 0.4244 - val_loss: 0.3804 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4424 - val_recall_tumor: 0.4723 - val_tumor_iou: 0.2949 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 93 lên WandB.\n\n--- Epoch 94/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9820 - dice_coef_metric_tumor: 0.4736 - loss: 0.3263 - mean_iou_all: 0.4540 - precision_tumor: 0.4606 - recall_tumor: 0.5650 - tumor_iou: 0.3400\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42955\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9820 - dice_coef_metric_tumor: 0.4736 - loss: 0.3263 - mean_iou_all: 0.4541 - precision_tumor: 0.4605 - recall_tumor: 0.5649 - tumor_iou: 0.3400 - val_acc: 0.9856 - val_dice_coef_metric_tumor: 0.4184 - val_loss: 0.3833 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5072 - val_recall_tumor: 0.4062 - val_tumor_iou: 0.2964 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 94 lên WandB.\n\n--- Epoch 95/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9812 - dice_coef_metric_tumor: 0.4640 - loss: 0.3386 - mean_iou_all: 0.4652 - precision_tumor: 0.4464 - recall_tumor: 0.5684 - tumor_iou: 0.3297\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42955\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9812 - dice_coef_metric_tumor: 0.4639 - loss: 0.3386 - mean_iou_all: 0.4652 - precision_tumor: 0.4464 - recall_tumor: 0.5684 - tumor_iou: 0.3296 - val_acc: 0.9859 - val_dice_coef_metric_tumor: 0.3096 - val_loss: 0.4489 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5530 - val_recall_tumor: 0.2540 - val_tumor_iou: 0.2099 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 95 lên WandB.\n\n--- Epoch 96/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.4777 - loss: 0.3230 - mean_iou_all: 0.4639 - precision_tumor: 0.4822 - recall_tumor: 0.5682 - tumor_iou: 0.3435\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42955\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.4777 - loss: 0.3230 - mean_iou_all: 0.4640 - precision_tumor: 0.4821 - recall_tumor: 0.5682 - tumor_iou: 0.3434 - val_acc: 0.9850 - val_dice_coef_metric_tumor: 0.3975 - val_loss: 0.3963 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5202 - val_recall_tumor: 0.3946 - val_tumor_iou: 0.2759 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 96 lên WandB.\n\n--- Epoch 97/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9819 - dice_coef_metric_tumor: 0.4803 - loss: 0.3307 - mean_iou_all: 0.4626 - precision_tumor: 0.4683 - recall_tumor: 0.5757 - tumor_iou: 0.3463\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42955\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9819 - dice_coef_metric_tumor: 0.4802 - loss: 0.3306 - mean_iou_all: 0.4627 - precision_tumor: 0.4683 - recall_tumor: 0.5756 - tumor_iou: 0.3463 - val_acc: 0.9833 - val_dice_coef_metric_tumor: 0.3565 - val_loss: 0.4215 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4891 - val_recall_tumor: 0.3468 - val_tumor_iou: 0.2413 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 97 lên WandB.\n\n--- Epoch 98/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9826 - dice_coef_metric_tumor: 0.4833 - loss: 0.3268 - mean_iou_all: 0.4637 - precision_tumor: 0.4837 - recall_tumor: 0.5628 - tumor_iou: 0.3482\nEpoch 1: val_dice_coef_metric_tumor improved from 0.42955 to 0.45633, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9826 - dice_coef_metric_tumor: 0.4832 - loss: 0.3268 - mean_iou_all: 0.4637 - precision_tumor: 0.4836 - recall_tumor: 0.5628 - tumor_iou: 0.3481 - val_acc: 0.9836 - val_dice_coef_metric_tumor: 0.4563 - val_loss: 0.3617 - val_mean_iou_all: 0.4393 - val_precision_tumor: 0.4590 - val_recall_tumor: 0.5251 - val_tumor_iou: 0.3263 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 98 lên WandB.\n\n--- Epoch 99/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9835 - dice_coef_metric_tumor: 0.5020 - loss: 0.3110 - mean_iou_all: 0.4562 - precision_tumor: 0.4936 - recall_tumor: 0.5945 - tumor_iou: 0.3644\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45633\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9835 - dice_coef_metric_tumor: 0.5019 - loss: 0.3110 - mean_iou_all: 0.4562 - precision_tumor: 0.4935 - recall_tumor: 0.5945 - tumor_iou: 0.3643 - val_acc: 0.9807 - val_dice_coef_metric_tumor: 0.4013 - val_loss: 0.3957 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4148 - val_recall_tumor: 0.4747 - val_tumor_iou: 0.2779 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 99 lên WandB.\n\n--- Epoch 100/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9832 - dice_coef_metric_tumor: 0.5032 - loss: 0.3194 - mean_iou_all: 0.4703 - precision_tumor: 0.5015 - recall_tumor: 0.5668 - tumor_iou: 0.3656\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45633\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9832 - dice_coef_metric_tumor: 0.5031 - loss: 0.3194 - mean_iou_all: 0.4704 - precision_tumor: 0.5015 - recall_tumor: 0.5668 - tumor_iou: 0.3655 - val_acc: 0.9847 - val_dice_coef_metric_tumor: 0.4239 - val_loss: 0.3814 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4995 - val_recall_tumor: 0.4415 - val_tumor_iou: 0.2974 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 100 lên WandB.\n\n--- Epoch 101/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.4895 - loss: 0.3236 - mean_iou_all: 0.4559 - precision_tumor: 0.4880 - recall_tumor: 0.5779 - tumor_iou: 0.3512\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45633\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.4895 - loss: 0.3236 - mean_iou_all: 0.4560 - precision_tumor: 0.4880 - recall_tumor: 0.5779 - tumor_iou: 0.3512 - val_acc: 0.9854 - val_dice_coef_metric_tumor: 0.4383 - val_loss: 0.3723 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5064 - val_recall_tumor: 0.4377 - val_tumor_iou: 0.3112 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 101 lên WandB.\n\n--- Epoch 102/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.4863 - loss: 0.3225 - mean_iou_all: 0.4707 - precision_tumor: 0.4782 - recall_tumor: 0.5814 - tumor_iou: 0.3488\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45633\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.4863 - loss: 0.3225 - mean_iou_all: 0.4707 - precision_tumor: 0.4782 - recall_tumor: 0.5814 - tumor_iou: 0.3488 - val_acc: 0.9850 - val_dice_coef_metric_tumor: 0.3544 - val_loss: 0.4236 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5361 - val_recall_tumor: 0.3189 - val_tumor_iou: 0.2425 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 102 lên WandB.\n\n--- Epoch 103/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.5013 - loss: 0.3177 - mean_iou_all: 0.4700 - precision_tumor: 0.5058 - recall_tumor: 0.5880 - tumor_iou: 0.3661\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45633\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.5013 - loss: 0.3177 - mean_iou_all: 0.4700 - precision_tumor: 0.5057 - recall_tumor: 0.5880 - tumor_iou: 0.3661 - val_acc: 0.9840 - val_dice_coef_metric_tumor: 0.4126 - val_loss: 0.3883 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4827 - val_recall_tumor: 0.4233 - val_tumor_iou: 0.2902 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 103 lên WandB.\n\n--- Epoch 104/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9837 - dice_coef_metric_tumor: 0.5101 - loss: 0.3086 - mean_iou_all: 0.4735 - precision_tumor: 0.5068 - recall_tumor: 0.5953 - tumor_iou: 0.3728\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45633\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9837 - dice_coef_metric_tumor: 0.5100 - loss: 0.3086 - mean_iou_all: 0.4735 - precision_tumor: 0.5067 - recall_tumor: 0.5953 - tumor_iou: 0.3728 - val_acc: 0.9855 - val_dice_coef_metric_tumor: 0.4448 - val_loss: 0.3688 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5182 - val_recall_tumor: 0.4498 - val_tumor_iou: 0.3141 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 104 lên WandB.\n\n--- Epoch 105/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9824 - dice_coef_metric_tumor: 0.4926 - loss: 0.3236 - mean_iou_all: 0.4632 - precision_tumor: 0.4885 - recall_tumor: 0.6002 - tumor_iou: 0.3547\nEpoch 1: val_dice_coef_metric_tumor improved from 0.45633 to 0.46606, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9824 - dice_coef_metric_tumor: 0.4926 - loss: 0.3236 - mean_iou_all: 0.4632 - precision_tumor: 0.4885 - recall_tumor: 0.6002 - tumor_iou: 0.3546 - val_acc: 0.9846 - val_dice_coef_metric_tumor: 0.4661 - val_loss: 0.3563 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5289 - val_recall_tumor: 0.4758 - val_tumor_iou: 0.3334 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 105 lên WandB.\n\n--- Epoch 106/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9823 - dice_coef_metric_tumor: 0.4973 - loss: 0.3202 - mean_iou_all: 0.4719 - precision_tumor: 0.4835 - recall_tumor: 0.6046 - tumor_iou: 0.3585\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.46606\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9823 - dice_coef_metric_tumor: 0.4973 - loss: 0.3202 - mean_iou_all: 0.4719 - precision_tumor: 0.4835 - recall_tumor: 0.6046 - tumor_iou: 0.3585 - val_acc: 0.9858 - val_dice_coef_metric_tumor: 0.3831 - val_loss: 0.4060 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5390 - val_recall_tumor: 0.3488 - val_tumor_iou: 0.2659 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 106 lên WandB.\n\n--- Epoch 107/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.4912 - loss: 0.3210 - mean_iou_all: 0.4715 - precision_tumor: 0.4867 - recall_tumor: 0.5860 - tumor_iou: 0.3543\nEpoch 1: val_dice_coef_metric_tumor improved from 0.46606 to 0.47219, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.4912 - loss: 0.3210 - mean_iou_all: 0.4715 - precision_tumor: 0.4867 - recall_tumor: 0.5861 - tumor_iou: 0.3543 - val_acc: 0.9848 - val_dice_coef_metric_tumor: 0.4722 - val_loss: 0.3522 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4784 - val_recall_tumor: 0.5358 - val_tumor_iou: 0.3384 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 107 lên WandB.\n\n--- Epoch 108/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9833 - dice_coef_metric_tumor: 0.5041 - loss: 0.3124 - mean_iou_all: 0.4666 - precision_tumor: 0.5013 - recall_tumor: 0.5919 - tumor_iou: 0.3688\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9833 - dice_coef_metric_tumor: 0.5040 - loss: 0.3125 - mean_iou_all: 0.4667 - precision_tumor: 0.5012 - recall_tumor: 0.5918 - tumor_iou: 0.3688 - val_acc: 0.9832 - val_dice_coef_metric_tumor: 0.4111 - val_loss: 0.3906 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4528 - val_recall_tumor: 0.4520 - val_tumor_iou: 0.2849 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 108 lên WandB.\n\n--- Epoch 109/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9821 - dice_coef_metric_tumor: 0.4899 - loss: 0.3206 - mean_iou_all: 0.4773 - precision_tumor: 0.4820 - recall_tumor: 0.5931 - tumor_iou: 0.3536\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9821 - dice_coef_metric_tumor: 0.4899 - loss: 0.3206 - mean_iou_all: 0.4773 - precision_tumor: 0.4820 - recall_tumor: 0.5930 - tumor_iou: 0.3536 - val_acc: 0.9857 - val_dice_coef_metric_tumor: 0.4483 - val_loss: 0.3675 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5260 - val_recall_tumor: 0.4602 - val_tumor_iou: 0.3185 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 109 lên WandB.\n\n--- Epoch 110/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.5139 - loss: 0.3043 - mean_iou_all: 0.4706 - precision_tumor: 0.5121 - recall_tumor: 0.5972 - tumor_iou: 0.3746\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.5138 - loss: 0.3043 - mean_iou_all: 0.4706 - precision_tumor: 0.5121 - recall_tumor: 0.5972 - tumor_iou: 0.3746 - val_acc: 0.9865 - val_dice_coef_metric_tumor: 0.4281 - val_loss: 0.3785 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5785 - val_recall_tumor: 0.3920 - val_tumor_iou: 0.3039 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 110 lên WandB.\n\n--- Epoch 111/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9846 - dice_coef_metric_tumor: 0.5129 - loss: 0.3105 - mean_iou_all: 0.4767 - precision_tumor: 0.5137 - recall_tumor: 0.5840 - tumor_iou: 0.3735\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9846 - dice_coef_metric_tumor: 0.5128 - loss: 0.3105 - mean_iou_all: 0.4768 - precision_tumor: 0.5136 - recall_tumor: 0.5840 - tumor_iou: 0.3734 - val_acc: 0.9860 - val_dice_coef_metric_tumor: 0.4531 - val_loss: 0.3639 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5272 - val_recall_tumor: 0.4617 - val_tumor_iou: 0.3248 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 111 lên WandB.\n\n--- Epoch 112/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9837 - dice_coef_metric_tumor: 0.5200 - loss: 0.3077 - mean_iou_all: 0.4854 - precision_tumor: 0.5065 - recall_tumor: 0.6170 - tumor_iou: 0.3805\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9837 - dice_coef_metric_tumor: 0.5199 - loss: 0.3077 - mean_iou_all: 0.4854 - precision_tumor: 0.5065 - recall_tumor: 0.6169 - tumor_iou: 0.3805 - val_acc: 0.9872 - val_dice_coef_metric_tumor: 0.3945 - val_loss: 0.3995 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6400 - val_recall_tumor: 0.3224 - val_tumor_iou: 0.2721 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 112 lên WandB.\n\n--- Epoch 113/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5134 - loss: 0.3034 - mean_iou_all: 0.4670 - precision_tumor: 0.5158 - recall_tumor: 0.5961 - tumor_iou: 0.3754\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5133 - loss: 0.3034 - mean_iou_all: 0.4670 - precision_tumor: 0.5157 - recall_tumor: 0.5961 - tumor_iou: 0.3753 - val_acc: 0.9848 - val_dice_coef_metric_tumor: 0.4340 - val_loss: 0.3765 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4934 - val_recall_tumor: 0.4587 - val_tumor_iou: 0.3013 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 113 lên WandB.\n\n--- Epoch 114/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9848 - dice_coef_metric_tumor: 0.5247 - loss: 0.2993 - mean_iou_all: 0.4735 - precision_tumor: 0.5215 - recall_tumor: 0.6025 - tumor_iou: 0.3892\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9848 - dice_coef_metric_tumor: 0.5247 - loss: 0.2993 - mean_iou_all: 0.4735 - precision_tumor: 0.5215 - recall_tumor: 0.6025 - tumor_iou: 0.3891 - val_acc: 0.9829 - val_dice_coef_metric_tumor: 0.4361 - val_loss: 0.3761 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4585 - val_recall_tumor: 0.4961 - val_tumor_iou: 0.3071 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 114 lên WandB.\n\n--- Epoch 115/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9826 - dice_coef_metric_tumor: 0.5102 - loss: 0.3110 - mean_iou_all: 0.4498 - precision_tumor: 0.4992 - recall_tumor: 0.6241 - tumor_iou: 0.3715\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9826 - dice_coef_metric_tumor: 0.5102 - loss: 0.3110 - mean_iou_all: 0.4498 - precision_tumor: 0.4992 - recall_tumor: 0.6240 - tumor_iou: 0.3714 - val_acc: 0.9832 - val_dice_coef_metric_tumor: 0.4223 - val_loss: 0.3842 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4973 - val_recall_tumor: 0.4316 - val_tumor_iou: 0.2957 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 115 lên WandB.\n\n--- Epoch 116/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9835 - dice_coef_metric_tumor: 0.5242 - loss: 0.3028 - mean_iou_all: 0.4818 - precision_tumor: 0.5197 - recall_tumor: 0.6184 - tumor_iou: 0.3870\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9835 - dice_coef_metric_tumor: 0.5241 - loss: 0.3028 - mean_iou_all: 0.4818 - precision_tumor: 0.5196 - recall_tumor: 0.6184 - tumor_iou: 0.3870 - val_acc: 0.9795 - val_dice_coef_metric_tumor: 0.4385 - val_loss: 0.3758 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3873 - val_recall_tumor: 0.6039 - val_tumor_iou: 0.3070 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 116 lên WandB.\n\n--- Epoch 117/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.5267 - loss: 0.3039 - mean_iou_all: 0.4821 - precision_tumor: 0.5184 - recall_tumor: 0.6257 - tumor_iou: 0.3860\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.5267 - loss: 0.3039 - mean_iou_all: 0.4821 - precision_tumor: 0.5184 - recall_tumor: 0.6257 - tumor_iou: 0.3859 - val_acc: 0.9854 - val_dice_coef_metric_tumor: 0.4376 - val_loss: 0.3741 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5173 - val_recall_tumor: 0.4372 - val_tumor_iou: 0.3163 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 117 lên WandB.\n\n--- Epoch 118/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9844 - dice_coef_metric_tumor: 0.5102 - loss: 0.3033 - mean_iou_all: 0.4670 - precision_tumor: 0.5122 - recall_tumor: 0.6024 - tumor_iou: 0.3739\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9844 - dice_coef_metric_tumor: 0.5101 - loss: 0.3033 - mean_iou_all: 0.4670 - precision_tumor: 0.5122 - recall_tumor: 0.6023 - tumor_iou: 0.3739 - val_acc: 0.9855 - val_dice_coef_metric_tumor: 0.4675 - val_loss: 0.3559 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4915 - val_recall_tumor: 0.5237 - val_tumor_iou: 0.3375 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 118 lên WandB.\n\n--- Epoch 119/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5197 - loss: 0.3000 - mean_iou_all: 0.4754 - precision_tumor: 0.5191 - recall_tumor: 0.5993 - tumor_iou: 0.3827\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5197 - loss: 0.3000 - mean_iou_all: 0.4754 - precision_tumor: 0.5190 - recall_tumor: 0.5993 - tumor_iou: 0.3827 - val_acc: 0.9845 - val_dice_coef_metric_tumor: 0.3274 - val_loss: 0.4422 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5641 - val_recall_tumor: 0.2904 - val_tumor_iou: 0.2215 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 119 lên WandB.\n\n--- Epoch 120/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9841 - dice_coef_metric_tumor: 0.5263 - loss: 0.3009 - mean_iou_all: 0.4772 - precision_tumor: 0.5173 - recall_tumor: 0.6256 - tumor_iou: 0.3879\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9841 - dice_coef_metric_tumor: 0.5262 - loss: 0.3009 - mean_iou_all: 0.4771 - precision_tumor: 0.5172 - recall_tumor: 0.6256 - tumor_iou: 0.3879 - val_acc: 0.9859 - val_dice_coef_metric_tumor: 0.4176 - val_loss: 0.3870 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5446 - val_recall_tumor: 0.3875 - val_tumor_iou: 0.2974 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 120 lên WandB.\n\n--- Epoch 121/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9849 - dice_coef_metric_tumor: 0.5315 - loss: 0.2990 - mean_iou_all: 0.4656 - precision_tumor: 0.5309 - recall_tumor: 0.6016 - tumor_iou: 0.3933\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9849 - dice_coef_metric_tumor: 0.5314 - loss: 0.2990 - mean_iou_all: 0.4656 - precision_tumor: 0.5308 - recall_tumor: 0.6015 - tumor_iou: 0.3932 - val_acc: 0.9778 - val_dice_coef_metric_tumor: 0.4311 - val_loss: 0.3813 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3931 - val_recall_tumor: 0.5988 - val_tumor_iou: 0.3042 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 121 lên WandB.\n\n--- Epoch 122/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9842 - dice_coef_metric_tumor: 0.5182 - loss: 0.3043 - mean_iou_all: 0.4754 - precision_tumor: 0.5213 - recall_tumor: 0.6094 - tumor_iou: 0.3784\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9842 - dice_coef_metric_tumor: 0.5181 - loss: 0.3043 - mean_iou_all: 0.4754 - precision_tumor: 0.5213 - recall_tumor: 0.6094 - tumor_iou: 0.3784 - val_acc: 0.9851 - val_dice_coef_metric_tumor: 0.4573 - val_loss: 0.3633 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5404 - val_recall_tumor: 0.4773 - val_tumor_iou: 0.3225 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 122 lên WandB.\n\n--- Epoch 123/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9840 - dice_coef_metric_tumor: 0.5188 - loss: 0.3068 - mean_iou_all: 0.4789 - precision_tumor: 0.5178 - recall_tumor: 0.6007 - tumor_iou: 0.3783\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9840 - dice_coef_metric_tumor: 0.5188 - loss: 0.3067 - mean_iou_all: 0.4789 - precision_tumor: 0.5178 - recall_tumor: 0.6007 - tumor_iou: 0.3782 - val_acc: 0.9736 - val_dice_coef_metric_tumor: 0.4268 - val_loss: 0.3855 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3476 - val_recall_tumor: 0.6780 - val_tumor_iou: 0.2982 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 123 lên WandB.\n\n--- Epoch 124/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5337 - loss: 0.3000 - mean_iou_all: 0.4522 - precision_tumor: 0.5387 - recall_tumor: 0.5948 - tumor_iou: 0.3927\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5336 - loss: 0.2999 - mean_iou_all: 0.4521 - precision_tumor: 0.5387 - recall_tumor: 0.5948 - tumor_iou: 0.3927 - val_acc: 0.9867 - val_dice_coef_metric_tumor: 0.4395 - val_loss: 0.3737 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5467 - val_recall_tumor: 0.4130 - val_tumor_iou: 0.3123 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 124 lên WandB.\n\n--- Epoch 125/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.5175 - loss: 0.3043 - mean_iou_all: 0.4490 - precision_tumor: 0.5018 - recall_tumor: 0.6208 - tumor_iou: 0.3775\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.5175 - loss: 0.3043 - mean_iou_all: 0.4489 - precision_tumor: 0.5017 - recall_tumor: 0.6207 - tumor_iou: 0.3774 - val_acc: 0.9873 - val_dice_coef_metric_tumor: 0.3751 - val_loss: 0.4130 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5750 - val_recall_tumor: 0.3141 - val_tumor_iou: 0.2651 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 125 lên WandB.\n\n--- Epoch 126/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5385 - loss: 0.2939 - mean_iou_all: 0.4670 - precision_tumor: 0.5435 - recall_tumor: 0.6078 - tumor_iou: 0.4006\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5384 - loss: 0.2940 - mean_iou_all: 0.4670 - precision_tumor: 0.5434 - recall_tumor: 0.6078 - tumor_iou: 0.4006 - val_acc: 0.9789 - val_dice_coef_metric_tumor: 0.4512 - val_loss: 0.3696 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3842 - val_recall_tumor: 0.6444 - val_tumor_iou: 0.3228 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 126 lên WandB.\n\n--- Epoch 127/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9843 - dice_coef_metric_tumor: 0.5319 - loss: 0.3034 - mean_iou_all: 0.4653 - precision_tumor: 0.5342 - recall_tumor: 0.6119 - tumor_iou: 0.3919\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9843 - dice_coef_metric_tumor: 0.5318 - loss: 0.3034 - mean_iou_all: 0.4653 - precision_tumor: 0.5341 - recall_tumor: 0.6119 - tumor_iou: 0.3919 - val_acc: 0.9851 - val_dice_coef_metric_tumor: 0.3689 - val_loss: 0.4174 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5230 - val_recall_tumor: 0.3479 - val_tumor_iou: 0.2597 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 127 lên WandB.\n\n--- Epoch 128/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9848 - dice_coef_metric_tumor: 0.5170 - loss: 0.3050 - mean_iou_all: 0.4821 - precision_tumor: 0.5208 - recall_tumor: 0.5924 - tumor_iou: 0.3785\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9848 - dice_coef_metric_tumor: 0.5170 - loss: 0.3050 - mean_iou_all: 0.4821 - precision_tumor: 0.5208 - recall_tumor: 0.5924 - tumor_iou: 0.3785 - val_acc: 0.9862 - val_dice_coef_metric_tumor: 0.4478 - val_loss: 0.3697 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5462 - val_recall_tumor: 0.4407 - val_tumor_iou: 0.3187 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 128 lên WandB.\n\n--- Epoch 129/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5554 - loss: 0.2845 - mean_iou_all: 0.4654 - precision_tumor: 0.5544 - recall_tumor: 0.6312 - tumor_iou: 0.4168\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5553 - loss: 0.2845 - mean_iou_all: 0.4654 - precision_tumor: 0.5543 - recall_tumor: 0.6312 - tumor_iou: 0.4167 - val_acc: 0.9800 - val_dice_coef_metric_tumor: 0.4494 - val_loss: 0.3699 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4025 - val_recall_tumor: 0.6193 - val_tumor_iou: 0.3173 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 129 lên WandB.\n\n--- Epoch 130/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9837 - dice_coef_metric_tumor: 0.5171 - loss: 0.3093 - mean_iou_all: 0.4670 - precision_tumor: 0.5169 - recall_tumor: 0.6246 - tumor_iou: 0.3763\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47219\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9837 - dice_coef_metric_tumor: 0.5171 - loss: 0.3093 - mean_iou_all: 0.4670 - precision_tumor: 0.5169 - recall_tumor: 0.6246 - tumor_iou: 0.3763 - val_acc: 0.9843 - val_dice_coef_metric_tumor: 0.4447 - val_loss: 0.3713 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4885 - val_recall_tumor: 0.4896 - val_tumor_iou: 0.3188 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 130 lên WandB.\n\n--- Epoch 131/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9838 - dice_coef_metric_tumor: 0.5185 - loss: 0.3038 - mean_iou_all: 0.4840 - precision_tumor: 0.4946 - recall_tumor: 0.6327 - tumor_iou: 0.3799\nEpoch 1: val_dice_coef_metric_tumor improved from 0.47219 to 0.48057, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9838 - dice_coef_metric_tumor: 0.5185 - loss: 0.3038 - mean_iou_all: 0.4840 - precision_tumor: 0.4947 - recall_tumor: 0.6326 - tumor_iou: 0.3799 - val_acc: 0.9849 - val_dice_coef_metric_tumor: 0.4806 - val_loss: 0.3498 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4633 - val_recall_tumor: 0.5700 - val_tumor_iou: 0.3471 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 131 lên WandB.\n\n--- Epoch 132/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5430 - loss: 0.2998 - mean_iou_all: 0.4765 - precision_tumor: 0.5567 - recall_tumor: 0.6120 - tumor_iou: 0.4052\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48057\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5430 - loss: 0.2998 - mean_iou_all: 0.4765 - precision_tumor: 0.5566 - recall_tumor: 0.6120 - tumor_iou: 0.4052 - val_acc: 0.9852 - val_dice_coef_metric_tumor: 0.4553 - val_loss: 0.3651 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5077 - val_recall_tumor: 0.4813 - val_tumor_iou: 0.3261 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 132 lên WandB.\n\n--- Epoch 133/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5447 - loss: 0.2925 - mean_iou_all: 0.4692 - precision_tumor: 0.5562 - recall_tumor: 0.6073 - tumor_iou: 0.4031\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48057\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5446 - loss: 0.2925 - mean_iou_all: 0.4692 - precision_tumor: 0.5562 - recall_tumor: 0.6072 - tumor_iou: 0.4031 - val_acc: 0.9874 - val_dice_coef_metric_tumor: 0.4428 - val_loss: 0.3730 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5723 - val_recall_tumor: 0.4014 - val_tumor_iou: 0.3171 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 133 lên WandB.\n\n--- Epoch 134/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5407 - loss: 0.2920 - mean_iou_all: 0.4749 - precision_tumor: 0.5399 - recall_tumor: 0.6314 - tumor_iou: 0.4008\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48057\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5406 - loss: 0.2920 - mean_iou_all: 0.4749 - precision_tumor: 0.5399 - recall_tumor: 0.6313 - tumor_iou: 0.4008 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.4805 - val_loss: 0.3494 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5886 - val_recall_tumor: 0.4563 - val_tumor_iou: 0.3521 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 134 lên WandB.\n\n--- Epoch 135/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9849 - dice_coef_metric_tumor: 0.5241 - loss: 0.3013 - mean_iou_all: 0.4664 - precision_tumor: 0.5349 - recall_tumor: 0.5949 - tumor_iou: 0.3842\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48057\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9849 - dice_coef_metric_tumor: 0.5241 - loss: 0.3013 - mean_iou_all: 0.4664 - precision_tumor: 0.5349 - recall_tumor: 0.5950 - tumor_iou: 0.3842 - val_acc: 0.9827 - val_dice_coef_metric_tumor: 0.4555 - val_loss: 0.3670 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4955 - val_recall_tumor: 0.5230 - val_tumor_iou: 0.3247 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 135 lên WandB.\n\n--- Epoch 136/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5491 - loss: 0.2877 - mean_iou_all: 0.4690 - precision_tumor: 0.5454 - recall_tumor: 0.6198 - tumor_iou: 0.4096\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48057\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5490 - loss: 0.2877 - mean_iou_all: 0.4690 - precision_tumor: 0.5454 - recall_tumor: 0.6197 - tumor_iou: 0.4096 - val_acc: 0.9845 - val_dice_coef_metric_tumor: 0.4768 - val_loss: 0.3531 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4630 - val_recall_tumor: 0.5702 - val_tumor_iou: 0.3434 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 136 lên WandB.\n\n--- Epoch 137/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5492 - loss: 0.2859 - mean_iou_all: 0.4761 - precision_tumor: 0.5400 - recall_tumor: 0.6482 - tumor_iou: 0.4078\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48057\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5491 - loss: 0.2859 - mean_iou_all: 0.4760 - precision_tumor: 0.5400 - recall_tumor: 0.6481 - tumor_iou: 0.4077 - val_acc: 0.9869 - val_dice_coef_metric_tumor: 0.4586 - val_loss: 0.3630 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5750 - val_recall_tumor: 0.4414 - val_tumor_iou: 0.3332 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 137 lên WandB.\n\n--- Epoch 138/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5484 - loss: 0.2895 - mean_iou_all: 0.4682 - precision_tumor: 0.5604 - recall_tumor: 0.6266 - tumor_iou: 0.4068\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48057\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5484 - loss: 0.2895 - mean_iou_all: 0.4682 - precision_tumor: 0.5604 - recall_tumor: 0.6266 - tumor_iou: 0.4067 - val_acc: 0.9851 - val_dice_coef_metric_tumor: 0.4636 - val_loss: 0.3605 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5439 - val_recall_tumor: 0.4778 - val_tumor_iou: 0.3283 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 138 lên WandB.\n\n--- Epoch 139/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9852 - dice_coef_metric_tumor: 0.5387 - loss: 0.2959 - mean_iou_all: 0.4771 - precision_tumor: 0.5417 - recall_tumor: 0.6234 - tumor_iou: 0.3991\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48057\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 463ms/step - acc: 0.9852 - dice_coef_metric_tumor: 0.5387 - loss: 0.2959 - mean_iou_all: 0.4770 - precision_tumor: 0.5417 - recall_tumor: 0.6234 - tumor_iou: 0.3991 - val_acc: 0.9877 - val_dice_coef_metric_tumor: 0.4374 - val_loss: 0.3766 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6493 - val_recall_tumor: 0.3786 - val_tumor_iou: 0.3129 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 139 lên WandB.\n\n--- Epoch 140/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9849 - dice_coef_metric_tumor: 0.5398 - loss: 0.2966 - mean_iou_all: 0.4732 - precision_tumor: 0.5453 - recall_tumor: 0.6191 - tumor_iou: 0.4039\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48057\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9849 - dice_coef_metric_tumor: 0.5397 - loss: 0.2966 - mean_iou_all: 0.4732 - precision_tumor: 0.5453 - recall_tumor: 0.6191 - tumor_iou: 0.4038 - val_acc: 0.9878 - val_dice_coef_metric_tumor: 0.4537 - val_loss: 0.3664 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6182 - val_recall_tumor: 0.4070 - val_tumor_iou: 0.3288 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 140 lên WandB.\n\n--- Epoch 141/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5523 - loss: 0.2860 - mean_iou_all: 0.4690 - precision_tumor: 0.5561 - recall_tumor: 0.6232 - tumor_iou: 0.4086\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48057\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5523 - loss: 0.2860 - mean_iou_all: 0.4690 - precision_tumor: 0.5561 - recall_tumor: 0.6232 - tumor_iou: 0.4086 - val_acc: 0.9879 - val_dice_coef_metric_tumor: 0.4365 - val_loss: 0.3771 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6468 - val_recall_tumor: 0.3741 - val_tumor_iou: 0.3150 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 141 lên WandB.\n\n--- Epoch 142/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5606 - loss: 0.2859 - mean_iou_all: 0.4733 - precision_tumor: 0.5766 - recall_tumor: 0.6256 - tumor_iou: 0.4185\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48057\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5605 - loss: 0.2859 - mean_iou_all: 0.4733 - precision_tumor: 0.5766 - recall_tumor: 0.6255 - tumor_iou: 0.4185 - val_acc: 0.9843 - val_dice_coef_metric_tumor: 0.4289 - val_loss: 0.3832 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5654 - val_recall_tumor: 0.4220 - val_tumor_iou: 0.3041 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 142 lên WandB.\n\n--- Epoch 143/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5415 - loss: 0.2956 - mean_iou_all: 0.4782 - precision_tumor: 0.5571 - recall_tumor: 0.6047 - tumor_iou: 0.4014\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.48057\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5415 - loss: 0.2956 - mean_iou_all: 0.4782 - precision_tumor: 0.5571 - recall_tumor: 0.6047 - tumor_iou: 0.4014 - val_acc: 0.9869 - val_dice_coef_metric_tumor: 0.4436 - val_loss: 0.3727 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5799 - val_recall_tumor: 0.4288 - val_tumor_iou: 0.3215 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 143 lên WandB.\n\n--- Epoch 144/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.5724 - loss: 0.2717 - mean_iou_all: 0.4683 - precision_tumor: 0.5901 - recall_tumor: 0.6190 - tumor_iou: 0.4325\nEpoch 1: val_dice_coef_metric_tumor improved from 0.48057 to 0.51534, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.5724 - loss: 0.2717 - mean_iou_all: 0.4682 - precision_tumor: 0.5901 - recall_tumor: 0.6190 - tumor_iou: 0.4325 - val_acc: 0.9846 - val_dice_coef_metric_tumor: 0.5153 - val_loss: 0.3310 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4937 - val_recall_tumor: 0.6190 - val_tumor_iou: 0.3807 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 144 lên WandB.\n\n--- Epoch 145/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5643 - loss: 0.2847 - mean_iou_all: 0.4527 - precision_tumor: 0.5692 - recall_tumor: 0.6411 - tumor_iou: 0.4233\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51534\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5643 - loss: 0.2847 - mean_iou_all: 0.4526 - precision_tumor: 0.5692 - recall_tumor: 0.6411 - tumor_iou: 0.4233 - val_acc: 0.9883 - val_dice_coef_metric_tumor: 0.4413 - val_loss: 0.3744 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6717 - val_recall_tumor: 0.3677 - val_tumor_iou: 0.3157 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 145 lên WandB.\n\n--- Epoch 146/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5566 - loss: 0.2872 - mean_iou_all: 0.4650 - precision_tumor: 0.5664 - recall_tumor: 0.6263 - tumor_iou: 0.4176\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51534\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5565 - loss: 0.2872 - mean_iou_all: 0.4650 - precision_tumor: 0.5664 - recall_tumor: 0.6263 - tumor_iou: 0.4176 - val_acc: 0.9883 - val_dice_coef_metric_tumor: 0.5011 - val_loss: 0.3378 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6105 - val_recall_tumor: 0.4793 - val_tumor_iou: 0.3703 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 146 lên WandB.\n\n--- Epoch 147/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5559 - loss: 0.2869 - mean_iou_all: 0.4574 - precision_tumor: 0.5477 - recall_tumor: 0.6539 - tumor_iou: 0.4126\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51534\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5559 - loss: 0.2869 - mean_iou_all: 0.4573 - precision_tumor: 0.5477 - recall_tumor: 0.6538 - tumor_iou: 0.4125 - val_acc: 0.9858 - val_dice_coef_metric_tumor: 0.5093 - val_loss: 0.3340 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5191 - val_recall_tumor: 0.5628 - val_tumor_iou: 0.3735 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 147 lên WandB.\n\n--- Epoch 148/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9855 - dice_coef_metric_tumor: 0.5583 - loss: 0.2893 - mean_iou_all: 0.4405 - precision_tumor: 0.5543 - recall_tumor: 0.6397 - tumor_iou: 0.4137\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51534\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9855 - dice_coef_metric_tumor: 0.5583 - loss: 0.2893 - mean_iou_all: 0.4404 - precision_tumor: 0.5543 - recall_tumor: 0.6397 - tumor_iou: 0.4137 - val_acc: 0.9843 - val_dice_coef_metric_tumor: 0.5012 - val_loss: 0.3398 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5066 - val_recall_tumor: 0.5728 - val_tumor_iou: 0.3635 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 148 lên WandB.\n\n--- Epoch 149/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5448 - loss: 0.2951 - mean_iou_all: 0.4808 - precision_tumor: 0.5437 - recall_tumor: 0.6199 - tumor_iou: 0.4045\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51534\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5448 - loss: 0.2951 - mean_iou_all: 0.4807 - precision_tumor: 0.5437 - recall_tumor: 0.6199 - tumor_iou: 0.4045 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.4968 - val_loss: 0.3413 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5891 - val_recall_tumor: 0.4900 - val_tumor_iou: 0.3652 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 149 lên WandB.\n\n--- Epoch 150/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5693 - loss: 0.2810 - mean_iou_all: 0.4674 - precision_tumor: 0.5733 - recall_tumor: 0.6376 - tumor_iou: 0.4288\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51534\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5692 - loss: 0.2810 - mean_iou_all: 0.4673 - precision_tumor: 0.5733 - recall_tumor: 0.6375 - tumor_iou: 0.4287 - val_acc: 0.9873 - val_dice_coef_metric_tumor: 0.4783 - val_loss: 0.3522 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5946 - val_recall_tumor: 0.4626 - val_tumor_iou: 0.3442 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 150 lên WandB.\n\n--- Epoch 151/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5715 - loss: 0.2826 - mean_iou_all: 0.4761 - precision_tumor: 0.5726 - recall_tumor: 0.6463 - tumor_iou: 0.4293\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51534\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5715 - loss: 0.2826 - mean_iou_all: 0.4761 - precision_tumor: 0.5726 - recall_tumor: 0.6463 - tumor_iou: 0.4293 - val_acc: 0.9877 - val_dice_coef_metric_tumor: 0.4362 - val_loss: 0.3791 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6712 - val_recall_tumor: 0.3658 - val_tumor_iou: 0.3091 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 151 lên WandB.\n\n--- Epoch 152/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5679 - loss: 0.2794 - mean_iou_all: 0.4741 - precision_tumor: 0.5887 - recall_tumor: 0.6193 - tumor_iou: 0.4275\nEpoch 1: val_dice_coef_metric_tumor improved from 0.51534 to 0.52237, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5678 - loss: 0.2794 - mean_iou_all: 0.4740 - precision_tumor: 0.5886 - recall_tumor: 0.6193 - tumor_iou: 0.4274 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.5224 - val_loss: 0.3261 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5875 - val_recall_tumor: 0.5242 - val_tumor_iou: 0.3864 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 152 lên WandB.\n\n--- Epoch 153/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5657 - loss: 0.2798 - mean_iou_all: 0.4744 - precision_tumor: 0.5760 - recall_tumor: 0.6285 - tumor_iou: 0.4242\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52237\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5657 - loss: 0.2798 - mean_iou_all: 0.4743 - precision_tumor: 0.5760 - recall_tumor: 0.6285 - tumor_iou: 0.4242 - val_acc: 0.9867 - val_dice_coef_metric_tumor: 0.5184 - val_loss: 0.3290 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5341 - val_recall_tumor: 0.5678 - val_tumor_iou: 0.3823 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 153 lên WandB.\n\n--- Epoch 154/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5531 - loss: 0.2867 - mean_iou_all: 0.4681 - precision_tumor: 0.5563 - recall_tumor: 0.6241 - tumor_iou: 0.4111\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52237\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5531 - loss: 0.2867 - mean_iou_all: 0.4681 - precision_tumor: 0.5563 - recall_tumor: 0.6241 - tumor_iou: 0.4111 - val_acc: 0.9790 - val_dice_coef_metric_tumor: 0.4608 - val_loss: 0.3663 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4662 - val_recall_tumor: 0.5842 - val_tumor_iou: 0.3304 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 154 lên WandB.\n\n--- Epoch 155/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5573 - loss: 0.2837 - mean_iou_all: 0.4638 - precision_tumor: 0.5618 - recall_tumor: 0.6359 - tumor_iou: 0.4161\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52237\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5573 - loss: 0.2837 - mean_iou_all: 0.4637 - precision_tumor: 0.5618 - recall_tumor: 0.6359 - tumor_iou: 0.4161 - val_acc: 0.9875 - val_dice_coef_metric_tumor: 0.5067 - val_loss: 0.3352 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5719 - val_recall_tumor: 0.5066 - val_tumor_iou: 0.3742 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 155 lên WandB.\n\n--- Epoch 156/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5724 - loss: 0.2747 - mean_iou_all: 0.4705 - precision_tumor: 0.5853 - recall_tumor: 0.6304 - tumor_iou: 0.4335\nEpoch 1: val_dice_coef_metric_tumor improved from 0.52237 to 0.52288, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5724 - loss: 0.2747 - mean_iou_all: 0.4705 - precision_tumor: 0.5853 - recall_tumor: 0.6304 - tumor_iou: 0.4334 - val_acc: 0.9866 - val_dice_coef_metric_tumor: 0.5229 - val_loss: 0.3266 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5375 - val_recall_tumor: 0.5675 - val_tumor_iou: 0.3890 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 156 lên WandB.\n\n--- Epoch 157/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5495 - loss: 0.2926 - mean_iou_all: 0.4498 - precision_tumor: 0.5581 - recall_tumor: 0.6205 - tumor_iou: 0.4090\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5495 - loss: 0.2926 - mean_iou_all: 0.4496 - precision_tumor: 0.5581 - recall_tumor: 0.6205 - tumor_iou: 0.4090 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.4399 - val_loss: 0.3763 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5747 - val_recall_tumor: 0.3974 - val_tumor_iou: 0.3230 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 157 lên WandB.\n\n--- Epoch 158/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5694 - loss: 0.2803 - mean_iou_all: 0.4681 - precision_tumor: 0.5701 - recall_tumor: 0.6375 - tumor_iou: 0.4292\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5694 - loss: 0.2802 - mean_iou_all: 0.4680 - precision_tumor: 0.5702 - recall_tumor: 0.6375 - tumor_iou: 0.4292 - val_acc: 0.9883 - val_dice_coef_metric_tumor: 0.4914 - val_loss: 0.3451 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6384 - val_recall_tumor: 0.4494 - val_tumor_iou: 0.3654 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 158 lên WandB.\n\n--- Epoch 159/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5695 - loss: 0.2807 - mean_iou_all: 0.4675 - precision_tumor: 0.5760 - recall_tumor: 0.6237 - tumor_iou: 0.4271\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5694 - loss: 0.2807 - mean_iou_all: 0.4674 - precision_tumor: 0.5760 - recall_tumor: 0.6237 - tumor_iou: 0.4270 - val_acc: 0.9860 - val_dice_coef_metric_tumor: 0.5069 - val_loss: 0.3360 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5278 - val_recall_tumor: 0.5686 - val_tumor_iou: 0.3767 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 159 lên WandB.\n\n--- Epoch 160/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9857 - dice_coef_metric_tumor: 0.5632 - loss: 0.2851 - mean_iou_all: 0.4763 - precision_tumor: 0.5569 - recall_tumor: 0.6437 - tumor_iou: 0.4224\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9857 - dice_coef_metric_tumor: 0.5631 - loss: 0.2851 - mean_iou_all: 0.4762 - precision_tumor: 0.5568 - recall_tumor: 0.6436 - tumor_iou: 0.4223 - val_acc: 0.9875 - val_dice_coef_metric_tumor: 0.4821 - val_loss: 0.3512 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5659 - val_recall_tumor: 0.4790 - val_tumor_iou: 0.3524 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 160 lên WandB.\n\n--- Epoch 161/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5613 - loss: 0.2855 - mean_iou_all: 0.4634 - precision_tumor: 0.5582 - recall_tumor: 0.6373 - tumor_iou: 0.4219\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5612 - loss: 0.2855 - mean_iou_all: 0.4634 - precision_tumor: 0.5582 - recall_tumor: 0.6372 - tumor_iou: 0.4218 - val_acc: 0.9880 - val_dice_coef_metric_tumor: 0.3883 - val_loss: 0.4079 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6814 - val_recall_tumor: 0.3126 - val_tumor_iou: 0.2756 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 161 lên WandB.\n\n--- Epoch 162/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5754 - loss: 0.2760 - mean_iou_all: 0.4483 - precision_tumor: 0.5878 - recall_tumor: 0.6402 - tumor_iou: 0.4351\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5754 - loss: 0.2760 - mean_iou_all: 0.4482 - precision_tumor: 0.5878 - recall_tumor: 0.6402 - tumor_iou: 0.4351 - val_acc: 0.9860 - val_dice_coef_metric_tumor: 0.5019 - val_loss: 0.3396 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4981 - val_recall_tumor: 0.5777 - val_tumor_iou: 0.3637 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 162 lên WandB.\n\n--- Epoch 163/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5624 - loss: 0.2803 - mean_iou_all: 0.4720 - precision_tumor: 0.5593 - recall_tumor: 0.6377 - tumor_iou: 0.4194\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5624 - loss: 0.2803 - mean_iou_all: 0.4719 - precision_tumor: 0.5593 - recall_tumor: 0.6377 - tumor_iou: 0.4194 - val_acc: 0.9872 - val_dice_coef_metric_tumor: 0.4969 - val_loss: 0.3421 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5492 - val_recall_tumor: 0.5049 - val_tumor_iou: 0.3608 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 163 lên WandB.\n\n--- Epoch 164/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5826 - loss: 0.2714 - mean_iou_all: 0.4371 - precision_tumor: 0.5818 - recall_tumor: 0.6529 - tumor_iou: 0.4380\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 466ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5826 - loss: 0.2714 - mean_iou_all: 0.4370 - precision_tumor: 0.5818 - recall_tumor: 0.6529 - tumor_iou: 0.4380 - val_acc: 0.9871 - val_dice_coef_metric_tumor: 0.5091 - val_loss: 0.3343 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5551 - val_recall_tumor: 0.5487 - val_tumor_iou: 0.3765 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 164 lên WandB.\n\n--- Epoch 165/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5784 - loss: 0.2731 - mean_iou_all: 0.4673 - precision_tumor: 0.5772 - recall_tumor: 0.6465 - tumor_iou: 0.4382\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 466ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5784 - loss: 0.2731 - mean_iou_all: 0.4672 - precision_tumor: 0.5772 - recall_tumor: 0.6465 - tumor_iou: 0.4381 - val_acc: 0.9868 - val_dice_coef_metric_tumor: 0.5106 - val_loss: 0.3342 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5669 - val_recall_tumor: 0.5337 - val_tumor_iou: 0.3753 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 165 lên WandB.\n\n--- Epoch 166/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5664 - loss: 0.2784 - mean_iou_all: 0.4735 - precision_tumor: 0.5634 - recall_tumor: 0.6465 - tumor_iou: 0.4284\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5664 - loss: 0.2784 - mean_iou_all: 0.4735 - precision_tumor: 0.5634 - recall_tumor: 0.6465 - tumor_iou: 0.4284 - val_acc: 0.9859 - val_dice_coef_metric_tumor: 0.5064 - val_loss: 0.3376 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5231 - val_recall_tumor: 0.5603 - val_tumor_iou: 0.3695 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 166 lên WandB.\n\n--- Epoch 167/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5791 - loss: 0.2802 - mean_iou_all: 0.4552 - precision_tumor: 0.5775 - recall_tumor: 0.6542 - tumor_iou: 0.4342\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5791 - loss: 0.2802 - mean_iou_all: 0.4551 - precision_tumor: 0.5776 - recall_tumor: 0.6542 - tumor_iou: 0.4342 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.4689 - val_loss: 0.3595 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6362 - val_recall_tumor: 0.4104 - val_tumor_iou: 0.3401 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 167 lên WandB.\n\n--- Epoch 168/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5688 - loss: 0.2766 - mean_iou_all: 0.4690 - precision_tumor: 0.5839 - recall_tumor: 0.6295 - tumor_iou: 0.4284\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5687 - loss: 0.2766 - mean_iou_all: 0.4690 - precision_tumor: 0.5839 - recall_tumor: 0.6295 - tumor_iou: 0.4283 - val_acc: 0.9848 - val_dice_coef_metric_tumor: 0.5062 - val_loss: 0.3376 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4879 - val_recall_tumor: 0.6140 - val_tumor_iou: 0.3760 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 168 lên WandB.\n\n--- Epoch 169/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5801 - loss: 0.2751 - mean_iou_all: 0.4538 - precision_tumor: 0.5834 - recall_tumor: 0.6539 - tumor_iou: 0.4382\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5801 - loss: 0.2751 - mean_iou_all: 0.4536 - precision_tumor: 0.5834 - recall_tumor: 0.6539 - tumor_iou: 0.4382 - val_acc: 0.9834 - val_dice_coef_metric_tumor: 0.5059 - val_loss: 0.3390 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4438 - val_recall_tumor: 0.6629 - val_tumor_iou: 0.3692 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 169 lên WandB.\n\n--- Epoch 170/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5886 - loss: 0.2725 - mean_iou_all: 0.4600 - precision_tumor: 0.5899 - recall_tumor: 0.6595 - tumor_iou: 0.4493\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5886 - loss: 0.2725 - mean_iou_all: 0.4599 - precision_tumor: 0.5898 - recall_tumor: 0.6594 - tumor_iou: 0.4493 - val_acc: 0.9840 - val_dice_coef_metric_tumor: 0.4675 - val_loss: 0.3619 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5062 - val_recall_tumor: 0.5265 - val_tumor_iou: 0.3351 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 170 lên WandB.\n\n--- Epoch 171/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.5835 - loss: 0.2717 - mean_iou_all: 0.4575 - precision_tumor: 0.6029 - recall_tumor: 0.6280 - tumor_iou: 0.4419\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.5835 - loss: 0.2717 - mean_iou_all: 0.4574 - precision_tumor: 0.6029 - recall_tumor: 0.6280 - tumor_iou: 0.4418 - val_acc: 0.9883 - val_dice_coef_metric_tumor: 0.4838 - val_loss: 0.3510 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6007 - val_recall_tumor: 0.4450 - val_tumor_iou: 0.3498 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 171 lên WandB.\n\n--- Epoch 172/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5767 - loss: 0.2751 - mean_iou_all: 0.4632 - precision_tumor: 0.5817 - recall_tumor: 0.6465 - tumor_iou: 0.4379\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5766 - loss: 0.2751 - mean_iou_all: 0.4631 - precision_tumor: 0.5817 - recall_tumor: 0.6465 - tumor_iou: 0.4379 - val_acc: 0.9873 - val_dice_coef_metric_tumor: 0.4699 - val_loss: 0.3601 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5766 - val_recall_tumor: 0.4651 - val_tumor_iou: 0.3402 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 172 lên WandB.\n\n--- Epoch 173/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5703 - loss: 0.2771 - mean_iou_all: 0.4611 - precision_tumor: 0.5841 - recall_tumor: 0.6359 - tumor_iou: 0.4322\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5702 - loss: 0.2771 - mean_iou_all: 0.4610 - precision_tumor: 0.5841 - recall_tumor: 0.6359 - tumor_iou: 0.4322 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.4847 - val_loss: 0.3510 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5400 - val_recall_tumor: 0.4858 - val_tumor_iou: 0.3535 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 173 lên WandB.\n\n--- Epoch 174/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5608 - loss: 0.2804 - mean_iou_all: 0.4688 - precision_tumor: 0.5690 - recall_tumor: 0.6202 - tumor_iou: 0.4235\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52288\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5607 - loss: 0.2804 - mean_iou_all: 0.4687 - precision_tumor: 0.5690 - recall_tumor: 0.6202 - tumor_iou: 0.4235 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.5208 - val_loss: 0.3288 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5793 - val_recall_tumor: 0.5320 - val_tumor_iou: 0.3902 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 174 lên WandB.\n\n--- Epoch 175/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5800 - loss: 0.2733 - mean_iou_all: 0.4753 - precision_tumor: 0.5837 - recall_tumor: 0.6480 - tumor_iou: 0.4381\nEpoch 1: val_dice_coef_metric_tumor improved from 0.52288 to 0.52589, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5799 - loss: 0.2733 - mean_iou_all: 0.4753 - precision_tumor: 0.5837 - recall_tumor: 0.6480 - tumor_iou: 0.4381 - val_acc: 0.9883 - val_dice_coef_metric_tumor: 0.5259 - val_loss: 0.3257 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5688 - val_recall_tumor: 0.5430 - val_tumor_iou: 0.3962 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 175 lên WandB.\n\n--- Epoch 176/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5758 - loss: 0.2758 - mean_iou_all: 0.4703 - precision_tumor: 0.5821 - recall_tumor: 0.6440 - tumor_iou: 0.4339\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52589\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5757 - loss: 0.2757 - mean_iou_all: 0.4702 - precision_tumor: 0.5821 - recall_tumor: 0.6440 - tumor_iou: 0.4339 - val_acc: 0.9883 - val_dice_coef_metric_tumor: 0.5037 - val_loss: 0.3397 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6105 - val_recall_tumor: 0.4815 - val_tumor_iou: 0.3721 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 176 lên WandB.\n\n--- Epoch 177/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.5999 - loss: 0.2652 - mean_iou_all: 0.4621 - precision_tumor: 0.6151 - recall_tumor: 0.6469 - tumor_iou: 0.4558\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52589\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.5999 - loss: 0.2652 - mean_iou_all: 0.4621 - precision_tumor: 0.6151 - recall_tumor: 0.6468 - tumor_iou: 0.4558 - val_acc: 0.9887 - val_dice_coef_metric_tumor: 0.4734 - val_loss: 0.3589 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6794 - val_recall_tumor: 0.4059 - val_tumor_iou: 0.3423 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 177 lên WandB.\n\n--- Epoch 178/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.5944 - loss: 0.2660 - mean_iou_all: 0.4784 - precision_tumor: 0.6140 - recall_tumor: 0.6370 - tumor_iou: 0.4527\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52589\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.5943 - loss: 0.2660 - mean_iou_all: 0.4784 - precision_tumor: 0.6140 - recall_tumor: 0.6370 - tumor_iou: 0.4526 - val_acc: 0.9844 - val_dice_coef_metric_tumor: 0.5187 - val_loss: 0.3317 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4949 - val_recall_tumor: 0.6252 - val_tumor_iou: 0.3836 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 178 lên WandB.\n\n--- Epoch 179/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9874 - dice_coef_metric_tumor: 0.5995 - loss: 0.2646 - mean_iou_all: 0.4634 - precision_tumor: 0.5989 - recall_tumor: 0.6703 - tumor_iou: 0.4544\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52589\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9874 - dice_coef_metric_tumor: 0.5994 - loss: 0.2647 - mean_iou_all: 0.4632 - precision_tumor: 0.5988 - recall_tumor: 0.6703 - tumor_iou: 0.4543 - val_acc: 0.9871 - val_dice_coef_metric_tumor: 0.4698 - val_loss: 0.3613 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6214 - val_recall_tumor: 0.4379 - val_tumor_iou: 0.3412 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 179 lên WandB.\n\n--- Epoch 180/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5840 - loss: 0.2744 - mean_iou_all: 0.4353 - precision_tumor: 0.5917 - recall_tumor: 0.6585 - tumor_iou: 0.4409\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52589\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5840 - loss: 0.2744 - mean_iou_all: 0.4352 - precision_tumor: 0.5916 - recall_tumor: 0.6585 - tumor_iou: 0.4409 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.4762 - val_loss: 0.3567 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6181 - val_recall_tumor: 0.4365 - val_tumor_iou: 0.3498 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 180 lên WandB.\n\n--- Epoch 181/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9874 - dice_coef_metric_tumor: 0.5966 - loss: 0.2658 - mean_iou_all: 0.4609 - precision_tumor: 0.5969 - recall_tumor: 0.6564 - tumor_iou: 0.4560\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.52589\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9874 - dice_coef_metric_tumor: 0.5965 - loss: 0.2658 - mean_iou_all: 0.4608 - precision_tumor: 0.5969 - recall_tumor: 0.6564 - tumor_iou: 0.4559 - val_acc: 0.9823 - val_dice_coef_metric_tumor: 0.4935 - val_loss: 0.3482 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4278 - val_recall_tumor: 0.6645 - val_tumor_iou: 0.3590 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 181 lên WandB.\n\n--- Epoch 182/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.5965 - loss: 0.2720 - mean_iou_all: 0.4705 - precision_tumor: 0.6072 - recall_tumor: 0.6479 - tumor_iou: 0.4519\nEpoch 1: val_dice_coef_metric_tumor improved from 0.52589 to 0.53897, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.5965 - loss: 0.2720 - mean_iou_all: 0.4704 - precision_tumor: 0.6072 - recall_tumor: 0.6479 - tumor_iou: 0.4519 - val_acc: 0.9874 - val_dice_coef_metric_tumor: 0.5390 - val_loss: 0.3186 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5434 - val_recall_tumor: 0.5853 - val_tumor_iou: 0.4048 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 182 lên WandB.\n\n--- Epoch 183/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5877 - loss: 0.2738 - mean_iou_all: 0.4569 - precision_tumor: 0.5902 - recall_tumor: 0.6528 - tumor_iou: 0.4463\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53897\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5877 - loss: 0.2738 - mean_iou_all: 0.4568 - precision_tumor: 0.5902 - recall_tumor: 0.6528 - tumor_iou: 0.4463 - val_acc: 0.9879 - val_dice_coef_metric_tumor: 0.5334 - val_loss: 0.3224 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5847 - val_recall_tumor: 0.5506 - val_tumor_iou: 0.3995 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 183 lên WandB.\n\n--- Epoch 184/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5899 - loss: 0.2711 - mean_iou_all: 0.4504 - precision_tumor: 0.6023 - recall_tumor: 0.6596 - tumor_iou: 0.4506\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53897\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5898 - loss: 0.2711 - mean_iou_all: 0.4503 - precision_tumor: 0.6023 - recall_tumor: 0.6595 - tumor_iou: 0.4505 - val_acc: 0.9867 - val_dice_coef_metric_tumor: 0.5292 - val_loss: 0.3248 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5854 - val_recall_tumor: 0.5501 - val_tumor_iou: 0.3966 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 184 lên WandB.\n\n--- Epoch 185/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.5945 - loss: 0.2711 - mean_iou_all: 0.4585 - precision_tumor: 0.5955 - recall_tumor: 0.6494 - tumor_iou: 0.4525\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53897\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.5944 - loss: 0.2711 - mean_iou_all: 0.4584 - precision_tumor: 0.5955 - recall_tumor: 0.6493 - tumor_iou: 0.4524 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.5284 - val_loss: 0.3250 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5237 - val_recall_tumor: 0.5824 - val_tumor_iou: 0.3919 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 185 lên WandB.\n\n--- Epoch 186/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.5939 - loss: 0.2648 - mean_iou_all: 0.4639 - precision_tumor: 0.5894 - recall_tumor: 0.6706 - tumor_iou: 0.4497\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53897\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.5938 - loss: 0.2648 - mean_iou_all: 0.4638 - precision_tumor: 0.5893 - recall_tumor: 0.6706 - tumor_iou: 0.4496 - val_acc: 0.9865 - val_dice_coef_metric_tumor: 0.5027 - val_loss: 0.3417 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5449 - val_recall_tumor: 0.5274 - val_tumor_iou: 0.3652 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 186 lên WandB.\n\n--- Epoch 187/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5909 - loss: 0.2726 - mean_iou_all: 0.4681 - precision_tumor: 0.5910 - recall_tumor: 0.6606 - tumor_iou: 0.4485\nEpoch 1: val_dice_coef_metric_tumor improved from 0.53897 to 0.54063, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5909 - loss: 0.2726 - mean_iou_all: 0.4680 - precision_tumor: 0.5910 - recall_tumor: 0.6605 - tumor_iou: 0.4485 - val_acc: 0.9873 - val_dice_coef_metric_tumor: 0.5406 - val_loss: 0.3183 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5403 - val_recall_tumor: 0.6074 - val_tumor_iou: 0.4022 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 187 lên WandB.\n\n--- Epoch 188/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5798 - loss: 0.2792 - mean_iou_all: 0.4573 - precision_tumor: 0.5667 - recall_tumor: 0.6798 - tumor_iou: 0.4375\nEpoch 1: val_dice_coef_metric_tumor improved from 0.54063 to 0.55826, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 469ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5798 - loss: 0.2791 - mean_iou_all: 0.4571 - precision_tumor: 0.5668 - recall_tumor: 0.6797 - tumor_iou: 0.4375 - val_acc: 0.9890 - val_dice_coef_metric_tumor: 0.5583 - val_loss: 0.3071 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6185 - val_recall_tumor: 0.5587 - val_tumor_iou: 0.4236 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 188 lên WandB.\n\n--- Epoch 189/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.5973 - loss: 0.2639 - mean_iou_all: 0.4550 - precision_tumor: 0.6007 - recall_tumor: 0.6673 - tumor_iou: 0.4545\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.5972 - loss: 0.2639 - mean_iou_all: 0.4549 - precision_tumor: 0.6006 - recall_tumor: 0.6673 - tumor_iou: 0.4544 - val_acc: 0.9882 - val_dice_coef_metric_tumor: 0.5319 - val_loss: 0.3231 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5814 - val_recall_tumor: 0.5530 - val_tumor_iou: 0.4021 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 189 lên WandB.\n\n--- Epoch 190/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.6104 - loss: 0.2624 - mean_iou_all: 0.4789 - precision_tumor: 0.6114 - recall_tumor: 0.6717 - tumor_iou: 0.4653\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.6103 - loss: 0.2623 - mean_iou_all: 0.4789 - precision_tumor: 0.6114 - recall_tumor: 0.6717 - tumor_iou: 0.4653 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.5263 - val_loss: 0.3268 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6475 - val_recall_tumor: 0.5081 - val_tumor_iou: 0.3989 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 190 lên WandB.\n\n--- Epoch 191/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.5879 - loss: 0.2701 - mean_iou_all: 0.4611 - precision_tumor: 0.6086 - recall_tumor: 0.6406 - tumor_iou: 0.4497\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.5879 - loss: 0.2701 - mean_iou_all: 0.4610 - precision_tumor: 0.6086 - recall_tumor: 0.6406 - tumor_iou: 0.4497 - val_acc: 0.9868 - val_dice_coef_metric_tumor: 0.5148 - val_loss: 0.3346 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5856 - val_recall_tumor: 0.5205 - val_tumor_iou: 0.3820 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 191 lên WandB.\n\n--- Epoch 192/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5940 - loss: 0.2706 - mean_iou_all: 0.4513 - precision_tumor: 0.5960 - recall_tumor: 0.6608 - tumor_iou: 0.4497\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.5940 - loss: 0.2706 - mean_iou_all: 0.4513 - precision_tumor: 0.5960 - recall_tumor: 0.6608 - tumor_iou: 0.4497 - val_acc: 0.9881 - val_dice_coef_metric_tumor: 0.5258 - val_loss: 0.3269 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6071 - val_recall_tumor: 0.5303 - val_tumor_iou: 0.3952 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 192 lên WandB.\n\n--- Epoch 193/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.5885 - loss: 0.2694 - mean_iou_all: 0.4754 - precision_tumor: 0.5950 - recall_tumor: 0.6518 - tumor_iou: 0.4502\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.5885 - loss: 0.2694 - mean_iou_all: 0.4753 - precision_tumor: 0.5950 - recall_tumor: 0.6518 - tumor_iou: 0.4502 - val_acc: 0.9860 - val_dice_coef_metric_tumor: 0.5183 - val_loss: 0.3326 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5287 - val_recall_tumor: 0.5781 - val_tumor_iou: 0.3832 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 193 lên WandB.\n\n--- Epoch 194/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9873 - dice_coef_metric_tumor: 0.5985 - loss: 0.2636 - mean_iou_all: 0.4675 - precision_tumor: 0.6015 - recall_tumor: 0.6684 - tumor_iou: 0.4541\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9873 - dice_coef_metric_tumor: 0.5985 - loss: 0.2636 - mean_iou_all: 0.4674 - precision_tumor: 0.6015 - recall_tumor: 0.6684 - tumor_iou: 0.4541 - val_acc: 0.9863 - val_dice_coef_metric_tumor: 0.5073 - val_loss: 0.3394 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5681 - val_recall_tumor: 0.5269 - val_tumor_iou: 0.3766 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 194 lên WandB.\n\n--- Epoch 195/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9874 - dice_coef_metric_tumor: 0.5967 - loss: 0.2677 - mean_iou_all: 0.4595 - precision_tumor: 0.5968 - recall_tumor: 0.6666 - tumor_iou: 0.4538\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9874 - dice_coef_metric_tumor: 0.5967 - loss: 0.2677 - mean_iou_all: 0.4594 - precision_tumor: 0.5968 - recall_tumor: 0.6666 - tumor_iou: 0.4538 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.5205 - val_loss: 0.3308 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6734 - val_recall_tumor: 0.4758 - val_tumor_iou: 0.3933 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 195 lên WandB.\n\n--- Epoch 196/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6066 - loss: 0.2573 - mean_iou_all: 0.4685 - precision_tumor: 0.6192 - recall_tumor: 0.6606 - tumor_iou: 0.4677\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6065 - loss: 0.2573 - mean_iou_all: 0.4683 - precision_tumor: 0.6192 - recall_tumor: 0.6606 - tumor_iou: 0.4676 - val_acc: 0.9873 - val_dice_coef_metric_tumor: 0.5485 - val_loss: 0.3141 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5384 - val_recall_tumor: 0.6264 - val_tumor_iou: 0.4127 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 196 lên WandB.\n\n--- Epoch 197/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6184 - loss: 0.2559 - mean_iou_all: 0.4335 - precision_tumor: 0.6211 - recall_tumor: 0.6721 - tumor_iou: 0.4756\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 463ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6184 - loss: 0.2559 - mean_iou_all: 0.4334 - precision_tumor: 0.6211 - recall_tumor: 0.6721 - tumor_iou: 0.4756 - val_acc: 0.9879 - val_dice_coef_metric_tumor: 0.4254 - val_loss: 0.3888 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6531 - val_recall_tumor: 0.3630 - val_tumor_iou: 0.3029 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 197 lên WandB.\n\n--- Epoch 198/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.5964 - loss: 0.2645 - mean_iou_all: 0.4759 - precision_tumor: 0.6138 - recall_tumor: 0.6454 - tumor_iou: 0.4553\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.5964 - loss: 0.2645 - mean_iou_all: 0.4758 - precision_tumor: 0.6138 - recall_tumor: 0.6454 - tumor_iou: 0.4553 - val_acc: 0.9872 - val_dice_coef_metric_tumor: 0.5340 - val_loss: 0.3230 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5414 - val_recall_tumor: 0.5926 - val_tumor_iou: 0.3988 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 198 lên WandB.\n\n--- Epoch 199/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5945 - loss: 0.2696 - mean_iou_all: 0.4636 - precision_tumor: 0.5950 - recall_tumor: 0.6692 - tumor_iou: 0.4510\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 466ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.5945 - loss: 0.2696 - mean_iou_all: 0.4635 - precision_tumor: 0.5950 - recall_tumor: 0.6692 - tumor_iou: 0.4510 - val_acc: 0.9857 - val_dice_coef_metric_tumor: 0.5054 - val_loss: 0.3410 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5435 - val_recall_tumor: 0.5446 - val_tumor_iou: 0.3784 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 199 lên WandB.\n\n--- Epoch 200/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6024 - loss: 0.2626 - mean_iou_all: 0.4786 - precision_tumor: 0.6161 - recall_tumor: 0.6586 - tumor_iou: 0.4610\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6024 - loss: 0.2625 - mean_iou_all: 0.4786 - precision_tumor: 0.6161 - recall_tumor: 0.6586 - tumor_iou: 0.4610 - val_acc: 0.9881 - val_dice_coef_metric_tumor: 0.5265 - val_loss: 0.3279 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6027 - val_recall_tumor: 0.5204 - val_tumor_iou: 0.3908 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 200 lên WandB.\n\n--- Epoch 201/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.5996 - loss: 0.2612 - mean_iou_all: 0.4664 - precision_tumor: 0.6161 - recall_tumor: 0.6450 - tumor_iou: 0.4567\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.5996 - loss: 0.2611 - mean_iou_all: 0.4663 - precision_tumor: 0.6161 - recall_tumor: 0.6450 - tumor_iou: 0.4567 - val_acc: 0.9879 - val_dice_coef_metric_tumor: 0.5319 - val_loss: 0.3242 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5626 - val_recall_tumor: 0.5572 - val_tumor_iou: 0.3994 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 201 lên WandB.\n\n--- Epoch 202/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6063 - loss: 0.2574 - mean_iou_all: 0.4765 - precision_tumor: 0.6146 - recall_tumor: 0.6600 - tumor_iou: 0.4681\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6063 - loss: 0.2574 - mean_iou_all: 0.4764 - precision_tumor: 0.6145 - recall_tumor: 0.6600 - tumor_iou: 0.4681 - val_acc: 0.9861 - val_dice_coef_metric_tumor: 0.5514 - val_loss: 0.3135 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5404 - val_recall_tumor: 0.6307 - val_tumor_iou: 0.4158 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 202 lên WandB.\n\n--- Epoch 203/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.5982 - loss: 0.2617 - mean_iou_all: 0.4332 - precision_tumor: 0.6047 - recall_tumor: 0.6531 - tumor_iou: 0.4564\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.5982 - loss: 0.2617 - mean_iou_all: 0.4330 - precision_tumor: 0.6047 - recall_tumor: 0.6531 - tumor_iou: 0.4564 - val_acc: 0.9880 - val_dice_coef_metric_tumor: 0.5434 - val_loss: 0.3180 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5690 - val_recall_tumor: 0.5768 - val_tumor_iou: 0.4078 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 203 lên WandB.\n\n--- Epoch 204/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.6057 - loss: 0.2640 - mean_iou_all: 0.4387 - precision_tumor: 0.6093 - recall_tumor: 0.6699 - tumor_iou: 0.4633\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.6057 - loss: 0.2640 - mean_iou_all: 0.4385 - precision_tumor: 0.6094 - recall_tumor: 0.6699 - tumor_iou: 0.4633 - val_acc: 0.9881 - val_dice_coef_metric_tumor: 0.4773 - val_loss: 0.3572 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6470 - val_recall_tumor: 0.4298 - val_tumor_iou: 0.3424 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 204 lên WandB.\n\n--- Epoch 205/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5969 - loss: 0.2697 - mean_iou_all: 0.4421 - precision_tumor: 0.5969 - recall_tumor: 0.6593 - tumor_iou: 0.4560\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55826\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.5968 - loss: 0.2697 - mean_iou_all: 0.4419 - precision_tumor: 0.5969 - recall_tumor: 0.6593 - tumor_iou: 0.4560 - val_acc: 0.9845 - val_dice_coef_metric_tumor: 0.5176 - val_loss: 0.3345 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4545 - val_recall_tumor: 0.6928 - val_tumor_iou: 0.3806 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 205 lên WandB.\n\n--- Epoch 206/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.6047 - loss: 0.2650 - mean_iou_all: 0.4273 - precision_tumor: 0.6107 - recall_tumor: 0.6537 - tumor_iou: 0.4651\nEpoch 1: val_dice_coef_metric_tumor improved from 0.55826 to 0.56306, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.6047 - loss: 0.2649 - mean_iou_all: 0.4271 - precision_tumor: 0.6108 - recall_tumor: 0.6537 - tumor_iou: 0.4651 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.5631 - val_loss: 0.3058 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5749 - val_recall_tumor: 0.6091 - val_tumor_iou: 0.4304 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 206 lên WandB.\n\n--- Epoch 207/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.5999 - loss: 0.2659 - mean_iou_all: 0.4410 - precision_tumor: 0.6043 - recall_tumor: 0.6578 - tumor_iou: 0.4589\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56306\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.5998 - loss: 0.2659 - mean_iou_all: 0.4408 - precision_tumor: 0.6043 - recall_tumor: 0.6578 - tumor_iou: 0.4589 - val_acc: 0.9874 - val_dice_coef_metric_tumor: 0.5469 - val_loss: 0.3162 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5548 - val_recall_tumor: 0.6088 - val_tumor_iou: 0.4123 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 207 lên WandB.\n\n--- Epoch 208/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6162 - loss: 0.2598 - mean_iou_all: 0.4409 - precision_tumor: 0.6307 - recall_tumor: 0.6628 - tumor_iou: 0.4742\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56306\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6161 - loss: 0.2598 - mean_iou_all: 0.4408 - precision_tumor: 0.6307 - recall_tumor: 0.6628 - tumor_iou: 0.4742 - val_acc: 0.9869 - val_dice_coef_metric_tumor: 0.5178 - val_loss: 0.3339 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5748 - val_recall_tumor: 0.5399 - val_tumor_iou: 0.3854 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 208 lên WandB.\n\n--- Epoch 209/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.6141 - loss: 0.2592 - mean_iou_all: 0.4584 - precision_tumor: 0.6197 - recall_tumor: 0.6726 - tumor_iou: 0.4731\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56306\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.6141 - loss: 0.2592 - mean_iou_all: 0.4584 - precision_tumor: 0.6197 - recall_tumor: 0.6726 - tumor_iou: 0.4730 - val_acc: 0.9887 - val_dice_coef_metric_tumor: 0.5486 - val_loss: 0.3145 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6186 - val_recall_tumor: 0.5496 - val_tumor_iou: 0.4143 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 209 lên WandB.\n\n--- Epoch 210/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6155 - loss: 0.2573 - mean_iou_all: 0.4785 - precision_tumor: 0.6192 - recall_tumor: 0.6694 - tumor_iou: 0.4788\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56306\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6154 - loss: 0.2573 - mean_iou_all: 0.4784 - precision_tumor: 0.6192 - recall_tumor: 0.6694 - tumor_iou: 0.4788 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.4799 - val_loss: 0.3571 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7479 - val_recall_tumor: 0.3906 - val_tumor_iou: 0.3490 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 210 lên WandB.\n\n--- Epoch 211/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6342 - loss: 0.2445 - mean_iou_all: 0.4605 - precision_tumor: 0.6480 - recall_tumor: 0.6780 - tumor_iou: 0.4917\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56306\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6342 - loss: 0.2445 - mean_iou_all: 0.4604 - precision_tumor: 0.6479 - recall_tumor: 0.6779 - tumor_iou: 0.4917 - val_acc: 0.9863 - val_dice_coef_metric_tumor: 0.5421 - val_loss: 0.3191 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5490 - val_recall_tumor: 0.6149 - val_tumor_iou: 0.4069 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 211 lên WandB.\n\n--- Epoch 212/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6055 - loss: 0.2651 - mean_iou_all: 0.4688 - precision_tumor: 0.6181 - recall_tumor: 0.6530 - tumor_iou: 0.4646\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56306\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6055 - loss: 0.2651 - mean_iou_all: 0.4688 - precision_tumor: 0.6181 - recall_tumor: 0.6530 - tumor_iou: 0.4646 - val_acc: 0.9842 - val_dice_coef_metric_tumor: 0.5143 - val_loss: 0.3378 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5292 - val_recall_tumor: 0.5840 - val_tumor_iou: 0.3831 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 212 lên WandB.\n\n--- Epoch 213/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6132 - loss: 0.2577 - mean_iou_all: 0.4612 - precision_tumor: 0.6255 - recall_tumor: 0.6586 - tumor_iou: 0.4722\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56306\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6132 - loss: 0.2577 - mean_iou_all: 0.4611 - precision_tumor: 0.6255 - recall_tumor: 0.6586 - tumor_iou: 0.4722 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.5573 - val_loss: 0.3094 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6265 - val_recall_tumor: 0.5640 - val_tumor_iou: 0.4227 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 213 lên WandB.\n\n--- Epoch 214/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6187 - loss: 0.2614 - mean_iou_all: 0.4664 - precision_tumor: 0.6318 - recall_tumor: 0.6616 - tumor_iou: 0.4780\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56306\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6187 - loss: 0.2614 - mean_iou_all: 0.4663 - precision_tumor: 0.6318 - recall_tumor: 0.6616 - tumor_iou: 0.4780 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.5322 - val_loss: 0.3256 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5962 - val_recall_tumor: 0.5349 - val_tumor_iou: 0.3944 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 214 lên WandB.\n\n--- Epoch 215/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6133 - loss: 0.2556 - mean_iou_all: 0.4654 - precision_tumor: 0.6099 - recall_tumor: 0.6766 - tumor_iou: 0.4733\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56306\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6133 - loss: 0.2556 - mean_iou_all: 0.4654 - precision_tumor: 0.6099 - recall_tumor: 0.6766 - tumor_iou: 0.4733 - val_acc: 0.9894 - val_dice_coef_metric_tumor: 0.5468 - val_loss: 0.3159 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6355 - val_recall_tumor: 0.5406 - val_tumor_iou: 0.4191 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 215 lên WandB.\n\n--- Epoch 216/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6159 - loss: 0.2588 - mean_iou_all: 0.4636 - precision_tumor: 0.6289 - recall_tumor: 0.6624 - tumor_iou: 0.4743\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56306\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6159 - loss: 0.2587 - mean_iou_all: 0.4635 - precision_tumor: 0.6289 - recall_tumor: 0.6624 - tumor_iou: 0.4743 - val_acc: 0.9877 - val_dice_coef_metric_tumor: 0.5309 - val_loss: 0.3264 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5723 - val_recall_tumor: 0.5567 - val_tumor_iou: 0.3984 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 216 lên WandB.\n\n--- Epoch 217/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6083 - loss: 0.2535 - mean_iou_all: 0.4502 - precision_tumor: 0.6139 - recall_tumor: 0.6622 - tumor_iou: 0.4692\nEpoch 1: val_dice_coef_metric_tumor improved from 0.56306 to 0.56833, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 469ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6083 - loss: 0.2535 - mean_iou_all: 0.4501 - precision_tumor: 0.6139 - recall_tumor: 0.6622 - tumor_iou: 0.4692 - val_acc: 0.9880 - val_dice_coef_metric_tumor: 0.5683 - val_loss: 0.3033 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5780 - val_recall_tumor: 0.6210 - val_tumor_iou: 0.4311 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 217 lên WandB.\n\n--- Epoch 218/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6087 - loss: 0.2628 - mean_iou_all: 0.4770 - precision_tumor: 0.6122 - recall_tumor: 0.6629 - tumor_iou: 0.4679\nEpoch 1: val_dice_coef_metric_tumor improved from 0.56833 to 0.56912, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6087 - loss: 0.2628 - mean_iou_all: 0.4769 - precision_tumor: 0.6122 - recall_tumor: 0.6628 - tumor_iou: 0.4679 - val_acc: 0.9855 - val_dice_coef_metric_tumor: 0.5691 - val_loss: 0.3043 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5080 - val_recall_tumor: 0.7166 - val_tumor_iou: 0.4322 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 218 lên WandB.\n\n--- Epoch 219/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6196 - loss: 0.2568 - mean_iou_all: 0.4421 - precision_tumor: 0.6277 - recall_tumor: 0.6707 - tumor_iou: 0.4763\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6196 - loss: 0.2568 - mean_iou_all: 0.4419 - precision_tumor: 0.6277 - recall_tumor: 0.6707 - tumor_iou: 0.4762 - val_acc: 0.9833 - val_dice_coef_metric_tumor: 0.5321 - val_loss: 0.3273 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4865 - val_recall_tumor: 0.6790 - val_tumor_iou: 0.3986 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 219 lên WandB.\n\n--- Epoch 220/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6339 - loss: 0.2515 - mean_iou_all: 0.4557 - precision_tumor: 0.6454 - recall_tumor: 0.6780 - tumor_iou: 0.4913\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6339 - loss: 0.2515 - mean_iou_all: 0.4556 - precision_tumor: 0.6454 - recall_tumor: 0.6780 - tumor_iou: 0.4913 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5222 - val_loss: 0.3315 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6569 - val_recall_tumor: 0.5007 - val_tumor_iou: 0.3898 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 220 lên WandB.\n\n--- Epoch 221/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6228 - loss: 0.2580 - mean_iou_all: 0.4492 - precision_tumor: 0.6293 - recall_tumor: 0.6750 - tumor_iou: 0.4775\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6228 - loss: 0.2580 - mean_iou_all: 0.4490 - precision_tumor: 0.6293 - recall_tumor: 0.6750 - tumor_iou: 0.4775 - val_acc: 0.9894 - val_dice_coef_metric_tumor: 0.5216 - val_loss: 0.3323 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6676 - val_recall_tumor: 0.4760 - val_tumor_iou: 0.3918 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 221 lên WandB.\n\n--- Epoch 222/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6270 - loss: 0.2484 - mean_iou_all: 0.4578 - precision_tumor: 0.6385 - recall_tumor: 0.6762 - tumor_iou: 0.4887\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6270 - loss: 0.2484 - mean_iou_all: 0.4577 - precision_tumor: 0.6385 - recall_tumor: 0.6762 - tumor_iou: 0.4886 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.5204 - val_loss: 0.3324 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6338 - val_recall_tumor: 0.5084 - val_tumor_iou: 0.3976 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 222 lên WandB.\n\n--- Epoch 223/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6132 - loss: 0.2592 - mean_iou_all: 0.4638 - precision_tumor: 0.6209 - recall_tumor: 0.6750 - tumor_iou: 0.4729\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6132 - loss: 0.2592 - mean_iou_all: 0.4637 - precision_tumor: 0.6209 - recall_tumor: 0.6750 - tumor_iou: 0.4729 - val_acc: 0.9883 - val_dice_coef_metric_tumor: 0.4964 - val_loss: 0.3479 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6680 - val_recall_tumor: 0.4518 - val_tumor_iou: 0.3644 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 223 lên WandB.\n\n--- Epoch 224/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6210 - loss: 0.2516 - mean_iou_all: 0.4698 - precision_tumor: 0.6393 - recall_tumor: 0.6770 - tumor_iou: 0.4825\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 463ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6209 - loss: 0.2516 - mean_iou_all: 0.4697 - precision_tumor: 0.6392 - recall_tumor: 0.6770 - tumor_iou: 0.4825 - val_acc: 0.9880 - val_dice_coef_metric_tumor: 0.5614 - val_loss: 0.3080 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5959 - val_recall_tumor: 0.5903 - val_tumor_iou: 0.4270 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 224 lên WandB.\n\n--- Epoch 225/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6351 - loss: 0.2486 - mean_iou_all: 0.4628 - precision_tumor: 0.6452 - recall_tumor: 0.6838 - tumor_iou: 0.4963\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6351 - loss: 0.2485 - mean_iou_all: 0.4627 - precision_tumor: 0.6452 - recall_tumor: 0.6838 - tumor_iou: 0.4963 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5313 - val_loss: 0.3259 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6249 - val_recall_tumor: 0.5196 - val_tumor_iou: 0.4008 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 225 lên WandB.\n\n--- Epoch 226/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6190 - loss: 0.2558 - mean_iou_all: 0.4666 - precision_tumor: 0.6284 - recall_tumor: 0.6675 - tumor_iou: 0.4778\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6190 - loss: 0.2557 - mean_iou_all: 0.4665 - precision_tumor: 0.6284 - recall_tumor: 0.6675 - tumor_iou: 0.4778 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.5362 - val_loss: 0.3232 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6059 - val_recall_tumor: 0.5435 - val_tumor_iou: 0.4049 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 226 lên WandB.\n\n--- Epoch 227/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6308 - loss: 0.2518 - mean_iou_all: 0.4609 - precision_tumor: 0.6349 - recall_tumor: 0.6818 - tumor_iou: 0.4882\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6308 - loss: 0.2518 - mean_iou_all: 0.4608 - precision_tumor: 0.6349 - recall_tumor: 0.6819 - tumor_iou: 0.4882 - val_acc: 0.9852 - val_dice_coef_metric_tumor: 0.5143 - val_loss: 0.3377 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5395 - val_recall_tumor: 0.5631 - val_tumor_iou: 0.3858 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 227 lên WandB.\n\n--- Epoch 228/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6264 - loss: 0.2540 - mean_iou_all: 0.4877 - precision_tumor: 0.6394 - recall_tumor: 0.6824 - tumor_iou: 0.4845\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6264 - loss: 0.2540 - mean_iou_all: 0.4876 - precision_tumor: 0.6394 - recall_tumor: 0.6824 - tumor_iou: 0.4845 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5499 - val_loss: 0.3150 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6323 - val_recall_tumor: 0.5462 - val_tumor_iou: 0.4169 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 228 lên WandB.\n\n--- Epoch 229/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6420 - loss: 0.2444 - mean_iou_all: 0.4682 - precision_tumor: 0.6490 - recall_tumor: 0.6896 - tumor_iou: 0.5009\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6419 - loss: 0.2445 - mean_iou_all: 0.4681 - precision_tumor: 0.6489 - recall_tumor: 0.6896 - tumor_iou: 0.5008 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5468 - val_loss: 0.3173 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6051 - val_recall_tumor: 0.5525 - val_tumor_iou: 0.4129 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 229 lên WandB.\n\n--- Epoch 230/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.6203 - loss: 0.2570 - mean_iou_all: 0.4696 - precision_tumor: 0.6180 - recall_tumor: 0.6815 - tumor_iou: 0.4800\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.6202 - loss: 0.2570 - mean_iou_all: 0.4695 - precision_tumor: 0.6180 - recall_tumor: 0.6814 - tumor_iou: 0.4799 - val_acc: 0.9879 - val_dice_coef_metric_tumor: 0.5542 - val_loss: 0.3130 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5536 - val_recall_tumor: 0.6079 - val_tumor_iou: 0.4192 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 230 lên WandB.\n\n--- Epoch 231/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6472 - loss: 0.2464 - mean_iou_all: 0.4667 - precision_tumor: 0.6653 - recall_tumor: 0.6905 - tumor_iou: 0.5066\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6472 - loss: 0.2464 - mean_iou_all: 0.4665 - precision_tumor: 0.6652 - recall_tumor: 0.6905 - tumor_iou: 0.5065 - val_acc: 0.9890 - val_dice_coef_metric_tumor: 0.5017 - val_loss: 0.3447 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6946 - val_recall_tumor: 0.4397 - val_tumor_iou: 0.3684 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 231 lên WandB.\n\n--- Epoch 232/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6222 - loss: 0.2523 - mean_iou_all: 0.4623 - precision_tumor: 0.6405 - recall_tumor: 0.6574 - tumor_iou: 0.4796\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6222 - loss: 0.2523 - mean_iou_all: 0.4622 - precision_tumor: 0.6405 - recall_tumor: 0.6574 - tumor_iou: 0.4796 - val_acc: 0.9898 - val_dice_coef_metric_tumor: 0.5656 - val_loss: 0.3057 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6607 - val_recall_tumor: 0.5422 - val_tumor_iou: 0.4328 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 232 lên WandB.\n\n--- Epoch 233/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6488 - loss: 0.2401 - mean_iou_all: 0.4669 - precision_tumor: 0.6637 - recall_tumor: 0.6934 - tumor_iou: 0.5073\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 463ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6487 - loss: 0.2401 - mean_iou_all: 0.4668 - precision_tumor: 0.6637 - recall_tumor: 0.6934 - tumor_iou: 0.5072 - val_acc: 0.9877 - val_dice_coef_metric_tumor: 0.5646 - val_loss: 0.3068 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5535 - val_recall_tumor: 0.6335 - val_tumor_iou: 0.4264 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 233 lên WandB.\n\n--- Epoch 234/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6264 - loss: 0.2546 - mean_iou_all: 0.4559 - precision_tumor: 0.6351 - recall_tumor: 0.6800 - tumor_iou: 0.4873\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6264 - loss: 0.2546 - mean_iou_all: 0.4558 - precision_tumor: 0.6352 - recall_tumor: 0.6800 - tumor_iou: 0.4873 - val_acc: 0.9888 - val_dice_coef_metric_tumor: 0.5496 - val_loss: 0.3158 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6059 - val_recall_tumor: 0.5653 - val_tumor_iou: 0.4162 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 234 lên WandB.\n\n--- Epoch 235/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6131 - loss: 0.2608 - mean_iou_all: 0.4547 - precision_tumor: 0.6234 - recall_tumor: 0.6695 - tumor_iou: 0.4712\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6131 - loss: 0.2607 - mean_iou_all: 0.4545 - precision_tumor: 0.6234 - recall_tumor: 0.6695 - tumor_iou: 0.4712 - val_acc: 0.9894 - val_dice_coef_metric_tumor: 0.5556 - val_loss: 0.3124 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6509 - val_recall_tumor: 0.5235 - val_tumor_iou: 0.4254 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 235 lên WandB.\n\n--- Epoch 236/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6210 - loss: 0.2602 - mean_iou_all: 0.4816 - precision_tumor: 0.6341 - recall_tumor: 0.6702 - tumor_iou: 0.4801\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6210 - loss: 0.2601 - mean_iou_all: 0.4815 - precision_tumor: 0.6341 - recall_tumor: 0.6702 - tumor_iou: 0.4801 - val_acc: 0.9886 - val_dice_coef_metric_tumor: 0.5474 - val_loss: 0.3174 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5949 - val_recall_tumor: 0.5664 - val_tumor_iou: 0.4159 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 236 lên WandB.\n\n--- Epoch 237/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6211 - loss: 0.2553 - mean_iou_all: 0.4731 - precision_tumor: 0.6349 - recall_tumor: 0.6682 - tumor_iou: 0.4805\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6211 - loss: 0.2553 - mean_iou_all: 0.4730 - precision_tumor: 0.6349 - recall_tumor: 0.6682 - tumor_iou: 0.4805 - val_acc: 0.9898 - val_dice_coef_metric_tumor: 0.5239 - val_loss: 0.3318 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7126 - val_recall_tumor: 0.4625 - val_tumor_iou: 0.3954 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 237 lên WandB.\n\n--- Epoch 238/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6287 - loss: 0.2515 - mean_iou_all: 0.4783 - precision_tumor: 0.6467 - recall_tumor: 0.6623 - tumor_iou: 0.4923\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6286 - loss: 0.2515 - mean_iou_all: 0.4782 - precision_tumor: 0.6467 - recall_tumor: 0.6623 - tumor_iou: 0.4922 - val_acc: 0.9881 - val_dice_coef_metric_tumor: 0.5453 - val_loss: 0.3194 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6053 - val_recall_tumor: 0.5563 - val_tumor_iou: 0.4144 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 238 lên WandB.\n\n--- Epoch 239/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6220 - loss: 0.2504 - mean_iou_all: 0.4498 - precision_tumor: 0.6264 - recall_tumor: 0.6818 - tumor_iou: 0.4832\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6220 - loss: 0.2504 - mean_iou_all: 0.4497 - precision_tumor: 0.6264 - recall_tumor: 0.6817 - tumor_iou: 0.4832 - val_acc: 0.9896 - val_dice_coef_metric_tumor: 0.4991 - val_loss: 0.3468 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7012 - val_recall_tumor: 0.4380 - val_tumor_iou: 0.3749 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 239 lên WandB.\n\n--- Epoch 240/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6413 - loss: 0.2460 - mean_iou_all: 0.4742 - precision_tumor: 0.6513 - recall_tumor: 0.6864 - tumor_iou: 0.5018\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6413 - loss: 0.2460 - mean_iou_all: 0.4741 - precision_tumor: 0.6513 - recall_tumor: 0.6864 - tumor_iou: 0.5018 - val_acc: 0.9895 - val_dice_coef_metric_tumor: 0.5510 - val_loss: 0.3153 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6387 - val_recall_tumor: 0.5351 - val_tumor_iou: 0.4191 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 240 lên WandB.\n\n--- Epoch 241/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6271 - loss: 0.2505 - mean_iou_all: 0.4556 - precision_tumor: 0.6381 - recall_tumor: 0.6773 - tumor_iou: 0.4842\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6270 - loss: 0.2505 - mean_iou_all: 0.4555 - precision_tumor: 0.6381 - recall_tumor: 0.6773 - tumor_iou: 0.4842 - val_acc: 0.9841 - val_dice_coef_metric_tumor: 0.5054 - val_loss: 0.3450 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5066 - val_recall_tumor: 0.6053 - val_tumor_iou: 0.3767 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 241 lên WandB.\n\n--- Epoch 242/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6437 - loss: 0.2445 - mean_iou_all: 0.4573 - precision_tumor: 0.6615 - recall_tumor: 0.6787 - tumor_iou: 0.5037\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6437 - loss: 0.2445 - mean_iou_all: 0.4571 - precision_tumor: 0.6615 - recall_tumor: 0.6786 - tumor_iou: 0.5037 - val_acc: 0.9875 - val_dice_coef_metric_tumor: 0.5532 - val_loss: 0.3148 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5422 - val_recall_tumor: 0.6240 - val_tumor_iou: 0.4242 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 242 lên WandB.\n\n--- Epoch 243/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6478 - loss: 0.2392 - mean_iou_all: 0.4261 - precision_tumor: 0.6633 - recall_tumor: 0.6891 - tumor_iou: 0.5079\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 463ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6478 - loss: 0.2392 - mean_iou_all: 0.4259 - precision_tumor: 0.6633 - recall_tumor: 0.6891 - tumor_iou: 0.5079 - val_acc: 0.9896 - val_dice_coef_metric_tumor: 0.5332 - val_loss: 0.3265 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6835 - val_recall_tumor: 0.4868 - val_tumor_iou: 0.4075 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 243 lên WandB.\n\n--- Epoch 244/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6494 - loss: 0.2392 - mean_iou_all: 0.4475 - precision_tumor: 0.6595 - recall_tumor: 0.6957 - tumor_iou: 0.5087\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 463ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6494 - loss: 0.2392 - mean_iou_all: 0.4473 - precision_tumor: 0.6595 - recall_tumor: 0.6957 - tumor_iou: 0.5087 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5617 - val_loss: 0.3089 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5824 - val_recall_tumor: 0.5995 - val_tumor_iou: 0.4296 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 244 lên WandB.\n\n--- Epoch 245/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6427 - loss: 0.2450 - mean_iou_all: 0.4440 - precision_tumor: 0.6530 - recall_tumor: 0.6867 - tumor_iou: 0.5010\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6427 - loss: 0.2450 - mean_iou_all: 0.4439 - precision_tumor: 0.6530 - recall_tumor: 0.6866 - tumor_iou: 0.5010 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5096 - val_loss: 0.3417 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7020 - val_recall_tumor: 0.4457 - val_tumor_iou: 0.3743 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 245 lên WandB.\n\n--- Epoch 246/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6447 - loss: 0.2437 - mean_iou_all: 0.4390 - precision_tumor: 0.6433 - recall_tumor: 0.6977 - tumor_iou: 0.5058\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.56912\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6446 - loss: 0.2437 - mean_iou_all: 0.4388 - precision_tumor: 0.6433 - recall_tumor: 0.6977 - tumor_iou: 0.5058 - val_acc: 0.9899 - val_dice_coef_metric_tumor: 0.5444 - val_loss: 0.3195 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7074 - val_recall_tumor: 0.4929 - val_tumor_iou: 0.4115 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 246 lên WandB.\n\n--- Epoch 247/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6340 - loss: 0.2446 - mean_iou_all: 0.4361 - precision_tumor: 0.6428 - recall_tumor: 0.6832 - tumor_iou: 0.4954\nEpoch 1: val_dice_coef_metric_tumor improved from 0.56912 to 0.57072, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6340 - loss: 0.2446 - mean_iou_all: 0.4359 - precision_tumor: 0.6428 - recall_tumor: 0.6832 - tumor_iou: 0.4954 - val_acc: 0.9895 - val_dice_coef_metric_tumor: 0.5707 - val_loss: 0.3036 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6262 - val_recall_tumor: 0.5698 - val_tumor_iou: 0.4376 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 247 lên WandB.\n\n--- Epoch 248/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6297 - loss: 0.2532 - mean_iou_all: 0.4575 - precision_tumor: 0.6289 - recall_tumor: 0.6981 - tumor_iou: 0.4849\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57072\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6297 - loss: 0.2532 - mean_iou_all: 0.4574 - precision_tumor: 0.6289 - recall_tumor: 0.6981 - tumor_iou: 0.4848 - val_acc: 0.9875 - val_dice_coef_metric_tumor: 0.5586 - val_loss: 0.3117 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5570 - val_recall_tumor: 0.6176 - val_tumor_iou: 0.4228 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 248 lên WandB.\n\n--- Epoch 249/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6454 - loss: 0.2406 - mean_iou_all: 0.4754 - precision_tumor: 0.6590 - recall_tumor: 0.6876 - tumor_iou: 0.5054\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57072\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6454 - loss: 0.2406 - mean_iou_all: 0.4753 - precision_tumor: 0.6589 - recall_tumor: 0.6876 - tumor_iou: 0.5054 - val_acc: 0.9871 - val_dice_coef_metric_tumor: 0.5044 - val_loss: 0.3450 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6321 - val_recall_tumor: 0.4831 - val_tumor_iou: 0.3733 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 249 lên WandB.\n\n--- Epoch 250/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6301 - loss: 0.2489 - mean_iou_all: 0.4702 - precision_tumor: 0.6333 - recall_tumor: 0.6821 - tumor_iou: 0.4919\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57072\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6302 - loss: 0.2488 - mean_iou_all: 0.4701 - precision_tumor: 0.6334 - recall_tumor: 0.6822 - tumor_iou: 0.4919 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.5548 - val_loss: 0.3135 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6357 - val_recall_tumor: 0.5434 - val_tumor_iou: 0.4212 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 250 lên WandB.\n\n--- Epoch 251/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6254 - loss: 0.2556 - mean_iou_all: 0.4582 - precision_tumor: 0.6432 - recall_tumor: 0.6686 - tumor_iou: 0.4822\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57072\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6253 - loss: 0.2556 - mean_iou_all: 0.4581 - precision_tumor: 0.6432 - recall_tumor: 0.6686 - tumor_iou: 0.4821 - val_acc: 0.9887 - val_dice_coef_metric_tumor: 0.5706 - val_loss: 0.3041 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5807 - val_recall_tumor: 0.6218 - val_tumor_iou: 0.4390 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 251 lên WandB.\n\n--- Epoch 252/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9900 - dice_coef_metric_tumor: 0.6516 - loss: 0.2402 - mean_iou_all: 0.4560 - precision_tumor: 0.6651 - recall_tumor: 0.6888 - tumor_iou: 0.5100\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57072\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9900 - dice_coef_metric_tumor: 0.6516 - loss: 0.2401 - mean_iou_all: 0.4558 - precision_tumor: 0.6651 - recall_tumor: 0.6888 - tumor_iou: 0.5100 - val_acc: 0.9886 - val_dice_coef_metric_tumor: 0.5470 - val_loss: 0.3186 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6327 - val_recall_tumor: 0.5393 - val_tumor_iou: 0.4134 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 252 lên WandB.\n\n--- Epoch 253/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9899 - dice_coef_metric_tumor: 0.6426 - loss: 0.2390 - mean_iou_all: 0.4595 - precision_tumor: 0.6489 - recall_tumor: 0.6905 - tumor_iou: 0.5061\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57072\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9899 - dice_coef_metric_tumor: 0.6426 - loss: 0.2390 - mean_iou_all: 0.4594 - precision_tumor: 0.6489 - recall_tumor: 0.6905 - tumor_iou: 0.5060 - val_acc: 0.9895 - val_dice_coef_metric_tumor: 0.5487 - val_loss: 0.3177 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6538 - val_recall_tumor: 0.5266 - val_tumor_iou: 0.4188 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 253 lên WandB.\n\n--- Epoch 254/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.6592 - loss: 0.2350 - mean_iou_all: 0.4741 - precision_tumor: 0.6914 - recall_tumor: 0.6791 - tumor_iou: 0.5178\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57072\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.6591 - loss: 0.2350 - mean_iou_all: 0.4740 - precision_tumor: 0.6914 - recall_tumor: 0.6791 - tumor_iou: 0.5177 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.5565 - val_loss: 0.3129 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6246 - val_recall_tumor: 0.5582 - val_tumor_iou: 0.4246 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 254 lên WandB.\n\n--- Epoch 255/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6552 - loss: 0.2370 - mean_iou_all: 0.4675 - precision_tumor: 0.6661 - recall_tumor: 0.6973 - tumor_iou: 0.5188\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57072\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6551 - loss: 0.2370 - mean_iou_all: 0.4674 - precision_tumor: 0.6661 - recall_tumor: 0.6973 - tumor_iou: 0.5187 - val_acc: 0.9886 - val_dice_coef_metric_tumor: 0.5677 - val_loss: 0.3060 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5782 - val_recall_tumor: 0.6148 - val_tumor_iou: 0.4347 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 255 lên WandB.\n\n--- Epoch 256/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6268 - loss: 0.2527 - mean_iou_all: 0.4580 - precision_tumor: 0.6347 - recall_tumor: 0.6816 - tumor_iou: 0.4875\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57072\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6268 - loss: 0.2527 - mean_iou_all: 0.4579 - precision_tumor: 0.6347 - recall_tumor: 0.6816 - tumor_iou: 0.4875 - val_acc: 0.9880 - val_dice_coef_metric_tumor: 0.5689 - val_loss: 0.3058 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5953 - val_recall_tumor: 0.5948 - val_tumor_iou: 0.4323 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 256 lên WandB.\n\n--- Epoch 257/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6522 - loss: 0.2418 - mean_iou_all: 0.4717 - precision_tumor: 0.6667 - recall_tumor: 0.6936 - tumor_iou: 0.5070\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57072\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6522 - loss: 0.2418 - mean_iou_all: 0.4716 - precision_tumor: 0.6667 - recall_tumor: 0.6935 - tumor_iou: 0.5070 - val_acc: 0.9897 - val_dice_coef_metric_tumor: 0.5543 - val_loss: 0.3139 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6617 - val_recall_tumor: 0.5292 - val_tumor_iou: 0.4218 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 257 lên WandB.\n\n--- Epoch 258/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6341 - loss: 0.2459 - mean_iou_all: 0.4807 - precision_tumor: 0.6336 - recall_tumor: 0.6970 - tumor_iou: 0.4955\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57072\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6340 - loss: 0.2459 - mean_iou_all: 0.4807 - precision_tumor: 0.6336 - recall_tumor: 0.6970 - tumor_iou: 0.4955 - val_acc: 0.9888 - val_dice_coef_metric_tumor: 0.5498 - val_loss: 0.3171 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6282 - val_recall_tumor: 0.5416 - val_tumor_iou: 0.4167 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 258 lên WandB.\n\n--- Epoch 259/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6388 - loss: 0.2456 - mean_iou_all: 0.4859 - precision_tumor: 0.6444 - recall_tumor: 0.6964 - tumor_iou: 0.4979\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57072\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6388 - loss: 0.2456 - mean_iou_all: 0.4858 - precision_tumor: 0.6444 - recall_tumor: 0.6964 - tumor_iou: 0.4979 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5475 - val_loss: 0.3188 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6655 - val_recall_tumor: 0.5124 - val_tumor_iou: 0.4129 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 259 lên WandB.\n\n--- Epoch 260/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6517 - loss: 0.2401 - mean_iou_all: 0.4762 - precision_tumor: 0.6614 - recall_tumor: 0.7012 - tumor_iou: 0.5076\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57072\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6517 - loss: 0.2401 - mean_iou_all: 0.4761 - precision_tumor: 0.6614 - recall_tumor: 0.7011 - tumor_iou: 0.5076 - val_acc: 0.9901 - val_dice_coef_metric_tumor: 0.5697 - val_loss: 0.3045 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6688 - val_recall_tumor: 0.5364 - val_tumor_iou: 0.4327 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 260 lên WandB.\n\n--- Epoch 261/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6518 - loss: 0.2413 - mean_iou_all: 0.4787 - precision_tumor: 0.6552 - recall_tumor: 0.7016 - tumor_iou: 0.5108\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57072\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6518 - loss: 0.2413 - mean_iou_all: 0.4786 - precision_tumor: 0.6552 - recall_tumor: 0.7015 - tumor_iou: 0.5108 - val_acc: 0.9899 - val_dice_coef_metric_tumor: 0.5482 - val_loss: 0.3181 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6982 - val_recall_tumor: 0.4897 - val_tumor_iou: 0.4144 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 261 lên WandB.\n\n--- Epoch 262/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6402 - loss: 0.2460 - mean_iou_all: 0.4662 - precision_tumor: 0.6666 - recall_tumor: 0.6782 - tumor_iou: 0.5042\nEpoch 1: val_dice_coef_metric_tumor improved from 0.57072 to 0.57848, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_31052025_221757.keras\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 470ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6402 - loss: 0.2460 - mean_iou_all: 0.4661 - precision_tumor: 0.6666 - recall_tumor: 0.6782 - tumor_iou: 0.5042 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5785 - val_loss: 0.3002 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6106 - val_recall_tumor: 0.6028 - val_tumor_iou: 0.4397 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 262 lên WandB.\n\n--- Epoch 263/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6440 - loss: 0.2470 - mean_iou_all: 0.4762 - precision_tumor: 0.6417 - recall_tumor: 0.7043 - tumor_iou: 0.5042\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57848\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6440 - loss: 0.2470 - mean_iou_all: 0.4761 - precision_tumor: 0.6417 - recall_tumor: 0.7042 - tumor_iou: 0.5042 - val_acc: 0.9881 - val_dice_coef_metric_tumor: 0.5389 - val_loss: 0.3245 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5736 - val_recall_tumor: 0.5701 - val_tumor_iou: 0.4070 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 263 lên WandB.\n\n--- Epoch 264/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6443 - loss: 0.2461 - mean_iou_all: 0.4718 - precision_tumor: 0.6524 - recall_tumor: 0.6920 - tumor_iou: 0.5055\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57848\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6443 - loss: 0.2460 - mean_iou_all: 0.4717 - precision_tumor: 0.6524 - recall_tumor: 0.6920 - tumor_iou: 0.5056 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5691 - val_loss: 0.3058 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6456 - val_recall_tumor: 0.5602 - val_tumor_iou: 0.4355 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 264 lên WandB.\n\n--- Epoch 265/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6622 - loss: 0.2353 - mean_iou_all: 0.4666 - precision_tumor: 0.6745 - recall_tumor: 0.7026 - tumor_iou: 0.5219\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57848\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6621 - loss: 0.2353 - mean_iou_all: 0.4665 - precision_tumor: 0.6745 - recall_tumor: 0.7026 - tumor_iou: 0.5219 - val_acc: 0.9879 - val_dice_coef_metric_tumor: 0.5322 - val_loss: 0.3291 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6184 - val_recall_tumor: 0.5261 - val_tumor_iou: 0.3975 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 265 lên WandB.\n\n--- Epoch 266/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9902 - dice_coef_metric_tumor: 0.6513 - loss: 0.2357 - mean_iou_all: 0.4644 - precision_tumor: 0.6739 - recall_tumor: 0.6816 - tumor_iou: 0.5140\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57848\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9902 - dice_coef_metric_tumor: 0.6513 - loss: 0.2357 - mean_iou_all: 0.4643 - precision_tumor: 0.6739 - recall_tumor: 0.6816 - tumor_iou: 0.5140 - val_acc: 0.9898 - val_dice_coef_metric_tumor: 0.5562 - val_loss: 0.3139 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6868 - val_recall_tumor: 0.5157 - val_tumor_iou: 0.4249 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 266 lên WandB.\n\n--- Epoch 267/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9900 - dice_coef_metric_tumor: 0.6553 - loss: 0.2379 - mean_iou_all: 0.4608 - precision_tumor: 0.6816 - recall_tumor: 0.6765 - tumor_iou: 0.5121\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57848\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9900 - dice_coef_metric_tumor: 0.6553 - loss: 0.2379 - mean_iou_all: 0.4607 - precision_tumor: 0.6815 - recall_tumor: 0.6765 - tumor_iou: 0.5120 - val_acc: 0.9874 - val_dice_coef_metric_tumor: 0.5558 - val_loss: 0.3155 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5997 - val_recall_tumor: 0.5768 - val_tumor_iou: 0.4215 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 267 lên WandB.\n\n--- Epoch 268/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6455 - loss: 0.2431 - mean_iou_all: 0.4431 - precision_tumor: 0.6598 - recall_tumor: 0.6903 - tumor_iou: 0.5074\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57848\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6455 - loss: 0.2431 - mean_iou_all: 0.4429 - precision_tumor: 0.6598 - recall_tumor: 0.6902 - tumor_iou: 0.5073 - val_acc: 0.9853 - val_dice_coef_metric_tumor: 0.5271 - val_loss: 0.3329 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5681 - val_recall_tumor: 0.5695 - val_tumor_iou: 0.3921 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 268 lên WandB.\n\n--- Epoch 269/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6449 - loss: 0.2468 - mean_iou_all: 0.4541 - precision_tumor: 0.6610 - recall_tumor: 0.6749 - tumor_iou: 0.5035\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57848\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6449 - loss: 0.2468 - mean_iou_all: 0.4540 - precision_tumor: 0.6610 - recall_tumor: 0.6748 - tumor_iou: 0.5035 - val_acc: 0.9899 - val_dice_coef_metric_tumor: 0.5569 - val_loss: 0.3142 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7249 - val_recall_tumor: 0.4973 - val_tumor_iou: 0.4240 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 269 lên WandB.\n\n--- Epoch 270/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6539 - loss: 0.2404 - mean_iou_all: 0.4660 - precision_tumor: 0.6635 - recall_tumor: 0.6976 - tumor_iou: 0.5157\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57848\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 465ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6539 - loss: 0.2404 - mean_iou_all: 0.4659 - precision_tumor: 0.6635 - recall_tumor: 0.6975 - tumor_iou: 0.5157 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5484 - val_loss: 0.3191 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6584 - val_recall_tumor: 0.5275 - val_tumor_iou: 0.4127 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 270 lên WandB.\n\n--- Epoch 271/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6325 - loss: 0.2459 - mean_iou_all: 0.4761 - precision_tumor: 0.6522 - recall_tumor: 0.6801 - tumor_iou: 0.4927\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57848\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 463ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6325 - loss: 0.2459 - mean_iou_all: 0.4760 - precision_tumor: 0.6522 - recall_tumor: 0.6801 - tumor_iou: 0.4927 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5696 - val_loss: 0.3064 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5869 - val_recall_tumor: 0.6047 - val_tumor_iou: 0.4352 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 271 lên WandB.\n\n--- Epoch 272/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9899 - dice_coef_metric_tumor: 0.6470 - loss: 0.2408 - mean_iou_all: 0.4580 - precision_tumor: 0.6682 - recall_tumor: 0.6792 - tumor_iou: 0.5081\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57848\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9899 - dice_coef_metric_tumor: 0.6470 - loss: 0.2408 - mean_iou_all: 0.4578 - precision_tumor: 0.6681 - recall_tumor: 0.6792 - tumor_iou: 0.5081 - val_acc: 0.9840 - val_dice_coef_metric_tumor: 0.5274 - val_loss: 0.3333 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4605 - val_recall_tumor: 0.7110 - val_tumor_iou: 0.3911 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 272 lên WandB.\n\n--- Epoch 273/300 ---\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6587 - loss: 0.2393 - mean_iou_all: 0.4473 - precision_tumor: 0.6591 - recall_tumor: 0.7052 - tumor_iou: 0.5154\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.57848\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 464ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6587 - loss: 0.2393 - mean_iou_all: 0.4472 - precision_tumor: 0.6591 - recall_tumor: 0.7052 - tumor_iou: 0.5154 - val_acc: 0.9897 - val_dice_coef_metric_tumor: 0.5647 - val_loss: 0.3091 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6619 - val_recall_tumor: 0.5403 - val_tumor_iou: 0.4288 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 273 lên WandB.\n\n--- Epoch 274/300 ---\n\u001b[1m139/336\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 414ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.6831 - loss: 0.2490 - mean_iou_all: 0.4928 - precision_tumor: 0.6949 - recall_tumor: 0.7090 - tumor_iou: 0.5385","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"   ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}