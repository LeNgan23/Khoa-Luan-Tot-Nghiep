{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11709306,"sourceType":"datasetVersion","datasetId":6711261}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"ver 8 (6), v10","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n# Keras được tích hợp trong TensorFlow dưới dạng tf.keras\nkeras_version_from_tf = tf.keras.__version__\nprint(f\"Phiên bản Keras API (thông qua tf.keras): {keras_version_from_tf}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:05:09.857798Z","iopub.execute_input":"2025-05-22T19:05:09.858222Z","iopub.status.idle":"2025-05-22T19:05:21.492621Z","shell.execute_reply.started":"2025-05-22T19:05:09.858182Z","shell.execute_reply":"2025-05-22T19:05:21.491905Z"}},"outputs":[{"name":"stdout","text":"Phiên bản Keras API (thông qua tf.keras): 3.5.0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!cat /proc/cpuinfo | grep \"model name\" | uniq \n# Hoặc để xem số core\n!nproc ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:59:33.535913Z","iopub.execute_input":"2025-05-22T18:59:33.536271Z","iopub.status.idle":"2025-05-22T18:59:33.773679Z","shell.execute_reply.started":"2025-05-22T18:59:33.536241Z","shell.execute_reply":"2025-05-22T18:59:33.772865Z"}},"outputs":[{"name":"stdout","text":"model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n4\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!free -h \n# Hoặc chi tiết hơn\n!cat /proc/meminfo | grep MemTotal","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:00:22.805424Z","iopub.execute_input":"2025-05-22T19:00:22.805756Z","iopub.status.idle":"2025-05-22T19:00:23.085306Z","shell.execute_reply.started":"2025-05-22T19:00:22.805729Z","shell.execute_reply":"2025-05-22T19:00:23.084541Z"}},"outputs":[{"name":"stdout","text":"               total        used        free      shared  buff/cache   available\nMem:            31Gi       836Mi        23Gi       1.0Mi       6.9Gi        30Gi\nSwap:             0B          0B          0B\nMemTotal:       32873392 kB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:58:04.760970Z","iopub.execute_input":"2025-05-22T18:58:04.761387Z","iopub.status.idle":"2025-05-22T18:58:04.933902Z","shell.execute_reply.started":"2025-05-22T18:58:04.761350Z","shell.execute_reply":"2025-05-22T18:58:04.932229Z"}},"outputs":[{"name":"stdout","text":"Thu May 22 18:58:04 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   31C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport json\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw\nfrom typing import Tuple\n\nimport cv2\nimport json\nfrom tqdm.notebook import tqdm\n\n\nimport pandas as pd\nimport glob\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\nimport shutil \n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom typing import List, Tuple, Optional","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T02:29:55.260747Z","iopub.execute_input":"2025-06-02T02:29:55.261044Z","iopub.status.idle":"2025-06-02T02:30:10.053173Z","shell.execute_reply.started":"2025-06-02T02:29:55.261022Z","shell.execute_reply":"2025-06-02T02:30:10.052230Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"base_input_dir = \"/kaggle/input/btxrd-data/BTXRD/BTXRD\" \nimage_dir = os.path.join(base_input_dir, \"images\")\nannotation_dir = os.path.join(base_input_dir, \"Annotations\")\nexcel_path = \"/kaggle/input/btxrd-data/classification.xlsx\"\n\n\n# output_dir = \"/kaggle/working/btxrd-v2.2\"\n# output_image_dir = os.path.join(output_dir, \"images\")\n# output_anno_dir = os.path.join(output_dir, \"Annotations\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.430179Z","iopub.status.idle":"2025-05-13T01:54:09.431135Z","shell.execute_reply.started":"2025-05-13T01:54:09.430368Z","shell.execute_reply":"2025-05-13T01:54:09.430415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Đọc file Excel\n# file_path = '/kaggle/input/btxrd-data/classification.xlsx'\ndf = pd.read_excel(excel_path)\n\n# Hiển thị 10 dòng đầu tiên\ndf.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.432391Z","iopub.status.idle":"2025-05-13T01:54:09.433268Z","shell.execute_reply.started":"2025-05-13T01:54:09.432557Z","shell.execute_reply":"2025-05-13T01:54:09.432619Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Xử lý ảnh**","metadata":{}},{"cell_type":"code","source":"# in 30 ảnh trước xử lý\nnum_images_to_show = 30\nimages_per_row = 5  # Số ảnh mỗi hàng\nmask_color = [255, 0, 0]  # Red\n\ndef create_mask(img_size: Tuple[int, int], ann_path: str) -> np.ndarray:\n    mask = Image.new('L', img_size, 0)\n    if os.path.exists(ann_path):\n        try:\n            with open(ann_path, 'r') as f:\n                data = json.load(f)\n                for shape in data.get('shapes', []):\n                    points = shape.get('points', [])\n                    polygon_points = [(int(x), int(y)) for x, y in points]\n                    if polygon_points:\n                        ImageDraw.Draw(mask).polygon(polygon_points, outline=1, fill=1)\n        except Exception as e:\n            print(f\"Lỗi annotation {ann_path}: {e}\")\n    return np.array(mask)\n\n# Lấy danh sách tất cả ảnh trong thư mục\nall_filenames = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# Chọn ngẫu nhiên 30 ảnh\nselected_filenames = random.sample(all_filenames, min(num_images_to_show, len(all_filenames)))\n\n# Plot ảnh với mask\nplt.figure(figsize=(18, 18))  # Tăng kích thước ảnh\nfor i, fname in enumerate(selected_filenames):\n    img_path = os.path.join(image_dir, fname)\n    ann_fname = os.path.splitext(fname)[0] + '.json'\n    ann_path = os.path.join(annotation_dir, ann_fname)\n\n    try:\n        img_pil = Image.open(img_path).convert('L')\n        img_np = np.array(img_pil)\n\n        mask_np = create_mask(img_pil.size, ann_path)\n        color_img = np.stack([img_np] * 3, axis=-1)\n        color_img[mask_np == 1] = mask_color\n\n        # Chia bố cục thành 6 hàng và 5 cột (số ảnh mỗi hàng là 5)\n        plt.subplot(6, 5, i + 1)\n        plt.imshow(color_img)\n        plt.axis('off')  # Tắt trục\n    except Exception as e:\n        print(f\"Lỗi khi xử lý {fname}: {e}\")\n        continue\n\n# Loại bỏ khoảng trống giữa các ảnh\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.434296Z","iopub.status.idle":"2025-05-13T01:54:09.435136Z","shell.execute_reply.started":"2025-05-13T01:54:09.434455Z","shell.execute_reply":"2025-05-13T01:54:09.434496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nTARGET_SIZE = 512\n\n# base_input_dir = \"/kaggle/input/btxrd-data/BTXRD/BTXRD\" # Đường dẫn gốc chứa ảnh và annotation\n# image_dir = os.path.join(base_input_dir, \"images\")      # Thư mục chứa ảnh gốc\n# annotation_dir = os.path.join(base_input_dir, \"Annotations\") # Thư mục chứa annotation gốc\n\noutput_dir = \"/kaggle/working/btxrd-v2.2\"\noutput_image_dir = os.path.join(output_dir, \"images\")\noutput_anno_dir = os.path.join(output_dir, \"annotations\")\n\nos.makedirs(output_image_dir, exist_ok=True)\nos.makedirs(output_anno_dir, exist_ok=True)\n\nMAX_VISUALIZATIONS = 5 # Số lượng ảnh tối đa để trực quan hóa\nvisualized_count = 0\n\n\ndef get_bounding_box(points):\n    if not points:\n        return None\n    points_array = np.array(points)\n    xmin = int(np.min(points_array[:, 0]))\n    ymin = int(np.min(points_array[:, 1]))\n    xmax = int(np.max(points_array[:, 0]))\n    ymax = int(np.max(points_array[:, 1]))\n    # Đảm bảo tọa độ không âm\n    xmin = max(0, xmin)\n    ymin = max(0, ymin)\n    return (xmin, ymin, xmax, ymax)\n\ntry:\n    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg'))]\n    total_images = len(image_files)\n    if total_images == 0:\n        print(f\"Không tìm thấy file ảnh nào trong: {image_dir}\")\n        exit()\n    print(f\"Tìm thấy {total_images} ảnh để xử lý.\")\nexcept FileNotFoundError:\n    print(f\"Không tìm thấy thư mục ảnh: {image_dir}\")\n    exit()\n\nprint(f\"Bắt đầu xử lý ảnh và lưu vào: {output_dir}\")\n# Sử dụng tqdm để hiển thị thanh tiến trình\nfor file in tqdm(image_files, desc=\"Processing Images\"):\n    img_path = os.path.join(image_dir, file)\n    anno_filename = file.rsplit('.', 1)[0] + '.json'\n    anno_path = os.path.join(annotation_dir, anno_filename)\n\n    # Đọc ảnh gốc\n    img_orig = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    if img_orig is None:\n        # print(f\"Không thể đọc ảnh: {file}\"\n        continue\n    orig_height, orig_width = img_orig.shape[:2]\n\n    # Đọc annotation gốc \n    annotation_orig = None\n    has_annotation = os.path.exists(anno_path)\n    if has_annotation:\n        try:\n            with open(anno_path, \"r\", encoding=\"utf-8\") as f:\n                annotation_orig = json.load(f)\n        except Exception as e:\n            # print(f\"Lỗi khi đọc annotation {anno_filename}: {e}\")\n            has_annotation = False # Coi như không có nếu đọc lỗi\n\n    img_to_draw_orig = None\n    img_to_draw_padded = None\n    original_bboxes = []\n    transformed_bboxes = []\n\n    should_visualize = has_annotation and (visualized_count < MAX_VISUALIZATIONS)\n\n    if should_visualize:\n        img_to_draw_orig = cv2.cvtColor(img_orig, cv2.COLOR_GRAY2BGR) # Chuyển sang BGR để vẽ màu\n        if annotation_orig and \"shapes\" in annotation_orig:\n             for shape in annotation_orig[\"shapes\"]:\n                if shape.get(\"shape_type\") == \"rectangle\" and \"points\" in shape and len(shape[\"points\"]) == 2:\n                     # LabelMe rectangle format uses [top-left, bottom-right]\n                     p1 = shape[\"points\"][0]\n                     p2 = shape[\"points\"][1]\n                     xmin = int(min(p1[0], p2[0]))\n                     ymin = int(min(p1[1], p2[1]))\n                     xmax = int(max(p1[0], p2[0]))\n                     ymax = int(max(p1[1], p2[1]))\n                     bbox = (max(0, xmin), max(0, ymin), xmax, ymax)\n                     original_bboxes.append(bbox)\n                     cv2.rectangle(img_to_draw_orig, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 2) # Vẽ màu đỏ (BGR)\n                elif shape.get(\"shape_type\") in [\"polygon\", \"linestrip\", \"point\"] and \"points\" in shape and shape[\"points\"]:\n                     # Lấy bounding box bao quanh các loại shape khác\n                     bbox = get_bounding_box(shape[\"points\"])\n                     if bbox:\n                        original_bboxes.append(bbox)\n                        cv2.rectangle(img_to_draw_orig, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 2) # Red\n\n    # Resize ảnh với padding để giữ tỉ lệ\n    # Tính tỉ lệ resize để cạnh dài nhất bằng TARGET_SIZE\n    scale = TARGET_SIZE / max(orig_height, orig_width)\n    new_width = int(orig_width * scale)\n    new_height = int(orig_height * scale)\n\n    # Đảm bảo kích thước mới không lớn hơn TARGET_SIZE\n    new_width = min(new_width, TARGET_SIZE)\n    new_height = min(new_height, TARGET_SIZE)\n\n    # Resize ảnh\n    img_resized = cv2.resize(img_orig, (new_width, new_height), interpolation=cv2.INTER_AREA)\n\n    # Tính toán padding\n    pad_h = TARGET_SIZE - new_height\n    pad_w = TARGET_SIZE - new_width\n    top = pad_h // 2\n    bottom = pad_h - top\n    left = pad_w // 2\n    right = pad_w - left\n\n    # Thêm padding\n    # Sử dụng giá trị 0 (màu đen) cho padding vì ảnh là grayscale\n    padded_img = cv2.copyMakeBorder(img_resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n\n    # Lưu ảnh đã xử lý\n    output_img_path = os.path.join(output_image_dir, file)\n    try:\n        # Đảm bảo kích thước cuối cùng đúng là TARGET_SIZE x TARGET_SIZE\n        if padded_img.shape[0] != TARGET_SIZE or padded_img.shape[1] != TARGET_SIZE:\n             # Nếu có sai lệch nhỏ do làm tròn, resize lại lần cuối\n             padded_img = cv2.resize(padded_img, (TARGET_SIZE, TARGET_SIZE), interpolation=cv2.INTER_AREA)\n             # print(f\"Final resize needed for {file}. Original: ({orig_width}x{orig_height}), Resized: ({new_width}x{new_height}), Padded: {padded_img.shape[:2]}\")\n\n\n        cv2.imwrite(output_img_path, padded_img)\n    except Exception as e:\n        # print(f\"Lỗi khi lưu ảnh {output_img_path}: {e}\") # Bỏ comment nếu cần debug\n        continue # Bỏ qua ảnh này nếu không lưu được\n\n    # Xử lý và lưu annotation\n    if has_annotation and annotation_orig:\n        # Tạo bản sao sâu để không ảnh hưởng annotation gốc\n        annotation_new = json.loads(json.dumps(annotation_orig))\n\n        if \"shapes\" in annotation_new:\n            new_shapes = [] # Tạo list mới để chứa các shape đã chuyển đổi\n            for shape in annotation_new[\"shapes\"]:\n                if \"points\" in shape and shape[\"points\"]:\n                    original_points = shape[\"points\"]\n                    new_points_transformed = []\n                    valid_shape = True\n                    for x, y in original_points:\n                        # Áp dụng tỉ lệ resize\n                        new_x = x * scale\n                        new_y = y * scale\n                        # Áp dụng padding offset\n                        new_x += left\n                        new_y += top\n\n                        # Kiểm tra xem điểm có nằm trong ảnh mới không\n                        # new_x = max(0, min(TARGET_SIZE - 1, new_x))\n                        # new_y = max(0, min(TARGET_SIZE - 1, new_y))\n                        new_points_transformed.append([new_x, new_y])\n\n                    # Cập nhật điểm trong shape\n                    shape[\"points\"] = new_points_transformed\n                    new_shapes.append(shape) # Thêm shape đã chuyển đổi vào list mới\n\n                    # Tính bbox mới để trực quan hóa\n                    if should_visualize:\n                        new_bbox = get_bounding_box(new_points_transformed)\n                        if new_bbox:\n                            # Đảm bảo bbox không vượt ra ngoài TARGET_SIZE\n                            xmin = max(0, min(TARGET_SIZE - 1, new_bbox[0]))\n                            ymin = max(0, min(TARGET_SIZE - 1, new_bbox[1]))\n                            xmax = max(0, min(TARGET_SIZE - 1, new_bbox[2]))\n                            ymax = max(0, min(TARGET_SIZE - 1, new_bbox[3]))\n                            # Chỉ thêm vào nếu bbox hợp lệ\n                            if xmax > xmin and ymax > ymin:\n                                transformed_bboxes.append((xmin, ymin, xmax, ymax))\n\n            # Cập nhật lại danh sách shapes và kích thước ảnh trong annotation\n            annotation_new[\"shapes\"] = new_shapes\n            annotation_new[\"imagePath\"] = file # Cập nhật tên file ảnh mới\n            annotation_new[\"imageWidth\"] = TARGET_SIZE\n            annotation_new[\"imageHeight\"] = TARGET_SIZE\n            \n            if \"imageData\" in annotation_new:\n                annotation_new[\"imageData\"] = None\n\n            # Lưu file annotation mới\n            output_annotation_path = os.path.join(output_anno_dir, anno_filename)\n            try:\n                with open(output_annotation_path, \"w\", encoding=\"utf-8\") as f:\n                    json.dump(annotation_new, f, indent=4, ensure_ascii=False)\n            except Exception as e:\n                # print(f\"Lỗi khi lưu annotation {anno_filename}: {e}\") # Bỏ comment nếu cần debug\n                pass # Bỏ qua nếu lưu lỗi\n\n            if should_visualize and img_to_draw_orig is not None:\n                # Chuyển ảnh đã padding sang BGR để vẽ màu\n                img_to_draw_padded = cv2.cvtColor(padded_img, cv2.COLOR_GRAY2BGR)\n                # Vẽ các bounding box đã biến đổi\n                for bbox in transformed_bboxes:\n                     # Đảm bảo tọa độ là số nguyên để vẽ\n                     pt1 = (int(bbox[0]), int(bbox[1]))\n                     pt2 = (int(bbox[2]), int(bbox[3]))\n                     cv2.rectangle(img_to_draw_padded, pt1, pt2, (0, 255, 0), 2) # Vẽ màu xanh lá (BGR)\n\n                # Hiển thị ảnh gốc và ảnh đã xử lý\n                fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\n                # Ảnh gốc với bbox gốc (màu đỏ)\n                axes[0].imshow(cv2.cvtColor(img_to_draw_orig, cv2.COLOR_BGR2RGB)) # Chuyển BGR sang RGB cho matplotlib\n                axes[0].set_title(f'Original: {file}\\nSize: {orig_width}x{orig_height}')\n                axes[0].axis('off')\n\n                # Ảnh đã xử lý với bbox mới (màu xanh)\n                axes[1].imshow(cv2.cvtColor(img_to_draw_padded, cv2.COLOR_BGR2RGB)) # Chuyển BGR sang RGB\n                axes[1].set_title(f'Processed (Resized & Padded)\\nSize: {TARGET_SIZE}x{TARGET_SIZE}')\n                axes[1].axis('off')\n\n                plt.suptitle(f\"Visualization {visualized_count + 1}/{MAX_VISUALIZATIONS}\")\n                plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Điều chỉnh layout để tiêu đề không bị che\n                plt.show()\n\n                visualized_count += 1\n\nprint(f\"Xử lý {total_images} ảnh.\")\nif visualized_count > 0:\n    print(f\"Hiển thị {visualized_count} ảnh trực quan hóa.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.436168Z","iopub.status.idle":"2025-05-13T01:54:09.436694Z","shell.execute_reply.started":"2025-05-13T01:54:09.436347Z","shell.execute_reply":"2025-05-13T01:54:09.436393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hiển thị random 30 hình sau khi xử lý ảnh\n\n\n# Cấu hình\nimage_dir_test = '/kaggle/working/btxrd-v2.2/images'\nannotation_dir_test = '/kaggle/working/btxrd-v2.2/annotations'\n# Cấu hình\nnum_images_to_show = 30\nimages_per_row = 5  # Số ảnh mỗi hàng\nmask_color = [255, 0, 0]  # Red\n\ndef create_mask(img_size: Tuple[int, int], ann_path: str) -> np.ndarray:\n    mask = Image.new('L', img_size, 0)\n    if os.path.exists(ann_path):\n        try:\n            with open(ann_path, 'r') as f:\n                data = json.load(f)\n                for shape in data.get('shapes', []):\n                    points = shape.get('points', [])\n                    polygon_points = [(int(x), int(y)) for x, y in points]\n                    if polygon_points:\n                        ImageDraw.Draw(mask).polygon(polygon_points, outline=1, fill=1)\n        except Exception as e:\n            print(f\"Lỗi annotation {ann_path}: {e}\")\n    return np.array(mask)\n\n# Lấy danh sách tất cả ảnh trong thư mục\nall_filenames = [f for f in os.listdir(image_dir_test) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# Chọn ngẫu nhiên 30 ảnh\nselected_filenames = random.sample(all_filenames, min(num_images_to_show, len(all_filenames)))\n\n# Plot ảnh với mask\nplt.figure(figsize=(18, 18))  # Tăng kích thước ảnh\nfor i, fname in enumerate(selected_filenames):\n    img_path = os.path.join(image_dir_test, fname)\n    ann_fname = os.path.splitext(fname)[0] + '.json'\n    ann_path = os.path.join(annotation_dir_test, ann_fname)\n\n    try:\n        img_pil = Image.open(img_path).convert('L')\n        img_np = np.array(img_pil)\n\n        mask_np = create_mask(img_pil.size, ann_path)\n        color_img = np.stack([img_np] * 3, axis=-1)\n        color_img[mask_np == 1] = mask_color\n\n        # Chia bố cục thành 6 hàng và 5 cột (số ảnh mỗi hàng là 5)\n        plt.subplot(6, 5, i + 1)\n        plt.imshow(color_img)\n        plt.axis('off')  # Tắt trục\n    except Exception as e:\n        print(f\"Lỗi khi xử lý {fname}: {e}\")\n        continue\n\n# Loại bỏ khoảng trống giữa các ảnh\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.437653Z","iopub.status.idle":"2025-05-13T01:54:09.438769Z","shell.execute_reply.started":"2025-05-13T01:54:09.437797Z","shell.execute_reply":"2025-05-13T01:54:09.437838Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Chia tập dữ liệu**","metadata":{}},{"cell_type":"code","source":"output_split_dir = \"/kaggle/working/btxrd-v2.1\"\n\nANNOTATION_EXTENSION = \".json\"\n\nVAL_SIZE = 0.20   # 20% cho tập validation\nTRAIN_SIZE = 0.70 # 70% cho tập train\nTEST_SIZE = 1.0 - VAL_SIZE - TRAIN_SIZE\n\nRANDOM_STATE = 42","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.439717Z","iopub.status.idle":"2025-05-13T01:54:09.440264Z","shell.execute_reply.started":"2025-05-13T01:54:09.439865Z","shell.execute_reply":"2025-05-13T01:54:09.439927Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Đọc Dữ liệu Phân loại từ Excel\ntry:\n    df_classification = pd.read_excel(excel_path)\n    required_columns = ['image_id', 'tumor_type', 'image_filename']\n    if not all(col in df_classification.columns for col in required_columns):\n        missing = [col for col in required_columns if col not in df_classification.columns]\n        raise ValueError(f\"File Excel thiếu các cột bắt buộc: {missing}\")\n\n    df_classification['image_id'] = df_classification['image_id'].astype(str).str.strip()\n    df_classification['image_filename'] = df_classification['image_filename'].astype(str).str.strip()\n\n    print(f\"Đọc thành công {len(df_classification)} dòng\")\n    print(df_classification['tumor_type'].value_counts())\nexcept FileNotFoundError:\n    print(f\"Không tìm thấy file Excel tại {excel_path}\")\n    exit()\nexcept ValueError as ve:\n    print(f\"Lỗi dữ liệu trong file Excel: {ve}\")\n    exit()\nexcept Exception as e:\n    print(f\"không xác định khi đọc file Excel: {e}\")\n    exit()\n\ntry:\n    all_image_files = glob.glob(os.path.join(image_dir_test, \"*.*\"))\n    annotation_files = glob.glob(os.path.join(annotation_dir_test, f\"*{ANNOTATION_EXTENSION}\"))\n\n    image_basenames_actual = set(os.path.splitext(os.path.basename(f))[0] for f in all_image_files)\n    annotation_basenames_actual = set(os.path.splitext(os.path.basename(f))[0] for f in annotation_files)\n\n    print(f\"Tìm thấy {len(all_image_files)} tệp\")\n    print(f\"Tìm thấy {len(annotation_files)} tệp annotation\")\nexcept Exception as e:\n    print(f\"Lỗi khi quét thư mục ảnh hoặc annotation: {e}\")\n    exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.441610Z","iopub.status.idle":"2025-05-13T01:54:09.442492Z","shell.execute_reply.started":"2025-05-13T01:54:09.442254Z","shell.execute_reply":"2025-05-13T01:54:09.442305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"excel_image_ids = set(df_classification['image_id'])\nvalid_ids = list(excel_image_ids.intersection(image_basenames_actual).intersection(annotation_basenames_actual))\n\nif not valid_ids:\n    print(\"Không tìm thấy dữ liệu hợp lệ nào.\")\n    exit()\ndf_filtered = df_classification[df_classification['image_id'].isin(valid_ids)].copy()\ndf_filtered = df_filtered.drop_duplicates(subset=['image_id'])\nfilename_map = pd.Series(df_filtered.image_filename.values, index=df_filtered.image_id).to_dict()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.443533Z","iopub.status.idle":"2025-05-13T01:54:09.444176Z","shell.execute_reply.started":"2025-05-13T01:54:09.443693Z","shell.execute_reply":"2025-05-13T01:54:09.443733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Chuẩn bị dữ liệu (X=IDs, y=Labels) cho việc chia\nX = df_filtered['image_id'].tolist() # Danh sách ID ảnh \ny = df_filtered['tumor_type'].tolist() # Danh sách nhãn tương ứng\n\n# Chia Lần 1 (Train+Val / Test)\nX_train_val, X_test, y_train_val, y_test = [], [], [], []\nif len(X) < 2:\n    print(\"Không đủ mẫu dữ liệu (< 2) để thực hiện chia.\")\n    exit()\nif TEST_SIZE <= 0 or TEST_SIZE >= 1:\n     print(f\"Tỷ lệ Test ({TEST_SIZE:.2f}) không hợp lệ. Toàn bộ dữ liệu sẽ là Train+Val.\")\n     X_train_val, y_train_val = X, y\nelse:\n    try:\n        unique_classes_total, counts_total = np.unique(y, return_counts=True)\n        stratify_option_1 = y\n        if len(unique_classes_total) < 2:\n            print(\"Chỉ có 1 lớp. Chia ngẫu nhiên cho Test.\")\n            stratify_option_1 = None\n        elif np.any(counts_total < 2):\n             print(f\"Có lớp < 2 mẫu. Chia ngẫu nhiên cho Test.\")\n             stratify_option_1 = None\n\n        X_train_val, X_test, y_train_val, y_test = train_test_split(\n            X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=stratify_option_1\n        )\n        print(f\"Chia lần 1: {len(X_train_val)} Train+Val, {len(X_test)} Test.\")\n        print(\"Phân phối 'tumor_type' trong Test:\", sorted(Counter(y_test).items()))\n    except ValueError as e:\n         print(f\"Lỗi khi chia lần 1 (Test): {e}. Thoát.\")\n         exit()\n\n\n# Chia lần 2 (Train / Validation)\nX_train, X_val, y_train, y_val = [], [], [], []\nif not X_train_val:\n     print(\"Tập Train+Val rỗng.\")\nelif len(X_train_val) == 1:\n     print(\"Tập Train+Val chỉ có 1 mẫu -> vào Train.\")\n     X_train, y_train = X_train_val, y_train_val\nelif VAL_SIZE <= 0 or VAL_SIZE >= 1:\n     print(f\"Tỷ lệ Val ({VAL_SIZE:.4f}) không hợp lệ. Toàn bộ Train+Val -> Train.\")\n     X_train, y_train = X_train_val, y_train_val\nelse:\n    try:\n        unique_classes_tv, counts_tv = np.unique(y_train_val, return_counts=True)\n        stratify_option_2 = y_train_val\n        if len(unique_classes_tv) < 2:\n            print(\"Train+Val chỉ còn 1 lớp. Chia ngẫu nhiên cho Val.\")\n            stratify_option_2 = None\n        elif np.any(counts_tv < 2):\n             print(f\"Có lớp < 2 mẫu trong Train+Val. Chia ngẫu nhiên cho Val.\")\n             stratify_option_2 = None\n\n        X_train, X_val, y_train, y_val = train_test_split(\n            X_train_val, y_train_val, test_size=VAL_SIZE,\n            random_state=RANDOM_STATE, stratify=stratify_option_2\n        )\n        print(f\"Chia lần 2: {len(X_train)} Train, {len(X_val)} Validation.\")\n        print(\"Phân phối 'tumor_type' trong Train:\", sorted(Counter(y_train).items()))\n        print(\"Phân phối 'tumor_type' trong Validation:\", sorted(Counter(y_val).items()))\n    except ValueError as e:\n        print(f\"Lỗi khi chia lần 2 (Validation): {e}. Toàn bộ Train+Val -> Train.\")\n        X_train, y_train = X_train_val, y_train_val # Gán lại vào Train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.445355Z","iopub.status.idle":"2025-05-13T01:54:09.445873Z","shell.execute_reply.started":"2025-05-13T01:54:09.445521Z","shell.execute_reply":"2025-05-13T01:54:09.445564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# kết quả sau khi chia\ntotal_ids_split = len(X_train) + len(X_val) + len(X_test)\noriginal_valid_count = len(df_filtered)\n\nprint(f\"Tổng số mẫu hợp lệ ban đầu: {original_valid_count}\")\nprint(f\"Tổng số IDs được chia vào các tập: {total_ids_split}\")\nif total_ids_split != original_valid_count:\n     print(f\"Số ID được chia ({total_ids_split}) không khớp số ID hợp lệ ({original_valid_count}). Kiểm tra logic chia.\")\n\nprint(f\"Train set IDs:      {len(X_train):>5}\")\nprint(f\"Validation set IDs: {len(X_val):>5}\")\nprint(f\"Test set IDs:       {len(X_test):>5}\")\n\nif total_ids_split > 0:\n    print(f\"\\nTỷ lệ thực tế (dựa trên IDs):\")\n    print(f\"  Train: {len(X_train) / total_ids_split * 100:>6.1f}%\")\n    print(f\"  Val:   {len(X_val) / total_ids_split * 100:>6.1f}%\")\n    print(f\"  Test:  {len(X_test) / total_ids_split * 100:>6.1f}%\")\n\nprint(\"\\nPhân phối 'tumor_type' cuối cùng (dựa trên IDs đã chia):\")\nprint(f\"Train:      {sorted(Counter(y_train).items())}\")\nprint(f\"Validation: {sorted(Counter(y_val).items())}\")\nprint(f\"Test:       {sorted(Counter(y_test).items())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:54:09.447098Z","iopub.status.idle":"2025-05-13T01:54:09.447781Z","shell.execute_reply.started":"2025-05-13T01:54:09.447359Z","shell.execute_reply":"2025-05-13T01:54:09.447402Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Huấn luyện mô hình**","metadata":{}},{"cell_type":"code","source":"!pip install wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T00:26:42.422684Z","iopub.execute_input":"2025-05-22T00:26:42.422966Z","iopub.status.idle":"2025-05-22T00:26:49.207863Z","shell.execute_reply.started":"2025-05-22T00:26:42.422940Z","shell.execute_reply":"2025-05-22T00:26:49.206145Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.11.0a2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.29.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# --- Cấu hình ---\nimport os # Thêm import os nếu chưa có\nimport numpy as np # Thêm import numpy nếu dùng trong tính mean/std\nimport pandas as pd # Thêm import pandas nếu dùng trong tải metadata\nfrom tqdm import tqdm # Thêm import tqdm\nimport tensorflow as tf # Thêm import tensorflow\nfrom PIL import Image, ImageDraw # Thêm import PIL\nimport json # Thêm import json\nimport matplotlib.pyplot as plt # Thêm import matplotlib nếu dùng plot_image\n\nINPUT_DATA_ROOT = '/kaggle/input/btxrd-data' # THAY ĐỔI NẾU MÔI TRƯỜNG CỦA BẠN KHÁC\nBASE_DATA_DIR = os.path.join(INPUT_DATA_ROOT, 'btxrd-v2.1')\nCLASSIFICATION_FILE = os.path.join(INPUT_DATA_ROOT, 'classification.xlsx')\nIMAGE_SUBDIR_NAME = 'images'\nANNOTATION_SUBDIR_NAME = 'annotations'\n\n# Tham số Model & Huấn luyện\nTARGET_SIZE = 512\nN_CLASSES = 2 # 2 lớp: 0 (nền), 1 (khối u)\nBATCH_SIZE = 8 # Sẽ được dùng trong config wandb\nBUFFER_SIZE = 100 # Dùng cho dataset.shuffle\nEPOCHS = 300 # Sẽ được dùng trong config wandb và vòng lặp for\nLEARNING_RATE = 1e-4 # Sẽ được dùng trong config wandb\nL2_REG_FACTOR = 1e-5\nDROPOUT_RATE = 0.3\n\n# --- Cải tiến để tăng IoU ---\nUSE_COMBINED_LOSS = True\nDICE_LOSS_WEIGHT = 0.6\nUSE_FOCAL_LOSS_IN_COMBINED = True\nFOCAL_LOSS_ALPHA = 0.25\nFOCAL_LOSS_GAMMA = 2.0\n\nUSE_ATTENTION_UNET = False\n\n# APPLY_POST_PROCESSING, POST_PROCESSING_KERNEL_SIZE, MIN_AREA_POST_PROCESSING\n# thường dùng sau huấn luyện, không trực tiếp ảnh hưởng đến vòng lặp huấn luyện này\n\nMODEL_CHECKPOINT_BASENAME = \"unet_model\"\nTENSORBOARD_LOG_DIR = \"./logs_unet_iou_focused\"\n\n# --- Các hằng số cho callback Keras tiêu chuẩn ---\nPATIENCE_EARLY_STOPPING = 35\nPATIENCE_REDUCE_LR = 12\nMONITOR_METRIC_CB = 'val_dice_coef_metric_tumor' # QUAN TRỌNG: Phải khớp với key trong history.history\n\n# --- Cấu hình WandB ---\nWANDB_PROJECT_NAME = \"btxrd-project\" # Đặt tên project của bạn trên WandB\nWANDB_ENTITY = \"nganltt2333\" # Đặt entity của bạn\nWANDB_API_KEY = \"2b7e633df37247dd52582a893eecab6314151a62\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T02:30:10.991923Z","iopub.execute_input":"2025-06-02T02:30:10.992523Z","iopub.status.idle":"2025-06-02T02:30:10.999173Z","shell.execute_reply.started":"2025-06-02T02:30:10.992494Z","shell.execute_reply":"2025-06-02T02:30:10.998200Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def get_valid_paths(base_dir: str, split_type: str, img_filename_with_ext: str) -> Optional[Tuple[str, str]]:\n    split_dir = os.path.join(base_dir, split_type); image_dir_path = os.path.join(split_dir, IMAGE_SUBDIR_NAME); annotation_dir_path = os.path.join(split_dir, ANNOTATION_SUBDIR_NAME)\n    img_path = os.path.join(image_dir_path, img_filename_with_ext); base_name = os.path.splitext(img_filename_with_ext)[0]; json_filename = base_name + '.json'\n    json_path = os.path.join(annotation_dir_path, json_filename)\n    if os.path.exists(img_path) and os.path.exists(json_path): return img_path, json_path\n    return None\n\ndef create_mask_pil(mask_size: Tuple[int, int], json_path: str) -> Image.Image:\n    if not os.path.exists(json_path): return Image.new('L', (mask_size[1], mask_size[0]), 0)\n    mask = Image.new('L', (mask_size[1], mask_size[0]), 0)\n    try:\n        with open(json_path, 'r') as f: data = json.load(f)\n        if 'shapes' not in data or not isinstance(data['shapes'], list) or not data['shapes']: return mask\n        for shape in data['shapes']:\n             if 'points' in shape and isinstance(shape['points'], list):\n                  polygon = [tuple(point) for point in shape['points']]\n                  if len(polygon) >= 3: ImageDraw.Draw(mask).polygon(polygon, outline=255, fill=255)\n    except (json.JSONDecodeError, Exception): return Image.new('L', (mask_size[1], mask_size[0]), 0)\n    return mask\n\ndef plot_image(ax: plt.Axes, image_data: np.ndarray, title: str, cmap='gray'):\n    if image_data.ndim == 2 or (image_data.ndim == 3 and image_data.shape[2] == 1): ax.imshow(image_data.squeeze(), cmap=cmap)\n    else: ax.imshow(image_data)\n    ax.set_title(title, fontsize=10); ax.axis('off')\n\nall_image_paths = []; all_mask_paths = []; all_types = []\ntry:\n    if not os.path.exists(CLASSIFICATION_FILE): raise FileNotFoundError(f\"Không tìm thấy file phân loại tại {CLASSIFICATION_FILE}\")\n    if not os.path.isdir(BASE_DATA_DIR): raise FileNotFoundError(f\"Không tìm thấy thư mục dữ liệu cơ sở: {BASE_DATA_DIR}\")\n    df_classification = pd.read_excel(CLASSIFICATION_FILE)\n    required_cols = ['image_filename', 'type']\n    if not all(col in df_classification.columns for col in required_cols): raise ValueError(f\"File Excel phải chứa các cột: {required_cols}\")\n    for index, row in tqdm(df_classification.iterrows(), total=len(df_classification), desc=\"Kiểm tra file\"):\n        img_filename_with_ext = row['image_filename']; file_type = row['type']\n        if pd.isna(img_filename_with_ext) or pd.isna(file_type) or file_type not in ['train', 'val', 'test']: continue\n        paths = get_valid_paths(BASE_DATA_DIR, str(file_type).lower(), str(img_filename_with_ext))\n        if paths: img_path, json_path = paths; all_image_paths.append(img_path); all_mask_paths.append(json_path); all_types.append(str(file_type).lower())\n    if not all_image_paths: print(\"\\nLỗi: Không tìm thấy cặp ảnh-chú thích hợp lệ nào.\"); exit()\n    df_paths = pd.DataFrame({'image_path': all_image_paths, 'mask_path': all_mask_paths, 'type': all_types})\n    df_train = df_paths[df_paths['type'] == 'train'].reset_index(drop=True); df_val = df_paths[df_paths['type'] == 'val'].reset_index(drop=True); df_test = df_paths[df_paths['type'] == 'test'].reset_index(drop=True)\n    train_image_paths = df_train['image_path'].tolist(); train_mask_paths = df_train['mask_path'].tolist()\n    val_image_paths = df_val['image_path'].tolist(); val_mask_paths = df_val['mask_path'].tolist()\n    test_image_paths = df_test['image_path'].tolist(); test_mask_paths = df_test['mask_path'].tolist()\n    print(f\"\\nPhân chia dữ liệu: Train({len(train_image_paths)}), Val({len(val_image_paths)}), Test({len(test_image_paths)})\")\n    if not train_image_paths: print(\"Cảnh báo: Tập huấn luyện rỗng!\"); exit()\nexcept Exception as e: print(f\"Lỗi khi tải siêu dữ liệu: {e}\"); import traceback; traceback.print_exc(); exit()\n\n# Tính toán Mean/Std\nmean_pixel = 0.5; std_pixel = 0.1\nnum_train_images = len(train_image_paths)\nif num_train_images > 0:\n    print(\"Đang tính toán Mean/Std...\")\n    pixel_sum = 0.0; pixel_sum_sq = 0.0; total_pixels_calculated = 0; processed_count = 0\n    sample_size_for_stats = min(num_train_images, 250) # Tăng nhẹ sample size\n    sampled_train_paths = np.random.choice(train_image_paths, size=sample_size_for_stats, replace=False)\n    for img_path in tqdm(sampled_train_paths, desc=\"Tính Mean/Std\"):\n        try:\n            img_bytes = tf.io.read_file(img_path); img = tf.io.decode_image(img_bytes, channels=1, expand_animations=False, dtype=tf.float32)\n            img = tf.image.resize(img, [TARGET_SIZE, TARGET_SIZE])\n            pixel_sum += tf.reduce_sum(img).numpy(); pixel_sum_sq += tf.reduce_sum(tf.square(img)).numpy()\n            total_pixels_calculated += (TARGET_SIZE * TARGET_SIZE); processed_count += 1\n        except Exception: pass\n    if processed_count > 0 and total_pixels_calculated > 0:\n        mean_pixel = pixel_sum / total_pixels_calculated; variance = (pixel_sum_sq / total_pixels_calculated) - (mean_pixel ** 2)\n        std_pixel = np.sqrt(max(variance, 1e-7)); print(f\"Mean: {mean_pixel:.4f}, Std Dev: {std_pixel:.4f}\")\n        if std_pixel < 1e-4: std_pixel = 0.1; print(\"Std Dev quá thấp, dùng mặc định 0.1.\")\n    else: print(f\"Cảnh báo: Không tính được mean/std, dùng mặc định.\")\nstd_pixel = max(std_pixel, 1e-7)\n\n# Pipeline Dữ liệu TensorFlow\ndef load_mask_from_json_py(json_path_bytes):\n    json_path = json_path_bytes.numpy().decode('utf-8'); pil_mask = create_mask_pil((TARGET_SIZE, TARGET_SIZE), json_path)\n    mask_np = np.array(pil_mask, dtype=np.uint8); mask_np = (mask_np > 128).astype(np.uint8)\n    return mask_np\n\n@tf.function\ndef load_and_preprocess(image_path, mask_json_path):\n    img_bytes = tf.io.read_file(image_path)\n    try: img = tf.io.decode_image(img_bytes, channels=1, expand_animations=False, dtype=tf.float32)\n    except tf.errors.InvalidArgumentError:\n        try: img = tf.image.decode_png(img_bytes, channels=1, dtype=tf.uint8); img = tf.cast(img, tf.float32) / 255.0\n        except tf.errors.InvalidArgumentError: img = tf.image.decode_jpeg(img_bytes, channels=1); img = tf.cast(img, tf.float32) / 255.0\n    img = tf.image.resize(img, [TARGET_SIZE, TARGET_SIZE]); img.set_shape([TARGET_SIZE, TARGET_SIZE, 1])\n    mask_np_binary = tf.py_function(func=load_mask_from_json_py, inp=[mask_json_path], Tout=tf.uint8)\n    mask_np_binary.set_shape([TARGET_SIZE, TARGET_SIZE])\n    mask_onehot = tf.one_hot(tf.cast(mask_np_binary, tf.int32), depth=N_CLASSES, dtype=tf.float32)\n    mask_onehot.set_shape([TARGET_SIZE, TARGET_SIZE, N_CLASSES])\n    img = (img - mean_pixel) / std_pixel\n    return img, mask_onehot\n\n@tf.function\ndef augment_data_tf(image, mask_onehot):\n    combined = tf.concat([image, tf.cast(mask_onehot, image.dtype)], axis=-1) # Nối image và mask (đã cast về dtype của image)\n    if tf.random.uniform(()) > 0.5: combined = tf.image.flip_left_right(combined)\n    if tf.random.uniform(()) > 0.5: combined = tf.image.flip_up_down(combined)\n    k_rot = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n    combined = tf.image.rot90(combined, k=k_rot)\n    img_aug = combined[..., :1]\n    mask_aug = tf.cast(combined[..., 1:], tf.float32)\n    img_aug = tf.image.random_brightness(img_aug, max_delta=0.25)\n    img_aug = tf.image.random_contrast(img_aug, lower=0.7, upper=1.3)\n    if tf.random.uniform(()) > 0.3:\n        scale = tf.random.uniform((), 0.8, 1.2)\n        new_height = tf.cast(TARGET_SIZE * scale, tf.int32)\n        new_width = tf.cast(TARGET_SIZE * scale, tf.int32)\n        img_scaled = tf.image.resize(img_aug, [new_height, new_width], method=tf.image.ResizeMethod.BILINEAR)\n        mask_scaled = tf.image.resize(mask_aug, [new_height, new_width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        img_aug = tf.image.resize_with_crop_or_pad(img_scaled, TARGET_SIZE, TARGET_SIZE)\n        mask_aug = tf.image.resize_with_crop_or_pad(mask_scaled, TARGET_SIZE, TARGET_SIZE)\n    img_aug = tf.clip_by_value(img_aug, -3.0, 3.0)\n    img_aug.set_shape([TARGET_SIZE, TARGET_SIZE, 1])\n    mask_aug.set_shape([TARGET_SIZE, TARGET_SIZE, N_CLASSES])\n    return img_aug, mask_aug\n\ndef create_dataset(image_paths, mask_paths, is_training=True):\n    if not image_paths or not mask_paths: return tf.data.Dataset.from_tensor_slices(([], [])).batch(BATCH_SIZE)\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n    if is_training: dataset = dataset.shuffle(buffer_size=min(BUFFER_SIZE, len(image_paths)), reshuffle_each_iteration=True)\n    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n    if is_training: dataset = dataset.map(augment_data_tf, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=(is_training if len(image_paths) >= BATCH_SIZE else False))\n    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return dataset\n\ntrain_ds = create_dataset(train_image_paths, train_mask_paths, is_training=True)\nval_ds = create_dataset(val_image_paths, val_mask_paths, is_training=False)\ntest_ds = create_dataset(test_image_paths, test_mask_paths, is_training=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T02:30:14.303899Z","iopub.execute_input":"2025-06-02T02:30:14.304208Z","iopub.status.idle":"2025-06-02T02:30:30.491287Z","shell.execute_reply.started":"2025-06-02T02:30:14.304185Z","shell.execute_reply":"2025-06-02T02:30:30.490544Z"}},"outputs":[{"name":"stderr","text":"Kiểm tra file: 100%|██████████| 3746/3746 [00:10<00:00, 372.61it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nPhân chia dữ liệu: Train(1344), Val(336), Test(187)\nĐang tính toán Mean/Std...\n","output_type":"stream"},{"name":"stderr","text":"Tính Mean/Std: 100%|██████████| 250/250 [00:04<00:00, 62.48it/s] \n","output_type":"stream"},{"name":"stdout","text":"Mean: 0.1994, Std Dev: 0.2361\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# UNET\nclass AttentionGate(layers.Layer):\n    def __init__(self, F_g, F_l, F_int, **kwargs): super(AttentionGate, self).__init__(**kwargs); self.W_g = layers.Conv2D(F_int, 1, padding='same', kernel_initializer='he_normal'); self.W_x = layers.Conv2D(F_int, 1, padding='same', kernel_initializer='he_normal'); self.psi = layers.Conv2D(1, 1, padding='same', kernel_initializer='he_normal', activation='sigmoid'); self.relu = layers.Activation('relu')\n    def call(self, g, x): g1 = self.W_g(g); x1 = self.W_x(x); psi_input = self.relu(g1 + x1); alpha = self.psi(psi_input); return x * alpha\ndef conv_block(inputs, num_filters, l2_reg, dropout):\n    x = layers.Conv2D(num_filters, 3, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(inputs); x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n    if dropout > 0: x = layers.Dropout(dropout)(x)\n    x = layers.Conv2D(num_filters, 3, padding='same', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x); x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n    return x\ndef encoder_block(inputs, num_filters, l2_reg, dropout, pool=True): c = conv_block(inputs, num_filters, l2_reg, dropout); p = layers.MaxPooling2D(2)(c) if pool else None; return c, p\ndef decoder_block(inputs, skip_features, num_filters, l2_reg, dropout, use_attention):\n    x = layers.Conv2DTranspose(num_filters, 2, strides=2, padding='same')(inputs)\n    if use_attention and skip_features is not None: att_gate = AttentionGate(num_filters, skip_features.shape[-1], max(1, skip_features.shape[-1] // 2) ); skip_features = att_gate(g=x, x=skip_features)\n    if skip_features is not None: x = layers.Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters, l2_reg, dropout); return x\ndef build_unet(input_shape, n_classes=N_CLASSES, l2_reg=L2_REG_FACTOR, dropout=DROPOUT_RATE, use_attention=USE_ATTENTION_UNET):\n    filters = [64, 128, 256, 512, 1024]\n    inputs = keras.Input(shape=input_shape); skips = []; x = inputs\n    for f in filters[:-1]: s, p = encoder_block(x, f, l2_reg, dropout, pool=True); skips.append(s); x = p\n    x, _ = encoder_block(x, filters[-1], l2_reg, dropout*1.3, pool=False)\n    for i, f in reversed(list(enumerate(filters[:-1]))): x = decoder_block(x, skips[i], f, l2_reg, dropout, use_attention)\n    outputs = layers.Conv2D(n_classes, 1, padding='same', activation='softmax')(x)\n    return keras.Model(inputs, outputs, name=f\"{'Attention' if use_attention else ''}UNet_filters{filters[0]}\")\n\n# --- HÀM MẤT MÁT (LOSS FUNCTIONS) ---\nSMOOTH = 1e-6\ndef dice_coef(y_true_one_hot, y_pred_softmax):\n    y_true_f = tf.keras.backend.flatten(y_true_one_hot)\n    y_pred_f = tf.keras.backend.flatten(y_pred_softmax)\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    return (2. * intersection + SMOOTH) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + SMOOTH)\n\ndef dice_coef_metric_tumor(y_true, y_pred):\n    # y_true: (batch, H, W, N_CLASSES), y_pred: (batch, H, W, N_CLASSES)\n    return dice_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\ndice_coef_metric_tumor.__name__ = 'dice_coef_metric_tumor' # Khớp với `metrics_to_plot`\n\ndef dice_loss_tumor(y_true, y_pred):\n    return 1.0 - dice_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\n\ndef iou_coef(y_true_one_hot, y_pred_softmax):\n    y_true_f = tf.keras.backend.flatten(y_true_one_hot)\n    y_pred_f = tf.keras.backend.flatten(y_pred_softmax)\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n    return (intersection + SMOOTH) / (union + SMOOTH)\n\ndef iou_metric_tumor(y_true, y_pred):\n    return iou_coef(y_true[..., 1], y_pred[..., 1]) if N_CLASSES >= 2 else 0.0\niou_metric_tumor.__name__ = 'tumor_iou' # Khớp với `metrics_to_plot`\n\n# --- CÁC METRICS MỚI CHO LỚP TUMOR ---\ndef precision_recall_tumor_base(y_true, y_pred, metric_type):\n    if N_CLASSES < 2:\n        return tf.constant(0.0, dtype=tf.float32)\n\n    # Lấy kênh của lớp tumor (giả sử lớp 1 là tumor)\n    y_true_tumor = y_true[..., 1] # Ground truth cho lớp tumor (0 hoặc 1)\n    \n    # Chuyển đổi y_pred (softmax probabilities) thành dự đoán nhãn cứng (0 hoặc 1) cho lớp tumor\n    # Cách 1: Dựa trên xác suất cao nhất (argmax)\n    y_pred_labels = tf.argmax(y_pred, axis=-1) # Shape: (batch, H, W)\n    y_pred_tumor_binary = tf.cast(tf.equal(y_pred_labels, 1), tf.float32) # 1 nếu dự đoán là tumor (lớp 1), 0 nếu khác\n\n    # Cách 2: (Nếu chỉ có 2 lớp, có thể dùng ngưỡng 0.5 cho xác suất lớp tumor)\n    # y_pred_tumor_binary = tf.cast(y_pred[..., 1] > 0.5, tf.float32) # Chỉ phù hợp nếu N_CLASSES=2 và lớp 1 là tumor\n\n    # Flatten để tính toán\n    y_true_tumor_flat = tf.keras.backend.flatten(y_true_tumor)\n    y_pred_tumor_binary_flat = tf.keras.backend.flatten(y_pred_tumor_binary)\n\n    true_positives = tf.keras.backend.sum(y_true_tumor_flat * y_pred_tumor_binary_flat)\n    \n    if metric_type == 'precision':\n        predicted_positives = tf.keras.backend.sum(y_pred_tumor_binary_flat)\n        value = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n    elif metric_type == 'recall':\n        possible_positives = tf.keras.backend.sum(y_true_tumor_flat)\n        value = true_positives / (possible_positives + tf.keras.backend.epsilon())\n    else:\n        value = tf.constant(0.0, dtype=tf.float32)\n        \n    return value\n\ndef precision_tumor_metric(y_true, y_pred):\n    return precision_recall_tumor_base(y_true, y_pred, 'precision')\nprecision_tumor_metric.__name__ = 'precision_tumor' # Khớp với `metrics_to_plot`\n\ndef recall_tumor_metric(y_true, y_pred):\n    return precision_recall_tumor_base(y_true, y_pred, 'recall')\nrecall_tumor_metric.__name__ = 'recall_tumor' # Khớp với `metrics_to_plot`\n# --- KẾT THÚC METRICS MỚI ---\n\ndef categorical_focal_loss_wrapper(alpha=FOCAL_LOSS_ALPHA, gamma=FOCAL_LOSS_GAMMA):\n    def focal_loss_fn(y_true, y_pred):\n        epsilon = tf.keras.backend.epsilon(); y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n        cross_entropy = -y_true * tf.math.log(y_pred)\n        loss = alpha * tf.pow(1 - y_pred, gamma) * cross_entropy\n        return tf.reduce_mean(tf.reduce_sum(loss, axis=-1))\n    focal_loss_fn.__name__ = f'focal_loss_alpha{alpha}_gamma{gamma}'\n    return focal_loss_fn\n\ndef combined_loss_fn(y_true, y_pred, dice_w=DICE_LOSS_WEIGHT):\n    d_loss = dice_loss_tumor(y_true, y_pred)\n    if USE_FOCAL_LOSS_IN_COMBINED: ce_or_focal_loss = categorical_focal_loss_wrapper()(y_true, y_pred)\n    else: ce_or_focal_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true, y_pred))\n    return (dice_w * d_loss) + ((1.0 - dice_w) * ce_or_focal_loss)\ncombined_loss_fn.__name__ = f'combined_dice{DICE_LOSS_WEIGHT}_{\"focal\" if USE_FOCAL_LOSS_IN_COMBINED else \"cce\"}'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T02:30:32.108042Z","iopub.execute_input":"2025-06-02T02:30:32.108381Z","iopub.status.idle":"2025-06-02T02:30:32.128822Z","shell.execute_reply.started":"2025-06-02T02:30:32.108350Z","shell.execute_reply":"2025-06-02T02:30:32.127709Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import wandb # Đảm bảo wandb đã được import\nfrom datetime import datetime, timedelta # Để tạo tên run\n\n# --- Build và Compile Model ---\nmodel = build_unet((TARGET_SIZE, TARGET_SIZE, 1), N_CLASSES, L2_REG_FACTOR, DROPOUT_RATE, USE_ATTENTION_UNET)\noptimizer = tf.keras.optimizers.AdamW(learning_rate=LEARNING_RATE)\n\nif USE_COMBINED_LOSS:\n    loss_to_use = combined_loss_fn\nelse:\n    if USE_FOCAL_LOSS_IN_COMBINED:\n        loss_to_use = categorical_focal_loss_wrapper(alpha=FOCAL_LOSS_ALPHA, gamma=FOCAL_LOSS_GAMMA)\n    else:\n        loss_to_use = tf.keras.losses.CategoricalCrossentropy()\n        loss_to_use.__name__ = \"categorical_crossentropy\" # Đặt tên nếu là object\n\nloss_name_str = loss_to_use.__name__ if hasattr(loss_to_use, '__name__') else \"custom_loss\"\n\n# --- Định nghĩa danh sách metrics cho model.compile() ---\n# Đảm bảo các tên này sẽ xuất hiện trong history.history\nmetrics_to_compile = [ # Đổi tên biến để tránh nhầm lẫn với list dùng để log\n    dice_coef_metric_tumor,\n    iou_metric_tumor,\n    precision_tumor_metric,\n    recall_tumor_metric,\n    tf.keras.metrics.MeanIoU(num_classes=N_CLASSES, name='mean_iou_all'),\n    tf.keras.metrics.CategoricalAccuracy(name='acc') # Keras có thể trả về 'acc' hoặc 'categorical_accuracy'\n]\n# Tạo list các tên metric thực tế sẽ dùng để log (từ history.history)\n# Điều này quan trọng để đảm bảo key khớp khi log thủ công\n# Keras trả về tên của hàm/object metric, hoặc tên bạn đặt trong tf.keras.metrics.Metric(name='...')\n# Nếu metric là một hàm, history.history sẽ dùng tên hàm.\n# Nếu là một object tf.keras.metrics.Metric, nó sẽ dùng thuộc tính .name\n# Đối với CategoricalAccuracy, Keras có thể dùng 'acc' hoặc 'categorical_accuracy'.\n# Chúng ta sẽ xử lý điều này linh hoạt hơn trong vòng lặp log.\n\n# Các tên metric cơ bản mà chúng ta muốn log, không bao gồm 'loss' và 'val_loss' (vì chúng luôn có)\n# và 'acc'/'val_acc' (sẽ xử lý riêng)\nmetric_names_to_log_manually = []\nfor m in metrics_to_compile:\n    if hasattr(m, 'name'):\n        metric_names_to_log_manually.append(m.name)\n    elif hasattr(m, '__name__'):\n        metric_names_to_log_manually.append(m.__name__)\n# Loại bỏ 'acc' nếu có, vì sẽ xử lý riêng\nif 'acc' in metric_names_to_log_manually:\n    metric_names_to_log_manually.remove('acc')\nif 'categorical_accuracy' in metric_names_to_log_manually:\n     metric_names_to_log_manually.remove('categorical_accuracy')\n\n\nmodel.compile(optimizer=optimizer, loss=loss_to_use, metrics=metrics_to_compile)\nmodel.summary()\n\n# --- KHỞI TẠO WEIGHTS & BIASES ---\nif WANDB_API_KEY:\n    wandb.login(key=WANDB_API_KEY)\nelse:\n    try:\n        wandb.login() # Thử đăng nhập tương tác nếu không có key\n    except Exception as e:\n        print(f\"Lỗi khi đăng nhập WandB: {e}. Vui lòng đảm bảo bạn đã đăng nhập WandB.\")\n        # Có thể exit() ở đây nếu WandB là bắt buộc\n\n# Lấy giờ VN cho tên run\nnow_vn = datetime.utcnow() + timedelta(hours=7)\n# Chỉnh sửa format tên run để không có ký tự '/' không hợp lệ cho tên file/directory\nrun_name_wandb = f\"{MODEL_CHECKPOINT_BASENAME}_{loss_name_str}_attn{USE_ATTENTION_UNET}_\" + now_vn.strftime(\"%d%m%Y_%H%M%S\")\n\nwandb_config = {\n    \"epochs\": EPOCHS,\n    \"batch_size\": BATCH_SIZE,\n    \"learning_rate\": LEARNING_RATE,\n    \"target_size\": TARGET_SIZE,\n    \"n_classes\": N_CLASSES,\n    \"l2_reg_factor\": L2_REG_FACTOR,\n    \"dropout_rate\": DROPOUT_RATE,\n    \"use_combined_loss\": USE_COMBINED_LOSS,\n    \"dice_loss_weight\": DICE_LOSS_WEIGHT,\n    \"use_focal_loss_in_combined\": USE_FOCAL_LOSS_IN_COMBINED,\n    \"focal_loss_alpha\": FOCAL_LOSS_ALPHA,\n    \"focal_loss_gamma\": FOCAL_LOSS_GAMMA,\n    \"use_attention_unet\": USE_ATTENTION_UNET,\n    \"architecture\": model.name,\n    \"optimizer\": type(optimizer).__name__,\n    \"loss_function\": loss_name_str,\n    \"mean_pixel_train\": mean_pixel, # Giả sử mean_pixel, std_pixel đã được tính\n    \"std_pixel_train\": std_pixel,\n    \"monitor_metric_callbacks\": MONITOR_METRIC_CB # Metric cho các Keras callback\n}\n\nwandb.init(\n    project=WANDB_PROJECT_NAME,\n    entity=WANDB_ENTITY,\n    name=run_name_wandb,\n    config=wandb_config\n    # sync_tensorboard=True # Vẫn có thể dùng nếu bạn có TensorBoard callback\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T02:30:34.987805Z","iopub.execute_input":"2025-06-02T02:30:34.988198Z","iopub.status.idle":"2025-06-02T02:30:52.856920Z","shell.execute_reply.started":"2025-06-02T02:30:34.988168Z","shell.execute_reply":"2025-06-02T02:30:52.856208Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"UNet_filters64\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"UNet_filters64\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m640\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_2 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_3 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_4 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m590,080\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_5 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_6 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_7 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │      \u001b[38;5;34m4,719,616\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_8 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │      \u001b[38;5;34m9,438,208\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_9 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,097,664\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                           │                        │                │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m4,719,104\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m524,544\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │      \u001b[38;5;34m1,179,904\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_12             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m590,080\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_13             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m131,200\u001b[0m │ activation_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_2[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m295,040\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_14             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_15             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m32,832\u001b[0m │ activation_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_3[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m73,792\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_16             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_17             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m2\u001b[0m)    │            \u001b[38;5;34m130\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                           │                        │                │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_12             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_13             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_14             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_15             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_16             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_17             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,054,210\u001b[0m (118.46 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,054,210</span> (118.46 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,042,434\u001b[0m (118.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,042,434</span> (118.42 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m11,776\u001b[0m (46.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,776</span> (46.00 KB)\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnganltt23\u001b[0m (\u001b[33mnganltt2333\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250602_023045-0hnjq36f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nganltt2333/btxrd-project/runs/0hnjq36f' target=\"_blank\">unet_model_combined_dice0.6_focal_attnFalse_02062025_093045</a></strong> to <a href='https://wandb.ai/nganltt2333/btxrd-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nganltt2333/btxrd-project' target=\"_blank\">https://wandb.ai/nganltt2333/btxrd-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nganltt2333/btxrd-project/runs/0hnjq36f' target=\"_blank\">https://wandb.ai/nganltt2333/btxrd-project/runs/0hnjq36f</a>"},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nganltt2333/btxrd-project/runs/0hnjq36f?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x782f4c11ead0>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport warnings\n\nclass CustomModelCheckpoint(tf.keras.callbacks.ModelCheckpoint):\n    def __init__(self, filepath, monitor='val_loss', verbose=0,\n                 save_best_only=False, save_weights_only=False,\n                 mode='auto', save_freq='epoch', initial_value_threshold=None, # Thêm initial_value_threshold\n                 **kwargs): # Thêm **kwargs để bắt các tham số không mong muốn\n\n        self.custom_filepath = filepath\n        temp_filepath = filepath\n        if not temp_filepath.endswith(\".keras\"):\n            base, ext = os.path.splitext(temp_filepath)\n            temp_filepath = base + \".keras\"\n\n        # Truyền tất cả các tham số mà ModelCheckpoint gốc chấp nhận\n        super().__init__(filepath=temp_filepath, monitor=monitor, verbose=verbose,\n                         save_best_only=save_best_only,\n                         save_weights_only=save_weights_only,\n                         mode=mode, save_freq=save_freq,\n                         initial_value_threshold=initial_value_threshold, # Truyền vào đây\n                         **kwargs) # Truyền kwargs\n\n        self.filepath = self.custom_filepath # Đặt lại filepath thật sau khi super init\n\n        # Đảm bảo các thuộc tính cần thiết được khởi tạo nếu save_freq là 'epoch'\n        # Lớp cha (ModelCheckpoint) nên đã xử lý việc này dựa trên save_freq.\n        # Tuy nhiên, để chắc chắn, chúng ta có thể kiểm tra và gán giá trị mặc định.\n        if not hasattr(self, 'epochs_since_last_save'):\n            self.epochs_since_last_save = 0\n        if not hasattr(self, 'period'):\n             # period là 1 nếu save_freq='epoch', hoặc giá trị của save_freq nếu là số nguyên\n            if save_freq == 'epoch':\n                self.period = 1\n            elif isinstance(save_freq, int):\n                self.period = save_freq\n            else: # Trường hợp không xác định, gán mặc định là 1\n                self.period = 1\n\n\n    def _save_model(self, epoch, batch, logs):\n        \"\"\"Saves the model.\n\n        Args:\n            epoch: the epoch finishing.\n            batch: batch ending (if `save_freq` is numeric).\n            logs: metric results for the current training epoch/batch.\n        \"\"\"\n        logs = logs or {}\n\n        # Điều kiện này dựa trên self.epochs_since_last_save và self.period\n        if isinstance(self.save_freq, int) or self.epochs_since_last_save >= self.period -1: # Sửa ở đây, thường là period -1\n            self.epochs_since_last_save = 0 # Reset sau khi kiểm tra\n            filepath = self._get_file_path(epoch, batch, logs)\n\n            try:\n                if self.save_best_only:\n                    current = logs.get(self.monitor)\n                    if current is None:\n                        warnings.warn(\n                            f\"Can save best model only with {self.monitor} available, \"\n                            \"skipping.\",\n                            RuntimeWarning,\n                        )\n                    else:\n                        if self.monitor_op(current, self.best):\n                            if self.verbose > 0:\n                                print(\n                                    f\"\\nEpoch {epoch + 1}: {self.monitor} improved \"\n                                    f\"from {self.best:.5f} to {current:.5f}, \"\n                                    f\"saving model to {filepath}\"\n                                )\n                            self.best = current\n                            if self.save_weights_only:\n                                self.model.save_weights(\n                                    filepath, overwrite=True,\n                                )\n                            else:\n                                self.model.save(filepath, save_format=\"h5\", overwrite=True)\n                        else:\n                            if self.verbose > 0:\n                                print(\n                                    f\"\\nEpoch {epoch + 1}: {self.monitor} did not \"\n                                    f\"improve from {self.best:.5f}\"\n                                )\n                else: # Không phải save_best_only, lưu mỗi khi save_freq đạt\n                    if self.verbose > 0:\n                        print(f\"\\nEpoch {epoch + 1}: saving model to {filepath}\")\n                    if self.save_weights_only:\n                        self.model.save_weights(\n                            filepath, overwrite=True,\n                        )\n                    else:\n                        self.model.save(filepath, save_format=\"h5\", overwrite=True)\n\n                # self._maybe_remove_file(filepath) # Cẩn thận với hàm này, nó có thể không hoạt động đúng\n                                                  # nếu self.filepath không phải là .keras\n            except IsADirectoryError:\n                raise IOError(\n                    \"Please specify a non-directory filepath for \"\n                    f\"ModelCheckpoint. Filepath: {filepath}\"\n                )\n            except Exception as e:\n                warnings.warn(f\"Error LƯU model: {e}\", RuntimeWarning)\n                raise e\n        # Tăng epochs_since_last_save sau mỗi lần gọi _save_model (thường là cuối epoch)\n        self.epochs_since_last_save += 1\n\n# Đường dẫn lưu checkpoint\ncheckpoint_path_h5 = f\"{MODEL_CHECKPOINT_BASENAME}_{run_name_wandb}.h5\"\n\n# MONITOR_METRIC_CB ('val_dice_coef_metric_tumor') phải là một key có trong history.history khi val_ds được dùng\nkeras_callbacks = [\n    CustomModelCheckpoint( # SỬ DỤNG CUSTOM CALLBACK\n        filepath=checkpoint_path_h5,\n        save_best_only=True,\n        monitor=MONITOR_METRIC_CB,\n        mode='max',\n        verbose=1\n    ),\n    tf.keras.callbacks.EarlyStopping(\n        monitor=MONITOR_METRIC_CB,\n        patience=PATIENCE_EARLY_STOPPING,\n        mode='max',\n        restore_best_weights=True,\n        verbose=1\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor=MONITOR_METRIC_CB,\n        factor=0.3,\n        patience=PATIENCE_REDUCE_LR,\n        mode='max',\n        min_lr=1e-7,\n        verbose=1\n    ),\n    tf.keras.callbacks.TensorBoard(\n        log_dir=TENSORBOARD_LOG_DIR,\n        histogram_freq=1\n    )\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T02:30:57.955362Z","iopub.execute_input":"2025-06-02T02:30:57.955722Z","iopub.status.idle":"2025-06-02T02:30:57.969547Z","shell.execute_reply.started":"2025-06-02T02:30:57.955696Z","shell.execute_reply":"2025-06-02T02:30:57.968647Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Class Weights\npix_cls0 = 0; pix_cls1 = 0\n# Giả sử train_mask_paths đã được tạo ở Đoạn 2\nif 'train_mask_paths' in locals() and train_mask_paths: # Kiểm tra biến tồn tại\n    for mask_p in tqdm(train_mask_paths, desc=\"Đếm pixels cho class weights\"):\n        try:\n            m = create_mask_pil((TARGET_SIZE, TARGET_SIZE), mask_p)\n            m_np = (np.array(m) > 128).astype(np.uint8)\n            pix_cls0 += np.sum(m_np == 0)\n            pix_cls1 += np.sum(m_np == 1)\n        except Exception as e:\n            print(f\"Lỗi khi xử lý mask {mask_p} cho class weights: {e}\")\n            continue\nelse:\n    print(\"Cảnh báo: train_mask_paths không tồn tại hoặc rỗng, không thể tính class weights.\")\n\nclass_weights = None # Khởi tạo class_weights\nif pix_cls1 > 0 and pix_cls0 > 0:\n    total_pix = float(pix_cls0 + pix_cls1)\n    w0 = (total_pix / (N_CLASSES * float(pix_cls0)))\n    w1 = (total_pix / (N_CLASSES * float(pix_cls1)))\n    class_weights = {0: w0, 1: w1} # Gán giá trị cho class_weights\n    print(f\"Class weights đã tính: Lớp 0: {w0:.4f}, Lớp 1: {w1:.4f}\")\n    if w1 < w0 :\n        print(\"Cảnh báo: Trọng số lớp khối u (1) nhỏ hơn lớp nền (0). Kiểm tra lại số lượng pixel hoặc dữ liệu.\")\n    if wandb.run:\n        wandb.config.update({\"class_weight_0\": w0, \"class_weight_1\": w1, \"calculated_class_weights\": True})\nelse:\n    print(\"Không tính được class weights (số pixel lớp 0 hoặc 1 bằng 0 hoặc train_mask_paths rỗng). Sử dụng None.\")\n    if wandb.run:\n        wandb.config.update({\"calculated_class_weights\": False})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T02:31:02.134702Z","iopub.execute_input":"2025-06-02T02:31:02.135051Z","iopub.status.idle":"2025-06-02T02:31:09.780267Z","shell.execute_reply.started":"2025-06-02T02:31:02.135024Z","shell.execute_reply":"2025-06-02T02:31:09.779389Z"}},"outputs":[{"name":"stderr","text":"Đếm pixels cho class weights: 100%|██████████| 1344/1344 [00:07<00:00, 176.12it/s]","output_type":"stream"},{"name":"stdout","text":"Class weights đã tính: Lớp 0: 0.5089, Lớp 1: 28.6592\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Huấn luyện Model với vòng lặp thủ công và log thủ công lên WandB\n\n# Kiểm tra sự tồn tại của train_ds và val_ds (nếu val_image_paths có)\nif 'train_ds' not in locals() or not train_ds:\n    print(\"Lỗi: Tập huấn luyện (train_ds) chưa được tạo hoặc rỗng.\")\n    if wandb.run: wandb.finish(exit_code=1)\n    exit()\n\nuse_validation = 'val_image_paths' in locals() and val_image_paths and 'val_ds' in locals() and val_ds\nif 'val_image_paths' in locals() and val_image_paths and ('val_ds' not in locals() or not val_ds):\n    print(\"Lỗi: Có val_image_paths nhưng tập validation (val_ds) chưa được tạo hoặc rỗng.\")\n    if wandb.run: wandb.finish(exit_code=1)\n    exit()\n\nprint(f\"\\nBắt đầu huấn luyện cho {EPOCHS} epochs...\")\n\nfor epoch in range(EPOCHS):\n    print(f\"\\n--- Epoch {epoch + 1}/{EPOCHS} ---\")\n\n    history = model.fit(\n        train_ds,\n        validation_data=val_ds if use_validation else None,\n        epochs=1, # CHỈ HUẤN LUYỆN 1 EPOCH MỖI LẦN GỌI FIT\n        class_weight=class_weights, # Từ Đoạn 6\n        callbacks=keras_callbacks, # Callbacks Keras tiêu chuẩn từ Đoạn 5\n        verbose=1\n    )\n\n    current_logs = history.history\n    if not current_logs:\n        print(f\"Cảnh báo: Không có logs nào được trả về từ model.fit() ở epoch {epoch + 1}.\")\n        continue\n\n    # --- Ghi log thủ công cho W&B ---\n    log_data_to_wandb = {\"epoch\": epoch + 1}\n\n    # Metrics huấn luyện\n    log_data_to_wandb[\"loss\"] = current_logs.get(\"loss\", [None])[0]\n    # Xử lý 'acc' hoặc 'categorical_accuracy' cho training\n    train_acc_key = None\n    if \"acc\" in current_logs:\n        train_acc_key = \"acc\"\n    elif \"categorical_accuracy\" in current_logs:\n        train_acc_key = \"categorical_accuracy\"\n    if train_acc_key:\n        log_data_to_wandb[train_acc_key] = current_logs.get(train_acc_key, [None])[0]\n\n    # Log các metrics tùy chỉnh khác cho training\n    for metric_name in metric_names_to_log_manually: # Từ Đoạn 4\n        if metric_name in current_logs:\n            log_data_to_wandb[metric_name] = current_logs.get(metric_name, [None])[0]\n\n\n    # Metrics validation (nếu có)\n    if use_validation:\n        log_data_to_wandb[\"val_loss\"] = current_logs.get(\"val_loss\", [None])[0]\n        # Xử lý 'val_acc' hoặc 'val_categorical_accuracy'\n        val_acc_key = None\n        if \"val_acc\" in current_logs:\n            val_acc_key = \"val_acc\"\n        elif \"val_categorical_accuracy\" in current_logs:\n            val_acc_key = \"val_categorical_accuracy\"\n        if val_acc_key:\n            log_data_to_wandb[val_acc_key] = current_logs.get(val_acc_key, [None])[0]\n\n        # Log các metrics tùy chỉnh khác cho validation\n        for metric_name in metric_names_to_log_manually: # Từ Đoạn 4\n            val_metric_key = f\"val_{metric_name}\"\n            if val_metric_key in current_logs:\n                log_data_to_wandb[val_metric_key] = current_logs.get(val_metric_key, [None])[0]\n\n    wandb.log(log_data_to_wandb)\n    print(f\"Đã log metrics cho epoch {epoch + 1} lên WandB.\")\n\n    # Kiểm tra điều kiện dừng sớm từ EarlyStopping callback\n    if model.stop_training:\n        print(f\"Huấn luyện dừng sớm bởi EarlyStopping callback sau epoch {epoch + 1}.\")\n        break\n\nprint(\"\\nHuấn luyện hoàn tất (hoặc dừng sớm)!\")\n\n# Kết thúc run WandB\nif wandb.run:\n    # (Tùy chọn) Log model tốt nhất như một artifact\n    # Giả sử ModelCheckpoint đã lưu model tốt nhất vào checkpoint_path\n    if os.path.exists(checkpoint_path_h5):\n        print(f\"Đang log model tốt nhất từ: {checkpoint_path_h5}\")\n        best_model_artifact = wandb.Artifact(\n            f'{MODEL_CHECKPOINT_BASENAME}-best_model',\n            type='model',\n            description=f'Best model based on {MONITOR_METRIC_CB} from run {run_name_wandb}',\n            metadata=dict(wandb.config) # Lưu config của run vào metadata artifact\n        )\n        best_model_artifact.add_file(checkpoint_path_h5)\n        wandb.log_artifact(best_model_artifact)\n        print(\"Đã log model tốt nhất lên WandB Artifacts.\")\n    else:\n        print(f\"Không tìm thấy model checkpoint tại: {checkpoint_path_h5} để log artifact.\")\n\n    wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T02:31:13.204448Z","iopub.execute_input":"2025-06-02T02:31:13.204751Z","execution_failed":"2025-06-02T14:29:40.749Z"}},"outputs":[{"name":"stdout","text":"\nBắt đầu huấn luyện cho 300 epochs...\n\n--- Epoch 1/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.8371 - dice_coef_metric_tumor: 0.0578 - loss: 0.6993 - mean_iou_all: 0.2510 - precision_tumor: 0.0561 - recall_tumor: 0.5049 - tumor_iou: 0.0301\nEpoch 1: val_dice_coef_metric_tumor improved from -inf to 0.07112, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 957ms/step - acc: 0.8372 - dice_coef_metric_tumor: 0.0578 - loss: 0.6991 - mean_iou_all: 0.2510 - precision_tumor: 0.0561 - recall_tumor: 0.5049 - tumor_iou: 0.0301 - val_acc: 0.7900 - val_dice_coef_metric_tumor: 0.0711 - val_loss: 0.6439 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0542 - val_recall_tumor: 0.7222 - val_tumor_iou: 0.0376 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 1 lên WandB.\n\n--- Epoch 2/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.8726 - dice_coef_metric_tumor: 0.1015 - loss: 0.6259 - mean_iou_all: 0.2528 - precision_tumor: 0.0786 - recall_tumor: 0.5658 - tumor_iou: 0.0545\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.07112\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.8727 - dice_coef_metric_tumor: 0.1014 - loss: 0.6258 - mean_iou_all: 0.2528 - precision_tumor: 0.0786 - recall_tumor: 0.5654 - tumor_iou: 0.0545 - val_acc: 0.8907 - val_dice_coef_metric_tumor: 0.0490 - val_loss: 0.6385 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0390 - val_recall_tumor: 0.1834 - val_tumor_iou: 0.0255 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 2 lên WandB.\n\n--- Epoch 3/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.8975 - dice_coef_metric_tumor: 0.1264 - loss: 0.5991 - mean_iou_all: 0.2531 - precision_tumor: 0.0943 - recall_tumor: 0.5262 - tumor_iou: 0.0693\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.07112\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.8975 - dice_coef_metric_tumor: 0.1263 - loss: 0.5990 - mean_iou_all: 0.2532 - precision_tumor: 0.0943 - recall_tumor: 0.5260 - tumor_iou: 0.0692 - val_acc: 0.9781 - val_dice_coef_metric_tumor: 0.0710 - val_loss: 0.6129 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0449 - val_recall_tumor: 0.0201 - val_tumor_iou: 0.0375 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 3 lên WandB.\n\n--- Epoch 4/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9061 - dice_coef_metric_tumor: 0.1297 - loss: 0.5819 - mean_iou_all: 0.2538 - precision_tumor: 0.0949 - recall_tumor: 0.4785 - tumor_iou: 0.0714\nEpoch 1: val_dice_coef_metric_tumor improved from 0.07112 to 0.07686, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 928ms/step - acc: 0.9061 - dice_coef_metric_tumor: 0.1296 - loss: 0.5818 - mean_iou_all: 0.2538 - precision_tumor: 0.0948 - recall_tumor: 0.4782 - tumor_iou: 0.0714 - val_acc: 0.9802 - val_dice_coef_metric_tumor: 0.0769 - val_loss: 0.6054 - val_mean_iou_all: 0.2920 - val_precision_tumor: 0.0863 - val_recall_tumor: 0.0191 - val_tumor_iou: 0.0405 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 4 lên WandB.\n\n--- Epoch 5/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9036 - dice_coef_metric_tumor: 0.1430 - loss: 0.5750 - mean_iou_all: 0.2524 - precision_tumor: 0.1055 - recall_tumor: 0.5254 - tumor_iou: 0.0795\nEpoch 1: val_dice_coef_metric_tumor improved from 0.07686 to 0.11402, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 926ms/step - acc: 0.9037 - dice_coef_metric_tumor: 0.1429 - loss: 0.5749 - mean_iou_all: 0.2524 - precision_tumor: 0.1055 - recall_tumor: 0.5249 - tumor_iou: 0.0795 - val_acc: 0.9570 - val_dice_coef_metric_tumor: 0.1140 - val_loss: 0.5828 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1229 - val_recall_tumor: 0.2084 - val_tumor_iou: 0.0626 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 5 lên WandB.\n\n--- Epoch 6/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9267 - dice_coef_metric_tumor: 0.1697 - loss: 0.5521 - mean_iou_all: 0.2551 - precision_tumor: 0.1251 - recall_tumor: 0.4935 - tumor_iou: 0.0965\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.11402\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9267 - dice_coef_metric_tumor: 0.1696 - loss: 0.5521 - mean_iou_all: 0.2551 - precision_tumor: 0.1251 - recall_tumor: 0.4932 - tumor_iou: 0.0964 - val_acc: 0.9584 - val_dice_coef_metric_tumor: 0.0768 - val_loss: 0.6074 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0818 - val_recall_tumor: 0.1372 - val_tumor_iou: 0.0414 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 6 lên WandB.\n\n--- Epoch 7/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9276 - dice_coef_metric_tumor: 0.1727 - loss: 0.5438 - mean_iou_all: 0.2528 - precision_tumor: 0.1261 - recall_tumor: 0.4711 - tumor_iou: 0.0989\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.11402\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9276 - dice_coef_metric_tumor: 0.1727 - loss: 0.5437 - mean_iou_all: 0.2528 - precision_tumor: 0.1260 - recall_tumor: 0.4709 - tumor_iou: 0.0989 - val_acc: 0.9812 - val_dice_coef_metric_tumor: 0.0233 - val_loss: 0.6355 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0596 - val_recall_tumor: 0.0131 - val_tumor_iou: 0.0121 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 7 lên WandB.\n\n--- Epoch 8/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815ms/step - acc: 0.9370 - dice_coef_metric_tumor: 0.1883 - loss: 0.5465 - mean_iou_all: 0.2513 - precision_tumor: 0.1413 - recall_tumor: 0.4492 - tumor_iou: 0.1081\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.11402\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9370 - dice_coef_metric_tumor: 0.1882 - loss: 0.5465 - mean_iou_all: 0.2513 - precision_tumor: 0.1412 - recall_tumor: 0.4491 - tumor_iou: 0.1081 - val_acc: 0.9832 - val_dice_coef_metric_tumor: 0.0216 - val_loss: 0.6334 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0566 - val_recall_tumor: 0.0025 - val_tumor_iou: 0.0110 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 8 lên WandB.\n\n--- Epoch 9/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9397 - dice_coef_metric_tumor: 0.1888 - loss: 0.5372 - mean_iou_all: 0.2524 - precision_tumor: 0.1413 - recall_tumor: 0.4439 - tumor_iou: 0.1087\nEpoch 1: val_dice_coef_metric_tumor improved from 0.11402 to 0.12287, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 926ms/step - acc: 0.9397 - dice_coef_metric_tumor: 0.1888 - loss: 0.5372 - mean_iou_all: 0.2524 - precision_tumor: 0.1412 - recall_tumor: 0.4439 - tumor_iou: 0.1087 - val_acc: 0.8288 - val_dice_coef_metric_tumor: 0.1229 - val_loss: 0.5851 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0709 - val_recall_tumor: 0.7910 - val_tumor_iou: 0.0673 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 9 lên WandB.\n\n--- Epoch 10/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9381 - dice_coef_metric_tumor: 0.1811 - loss: 0.5384 - mean_iou_all: 0.2527 - precision_tumor: 0.1349 - recall_tumor: 0.4196 - tumor_iou: 0.1046\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.12287\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9381 - dice_coef_metric_tumor: 0.1810 - loss: 0.5383 - mean_iou_all: 0.2527 - precision_tumor: 0.1348 - recall_tumor: 0.4195 - tumor_iou: 0.1046 - val_acc: 0.9836 - val_dice_coef_metric_tumor: 0.0025 - val_loss: 0.6486 - val_mean_iou_all: 0.2972 - val_precision_tumor: 0.0391 - val_recall_tumor: 2.9925e-04 - val_tumor_iou: 0.0013 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 10 lên WandB.\n\n--- Epoch 11/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815ms/step - acc: 0.9351 - dice_coef_metric_tumor: 0.1925 - loss: 0.5318 - mean_iou_all: 0.2522 - precision_tumor: 0.1402 - recall_tumor: 0.4733 - tumor_iou: 0.1113\nEpoch 1: val_dice_coef_metric_tumor improved from 0.12287 to 0.15543, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 925ms/step - acc: 0.9351 - dice_coef_metric_tumor: 0.1924 - loss: 0.5318 - mean_iou_all: 0.2522 - precision_tumor: 0.1402 - recall_tumor: 0.4732 - tumor_iou: 0.1112 - val_acc: 0.9547 - val_dice_coef_metric_tumor: 0.1554 - val_loss: 0.5508 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1408 - val_recall_tumor: 0.3182 - val_tumor_iou: 0.0882 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 11 lên WandB.\n\n--- Epoch 12/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9396 - dice_coef_metric_tumor: 0.2032 - loss: 0.5267 - mean_iou_all: 0.2515 - precision_tumor: 0.1509 - recall_tumor: 0.4750 - tumor_iou: 0.1187\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.15543\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9396 - dice_coef_metric_tumor: 0.2032 - loss: 0.5267 - mean_iou_all: 0.2515 - precision_tumor: 0.1509 - recall_tumor: 0.4749 - tumor_iou: 0.1187 - val_acc: 0.9766 - val_dice_coef_metric_tumor: 0.0762 - val_loss: 0.5976 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1226 - val_recall_tumor: 0.0755 - val_tumor_iou: 0.0419 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 12 lên WandB.\n\n--- Epoch 13/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9445 - dice_coef_metric_tumor: 0.2091 - loss: 0.5232 - mean_iou_all: 0.2525 - precision_tumor: 0.1563 - recall_tumor: 0.4518 - tumor_iou: 0.1224\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.15543\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9446 - dice_coef_metric_tumor: 0.2091 - loss: 0.5231 - mean_iou_all: 0.2525 - precision_tumor: 0.1563 - recall_tumor: 0.4517 - tumor_iou: 0.1223 - val_acc: 0.9621 - val_dice_coef_metric_tumor: 0.1281 - val_loss: 0.5659 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1298 - val_recall_tumor: 0.2138 - val_tumor_iou: 0.0720 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 13 lên WandB.\n\n--- Epoch 14/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9465 - dice_coef_metric_tumor: 0.2175 - loss: 0.5101 - mean_iou_all: 0.2512 - precision_tumor: 0.1652 - recall_tumor: 0.4539 - tumor_iou: 0.1286\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.15543\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9465 - dice_coef_metric_tumor: 0.2174 - loss: 0.5100 - mean_iou_all: 0.2512 - precision_tumor: 0.1651 - recall_tumor: 0.4538 - tumor_iou: 0.1286 - val_acc: 0.9745 - val_dice_coef_metric_tumor: 0.0810 - val_loss: 0.5938 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1141 - val_recall_tumor: 0.0883 - val_tumor_iou: 0.0443 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 14 lên WandB.\n\n--- Epoch 15/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9471 - dice_coef_metric_tumor: 0.2067 - loss: 0.5199 - mean_iou_all: 0.2517 - precision_tumor: 0.1565 - recall_tumor: 0.4160 - tumor_iou: 0.1215\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.15543\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9471 - dice_coef_metric_tumor: 0.2066 - loss: 0.5198 - mean_iou_all: 0.2517 - precision_tumor: 0.1565 - recall_tumor: 0.4159 - tumor_iou: 0.1214 - val_acc: 0.9768 - val_dice_coef_metric_tumor: 0.0755 - val_loss: 0.5969 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1195 - val_recall_tumor: 0.0733 - val_tumor_iou: 0.0415 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 15 lên WandB.\n\n--- Epoch 16/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815ms/step - acc: 0.9435 - dice_coef_metric_tumor: 0.2137 - loss: 0.5176 - mean_iou_all: 0.2511 - precision_tumor: 0.1594 - recall_tumor: 0.4738 - tumor_iou: 0.1259\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.15543\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 916ms/step - acc: 0.9435 - dice_coef_metric_tumor: 0.2137 - loss: 0.5175 - mean_iou_all: 0.2511 - precision_tumor: 0.1593 - recall_tumor: 0.4736 - tumor_iou: 0.1259 - val_acc: 0.9738 - val_dice_coef_metric_tumor: 0.1082 - val_loss: 0.5754 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1416 - val_recall_tumor: 0.1220 - val_tumor_iou: 0.0603 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 16 lên WandB.\n\n--- Epoch 17/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9523 - dice_coef_metric_tumor: 0.2183 - loss: 0.5042 - mean_iou_all: 0.2519 - precision_tumor: 0.1720 - recall_tumor: 0.4147 - tumor_iou: 0.1292\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.15543\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9523 - dice_coef_metric_tumor: 0.2182 - loss: 0.5042 - mean_iou_all: 0.2519 - precision_tumor: 0.1719 - recall_tumor: 0.4146 - tumor_iou: 0.1291 - val_acc: 0.9622 - val_dice_coef_metric_tumor: 0.1522 - val_loss: 0.5493 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1397 - val_recall_tumor: 0.2510 - val_tumor_iou: 0.0864 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 17 lên WandB.\n\n--- Epoch 18/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9518 - dice_coef_metric_tumor: 0.2249 - loss: 0.5057 - mean_iou_all: 0.2514 - precision_tumor: 0.1738 - recall_tumor: 0.4219 - tumor_iou: 0.1329\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.15543\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9518 - dice_coef_metric_tumor: 0.2248 - loss: 0.5057 - mean_iou_all: 0.2514 - precision_tumor: 0.1737 - recall_tumor: 0.4218 - tumor_iou: 0.1328 - val_acc: 0.9822 - val_dice_coef_metric_tumor: 0.0300 - val_loss: 0.6235 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0999 - val_recall_tumor: 0.0182 - val_tumor_iou: 0.0157 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 18 lên WandB.\n\n--- Epoch 19/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9495 - dice_coef_metric_tumor: 0.2212 - loss: 0.5202 - mean_iou_all: 0.2513 - precision_tumor: 0.1703 - recall_tumor: 0.4396 - tumor_iou: 0.1302\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.15543\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9495 - dice_coef_metric_tumor: 0.2211 - loss: 0.5201 - mean_iou_all: 0.2513 - precision_tumor: 0.1703 - recall_tumor: 0.4395 - tumor_iou: 0.1301 - val_acc: 0.9754 - val_dice_coef_metric_tumor: 0.1237 - val_loss: 0.5656 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1722 - val_recall_tumor: 0.1322 - val_tumor_iou: 0.0702 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 19 lên WandB.\n\n--- Epoch 20/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9567 - dice_coef_metric_tumor: 0.2328 - loss: 0.4931 - mean_iou_all: 0.2512 - precision_tumor: 0.1866 - recall_tumor: 0.4058 - tumor_iou: 0.1390\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.15543\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9567 - dice_coef_metric_tumor: 0.2327 - loss: 0.4930 - mean_iou_all: 0.2512 - precision_tumor: 0.1866 - recall_tumor: 0.4058 - tumor_iou: 0.1389 - val_acc: 0.9651 - val_dice_coef_metric_tumor: 0.1426 - val_loss: 0.5540 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1392 - val_recall_tumor: 0.2153 - val_tumor_iou: 0.0810 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 20 lên WandB.\n\n--- Epoch 21/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9521 - dice_coef_metric_tumor: 0.2396 - loss: 0.5029 - mean_iou_all: 0.2521 - precision_tumor: 0.1954 - recall_tumor: 0.4550 - tumor_iou: 0.1441\nEpoch 1: val_dice_coef_metric_tumor improved from 0.15543 to 0.16282, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 928ms/step - acc: 0.9521 - dice_coef_metric_tumor: 0.2394 - loss: 0.5029 - mean_iou_all: 0.2521 - precision_tumor: 0.1952 - recall_tumor: 0.4550 - tumor_iou: 0.1440 - val_acc: 0.8893 - val_dice_coef_metric_tumor: 0.1628 - val_loss: 0.5510 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.0980 - val_recall_tumor: 0.7083 - val_tumor_iou: 0.0921 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 21 lên WandB.\n\n--- Epoch 22/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9545 - dice_coef_metric_tumor: 0.2500 - loss: 0.4931 - mean_iou_all: 0.2513 - precision_tumor: 0.1982 - recall_tumor: 0.4428 - tumor_iou: 0.1494\nEpoch 1: val_dice_coef_metric_tumor improved from 0.16282 to 0.16495, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 925ms/step - acc: 0.9545 - dice_coef_metric_tumor: 0.2499 - loss: 0.4930 - mean_iou_all: 0.2513 - precision_tumor: 0.1982 - recall_tumor: 0.4426 - tumor_iou: 0.1494 - val_acc: 0.9544 - val_dice_coef_metric_tumor: 0.1650 - val_loss: 0.5433 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1350 - val_recall_tumor: 0.3166 - val_tumor_iou: 0.0952 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 22 lên WandB.\n\n--- Epoch 23/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9577 - dice_coef_metric_tumor: 0.2575 - loss: 0.4855 - mean_iou_all: 0.2516 - precision_tumor: 0.2023 - recall_tumor: 0.4635 - tumor_iou: 0.1544\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.16495\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9577 - dice_coef_metric_tumor: 0.2574 - loss: 0.4855 - mean_iou_all: 0.2516 - precision_tumor: 0.2022 - recall_tumor: 0.4633 - tumor_iou: 0.1544 - val_acc: 0.9659 - val_dice_coef_metric_tumor: 0.1559 - val_loss: 0.5468 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1505 - val_recall_tumor: 0.2248 - val_tumor_iou: 0.0900 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 23 lên WandB.\n\n--- Epoch 24/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9562 - dice_coef_metric_tumor: 0.2638 - loss: 0.4859 - mean_iou_all: 0.2515 - precision_tumor: 0.2137 - recall_tumor: 0.4636 - tumor_iou: 0.1605\nEpoch 1: val_dice_coef_metric_tumor improved from 0.16495 to 0.18570, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 925ms/step - acc: 0.9562 - dice_coef_metric_tumor: 0.2637 - loss: 0.4859 - mean_iou_all: 0.2515 - precision_tumor: 0.2136 - recall_tumor: 0.4634 - tumor_iou: 0.1604 - val_acc: 0.9614 - val_dice_coef_metric_tumor: 0.1857 - val_loss: 0.5280 - val_mean_iou_all: 0.2510 - val_precision_tumor: 0.1573 - val_recall_tumor: 0.3165 - val_tumor_iou: 0.1076 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 24 lên WandB.\n\n--- Epoch 25/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9607 - dice_coef_metric_tumor: 0.2598 - loss: 0.4736 - mean_iou_all: 0.2540 - precision_tumor: 0.2106 - recall_tumor: 0.4203 - tumor_iou: 0.1572\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18570\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9607 - dice_coef_metric_tumor: 0.2597 - loss: 0.4735 - mean_iou_all: 0.2540 - precision_tumor: 0.2106 - recall_tumor: 0.4203 - tumor_iou: 0.1571 - val_acc: 0.9644 - val_dice_coef_metric_tumor: 0.1713 - val_loss: 0.5375 - val_mean_iou_all: 0.2505 - val_precision_tumor: 0.1582 - val_recall_tumor: 0.2642 - val_tumor_iou: 0.0996 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 25 lên WandB.\n\n--- Epoch 26/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9589 - dice_coef_metric_tumor: 0.2602 - loss: 0.4827 - mean_iou_all: 0.2526 - precision_tumor: 0.2124 - recall_tumor: 0.4453 - tumor_iou: 0.1586\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18570\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9589 - dice_coef_metric_tumor: 0.2601 - loss: 0.4826 - mean_iou_all: 0.2526 - precision_tumor: 0.2124 - recall_tumor: 0.4452 - tumor_iou: 0.1585 - val_acc: 0.9748 - val_dice_coef_metric_tumor: 0.1507 - val_loss: 0.5478 - val_mean_iou_all: 0.2502 - val_precision_tumor: 0.1892 - val_recall_tumor: 0.1617 - val_tumor_iou: 0.0873 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 26 lên WandB.\n\n--- Epoch 27/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9625 - dice_coef_metric_tumor: 0.2738 - loss: 0.4686 - mean_iou_all: 0.2520 - precision_tumor: 0.2268 - recall_tumor: 0.4347 - tumor_iou: 0.1686\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18570\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9625 - dice_coef_metric_tumor: 0.2737 - loss: 0.4686 - mean_iou_all: 0.2520 - precision_tumor: 0.2268 - recall_tumor: 0.4345 - tumor_iou: 0.1685 - val_acc: 0.9711 - val_dice_coef_metric_tumor: 0.1494 - val_loss: 0.5498 - val_mean_iou_all: 0.2519 - val_precision_tumor: 0.1781 - val_recall_tumor: 0.1805 - val_tumor_iou: 0.0873 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 27 lên WandB.\n\n--- Epoch 28/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9619 - dice_coef_metric_tumor: 0.2660 - loss: 0.4842 - mean_iou_all: 0.2542 - precision_tumor: 0.2266 - recall_tumor: 0.4221 - tumor_iou: 0.1626\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18570\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9619 - dice_coef_metric_tumor: 0.2659 - loss: 0.4841 - mean_iou_all: 0.2542 - precision_tumor: 0.2266 - recall_tumor: 0.4221 - tumor_iou: 0.1625 - val_acc: 0.9795 - val_dice_coef_metric_tumor: 0.1217 - val_loss: 0.5646 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.2188 - val_recall_tumor: 0.1031 - val_tumor_iou: 0.0690 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 28 lên WandB.\n\n--- Epoch 29/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9568 - dice_coef_metric_tumor: 0.2493 - loss: 0.4828 - mean_iou_all: 0.2513 - precision_tumor: 0.2022 - recall_tumor: 0.4463 - tumor_iou: 0.1503\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18570\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9568 - dice_coef_metric_tumor: 0.2493 - loss: 0.4827 - mean_iou_all: 0.2513 - precision_tumor: 0.2022 - recall_tumor: 0.4462 - tumor_iou: 0.1503 - val_acc: 0.9742 - val_dice_coef_metric_tumor: 0.1487 - val_loss: 0.5483 - val_mean_iou_all: 0.2501 - val_precision_tumor: 0.1813 - val_recall_tumor: 0.1634 - val_tumor_iou: 0.0859 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 29 lên WandB.\n\n--- Epoch 30/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9638 - dice_coef_metric_tumor: 0.2812 - loss: 0.4684 - mean_iou_all: 0.2515 - precision_tumor: 0.2435 - recall_tumor: 0.4351 - tumor_iou: 0.1736\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18570\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9638 - dice_coef_metric_tumor: 0.2812 - loss: 0.4683 - mean_iou_all: 0.2515 - precision_tumor: 0.2434 - recall_tumor: 0.4350 - tumor_iou: 0.1735 - val_acc: 0.9693 - val_dice_coef_metric_tumor: 0.1661 - val_loss: 0.5387 - val_mean_iou_all: 0.2511 - val_precision_tumor: 0.1688 - val_recall_tumor: 0.2191 - val_tumor_iou: 0.0972 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 30 lên WandB.\n\n--- Epoch 31/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9648 - dice_coef_metric_tumor: 0.2878 - loss: 0.4523 - mean_iou_all: 0.2538 - precision_tumor: 0.2416 - recall_tumor: 0.4301 - tumor_iou: 0.1798\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18570\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 914ms/step - acc: 0.9648 - dice_coef_metric_tumor: 0.2877 - loss: 0.4524 - mean_iou_all: 0.2538 - precision_tumor: 0.2415 - recall_tumor: 0.4300 - tumor_iou: 0.1797 - val_acc: 0.9825 - val_dice_coef_metric_tumor: 0.0675 - val_loss: 0.5980 - val_mean_iou_all: 0.2502 - val_precision_tumor: 0.2331 - val_recall_tumor: 0.0437 - val_tumor_iou: 0.0369 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 31 lên WandB.\n\n--- Epoch 32/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9646 - dice_coef_metric_tumor: 0.2808 - loss: 0.4669 - mean_iou_all: 0.2522 - precision_tumor: 0.2454 - recall_tumor: 0.4280 - tumor_iou: 0.1735\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18570\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9646 - dice_coef_metric_tumor: 0.2807 - loss: 0.4668 - mean_iou_all: 0.2522 - precision_tumor: 0.2453 - recall_tumor: 0.4281 - tumor_iou: 0.1735 - val_acc: 0.9686 - val_dice_coef_metric_tumor: 0.1738 - val_loss: 0.5352 - val_mean_iou_all: 0.2502 - val_precision_tumor: 0.1741 - val_recall_tumor: 0.2353 - val_tumor_iou: 0.1033 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 32 lên WandB.\n\n--- Epoch 33/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9627 - dice_coef_metric_tumor: 0.2814 - loss: 0.4590 - mean_iou_all: 0.2523 - precision_tumor: 0.2377 - recall_tumor: 0.4377 - tumor_iou: 0.1744\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.18570\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9627 - dice_coef_metric_tumor: 0.2813 - loss: 0.4590 - mean_iou_all: 0.2523 - precision_tumor: 0.2376 - recall_tumor: 0.4376 - tumor_iou: 0.1743 - val_acc: 0.9664 - val_dice_coef_metric_tumor: 0.1717 - val_loss: 0.5363 - val_mean_iou_all: 0.2500 - val_precision_tumor: 0.1731 - val_recall_tumor: 0.2522 - val_tumor_iou: 0.1010 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 33 lên WandB.\n\n--- Epoch 34/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9662 - dice_coef_metric_tumor: 0.3071 - loss: 0.4531 - mean_iou_all: 0.2522 - precision_tumor: 0.2681 - recall_tumor: 0.4571 - tumor_iou: 0.1922\nEpoch 1: val_dice_coef_metric_tumor improved from 0.18570 to 0.19102, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 926ms/step - acc: 0.9662 - dice_coef_metric_tumor: 0.3070 - loss: 0.4530 - mean_iou_all: 0.2522 - precision_tumor: 0.2680 - recall_tumor: 0.4570 - tumor_iou: 0.1922 - val_acc: 0.9772 - val_dice_coef_metric_tumor: 0.1910 - val_loss: 0.5224 - val_mean_iou_all: 0.2501 - val_precision_tumor: 0.2463 - val_recall_tumor: 0.1954 - val_tumor_iou: 0.1138 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 34 lên WandB.\n\n--- Epoch 35/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9657 - dice_coef_metric_tumor: 0.2818 - loss: 0.4579 - mean_iou_all: 0.2527 - precision_tumor: 0.2457 - recall_tumor: 0.4330 - tumor_iou: 0.1737\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.19102\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9657 - dice_coef_metric_tumor: 0.2817 - loss: 0.4578 - mean_iou_all: 0.2527 - precision_tumor: 0.2456 - recall_tumor: 0.4330 - tumor_iou: 0.1736 - val_acc: 0.9829 - val_dice_coef_metric_tumor: 0.0798 - val_loss: 0.5898 - val_mean_iou_all: 0.2515 - val_precision_tumor: 0.3519 - val_recall_tumor: 0.0498 - val_tumor_iou: 0.0442 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 35 lên WandB.\n\n--- Epoch 36/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9676 - dice_coef_metric_tumor: 0.3004 - loss: 0.4455 - mean_iou_all: 0.2537 - precision_tumor: 0.2599 - recall_tumor: 0.4355 - tumor_iou: 0.1895\nEpoch 1: val_dice_coef_metric_tumor improved from 0.19102 to 0.19271, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 925ms/step - acc: 0.9676 - dice_coef_metric_tumor: 0.3003 - loss: 0.4455 - mean_iou_all: 0.2537 - precision_tumor: 0.2598 - recall_tumor: 0.4355 - tumor_iou: 0.1894 - val_acc: 0.9702 - val_dice_coef_metric_tumor: 0.1927 - val_loss: 0.5233 - val_mean_iou_all: 0.2568 - val_precision_tumor: 0.1927 - val_recall_tumor: 0.2526 - val_tumor_iou: 0.1156 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 36 lên WandB.\n\n--- Epoch 37/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9662 - dice_coef_metric_tumor: 0.3171 - loss: 0.4379 - mean_iou_all: 0.2631 - precision_tumor: 0.2705 - recall_tumor: 0.4858 - tumor_iou: 0.2001\nEpoch 1: val_dice_coef_metric_tumor improved from 0.19271 to 0.22356, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 927ms/step - acc: 0.9662 - dice_coef_metric_tumor: 0.3170 - loss: 0.4379 - mean_iou_all: 0.2631 - precision_tumor: 0.2704 - recall_tumor: 0.4858 - tumor_iou: 0.2000 - val_acc: 0.9644 - val_dice_coef_metric_tumor: 0.2236 - val_loss: 0.5050 - val_mean_iou_all: 0.2524 - val_precision_tumor: 0.1989 - val_recall_tumor: 0.3454 - val_tumor_iou: 0.1356 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 37 lên WandB.\n\n--- Epoch 38/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9655 - dice_coef_metric_tumor: 0.3106 - loss: 0.4467 - mean_iou_all: 0.2569 - precision_tumor: 0.2665 - recall_tumor: 0.4872 - tumor_iou: 0.1956\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.22356\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 915ms/step - acc: 0.9655 - dice_coef_metric_tumor: 0.3106 - loss: 0.4466 - mean_iou_all: 0.2569 - precision_tumor: 0.2665 - recall_tumor: 0.4871 - tumor_iou: 0.1956 - val_acc: 0.9804 - val_dice_coef_metric_tumor: 0.1311 - val_loss: 0.5594 - val_mean_iou_all: 0.2520 - val_precision_tumor: 0.2444 - val_recall_tumor: 0.1030 - val_tumor_iou: 0.0758 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 38 lên WandB.\n\n--- Epoch 39/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9689 - dice_coef_metric_tumor: 0.3115 - loss: 0.4424 - mean_iou_all: 0.2542 - precision_tumor: 0.2779 - recall_tumor: 0.4512 - tumor_iou: 0.1949\nEpoch 1: val_dice_coef_metric_tumor improved from 0.22356 to 0.24149, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 929ms/step - acc: 0.9689 - dice_coef_metric_tumor: 0.3115 - loss: 0.4423 - mean_iou_all: 0.2542 - precision_tumor: 0.2779 - recall_tumor: 0.4512 - tumor_iou: 0.1950 - val_acc: 0.9676 - val_dice_coef_metric_tumor: 0.2415 - val_loss: 0.4938 - val_mean_iou_all: 0.2539 - val_precision_tumor: 0.2208 - val_recall_tumor: 0.3528 - val_tumor_iou: 0.1467 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 39 lên WandB.\n\n--- Epoch 40/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9705 - dice_coef_metric_tumor: 0.3296 - loss: 0.4356 - mean_iou_all: 0.2555 - precision_tumor: 0.2924 - recall_tumor: 0.4546 - tumor_iou: 0.2090\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.24149\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 922ms/step - acc: 0.9705 - dice_coef_metric_tumor: 0.3296 - loss: 0.4355 - mean_iou_all: 0.2555 - precision_tumor: 0.2924 - recall_tumor: 0.4546 - tumor_iou: 0.2090 - val_acc: 0.9753 - val_dice_coef_metric_tumor: 0.2088 - val_loss: 0.5133 - val_mean_iou_all: 0.2501 - val_precision_tumor: 0.2489 - val_recall_tumor: 0.2362 - val_tumor_iou: 0.1261 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 40 lên WandB.\n\n--- Epoch 41/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9728 - dice_coef_metric_tumor: 0.3428 - loss: 0.4252 - mean_iou_all: 0.2529 - precision_tumor: 0.3193 - recall_tumor: 0.4452 - tumor_iou: 0.2204\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.24149\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9728 - dice_coef_metric_tumor: 0.3427 - loss: 0.4252 - mean_iou_all: 0.2530 - precision_tumor: 0.3191 - recall_tumor: 0.4452 - tumor_iou: 0.2203 - val_acc: 0.9678 - val_dice_coef_metric_tumor: 0.2201 - val_loss: 0.5086 - val_mean_iou_all: 0.2511 - val_precision_tumor: 0.2129 - val_recall_tumor: 0.3075 - val_tumor_iou: 0.1322 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 41 lên WandB.\n\n--- Epoch 42/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9715 - dice_coef_metric_tumor: 0.3380 - loss: 0.4277 - mean_iou_all: 0.2523 - precision_tumor: 0.3016 - recall_tumor: 0.4610 - tumor_iou: 0.2165\nEpoch 1: val_dice_coef_metric_tumor improved from 0.24149 to 0.24543, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 927ms/step - acc: 0.9715 - dice_coef_metric_tumor: 0.3380 - loss: 0.4276 - mean_iou_all: 0.2523 - precision_tumor: 0.3016 - recall_tumor: 0.4610 - tumor_iou: 0.2165 - val_acc: 0.9515 - val_dice_coef_metric_tumor: 0.2454 - val_loss: 0.4971 - val_mean_iou_all: 0.2525 - val_precision_tumor: 0.1792 - val_recall_tumor: 0.5204 - val_tumor_iou: 0.1499 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 42 lên WandB.\n\n--- Epoch 43/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9719 - dice_coef_metric_tumor: 0.3479 - loss: 0.4182 - mean_iou_all: 0.2540 - precision_tumor: 0.3140 - recall_tumor: 0.4765 - tumor_iou: 0.2230\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.24543\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9719 - dice_coef_metric_tumor: 0.3479 - loss: 0.4182 - mean_iou_all: 0.2540 - precision_tumor: 0.3140 - recall_tumor: 0.4764 - tumor_iou: 0.2229 - val_acc: 0.9805 - val_dice_coef_metric_tumor: 0.2350 - val_loss: 0.4972 - val_mean_iou_all: 0.2532 - val_precision_tumor: 0.3148 - val_recall_tumor: 0.2166 - val_tumor_iou: 0.1454 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 43 lên WandB.\n\n--- Epoch 44/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9732 - dice_coef_metric_tumor: 0.3586 - loss: 0.4156 - mean_iou_all: 0.2583 - precision_tumor: 0.3367 - recall_tumor: 0.4750 - tumor_iou: 0.2311\nEpoch 1: val_dice_coef_metric_tumor improved from 0.24543 to 0.27052, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 930ms/step - acc: 0.9732 - dice_coef_metric_tumor: 0.3585 - loss: 0.4156 - mean_iou_all: 0.2583 - precision_tumor: 0.3366 - recall_tumor: 0.4750 - tumor_iou: 0.2310 - val_acc: 0.9703 - val_dice_coef_metric_tumor: 0.2705 - val_loss: 0.4766 - val_mean_iou_all: 0.2548 - val_precision_tumor: 0.2462 - val_recall_tumor: 0.3809 - val_tumor_iou: 0.1673 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 44 lên WandB.\n\n--- Epoch 45/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9740 - dice_coef_metric_tumor: 0.3553 - loss: 0.4135 - mean_iou_all: 0.2583 - precision_tumor: 0.3358 - recall_tumor: 0.4548 - tumor_iou: 0.2314\nEpoch 1: val_dice_coef_metric_tumor improved from 0.27052 to 0.31011, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 927ms/step - acc: 0.9740 - dice_coef_metric_tumor: 0.3551 - loss: 0.4135 - mean_iou_all: 0.2584 - precision_tumor: 0.3357 - recall_tumor: 0.4548 - tumor_iou: 0.2313 - val_acc: 0.9681 - val_dice_coef_metric_tumor: 0.3101 - val_loss: 0.4529 - val_mean_iou_all: 0.2518 - val_precision_tumor: 0.2526 - val_recall_tumor: 0.5069 - val_tumor_iou: 0.1944 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 45 lên WandB.\n\n--- Epoch 46/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9723 - dice_coef_metric_tumor: 0.3573 - loss: 0.4131 - mean_iou_all: 0.2568 - precision_tumor: 0.3259 - recall_tumor: 0.4732 - tumor_iou: 0.2315\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31011\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9723 - dice_coef_metric_tumor: 0.3573 - loss: 0.4130 - mean_iou_all: 0.2569 - precision_tumor: 0.3258 - recall_tumor: 0.4732 - tumor_iou: 0.2315 - val_acc: 0.9636 - val_dice_coef_metric_tumor: 0.2540 - val_loss: 0.4902 - val_mean_iou_all: 0.2527 - val_precision_tumor: 0.2078 - val_recall_tumor: 0.4215 - val_tumor_iou: 0.1562 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 46 lên WandB.\n\n--- Epoch 47/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9743 - dice_coef_metric_tumor: 0.3834 - loss: 0.3987 - mean_iou_all: 0.2555 - precision_tumor: 0.3508 - recall_tumor: 0.5044 - tumor_iou: 0.2504\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31011\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 921ms/step - acc: 0.9743 - dice_coef_metric_tumor: 0.3833 - loss: 0.3987 - mean_iou_all: 0.2555 - precision_tumor: 0.3507 - recall_tumor: 0.5043 - tumor_iou: 0.2503 - val_acc: 0.9721 - val_dice_coef_metric_tumor: 0.2907 - val_loss: 0.4649 - val_mean_iou_all: 0.2587 - val_precision_tumor: 0.2570 - val_recall_tumor: 0.3997 - val_tumor_iou: 0.1821 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 47 lên WandB.\n\n--- Epoch 48/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9756 - dice_coef_metric_tumor: 0.3924 - loss: 0.4058 - mean_iou_all: 0.2625 - precision_tumor: 0.3722 - recall_tumor: 0.4784 - tumor_iou: 0.2574\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31011\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9756 - dice_coef_metric_tumor: 0.3923 - loss: 0.4057 - mean_iou_all: 0.2626 - precision_tumor: 0.3721 - recall_tumor: 0.4783 - tumor_iou: 0.2573 - val_acc: 0.9680 - val_dice_coef_metric_tumor: 0.2664 - val_loss: 0.4820 - val_mean_iou_all: 0.2599 - val_precision_tumor: 0.2382 - val_recall_tumor: 0.3923 - val_tumor_iou: 0.1664 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 48 lên WandB.\n\n--- Epoch 49/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9755 - dice_coef_metric_tumor: 0.3772 - loss: 0.4035 - mean_iou_all: 0.2633 - precision_tumor: 0.3479 - recall_tumor: 0.4735 - tumor_iou: 0.2470\nEpoch 1: val_dice_coef_metric_tumor improved from 0.31011 to 0.31319, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 925ms/step - acc: 0.9755 - dice_coef_metric_tumor: 0.3771 - loss: 0.4035 - mean_iou_all: 0.2634 - precision_tumor: 0.3478 - recall_tumor: 0.4734 - tumor_iou: 0.2469 - val_acc: 0.9743 - val_dice_coef_metric_tumor: 0.3132 - val_loss: 0.4510 - val_mean_iou_all: 0.2526 - val_precision_tumor: 0.2921 - val_recall_tumor: 0.4078 - val_tumor_iou: 0.1971 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 49 lên WandB.\n\n--- Epoch 50/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9745 - dice_coef_metric_tumor: 0.3710 - loss: 0.4007 - mean_iou_all: 0.2565 - precision_tumor: 0.3456 - recall_tumor: 0.4841 - tumor_iou: 0.2413\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.31319\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9745 - dice_coef_metric_tumor: 0.3709 - loss: 0.4007 - mean_iou_all: 0.2565 - precision_tumor: 0.3456 - recall_tumor: 0.4841 - tumor_iou: 0.2413 - val_acc: 0.9787 - val_dice_coef_metric_tumor: 0.2905 - val_loss: 0.4629 - val_mean_iou_all: 0.2522 - val_precision_tumor: 0.3326 - val_recall_tumor: 0.3122 - val_tumor_iou: 0.1842 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 50 lên WandB.\n\n--- Epoch 51/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9747 - dice_coef_metric_tumor: 0.3804 - loss: 0.3999 - mean_iou_all: 0.2599 - precision_tumor: 0.3636 - recall_tumor: 0.4784 - tumor_iou: 0.2510\nEpoch 1: val_dice_coef_metric_tumor improved from 0.31319 to 0.32302, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 928ms/step - acc: 0.9747 - dice_coef_metric_tumor: 0.3802 - loss: 0.3999 - mean_iou_all: 0.2599 - precision_tumor: 0.3634 - recall_tumor: 0.4784 - tumor_iou: 0.2509 - val_acc: 0.9731 - val_dice_coef_metric_tumor: 0.3230 - val_loss: 0.4443 - val_mean_iou_all: 0.2570 - val_precision_tumor: 0.2888 - val_recall_tumor: 0.4444 - val_tumor_iou: 0.2056 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 51 lên WandB.\n\n--- Epoch 52/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9760 - dice_coef_metric_tumor: 0.3933 - loss: 0.4005 - mean_iou_all: 0.2598 - precision_tumor: 0.3712 - recall_tumor: 0.4839 - tumor_iou: 0.2591\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.32302\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9760 - dice_coef_metric_tumor: 0.3931 - loss: 0.4004 - mean_iou_all: 0.2598 - precision_tumor: 0.3710 - recall_tumor: 0.4839 - tumor_iou: 0.2590 - val_acc: 0.9506 - val_dice_coef_metric_tumor: 0.2703 - val_loss: 0.4855 - val_mean_iou_all: 0.2583 - val_precision_tumor: 0.1898 - val_recall_tumor: 0.6062 - val_tumor_iou: 0.1669 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 52 lên WandB.\n\n--- Epoch 53/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9758 - dice_coef_metric_tumor: 0.3965 - loss: 0.3947 - mean_iou_all: 0.2590 - precision_tumor: 0.3733 - recall_tumor: 0.4985 - tumor_iou: 0.2621\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.32302\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9758 - dice_coef_metric_tumor: 0.3964 - loss: 0.3947 - mean_iou_all: 0.2591 - precision_tumor: 0.3731 - recall_tumor: 0.4985 - tumor_iou: 0.2620 - val_acc: 0.9751 - val_dice_coef_metric_tumor: 0.3169 - val_loss: 0.4488 - val_mean_iou_all: 0.2586 - val_precision_tumor: 0.3235 - val_recall_tumor: 0.3868 - val_tumor_iou: 0.2040 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 53 lên WandB.\n\n--- Epoch 54/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9768 - dice_coef_metric_tumor: 0.4022 - loss: 0.3868 - mean_iou_all: 0.2680 - precision_tumor: 0.3833 - recall_tumor: 0.4885 - tumor_iou: 0.2675\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.32302\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 922ms/step - acc: 0.9768 - dice_coef_metric_tumor: 0.4021 - loss: 0.3867 - mean_iou_all: 0.2681 - precision_tumor: 0.3832 - recall_tumor: 0.4885 - tumor_iou: 0.2674 - val_acc: 0.9765 - val_dice_coef_metric_tumor: 0.2856 - val_loss: 0.4668 - val_mean_iou_all: 0.2582 - val_precision_tumor: 0.2955 - val_recall_tumor: 0.3352 - val_tumor_iou: 0.1804 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 54 lên WandB.\n\n--- Epoch 55/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9770 - dice_coef_metric_tumor: 0.4122 - loss: 0.3853 - mean_iou_all: 0.2630 - precision_tumor: 0.3913 - recall_tumor: 0.5027 - tumor_iou: 0.2764\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.32302\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9770 - dice_coef_metric_tumor: 0.4120 - loss: 0.3853 - mean_iou_all: 0.2631 - precision_tumor: 0.3911 - recall_tumor: 0.5026 - tumor_iou: 0.2763 - val_acc: 0.9730 - val_dice_coef_metric_tumor: 0.2717 - val_loss: 0.4768 - val_mean_iou_all: 0.2581 - val_precision_tumor: 0.2747 - val_recall_tumor: 0.3420 - val_tumor_iou: 0.1695 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 55 lên WandB.\n\n--- Epoch 56/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9744 - dice_coef_metric_tumor: 0.3692 - loss: 0.4080 - mean_iou_all: 0.2688 - precision_tumor: 0.3372 - recall_tumor: 0.4791 - tumor_iou: 0.2399\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.32302\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9744 - dice_coef_metric_tumor: 0.3691 - loss: 0.4079 - mean_iou_all: 0.2689 - precision_tumor: 0.3372 - recall_tumor: 0.4792 - tumor_iou: 0.2399 - val_acc: 0.9736 - val_dice_coef_metric_tumor: 0.3175 - val_loss: 0.4484 - val_mean_iou_all: 0.2588 - val_precision_tumor: 0.2885 - val_recall_tumor: 0.4212 - val_tumor_iou: 0.2024 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 56 lên WandB.\n\n--- Epoch 57/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9788 - dice_coef_metric_tumor: 0.4296 - loss: 0.3671 - mean_iou_all: 0.2686 - precision_tumor: 0.4156 - recall_tumor: 0.5077 - tumor_iou: 0.2888\nEpoch 1: val_dice_coef_metric_tumor improved from 0.32302 to 0.33982, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 926ms/step - acc: 0.9788 - dice_coef_metric_tumor: 0.4294 - loss: 0.3672 - mean_iou_all: 0.2687 - precision_tumor: 0.4154 - recall_tumor: 0.5076 - tumor_iou: 0.2886 - val_acc: 0.9744 - val_dice_coef_metric_tumor: 0.3398 - val_loss: 0.4343 - val_mean_iou_all: 0.2555 - val_precision_tumor: 0.3015 - val_recall_tumor: 0.4498 - val_tumor_iou: 0.2196 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 57 lên WandB.\n\n--- Epoch 58/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9778 - dice_coef_metric_tumor: 0.4134 - loss: 0.3812 - mean_iou_all: 0.2657 - precision_tumor: 0.4033 - recall_tumor: 0.4966 - tumor_iou: 0.2758\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.33982\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9778 - dice_coef_metric_tumor: 0.4132 - loss: 0.3812 - mean_iou_all: 0.2658 - precision_tumor: 0.4031 - recall_tumor: 0.4966 - tumor_iou: 0.2756 - val_acc: 0.9714 - val_dice_coef_metric_tumor: 0.3231 - val_loss: 0.4459 - val_mean_iou_all: 0.2563 - val_precision_tumor: 0.2789 - val_recall_tumor: 0.4553 - val_tumor_iou: 0.2076 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 58 lên WandB.\n\n--- Epoch 59/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9778 - dice_coef_metric_tumor: 0.4145 - loss: 0.3756 - mean_iou_all: 0.2637 - precision_tumor: 0.3946 - recall_tumor: 0.5215 - tumor_iou: 0.2761\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.33982\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9778 - dice_coef_metric_tumor: 0.4144 - loss: 0.3756 - mean_iou_all: 0.2637 - precision_tumor: 0.3945 - recall_tumor: 0.5214 - tumor_iou: 0.2760 - val_acc: 0.9740 - val_dice_coef_metric_tumor: 0.3055 - val_loss: 0.4556 - val_mean_iou_all: 0.2555 - val_precision_tumor: 0.2808 - val_recall_tumor: 0.3846 - val_tumor_iou: 0.1950 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 59 lên WandB.\n\n--- Epoch 60/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9770 - dice_coef_metric_tumor: 0.4082 - loss: 0.3808 - mean_iou_all: 0.2595 - precision_tumor: 0.3916 - recall_tumor: 0.5059 - tumor_iou: 0.2734\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.33982\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9770 - dice_coef_metric_tumor: 0.4081 - loss: 0.3808 - mean_iou_all: 0.2596 - precision_tumor: 0.3915 - recall_tumor: 0.5059 - tumor_iou: 0.2733 - val_acc: 0.9673 - val_dice_coef_metric_tumor: 0.2991 - val_loss: 0.4620 - val_mean_iou_all: 0.2541 - val_precision_tumor: 0.2508 - val_recall_tumor: 0.4496 - val_tumor_iou: 0.1891 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 60 lên WandB.\n\n--- Epoch 61/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9772 - dice_coef_metric_tumor: 0.4231 - loss: 0.3742 - mean_iou_all: 0.2563 - precision_tumor: 0.3918 - recall_tumor: 0.5373 - tumor_iou: 0.2836\nEpoch 1: val_dice_coef_metric_tumor improved from 0.33982 to 0.34015, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 927ms/step - acc: 0.9772 - dice_coef_metric_tumor: 0.4230 - loss: 0.3743 - mean_iou_all: 0.2563 - precision_tumor: 0.3917 - recall_tumor: 0.5372 - tumor_iou: 0.2835 - val_acc: 0.9803 - val_dice_coef_metric_tumor: 0.3402 - val_loss: 0.4322 - val_mean_iou_all: 0.2530 - val_precision_tumor: 0.3812 - val_recall_tumor: 0.3567 - val_tumor_iou: 0.2222 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 61 lên WandB.\n\n--- Epoch 62/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9784 - dice_coef_metric_tumor: 0.4276 - loss: 0.3728 - mean_iou_all: 0.2601 - precision_tumor: 0.4060 - recall_tumor: 0.5199 - tumor_iou: 0.2890\nEpoch 1: val_dice_coef_metric_tumor improved from 0.34015 to 0.36135, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 929ms/step - acc: 0.9784 - dice_coef_metric_tumor: 0.4274 - loss: 0.3728 - mean_iou_all: 0.2602 - precision_tumor: 0.4058 - recall_tumor: 0.5198 - tumor_iou: 0.2889 - val_acc: 0.9792 - val_dice_coef_metric_tumor: 0.3613 - val_loss: 0.4199 - val_mean_iou_all: 0.2614 - val_precision_tumor: 0.3622 - val_recall_tumor: 0.4075 - val_tumor_iou: 0.2373 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 62 lên WandB.\n\n--- Epoch 63/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9786 - dice_coef_metric_tumor: 0.4271 - loss: 0.3687 - mean_iou_all: 0.2656 - precision_tumor: 0.4058 - recall_tumor: 0.5259 - tumor_iou: 0.2871\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.36135\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9786 - dice_coef_metric_tumor: 0.4270 - loss: 0.3687 - mean_iou_all: 0.2656 - precision_tumor: 0.4056 - recall_tumor: 0.5258 - tumor_iou: 0.2870 - val_acc: 0.9803 - val_dice_coef_metric_tumor: 0.3535 - val_loss: 0.4248 - val_mean_iou_all: 0.2549 - val_precision_tumor: 0.3836 - val_recall_tumor: 0.3718 - val_tumor_iou: 0.2315 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 63 lên WandB.\n\n--- Epoch 64/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4365 - loss: 0.3640 - mean_iou_all: 0.2673 - precision_tumor: 0.4243 - recall_tumor: 0.5099 - tumor_iou: 0.2999\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.36135\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4364 - loss: 0.3640 - mean_iou_all: 0.2674 - precision_tumor: 0.4242 - recall_tumor: 0.5098 - tumor_iou: 0.2998 - val_acc: 0.9628 - val_dice_coef_metric_tumor: 0.3095 - val_loss: 0.4585 - val_mean_iou_all: 0.2600 - val_precision_tumor: 0.2328 - val_recall_tumor: 0.5644 - val_tumor_iou: 0.1953 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 64 lên WandB.\n\n--- Epoch 65/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9789 - dice_coef_metric_tumor: 0.4313 - loss: 0.3626 - mean_iou_all: 0.2729 - precision_tumor: 0.4137 - recall_tumor: 0.5185 - tumor_iou: 0.2943\nEpoch 1: val_dice_coef_metric_tumor improved from 0.36135 to 0.37520, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 927ms/step - acc: 0.9789 - dice_coef_metric_tumor: 0.4312 - loss: 0.3626 - mean_iou_all: 0.2730 - precision_tumor: 0.4136 - recall_tumor: 0.5185 - tumor_iou: 0.2942 - val_acc: 0.9792 - val_dice_coef_metric_tumor: 0.3752 - val_loss: 0.4115 - val_mean_iou_all: 0.2563 - val_precision_tumor: 0.3650 - val_recall_tumor: 0.4350 - val_tumor_iou: 0.2484 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 65 lên WandB.\n\n--- Epoch 66/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4313 - loss: 0.3597 - mean_iou_all: 0.2666 - precision_tumor: 0.4236 - recall_tumor: 0.5164 - tumor_iou: 0.2948\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.37520\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9794 - dice_coef_metric_tumor: 0.4312 - loss: 0.3597 - mean_iou_all: 0.2667 - precision_tumor: 0.4234 - recall_tumor: 0.5163 - tumor_iou: 0.2947 - val_acc: 0.9676 - val_dice_coef_metric_tumor: 0.3411 - val_loss: 0.4370 - val_mean_iou_all: 0.2612 - val_precision_tumor: 0.2654 - val_recall_tumor: 0.5806 - val_tumor_iou: 0.2178 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 66 lên WandB.\n\n--- Epoch 67/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9783 - dice_coef_metric_tumor: 0.4321 - loss: 0.3652 - mean_iou_all: 0.2683 - precision_tumor: 0.4119 - recall_tumor: 0.5328 - tumor_iou: 0.2952\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.37520\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9783 - dice_coef_metric_tumor: 0.4320 - loss: 0.3652 - mean_iou_all: 0.2683 - precision_tumor: 0.4118 - recall_tumor: 0.5328 - tumor_iou: 0.2951 - val_acc: 0.9681 - val_dice_coef_metric_tumor: 0.3301 - val_loss: 0.4427 - val_mean_iou_all: 0.2559 - val_precision_tumor: 0.2790 - val_recall_tumor: 0.5093 - val_tumor_iou: 0.2124 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 67 lên WandB.\n\n--- Epoch 68/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9778 - dice_coef_metric_tumor: 0.4199 - loss: 0.3763 - mean_iou_all: 0.2629 - precision_tumor: 0.3970 - recall_tumor: 0.5123 - tumor_iou: 0.2817\nEpoch 1: val_dice_coef_metric_tumor improved from 0.37520 to 0.38112, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 926ms/step - acc: 0.9778 - dice_coef_metric_tumor: 0.4199 - loss: 0.3762 - mean_iou_all: 0.2630 - precision_tumor: 0.3971 - recall_tumor: 0.5122 - tumor_iou: 0.2817 - val_acc: 0.9800 - val_dice_coef_metric_tumor: 0.3811 - val_loss: 0.4076 - val_mean_iou_all: 0.2526 - val_precision_tumor: 0.4209 - val_recall_tumor: 0.4143 - val_tumor_iou: 0.2508 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 68 lên WandB.\n\n--- Epoch 69/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9796 - dice_coef_metric_tumor: 0.4344 - loss: 0.3733 - mean_iou_all: 0.2605 - precision_tumor: 0.4338 - recall_tumor: 0.5035 - tumor_iou: 0.2921\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.38112\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9796 - dice_coef_metric_tumor: 0.4343 - loss: 0.3732 - mean_iou_all: 0.2605 - precision_tumor: 0.4336 - recall_tumor: 0.5035 - tumor_iou: 0.2920 - val_acc: 0.9665 - val_dice_coef_metric_tumor: 0.3190 - val_loss: 0.4514 - val_mean_iou_all: 0.2559 - val_precision_tumor: 0.2507 - val_recall_tumor: 0.5279 - val_tumor_iou: 0.2038 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 69 lên WandB.\n\n--- Epoch 70/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9800 - dice_coef_metric_tumor: 0.4417 - loss: 0.3527 - mean_iou_all: 0.2734 - precision_tumor: 0.4250 - recall_tumor: 0.5387 - tumor_iou: 0.3005\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.38112\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9800 - dice_coef_metric_tumor: 0.4415 - loss: 0.3528 - mean_iou_all: 0.2736 - precision_tumor: 0.4249 - recall_tumor: 0.5387 - tumor_iou: 0.3004 - val_acc: 0.9717 - val_dice_coef_metric_tumor: 0.3392 - val_loss: 0.4368 - val_mean_iou_all: 0.2630 - val_precision_tumor: 0.3022 - val_recall_tumor: 0.4732 - val_tumor_iou: 0.2202 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 70 lên WandB.\n\n--- Epoch 71/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9803 - dice_coef_metric_tumor: 0.4493 - loss: 0.3583 - mean_iou_all: 0.2805 - precision_tumor: 0.4421 - recall_tumor: 0.5230 - tumor_iou: 0.3050\nEpoch 1: val_dice_coef_metric_tumor improved from 0.38112 to 0.40536, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 925ms/step - acc: 0.9803 - dice_coef_metric_tumor: 0.4493 - loss: 0.3583 - mean_iou_all: 0.2806 - precision_tumor: 0.4421 - recall_tumor: 0.5229 - tumor_iou: 0.3050 - val_acc: 0.9800 - val_dice_coef_metric_tumor: 0.4054 - val_loss: 0.3934 - val_mean_iou_all: 0.2568 - val_precision_tumor: 0.3902 - val_recall_tumor: 0.4665 - val_tumor_iou: 0.2730 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 71 lên WandB.\n\n--- Epoch 72/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9782 - dice_coef_metric_tumor: 0.4392 - loss: 0.3628 - mean_iou_all: 0.2691 - precision_tumor: 0.4087 - recall_tumor: 0.5530 - tumor_iou: 0.2994\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.40536\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9782 - dice_coef_metric_tumor: 0.4391 - loss: 0.3628 - mean_iou_all: 0.2692 - precision_tumor: 0.4086 - recall_tumor: 0.5529 - tumor_iou: 0.2993 - val_acc: 0.9822 - val_dice_coef_metric_tumor: 0.3882 - val_loss: 0.4034 - val_mean_iou_all: 0.2628 - val_precision_tumor: 0.4364 - val_recall_tumor: 0.3987 - val_tumor_iou: 0.2584 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 72 lên WandB.\n\n--- Epoch 73/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9799 - dice_coef_metric_tumor: 0.4514 - loss: 0.3608 - mean_iou_all: 0.2792 - precision_tumor: 0.4407 - recall_tumor: 0.5233 - tumor_iou: 0.3077\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.40536\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9799 - dice_coef_metric_tumor: 0.4513 - loss: 0.3608 - mean_iou_all: 0.2793 - precision_tumor: 0.4405 - recall_tumor: 0.5233 - tumor_iou: 0.3076 - val_acc: 0.9735 - val_dice_coef_metric_tumor: 0.3601 - val_loss: 0.4236 - val_mean_iou_all: 0.2629 - val_precision_tumor: 0.3106 - val_recall_tumor: 0.5007 - val_tumor_iou: 0.2363 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 73 lên WandB.\n\n--- Epoch 74/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9799 - dice_coef_metric_tumor: 0.4473 - loss: 0.3573 - mean_iou_all: 0.2815 - precision_tumor: 0.4404 - recall_tumor: 0.5329 - tumor_iou: 0.3042\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.40536\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9799 - dice_coef_metric_tumor: 0.4472 - loss: 0.3573 - mean_iou_all: 0.2816 - precision_tumor: 0.4403 - recall_tumor: 0.5329 - tumor_iou: 0.3041 - val_acc: 0.9820 - val_dice_coef_metric_tumor: 0.3955 - val_loss: 0.3997 - val_mean_iou_all: 0.2620 - val_precision_tumor: 0.4099 - val_recall_tumor: 0.4213 - val_tumor_iou: 0.2661 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 74 lên WandB.\n\n--- Epoch 75/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9810 - dice_coef_metric_tumor: 0.4698 - loss: 0.3422 - mean_iou_all: 0.2778 - precision_tumor: 0.4561 - recall_tumor: 0.5489 - tumor_iou: 0.3238\nEpoch 1: val_dice_coef_metric_tumor improved from 0.40536 to 0.40760, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 925ms/step - acc: 0.9810 - dice_coef_metric_tumor: 0.4697 - loss: 0.3422 - mean_iou_all: 0.2780 - precision_tumor: 0.4560 - recall_tumor: 0.5488 - tumor_iou: 0.3237 - val_acc: 0.9832 - val_dice_coef_metric_tumor: 0.4076 - val_loss: 0.3912 - val_mean_iou_all: 0.2600 - val_precision_tumor: 0.4522 - val_recall_tumor: 0.4167 - val_tumor_iou: 0.2741 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 75 lên WandB.\n\n--- Epoch 76/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9800 - dice_coef_metric_tumor: 0.4620 - loss: 0.3492 - mean_iou_all: 0.2869 - precision_tumor: 0.4544 - recall_tumor: 0.5457 - tumor_iou: 0.3194\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.40760\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 921ms/step - acc: 0.9800 - dice_coef_metric_tumor: 0.4619 - loss: 0.3492 - mean_iou_all: 0.2871 - precision_tumor: 0.4542 - recall_tumor: 0.5456 - tumor_iou: 0.3193 - val_acc: 0.9793 - val_dice_coef_metric_tumor: 0.3896 - val_loss: 0.4034 - val_mean_iou_all: 0.2577 - val_precision_tumor: 0.3669 - val_recall_tumor: 0.4727 - val_tumor_iou: 0.2596 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 76 lên WandB.\n\n--- Epoch 77/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9800 - dice_coef_metric_tumor: 0.4497 - loss: 0.3581 - mean_iou_all: 0.2856 - precision_tumor: 0.4376 - recall_tumor: 0.5329 - tumor_iou: 0.3072\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.40760\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9800 - dice_coef_metric_tumor: 0.4497 - loss: 0.3581 - mean_iou_all: 0.2858 - precision_tumor: 0.4376 - recall_tumor: 0.5329 - tumor_iou: 0.3072 - val_acc: 0.9809 - val_dice_coef_metric_tumor: 0.4028 - val_loss: 0.3953 - val_mean_iou_all: 0.2566 - val_precision_tumor: 0.3862 - val_recall_tumor: 0.4639 - val_tumor_iou: 0.2723 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 77 lên WandB.\n\n--- Epoch 78/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9816 - dice_coef_metric_tumor: 0.4727 - loss: 0.3379 - mean_iou_all: 0.2808 - precision_tumor: 0.4594 - recall_tumor: 0.5520 - tumor_iou: 0.3283\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.40760\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9816 - dice_coef_metric_tumor: 0.4725 - loss: 0.3380 - mean_iou_all: 0.2810 - precision_tumor: 0.4591 - recall_tumor: 0.5520 - tumor_iou: 0.3282 - val_acc: 0.9842 - val_dice_coef_metric_tumor: 0.3860 - val_loss: 0.4055 - val_mean_iou_all: 0.2602 - val_precision_tumor: 0.4594 - val_recall_tumor: 0.3653 - val_tumor_iou: 0.2589 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 78 lên WandB.\n\n--- Epoch 79/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9815 - dice_coef_metric_tumor: 0.4756 - loss: 0.3418 - mean_iou_all: 0.2817 - precision_tumor: 0.4788 - recall_tumor: 0.5398 - tumor_iou: 0.3289\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.40760\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9815 - dice_coef_metric_tumor: 0.4754 - loss: 0.3418 - mean_iou_all: 0.2818 - precision_tumor: 0.4787 - recall_tumor: 0.5398 - tumor_iou: 0.3288 - val_acc: 0.9680 - val_dice_coef_metric_tumor: 0.3536 - val_loss: 0.4307 - val_mean_iou_all: 0.2554 - val_precision_tumor: 0.2785 - val_recall_tumor: 0.5780 - val_tumor_iou: 0.2294 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 79 lên WandB.\n\n--- Epoch 80/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9812 - dice_coef_metric_tumor: 0.4714 - loss: 0.3446 - mean_iou_all: 0.2890 - precision_tumor: 0.4598 - recall_tumor: 0.5399 - tumor_iou: 0.3243\nEpoch 1: val_dice_coef_metric_tumor improved from 0.40760 to 0.42922, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 926ms/step - acc: 0.9812 - dice_coef_metric_tumor: 0.4713 - loss: 0.3446 - mean_iou_all: 0.2892 - precision_tumor: 0.4598 - recall_tumor: 0.5398 - tumor_iou: 0.3242 - val_acc: 0.9829 - val_dice_coef_metric_tumor: 0.4292 - val_loss: 0.3788 - val_mean_iou_all: 0.2595 - val_precision_tumor: 0.4362 - val_recall_tumor: 0.4655 - val_tumor_iou: 0.2950 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 80 lên WandB.\n\n--- Epoch 81/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9810 - dice_coef_metric_tumor: 0.4800 - loss: 0.3397 - mean_iou_all: 0.2896 - precision_tumor: 0.4605 - recall_tumor: 0.5613 - tumor_iou: 0.3338\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42922\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9810 - dice_coef_metric_tumor: 0.4799 - loss: 0.3397 - mean_iou_all: 0.2898 - precision_tumor: 0.4604 - recall_tumor: 0.5611 - tumor_iou: 0.3336 - val_acc: 0.9831 - val_dice_coef_metric_tumor: 0.4111 - val_loss: 0.3895 - val_mean_iou_all: 0.2556 - val_precision_tumor: 0.4537 - val_recall_tumor: 0.4274 - val_tumor_iou: 0.2756 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 81 lên WandB.\n\n--- Epoch 82/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9811 - dice_coef_metric_tumor: 0.4810 - loss: 0.3389 - mean_iou_all: 0.2887 - precision_tumor: 0.4696 - recall_tumor: 0.5704 - tumor_iou: 0.3319\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42922\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9811 - dice_coef_metric_tumor: 0.4809 - loss: 0.3389 - mean_iou_all: 0.2889 - precision_tumor: 0.4696 - recall_tumor: 0.5703 - tumor_iou: 0.3319 - val_acc: 0.9832 - val_dice_coef_metric_tumor: 0.3902 - val_loss: 0.4021 - val_mean_iou_all: 0.2627 - val_precision_tumor: 0.4701 - val_recall_tumor: 0.3883 - val_tumor_iou: 0.2569 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 82 lên WandB.\n\n--- Epoch 83/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9811 - dice_coef_metric_tumor: 0.4701 - loss: 0.3449 - mean_iou_all: 0.2981 - precision_tumor: 0.4586 - recall_tumor: 0.5535 - tumor_iou: 0.3241\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.42922\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9811 - dice_coef_metric_tumor: 0.4700 - loss: 0.3449 - mean_iou_all: 0.2984 - precision_tumor: 0.4584 - recall_tumor: 0.5534 - tumor_iou: 0.3240 - val_acc: 0.9783 - val_dice_coef_metric_tumor: 0.4072 - val_loss: 0.3940 - val_mean_iou_all: 0.2630 - val_precision_tumor: 0.3759 - val_recall_tumor: 0.5015 - val_tumor_iou: 0.2736 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 83 lên WandB.\n\n--- Epoch 84/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9820 - dice_coef_metric_tumor: 0.4807 - loss: 0.3319 - mean_iou_all: 0.2865 - precision_tumor: 0.4717 - recall_tumor: 0.5667 - tumor_iou: 0.3345\nEpoch 1: val_dice_coef_metric_tumor improved from 0.42922 to 0.45122, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 924ms/step - acc: 0.9820 - dice_coef_metric_tumor: 0.4805 - loss: 0.3320 - mean_iou_all: 0.2866 - precision_tumor: 0.4716 - recall_tumor: 0.5665 - tumor_iou: 0.3343 - val_acc: 0.9821 - val_dice_coef_metric_tumor: 0.4512 - val_loss: 0.3659 - val_mean_iou_all: 0.2577 - val_precision_tumor: 0.4219 - val_recall_tumor: 0.5406 - val_tumor_iou: 0.3096 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 84 lên WandB.\n\n--- Epoch 85/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9806 - dice_coef_metric_tumor: 0.4699 - loss: 0.3449 - mean_iou_all: 0.2937 - precision_tumor: 0.4598 - recall_tumor: 0.5609 - tumor_iou: 0.3272\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45122\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9806 - dice_coef_metric_tumor: 0.4698 - loss: 0.3449 - mean_iou_all: 0.2938 - precision_tumor: 0.4598 - recall_tumor: 0.5608 - tumor_iou: 0.3271 - val_acc: 0.9847 - val_dice_coef_metric_tumor: 0.4023 - val_loss: 0.3953 - val_mean_iou_all: 0.2511 - val_precision_tumor: 0.5264 - val_recall_tumor: 0.3591 - val_tumor_iou: 0.2714 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 85 lên WandB.\n\n--- Epoch 86/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9811 - dice_coef_metric_tumor: 0.4783 - loss: 0.3350 - mean_iou_all: 0.2809 - precision_tumor: 0.4683 - recall_tumor: 0.5705 - tumor_iou: 0.3333\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45122\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9811 - dice_coef_metric_tumor: 0.4782 - loss: 0.3350 - mean_iou_all: 0.2811 - precision_tumor: 0.4682 - recall_tumor: 0.5705 - tumor_iou: 0.3332 - val_acc: 0.9857 - val_dice_coef_metric_tumor: 0.4293 - val_loss: 0.3777 - val_mean_iou_all: 0.2935 - val_precision_tumor: 0.5224 - val_recall_tumor: 0.3993 - val_tumor_iou: 0.2939 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 86 lên WandB.\n\n--- Epoch 87/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9821 - dice_coef_metric_tumor: 0.4808 - loss: 0.3412 - mean_iou_all: 0.2877 - precision_tumor: 0.4935 - recall_tumor: 0.5427 - tumor_iou: 0.3349\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45122\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9821 - dice_coef_metric_tumor: 0.4808 - loss: 0.3411 - mean_iou_all: 0.2879 - precision_tumor: 0.4934 - recall_tumor: 0.5427 - tumor_iou: 0.3348 - val_acc: 0.9796 - val_dice_coef_metric_tumor: 0.4488 - val_loss: 0.3686 - val_mean_iou_all: 0.2640 - val_precision_tumor: 0.4135 - val_recall_tumor: 0.5551 - val_tumor_iou: 0.3061 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 87 lên WandB.\n\n--- Epoch 88/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9816 - dice_coef_metric_tumor: 0.4634 - loss: 0.3406 - mean_iou_all: 0.2976 - precision_tumor: 0.4593 - recall_tumor: 0.5427 - tumor_iou: 0.3223\nEpoch 1: val_dice_coef_metric_tumor improved from 0.45122 to 0.45828, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 925ms/step - acc: 0.9816 - dice_coef_metric_tumor: 0.4633 - loss: 0.3406 - mean_iou_all: 0.2978 - precision_tumor: 0.4592 - recall_tumor: 0.5427 - tumor_iou: 0.3222 - val_acc: 0.9850 - val_dice_coef_metric_tumor: 0.4583 - val_loss: 0.3612 - val_mean_iou_all: 0.2586 - val_precision_tumor: 0.4978 - val_recall_tumor: 0.4591 - val_tumor_iou: 0.3188 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 88 lên WandB.\n\n--- Epoch 89/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9819 - dice_coef_metric_tumor: 0.4999 - loss: 0.3324 - mean_iou_all: 0.2926 - precision_tumor: 0.4884 - recall_tumor: 0.5717 - tumor_iou: 0.3499\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45828\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9819 - dice_coef_metric_tumor: 0.4998 - loss: 0.3324 - mean_iou_all: 0.2928 - precision_tumor: 0.4883 - recall_tumor: 0.5716 - tumor_iou: 0.3498 - val_acc: 0.9800 - val_dice_coef_metric_tumor: 0.4474 - val_loss: 0.3701 - val_mean_iou_all: 0.2596 - val_precision_tumor: 0.4029 - val_recall_tumor: 0.5540 - val_tumor_iou: 0.3091 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 89 lên WandB.\n\n--- Epoch 90/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821ms/step - acc: 0.9821 - dice_coef_metric_tumor: 0.4913 - loss: 0.3244 - mean_iou_all: 0.2922 - precision_tumor: 0.4723 - recall_tumor: 0.5851 - tumor_iou: 0.3457\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45828\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 921ms/step - acc: 0.9821 - dice_coef_metric_tumor: 0.4911 - loss: 0.3245 - mean_iou_all: 0.2924 - precision_tumor: 0.4721 - recall_tumor: 0.5850 - tumor_iou: 0.3456 - val_acc: 0.9862 - val_dice_coef_metric_tumor: 0.4306 - val_loss: 0.3776 - val_mean_iou_all: 0.2913 - val_precision_tumor: 0.5287 - val_recall_tumor: 0.3962 - val_tumor_iou: 0.2985 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 90 lên WandB.\n\n--- Epoch 91/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.5037 - loss: 0.3203 - mean_iou_all: 0.2923 - precision_tumor: 0.4886 - recall_tumor: 0.5817 - tumor_iou: 0.3537\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45828\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.5036 - loss: 0.3204 - mean_iou_all: 0.2925 - precision_tumor: 0.4885 - recall_tumor: 0.5816 - tumor_iou: 0.3536 - val_acc: 0.9768 - val_dice_coef_metric_tumor: 0.4163 - val_loss: 0.3894 - val_mean_iou_all: 0.3552 - val_precision_tumor: 0.3455 - val_recall_tumor: 0.6030 - val_tumor_iou: 0.2792 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 91 lên WandB.\n\n--- Epoch 92/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822ms/step - acc: 0.9821 - dice_coef_metric_tumor: 0.5005 - loss: 0.3276 - mean_iou_all: 0.3053 - precision_tumor: 0.4860 - recall_tumor: 0.5721 - tumor_iou: 0.3479\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45828\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 921ms/step - acc: 0.9821 - dice_coef_metric_tumor: 0.5004 - loss: 0.3276 - mean_iou_all: 0.3056 - precision_tumor: 0.4859 - recall_tumor: 0.5721 - tumor_iou: 0.3478 - val_acc: 0.9849 - val_dice_coef_metric_tumor: 0.4133 - val_loss: 0.3885 - val_mean_iou_all: 0.2581 - val_precision_tumor: 0.4919 - val_recall_tumor: 0.3812 - val_tumor_iou: 0.2829 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 92 lên WandB.\n\n--- Epoch 93/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.4899 - loss: 0.3263 - mean_iou_all: 0.3127 - precision_tumor: 0.4842 - recall_tumor: 0.5532 - tumor_iou: 0.3448\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45828\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.4899 - loss: 0.3263 - mean_iou_all: 0.3131 - precision_tumor: 0.4840 - recall_tumor: 0.5532 - tumor_iou: 0.3448 - val_acc: 0.9830 - val_dice_coef_metric_tumor: 0.4511 - val_loss: 0.3666 - val_mean_iou_all: 0.2691 - val_precision_tumor: 0.4315 - val_recall_tumor: 0.5098 - val_tumor_iou: 0.3131 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 93 lên WandB.\n\n--- Epoch 94/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9835 - dice_coef_metric_tumor: 0.4992 - loss: 0.3251 - mean_iou_all: 0.3062 - precision_tumor: 0.5029 - recall_tumor: 0.5627 - tumor_iou: 0.3528\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45828\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9835 - dice_coef_metric_tumor: 0.4991 - loss: 0.3251 - mean_iou_all: 0.3065 - precision_tumor: 0.5027 - recall_tumor: 0.5627 - tumor_iou: 0.3527 - val_acc: 0.9797 - val_dice_coef_metric_tumor: 0.3960 - val_loss: 0.4015 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4054 - val_recall_tumor: 0.4420 - val_tumor_iou: 0.2662 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 94 lên WandB.\n\n--- Epoch 95/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821ms/step - acc: 0.9825 - dice_coef_metric_tumor: 0.4945 - loss: 0.3337 - mean_iou_all: 0.3475 - precision_tumor: 0.4973 - recall_tumor: 0.5523 - tumor_iou: 0.3455\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.45828\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 922ms/step - acc: 0.9825 - dice_coef_metric_tumor: 0.4944 - loss: 0.3337 - mean_iou_all: 0.3479 - precision_tumor: 0.4973 - recall_tumor: 0.5522 - tumor_iou: 0.3455 - val_acc: 0.9831 - val_dice_coef_metric_tumor: 0.4228 - val_loss: 0.3836 - val_mean_iou_all: 0.2902 - val_precision_tumor: 0.4517 - val_recall_tumor: 0.4493 - val_tumor_iou: 0.2835 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 95 lên WandB.\n\n--- Epoch 96/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9812 - dice_coef_metric_tumor: 0.4792 - loss: 0.3453 - mean_iou_all: 0.3345 - precision_tumor: 0.4866 - recall_tumor: 0.5520 - tumor_iou: 0.3314\nEpoch 1: val_dice_coef_metric_tumor improved from 0.45828 to 0.47567, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 927ms/step - acc: 0.9812 - dice_coef_metric_tumor: 0.4791 - loss: 0.3452 - mean_iou_all: 0.3349 - precision_tumor: 0.4865 - recall_tumor: 0.5520 - tumor_iou: 0.3314 - val_acc: 0.9858 - val_dice_coef_metric_tumor: 0.4757 - val_loss: 0.3510 - val_mean_iou_all: 0.2716 - val_precision_tumor: 0.5108 - val_recall_tumor: 0.4696 - val_tumor_iou: 0.3321 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 96 lên WandB.\n\n--- Epoch 97/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9845 - dice_coef_metric_tumor: 0.5137 - loss: 0.3149 - mean_iou_all: 0.3463 - precision_tumor: 0.5327 - recall_tumor: 0.5547 - tumor_iou: 0.3637\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47567\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9845 - dice_coef_metric_tumor: 0.5136 - loss: 0.3149 - mean_iou_all: 0.3467 - precision_tumor: 0.5326 - recall_tumor: 0.5546 - tumor_iou: 0.3637 - val_acc: 0.9822 - val_dice_coef_metric_tumor: 0.4410 - val_loss: 0.3738 - val_mean_iou_all: 0.2918 - val_precision_tumor: 0.4319 - val_recall_tumor: 0.4924 - val_tumor_iou: 0.3037 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 97 lên WandB.\n\n--- Epoch 98/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9832 - dice_coef_metric_tumor: 0.5101 - loss: 0.3162 - mean_iou_all: 0.3444 - precision_tumor: 0.4980 - recall_tumor: 0.5897 - tumor_iou: 0.3596\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47567\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9832 - dice_coef_metric_tumor: 0.5100 - loss: 0.3162 - mean_iou_all: 0.3448 - precision_tumor: 0.4979 - recall_tumor: 0.5896 - tumor_iou: 0.3595 - val_acc: 0.9817 - val_dice_coef_metric_tumor: 0.4329 - val_loss: 0.3785 - val_mean_iou_all: 0.3953 - val_precision_tumor: 0.4264 - val_recall_tumor: 0.4937 - val_tumor_iou: 0.2961 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 98 lên WandB.\n\n--- Epoch 99/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.5065 - loss: 0.3284 - mean_iou_all: 0.3222 - precision_tumor: 0.5043 - recall_tumor: 0.5594 - tumor_iou: 0.3578\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47567\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9827 - dice_coef_metric_tumor: 0.5065 - loss: 0.3284 - mean_iou_all: 0.3225 - precision_tumor: 0.5043 - recall_tumor: 0.5593 - tumor_iou: 0.3578 - val_acc: 0.9847 - val_dice_coef_metric_tumor: 0.4356 - val_loss: 0.3763 - val_mean_iou_all: 0.2602 - val_precision_tumor: 0.4931 - val_recall_tumor: 0.4255 - val_tumor_iou: 0.2985 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 99 lên WandB.\n\n--- Epoch 100/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9838 - dice_coef_metric_tumor: 0.5277 - loss: 0.3134 - mean_iou_all: 0.3219 - precision_tumor: 0.5252 - recall_tumor: 0.5775 - tumor_iou: 0.3762\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47567\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9838 - dice_coef_metric_tumor: 0.5275 - loss: 0.3134 - mean_iou_all: 0.3222 - precision_tumor: 0.5251 - recall_tumor: 0.5775 - tumor_iou: 0.3761 - val_acc: 0.9788 - val_dice_coef_metric_tumor: 0.4317 - val_loss: 0.3807 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3925 - val_recall_tumor: 0.5510 - val_tumor_iou: 0.2952 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 100 lên WandB.\n\n--- Epoch 101/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9833 - dice_coef_metric_tumor: 0.5106 - loss: 0.3164 - mean_iou_all: 0.3442 - precision_tumor: 0.4997 - recall_tumor: 0.5863 - tumor_iou: 0.3618\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47567\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9833 - dice_coef_metric_tumor: 0.5105 - loss: 0.3164 - mean_iou_all: 0.3445 - precision_tumor: 0.4995 - recall_tumor: 0.5862 - tumor_iou: 0.3616 - val_acc: 0.9871 - val_dice_coef_metric_tumor: 0.4534 - val_loss: 0.3645 - val_mean_iou_all: 0.3770 - val_precision_tumor: 0.6048 - val_recall_tumor: 0.3912 - val_tumor_iou: 0.3151 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 101 lên WandB.\n\n--- Epoch 102/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9835 - dice_coef_metric_tumor: 0.5139 - loss: 0.3166 - mean_iou_all: 0.3456 - precision_tumor: 0.5252 - recall_tumor: 0.5732 - tumor_iou: 0.3636\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47567\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9835 - dice_coef_metric_tumor: 0.5138 - loss: 0.3166 - mean_iou_all: 0.3460 - precision_tumor: 0.5250 - recall_tumor: 0.5731 - tumor_iou: 0.3635 - val_acc: 0.9816 - val_dice_coef_metric_tumor: 0.4497 - val_loss: 0.3688 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4229 - val_recall_tumor: 0.5387 - val_tumor_iou: 0.3108 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 102 lên WandB.\n\n--- Epoch 103/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.5233 - loss: 0.3115 - mean_iou_all: 0.3635 - precision_tumor: 0.5185 - recall_tumor: 0.5940 - tumor_iou: 0.3713\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47567\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.5232 - loss: 0.3115 - mean_iou_all: 0.3639 - precision_tumor: 0.5184 - recall_tumor: 0.5939 - tumor_iou: 0.3711 - val_acc: 0.9863 - val_dice_coef_metric_tumor: 0.4191 - val_loss: 0.3858 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5436 - val_recall_tumor: 0.3617 - val_tumor_iou: 0.2853 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 103 lên WandB.\n\n--- Epoch 104/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9826 - dice_coef_metric_tumor: 0.5088 - loss: 0.3273 - mean_iou_all: 0.3683 - precision_tumor: 0.5045 - recall_tumor: 0.5831 - tumor_iou: 0.3590\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47567\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9826 - dice_coef_metric_tumor: 0.5087 - loss: 0.3273 - mean_iou_all: 0.3687 - precision_tumor: 0.5044 - recall_tumor: 0.5830 - tumor_iou: 0.3589 - val_acc: 0.9737 - val_dice_coef_metric_tumor: 0.4311 - val_loss: 0.3821 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3491 - val_recall_tumor: 0.6692 - val_tumor_iou: 0.2895 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 104 lên WandB.\n\n--- Epoch 105/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.5229 - loss: 0.3132 - mean_iou_all: 0.3812 - precision_tumor: 0.5256 - recall_tumor: 0.5874 - tumor_iou: 0.3736\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47567\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.5228 - loss: 0.3132 - mean_iou_all: 0.3817 - precision_tumor: 0.5255 - recall_tumor: 0.5874 - tumor_iou: 0.3735 - val_acc: 0.9858 - val_dice_coef_metric_tumor: 0.4640 - val_loss: 0.3595 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5357 - val_recall_tumor: 0.4490 - val_tumor_iou: 0.3238 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 105 lên WandB.\n\n--- Epoch 106/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9842 - dice_coef_metric_tumor: 0.5269 - loss: 0.3133 - mean_iou_all: 0.3573 - precision_tumor: 0.5343 - recall_tumor: 0.5809 - tumor_iou: 0.3754\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.47567\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9842 - dice_coef_metric_tumor: 0.5268 - loss: 0.3133 - mean_iou_all: 0.3577 - precision_tumor: 0.5342 - recall_tumor: 0.5808 - tumor_iou: 0.3753 - val_acc: 0.9836 - val_dice_coef_metric_tumor: 0.4485 - val_loss: 0.3696 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4552 - val_recall_tumor: 0.4777 - val_tumor_iou: 0.3111 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 106 lên WandB.\n\n--- Epoch 107/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.5255 - loss: 0.3092 - mean_iou_all: 0.3704 - precision_tumor: 0.5182 - recall_tumor: 0.6025 - tumor_iou: 0.3764\nEpoch 1: val_dice_coef_metric_tumor improved from 0.47567 to 0.49911, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 924ms/step - acc: 0.9836 - dice_coef_metric_tumor: 0.5255 - loss: 0.3091 - mean_iou_all: 0.3709 - precision_tumor: 0.5182 - recall_tumor: 0.6024 - tumor_iou: 0.3764 - val_acc: 0.9858 - val_dice_coef_metric_tumor: 0.4991 - val_loss: 0.3375 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5152 - val_recall_tumor: 0.5238 - val_tumor_iou: 0.3550 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 107 lên WandB.\n\n--- Epoch 108/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.5235 - loss: 0.3110 - mean_iou_all: 0.3943 - precision_tumor: 0.5107 - recall_tumor: 0.6061 - tumor_iou: 0.3756\nEpoch 1: val_dice_coef_metric_tumor improved from 0.49911 to 0.51287, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 925ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.5234 - loss: 0.3110 - mean_iou_all: 0.3948 - precision_tumor: 0.5107 - recall_tumor: 0.6060 - tumor_iou: 0.3756 - val_acc: 0.9850 - val_dice_coef_metric_tumor: 0.5129 - val_loss: 0.3297 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4956 - val_recall_tumor: 0.5844 - val_tumor_iou: 0.3633 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 108 lên WandB.\n\n--- Epoch 109/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.5417 - loss: 0.3057 - mean_iou_all: 0.3868 - precision_tumor: 0.5328 - recall_tumor: 0.6084 - tumor_iou: 0.3881\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51287\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.5416 - loss: 0.3056 - mean_iou_all: 0.3873 - precision_tumor: 0.5328 - recall_tumor: 0.6083 - tumor_iou: 0.3880 - val_acc: 0.9845 - val_dice_coef_metric_tumor: 0.4761 - val_loss: 0.3523 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4918 - val_recall_tumor: 0.5046 - val_tumor_iou: 0.3311 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 109 lên WandB.\n\n--- Epoch 110/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821ms/step - acc: 0.9843 - dice_coef_metric_tumor: 0.5246 - loss: 0.3110 - mean_iou_all: 0.3949 - precision_tumor: 0.5294 - recall_tumor: 0.5764 - tumor_iou: 0.3733\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51287\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9843 - dice_coef_metric_tumor: 0.5245 - loss: 0.3110 - mean_iou_all: 0.3954 - precision_tumor: 0.5293 - recall_tumor: 0.5764 - tumor_iou: 0.3733 - val_acc: 0.9811 - val_dice_coef_metric_tumor: 0.4358 - val_loss: 0.3780 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4161 - val_recall_tumor: 0.5208 - val_tumor_iou: 0.2979 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 110 lên WandB.\n\n--- Epoch 111/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.5299 - loss: 0.3045 - mean_iou_all: 0.3937 - precision_tumor: 0.5113 - recall_tumor: 0.6095 - tumor_iou: 0.3795\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51287\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9839 - dice_coef_metric_tumor: 0.5299 - loss: 0.3045 - mean_iou_all: 0.3942 - precision_tumor: 0.5113 - recall_tumor: 0.6094 - tumor_iou: 0.3794 - val_acc: 0.9848 - val_dice_coef_metric_tumor: 0.4726 - val_loss: 0.3548 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4986 - val_recall_tumor: 0.4828 - val_tumor_iou: 0.3332 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 111 lên WandB.\n\n--- Epoch 112/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9841 - dice_coef_metric_tumor: 0.5304 - loss: 0.3068 - mean_iou_all: 0.3768 - precision_tumor: 0.5308 - recall_tumor: 0.5904 - tumor_iou: 0.3796\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51287\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9841 - dice_coef_metric_tumor: 0.5303 - loss: 0.3069 - mean_iou_all: 0.3772 - precision_tumor: 0.5307 - recall_tumor: 0.5904 - tumor_iou: 0.3795 - val_acc: 0.9713 - val_dice_coef_metric_tumor: 0.4343 - val_loss: 0.3832 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3558 - val_recall_tumor: 0.6732 - val_tumor_iou: 0.2942 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 112 lên WandB.\n\n--- Epoch 113/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.5245 - loss: 0.3167 - mean_iou_all: 0.3935 - precision_tumor: 0.5187 - recall_tumor: 0.5947 - tumor_iou: 0.3719\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51287\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.5244 - loss: 0.3166 - mean_iou_all: 0.3940 - precision_tumor: 0.5187 - recall_tumor: 0.5946 - tumor_iou: 0.3719 - val_acc: 0.9877 - val_dice_coef_metric_tumor: 0.4774 - val_loss: 0.3505 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6096 - val_recall_tumor: 0.4178 - val_tumor_iou: 0.3398 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 113 lên WandB.\n\n--- Epoch 114/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5468 - loss: 0.2980 - mean_iou_all: 0.4179 - precision_tumor: 0.5517 - recall_tumor: 0.5971 - tumor_iou: 0.3962\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51287\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5467 - loss: 0.2980 - mean_iou_all: 0.4184 - precision_tumor: 0.5516 - recall_tumor: 0.5971 - tumor_iou: 0.3961 - val_acc: 0.9848 - val_dice_coef_metric_tumor: 0.5099 - val_loss: 0.3323 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4959 - val_recall_tumor: 0.5608 - val_tumor_iou: 0.3659 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 114 lên WandB.\n\n--- Epoch 115/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5498 - loss: 0.3001 - mean_iou_all: 0.4218 - precision_tumor: 0.5388 - recall_tumor: 0.6118 - tumor_iou: 0.3974\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51287\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5497 - loss: 0.3001 - mean_iou_all: 0.4222 - precision_tumor: 0.5387 - recall_tumor: 0.6117 - tumor_iou: 0.3973 - val_acc: 0.9847 - val_dice_coef_metric_tumor: 0.4824 - val_loss: 0.3486 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4833 - val_recall_tumor: 0.5346 - val_tumor_iou: 0.3365 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 115 lên WandB.\n\n--- Epoch 116/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.5178 - loss: 0.3204 - mean_iou_all: 0.4161 - precision_tumor: 0.5117 - recall_tumor: 0.5799 - tumor_iou: 0.3652\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51287\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9831 - dice_coef_metric_tumor: 0.5178 - loss: 0.3204 - mean_iou_all: 0.4165 - precision_tumor: 0.5117 - recall_tumor: 0.5799 - tumor_iou: 0.3651 - val_acc: 0.9832 - val_dice_coef_metric_tumor: 0.4856 - val_loss: 0.3478 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4760 - val_recall_tumor: 0.5487 - val_tumor_iou: 0.3416 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 116 lên WandB.\n\n--- Epoch 117/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5467 - loss: 0.2982 - mean_iou_all: 0.4100 - precision_tumor: 0.5455 - recall_tumor: 0.6097 - tumor_iou: 0.3936\nEpoch 1: val_dice_coef_metric_tumor improved from 0.51287 to 0.51399, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 926ms/step - acc: 0.9847 - dice_coef_metric_tumor: 0.5466 - loss: 0.2982 - mean_iou_all: 0.4105 - precision_tumor: 0.5454 - recall_tumor: 0.6097 - tumor_iou: 0.3935 - val_acc: 0.9857 - val_dice_coef_metric_tumor: 0.5140 - val_loss: 0.3299 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5245 - val_recall_tumor: 0.5439 - val_tumor_iou: 0.3669 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 117 lên WandB.\n\n--- Epoch 118/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9849 - dice_coef_metric_tumor: 0.5494 - loss: 0.2952 - mean_iou_all: 0.4243 - precision_tumor: 0.5491 - recall_tumor: 0.6079 - tumor_iou: 0.3960\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51399\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5492 - loss: 0.2952 - mean_iou_all: 0.4247 - precision_tumor: 0.5490 - recall_tumor: 0.6079 - tumor_iou: 0.3959 - val_acc: 0.9826 - val_dice_coef_metric_tumor: 0.5009 - val_loss: 0.3387 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4450 - val_recall_tumor: 0.6260 - val_tumor_iou: 0.3559 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 118 lên WandB.\n\n--- Epoch 119/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5542 - loss: 0.2954 - mean_iou_all: 0.4066 - precision_tumor: 0.5595 - recall_tumor: 0.5985 - tumor_iou: 0.4009\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51399\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5541 - loss: 0.2954 - mean_iou_all: 0.4071 - precision_tumor: 0.5593 - recall_tumor: 0.5984 - tumor_iou: 0.4008 - val_acc: 0.9870 - val_dice_coef_metric_tumor: 0.4656 - val_loss: 0.3588 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5838 - val_recall_tumor: 0.4210 - val_tumor_iou: 0.3308 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 119 lên WandB.\n\n--- Epoch 120/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5497 - loss: 0.3019 - mean_iou_all: 0.4161 - precision_tumor: 0.5642 - recall_tumor: 0.5987 - tumor_iou: 0.3959\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51399\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5496 - loss: 0.3018 - mean_iou_all: 0.4165 - precision_tumor: 0.5640 - recall_tumor: 0.5987 - tumor_iou: 0.3958 - val_acc: 0.9772 - val_dice_coef_metric_tumor: 0.4673 - val_loss: 0.3617 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3825 - val_recall_tumor: 0.6829 - val_tumor_iou: 0.3233 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 120 lên WandB.\n\n--- Epoch 121/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5484 - loss: 0.2996 - mean_iou_all: 0.4015 - precision_tumor: 0.5535 - recall_tumor: 0.5999 - tumor_iou: 0.3980\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51399\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5483 - loss: 0.2995 - mean_iou_all: 0.4020 - precision_tumor: 0.5533 - recall_tumor: 0.6000 - tumor_iou: 0.3979 - val_acc: 0.9823 - val_dice_coef_metric_tumor: 0.5008 - val_loss: 0.3387 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4475 - val_recall_tumor: 0.6335 - val_tumor_iou: 0.3546 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 121 lên WandB.\n\n--- Epoch 122/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5627 - loss: 0.2889 - mean_iou_all: 0.4312 - precision_tumor: 0.5580 - recall_tumor: 0.6305 - tumor_iou: 0.4114\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51399\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 915ms/step - acc: 0.9853 - dice_coef_metric_tumor: 0.5626 - loss: 0.2890 - mean_iou_all: 0.4316 - precision_tumor: 0.5580 - recall_tumor: 0.6303 - tumor_iou: 0.4113 - val_acc: 0.9744 - val_dice_coef_metric_tumor: 0.4139 - val_loss: 0.3959 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3577 - val_recall_tumor: 0.5942 - val_tumor_iou: 0.2780 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 122 lên WandB.\n\n--- Epoch 123/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5425 - loss: 0.3061 - mean_iou_all: 0.4374 - precision_tumor: 0.5545 - recall_tumor: 0.5876 - tumor_iou: 0.3913\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51399\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 921ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5425 - loss: 0.3060 - mean_iou_all: 0.4377 - precision_tumor: 0.5546 - recall_tumor: 0.5876 - tumor_iou: 0.3913 - val_acc: 0.9825 - val_dice_coef_metric_tumor: 0.4962 - val_loss: 0.3422 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4429 - val_recall_tumor: 0.6163 - val_tumor_iou: 0.3514 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 123 lên WandB.\n\n--- Epoch 124/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5514 - loss: 0.2919 - mean_iou_all: 0.4313 - precision_tumor: 0.5391 - recall_tumor: 0.6212 - tumor_iou: 0.4010\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.51399\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 921ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5514 - loss: 0.2919 - mean_iou_all: 0.4317 - precision_tumor: 0.5391 - recall_tumor: 0.6212 - tumor_iou: 0.4009 - val_acc: 0.9871 - val_dice_coef_metric_tumor: 0.5063 - val_loss: 0.3347 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5862 - val_recall_tumor: 0.4763 - val_tumor_iou: 0.3584 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 124 lên WandB.\n\n--- Epoch 125/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9857 - dice_coef_metric_tumor: 0.5616 - loss: 0.2901 - mean_iou_all: 0.4335 - precision_tumor: 0.5717 - recall_tumor: 0.6094 - tumor_iou: 0.4088\nEpoch 1: val_dice_coef_metric_tumor improved from 0.51399 to 0.52444, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 926ms/step - acc: 0.9857 - dice_coef_metric_tumor: 0.5616 - loss: 0.2900 - mean_iou_all: 0.4338 - precision_tumor: 0.5717 - recall_tumor: 0.6093 - tumor_iou: 0.4087 - val_acc: 0.9856 - val_dice_coef_metric_tumor: 0.5244 - val_loss: 0.3245 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5228 - val_recall_tumor: 0.5726 - val_tumor_iou: 0.3749 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 125 lên WandB.\n\n--- Epoch 126/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9852 - dice_coef_metric_tumor: 0.5645 - loss: 0.2891 - mean_iou_all: 0.4413 - precision_tumor: 0.5554 - recall_tumor: 0.6211 - tumor_iou: 0.4130\nEpoch 1: val_dice_coef_metric_tumor improved from 0.52444 to 0.53080, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 924ms/step - acc: 0.9852 - dice_coef_metric_tumor: 0.5644 - loss: 0.2891 - mean_iou_all: 0.4416 - precision_tumor: 0.5553 - recall_tumor: 0.6210 - tumor_iou: 0.4129 - val_acc: 0.9869 - val_dice_coef_metric_tumor: 0.5308 - val_loss: 0.3200 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5643 - val_recall_tumor: 0.5289 - val_tumor_iou: 0.3866 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 126 lên WandB.\n\n--- Epoch 127/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5516 - loss: 0.2985 - mean_iou_all: 0.4485 - precision_tumor: 0.5540 - recall_tumor: 0.6088 - tumor_iou: 0.4005\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53080\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9850 - dice_coef_metric_tumor: 0.5515 - loss: 0.2985 - mean_iou_all: 0.4488 - precision_tumor: 0.5540 - recall_tumor: 0.6087 - tumor_iou: 0.4005 - val_acc: 0.9856 - val_dice_coef_metric_tumor: 0.5219 - val_loss: 0.3255 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5066 - val_recall_tumor: 0.5767 - val_tumor_iou: 0.3767 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 127 lên WandB.\n\n--- Epoch 128/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5430 - loss: 0.2970 - mean_iou_all: 0.4542 - precision_tumor: 0.5432 - recall_tumor: 0.6133 - tumor_iou: 0.3958\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53080\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9851 - dice_coef_metric_tumor: 0.5429 - loss: 0.2970 - mean_iou_all: 0.4544 - precision_tumor: 0.5431 - recall_tumor: 0.6132 - tumor_iou: 0.3957 - val_acc: 0.9814 - val_dice_coef_metric_tumor: 0.5106 - val_loss: 0.3346 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4367 - val_recall_tumor: 0.6685 - val_tumor_iou: 0.3634 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 128 lên WandB.\n\n--- Epoch 129/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5615 - loss: 0.2906 - mean_iou_all: 0.4488 - precision_tumor: 0.5601 - recall_tumor: 0.6203 - tumor_iou: 0.4097\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53080\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9856 - dice_coef_metric_tumor: 0.5614 - loss: 0.2906 - mean_iou_all: 0.4491 - precision_tumor: 0.5600 - recall_tumor: 0.6202 - tumor_iou: 0.4096 - val_acc: 0.9854 - val_dice_coef_metric_tumor: 0.5209 - val_loss: 0.3269 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5154 - val_recall_tumor: 0.5666 - val_tumor_iou: 0.3770 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 129 lên WandB.\n\n--- Epoch 130/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5747 - loss: 0.2838 - mean_iou_all: 0.4470 - precision_tumor: 0.5828 - recall_tumor: 0.6161 - tumor_iou: 0.4209\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53080\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5746 - loss: 0.2838 - mean_iou_all: 0.4473 - precision_tumor: 0.5827 - recall_tumor: 0.6160 - tumor_iou: 0.4209 - val_acc: 0.9871 - val_dice_coef_metric_tumor: 0.5177 - val_loss: 0.3283 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5710 - val_recall_tumor: 0.5118 - val_tumor_iou: 0.3728 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 130 lên WandB.\n\n--- Epoch 131/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9841 - dice_coef_metric_tumor: 0.5485 - loss: 0.2973 - mean_iou_all: 0.4527 - precision_tumor: 0.5382 - recall_tumor: 0.6258 - tumor_iou: 0.3984\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53080\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9841 - dice_coef_metric_tumor: 0.5483 - loss: 0.2973 - mean_iou_all: 0.4529 - precision_tumor: 0.5381 - recall_tumor: 0.6257 - tumor_iou: 0.3984 - val_acc: 0.9872 - val_dice_coef_metric_tumor: 0.5248 - val_loss: 0.3239 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5763 - val_recall_tumor: 0.5180 - val_tumor_iou: 0.3820 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 131 lên WandB.\n\n--- Epoch 132/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5772 - loss: 0.2822 - mean_iou_all: 0.4505 - precision_tumor: 0.5828 - recall_tumor: 0.6248 - tumor_iou: 0.4266\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53080\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5771 - loss: 0.2822 - mean_iou_all: 0.4506 - precision_tumor: 0.5826 - recall_tumor: 0.6247 - tumor_iou: 0.4264 - val_acc: 0.9875 - val_dice_coef_metric_tumor: 0.4996 - val_loss: 0.3389 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5788 - val_recall_tumor: 0.4725 - val_tumor_iou: 0.3619 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 132 lên WandB.\n\n--- Epoch 133/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5749 - loss: 0.2851 - mean_iou_all: 0.4392 - precision_tumor: 0.5822 - recall_tumor: 0.6209 - tumor_iou: 0.4212\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53080\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 915ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5748 - loss: 0.2852 - mean_iou_all: 0.4395 - precision_tumor: 0.5821 - recall_tumor: 0.6208 - tumor_iou: 0.4211 - val_acc: 0.9877 - val_dice_coef_metric_tumor: 0.5242 - val_loss: 0.3242 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6023 - val_recall_tumor: 0.4969 - val_tumor_iou: 0.3782 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 133 lên WandB.\n\n--- Epoch 134/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5818 - loss: 0.2821 - mean_iou_all: 0.4475 - precision_tumor: 0.5965 - recall_tumor: 0.6239 - tumor_iou: 0.4260\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53080\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5817 - loss: 0.2821 - mean_iou_all: 0.4477 - precision_tumor: 0.5963 - recall_tumor: 0.6239 - tumor_iou: 0.4259 - val_acc: 0.9877 - val_dice_coef_metric_tumor: 0.4367 - val_loss: 0.3772 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6433 - val_recall_tumor: 0.3618 - val_tumor_iou: 0.3051 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 134 lên WandB.\n\n--- Epoch 135/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5765 - loss: 0.2883 - mean_iou_all: 0.4630 - precision_tumor: 0.5992 - recall_tumor: 0.6121 - tumor_iou: 0.4211\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53080\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9860 - dice_coef_metric_tumor: 0.5765 - loss: 0.2882 - mean_iou_all: 0.4632 - precision_tumor: 0.5991 - recall_tumor: 0.6121 - tumor_iou: 0.4211 - val_acc: 0.9827 - val_dice_coef_metric_tumor: 0.5096 - val_loss: 0.3346 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4385 - val_recall_tumor: 0.6582 - val_tumor_iou: 0.3634 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 135 lên WandB.\n\n--- Epoch 136/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5921 - loss: 0.2804 - mean_iou_all: 0.4620 - precision_tumor: 0.5896 - recall_tumor: 0.6351 - tumor_iou: 0.4403\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53080\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9861 - dice_coef_metric_tumor: 0.5920 - loss: 0.2803 - mean_iou_all: 0.4622 - precision_tumor: 0.5895 - recall_tumor: 0.6350 - tumor_iou: 0.4402 - val_acc: 0.9841 - val_dice_coef_metric_tumor: 0.5254 - val_loss: 0.3248 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4872 - val_recall_tumor: 0.6135 - val_tumor_iou: 0.3797 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 136 lên WandB.\n\n--- Epoch 137/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5722 - loss: 0.2854 - mean_iou_all: 0.4561 - precision_tumor: 0.5664 - recall_tumor: 0.6317 - tumor_iou: 0.4206\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.53080\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9854 - dice_coef_metric_tumor: 0.5721 - loss: 0.2854 - mean_iou_all: 0.4563 - precision_tumor: 0.5663 - recall_tumor: 0.6316 - tumor_iou: 0.4205 - val_acc: 0.9858 - val_dice_coef_metric_tumor: 0.5174 - val_loss: 0.3292 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5369 - val_recall_tumor: 0.5422 - val_tumor_iou: 0.3753 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 137 lên WandB.\n\n--- Epoch 138/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9855 - dice_coef_metric_tumor: 0.5641 - loss: 0.2891 - mean_iou_all: 0.4678 - precision_tumor: 0.5657 - recall_tumor: 0.6219 - tumor_iou: 0.4159\nEpoch 1: val_dice_coef_metric_tumor improved from 0.53080 to 0.54003, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 925ms/step - acc: 0.9855 - dice_coef_metric_tumor: 0.5641 - loss: 0.2891 - mean_iou_all: 0.4679 - precision_tumor: 0.5657 - recall_tumor: 0.6219 - tumor_iou: 0.4158 - val_acc: 0.9870 - val_dice_coef_metric_tumor: 0.5400 - val_loss: 0.3148 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5435 - val_recall_tumor: 0.5732 - val_tumor_iou: 0.3924 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 138 lên WandB.\n\n--- Epoch 139/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.6051 - loss: 0.2699 - mean_iou_all: 0.4554 - precision_tumor: 0.6133 - recall_tumor: 0.6418 - tumor_iou: 0.4503\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54003\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.6051 - loss: 0.2699 - mean_iou_all: 0.4556 - precision_tumor: 0.6133 - recall_tumor: 0.6418 - tumor_iou: 0.4502 - val_acc: 0.9829 - val_dice_coef_metric_tumor: 0.5102 - val_loss: 0.3346 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4440 - val_recall_tumor: 0.6478 - val_tumor_iou: 0.3619 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 139 lên WandB.\n\n--- Epoch 140/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.6020 - loss: 0.2691 - mean_iou_all: 0.4614 - precision_tumor: 0.5997 - recall_tumor: 0.6448 - tumor_iou: 0.4477\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54003\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.6019 - loss: 0.2691 - mean_iou_all: 0.4616 - precision_tumor: 0.5997 - recall_tumor: 0.6447 - tumor_iou: 0.4476 - val_acc: 0.9861 - val_dice_coef_metric_tumor: 0.5325 - val_loss: 0.3204 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5228 - val_recall_tumor: 0.5850 - val_tumor_iou: 0.3867 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 140 lên WandB.\n\n--- Epoch 141/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5820 - loss: 0.2820 - mean_iou_all: 0.4600 - precision_tumor: 0.5837 - recall_tumor: 0.6284 - tumor_iou: 0.4287\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54003\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9862 - dice_coef_metric_tumor: 0.5819 - loss: 0.2820 - mean_iou_all: 0.4602 - precision_tumor: 0.5836 - recall_tumor: 0.6284 - tumor_iou: 0.4287 - val_acc: 0.9867 - val_dice_coef_metric_tumor: 0.5106 - val_loss: 0.3331 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5619 - val_recall_tumor: 0.5086 - val_tumor_iou: 0.3648 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 141 lên WandB.\n\n--- Epoch 142/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5784 - loss: 0.2809 - mean_iou_all: 0.4683 - precision_tumor: 0.5945 - recall_tumor: 0.6020 - tumor_iou: 0.4269\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54003\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9864 - dice_coef_metric_tumor: 0.5783 - loss: 0.2809 - mean_iou_all: 0.4685 - precision_tumor: 0.5944 - recall_tumor: 0.6020 - tumor_iou: 0.4269 - val_acc: 0.9874 - val_dice_coef_metric_tumor: 0.5116 - val_loss: 0.3327 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5799 - val_recall_tumor: 0.4841 - val_tumor_iou: 0.3714 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 142 lên WandB.\n\n--- Epoch 143/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.6069 - loss: 0.2642 - mean_iou_all: 0.4589 - precision_tumor: 0.6162 - recall_tumor: 0.6359 - tumor_iou: 0.4524\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54003\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.6068 - loss: 0.2643 - mean_iou_all: 0.4591 - precision_tumor: 0.6161 - recall_tumor: 0.6358 - tumor_iou: 0.4523 - val_acc: 0.9863 - val_dice_coef_metric_tumor: 0.5134 - val_loss: 0.3320 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5304 - val_recall_tumor: 0.5343 - val_tumor_iou: 0.3702 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 143 lên WandB.\n\n--- Epoch 144/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9858 - dice_coef_metric_tumor: 0.5754 - loss: 0.2888 - mean_iou_all: 0.4718 - precision_tumor: 0.5865 - recall_tumor: 0.6196 - tumor_iou: 0.4233\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54003\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5753 - loss: 0.2888 - mean_iou_all: 0.4719 - precision_tumor: 0.5865 - recall_tumor: 0.6195 - tumor_iou: 0.4233 - val_acc: 0.9853 - val_dice_coef_metric_tumor: 0.5345 - val_loss: 0.3201 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4981 - val_recall_tumor: 0.6209 - val_tumor_iou: 0.3853 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 144 lên WandB.\n\n--- Epoch 145/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.6006 - loss: 0.2727 - mean_iou_all: 0.4686 - precision_tumor: 0.6004 - recall_tumor: 0.6464 - tumor_iou: 0.4441\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54003\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.6005 - loss: 0.2727 - mean_iou_all: 0.4688 - precision_tumor: 0.6004 - recall_tumor: 0.6462 - tumor_iou: 0.4440 - val_acc: 0.9842 - val_dice_coef_metric_tumor: 0.5231 - val_loss: 0.3269 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4634 - val_recall_tumor: 0.6447 - val_tumor_iou: 0.3748 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 145 lên WandB.\n\n--- Epoch 146/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5966 - loss: 0.2737 - mean_iou_all: 0.4756 - precision_tumor: 0.5907 - recall_tumor: 0.6566 - tumor_iou: 0.4414\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54003\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5965 - loss: 0.2737 - mean_iou_all: 0.4756 - precision_tumor: 0.5907 - recall_tumor: 0.6564 - tumor_iou: 0.4413 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.5143 - val_loss: 0.3312 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5853 - val_recall_tumor: 0.4867 - val_tumor_iou: 0.3750 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 146 lên WandB.\n\n--- Epoch 147/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9865 - dice_coef_metric_tumor: 0.5742 - loss: 0.2812 - mean_iou_all: 0.4652 - precision_tumor: 0.5767 - recall_tumor: 0.6261 - tumor_iou: 0.4187\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54003\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 921ms/step - acc: 0.9865 - dice_coef_metric_tumor: 0.5741 - loss: 0.2812 - mean_iou_all: 0.4653 - precision_tumor: 0.5767 - recall_tumor: 0.6261 - tumor_iou: 0.4187 - val_acc: 0.9799 - val_dice_coef_metric_tumor: 0.4781 - val_loss: 0.3563 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4226 - val_recall_tumor: 0.6250 - val_tumor_iou: 0.3357 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 147 lên WandB.\n\n--- Epoch 148/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5997 - loss: 0.2766 - mean_iou_all: 0.4733 - precision_tumor: 0.5999 - recall_tumor: 0.6447 - tumor_iou: 0.4427\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54003\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5996 - loss: 0.2765 - mean_iou_all: 0.4734 - precision_tumor: 0.5998 - recall_tumor: 0.6447 - tumor_iou: 0.4426 - val_acc: 0.9849 - val_dice_coef_metric_tumor: 0.5284 - val_loss: 0.3238 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5061 - val_recall_tumor: 0.6085 - val_tumor_iou: 0.3810 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 148 lên WandB.\n\n--- Epoch 149/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5894 - loss: 0.2703 - mean_iou_all: 0.4650 - precision_tumor: 0.5941 - recall_tumor: 0.6337 - tumor_iou: 0.4367\nEpoch 1: val_dice_coef_metric_tumor improved from 0.54003 to 0.54328, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 925ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5893 - loss: 0.2703 - mean_iou_all: 0.4651 - precision_tumor: 0.5940 - recall_tumor: 0.6336 - tumor_iou: 0.4366 - val_acc: 0.9881 - val_dice_coef_metric_tumor: 0.5433 - val_loss: 0.3140 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6320 - val_recall_tumor: 0.5044 - val_tumor_iou: 0.3952 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 149 lên WandB.\n\n--- Epoch 150/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5973 - loss: 0.2744 - mean_iou_all: 0.4732 - precision_tumor: 0.6074 - recall_tumor: 0.6335 - tumor_iou: 0.4438\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54328\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5972 - loss: 0.2744 - mean_iou_all: 0.4732 - precision_tumor: 0.6073 - recall_tumor: 0.6335 - tumor_iou: 0.4437 - val_acc: 0.9868 - val_dice_coef_metric_tumor: 0.5398 - val_loss: 0.3162 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5373 - val_recall_tumor: 0.5809 - val_tumor_iou: 0.3937 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 150 lên WandB.\n\n--- Epoch 151/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.5853 - loss: 0.2782 - mean_iou_all: 0.4639 - precision_tumor: 0.5896 - recall_tumor: 0.6317 - tumor_iou: 0.4310\nEpoch 1: val_dice_coef_metric_tumor improved from 0.54328 to 0.54521, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 926ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.5852 - loss: 0.2782 - mean_iou_all: 0.4640 - precision_tumor: 0.5896 - recall_tumor: 0.6316 - tumor_iou: 0.4309 - val_acc: 0.9875 - val_dice_coef_metric_tumor: 0.5452 - val_loss: 0.3125 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5721 - val_recall_tumor: 0.5649 - val_tumor_iou: 0.3967 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 151 lên WandB.\n\n--- Epoch 152/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5768 - loss: 0.2774 - mean_iou_all: 0.4725 - precision_tumor: 0.5700 - recall_tumor: 0.6455 - tumor_iou: 0.4267\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54521\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5767 - loss: 0.2774 - mean_iou_all: 0.4725 - precision_tumor: 0.5700 - recall_tumor: 0.6455 - tumor_iou: 0.4266 - val_acc: 0.9877 - val_dice_coef_metric_tumor: 0.5412 - val_loss: 0.3153 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5796 - val_recall_tumor: 0.5417 - val_tumor_iou: 0.3964 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 152 lên WandB.\n\n--- Epoch 153/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9865 - dice_coef_metric_tumor: 0.5967 - loss: 0.2728 - mean_iou_all: 0.4696 - precision_tumor: 0.5995 - recall_tumor: 0.6505 - tumor_iou: 0.4451\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.54521\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9865 - dice_coef_metric_tumor: 0.5966 - loss: 0.2728 - mean_iou_all: 0.4697 - precision_tumor: 0.5995 - recall_tumor: 0.6504 - tumor_iou: 0.4450 - val_acc: 0.9835 - val_dice_coef_metric_tumor: 0.5190 - val_loss: 0.3305 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4698 - val_recall_tumor: 0.6431 - val_tumor_iou: 0.3710 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 153 lên WandB.\n\n--- Epoch 154/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.6067 - loss: 0.2653 - mean_iou_all: 0.4658 - precision_tumor: 0.6065 - recall_tumor: 0.6462 - tumor_iou: 0.4551\nEpoch 1: val_dice_coef_metric_tumor improved from 0.54521 to 0.55251, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 928ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.6066 - loss: 0.2653 - mean_iou_all: 0.4659 - precision_tumor: 0.6065 - recall_tumor: 0.6460 - tumor_iou: 0.4550 - val_acc: 0.9859 - val_dice_coef_metric_tumor: 0.5525 - val_loss: 0.3088 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5342 - val_recall_tumor: 0.6232 - val_tumor_iou: 0.4052 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 154 lên WandB.\n\n--- Epoch 155/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.5843 - loss: 0.2732 - mean_iou_all: 0.4755 - precision_tumor: 0.5813 - recall_tumor: 0.6434 - tumor_iou: 0.4337\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55251\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9866 - dice_coef_metric_tumor: 0.5843 - loss: 0.2732 - mean_iou_all: 0.4755 - precision_tumor: 0.5814 - recall_tumor: 0.6433 - tumor_iou: 0.4336 - val_acc: 0.9869 - val_dice_coef_metric_tumor: 0.5448 - val_loss: 0.3136 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5405 - val_recall_tumor: 0.5896 - val_tumor_iou: 0.3965 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 155 lên WandB.\n\n--- Epoch 156/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.6083 - loss: 0.2701 - mean_iou_all: 0.4702 - precision_tumor: 0.6190 - recall_tumor: 0.6496 - tumor_iou: 0.4514\nEpoch 1: val_dice_coef_metric_tumor improved from 0.55251 to 0.55674, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 924ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.6082 - loss: 0.2701 - mean_iou_all: 0.4702 - precision_tumor: 0.6189 - recall_tumor: 0.6496 - tumor_iou: 0.4513 - val_acc: 0.9880 - val_dice_coef_metric_tumor: 0.5567 - val_loss: 0.3061 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5833 - val_recall_tumor: 0.5603 - val_tumor_iou: 0.4138 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 156 lên WandB.\n\n--- Epoch 157/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9865 - dice_coef_metric_tumor: 0.5850 - loss: 0.2787 - mean_iou_all: 0.4630 - precision_tumor: 0.5888 - recall_tumor: 0.6279 - tumor_iou: 0.4323\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55674\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9865 - dice_coef_metric_tumor: 0.5849 - loss: 0.2787 - mean_iou_all: 0.4630 - precision_tumor: 0.5887 - recall_tumor: 0.6279 - tumor_iou: 0.4323 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.5381 - val_loss: 0.3175 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5936 - val_recall_tumor: 0.5225 - val_tumor_iou: 0.3962 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 157 lên WandB.\n\n--- Epoch 158/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5956 - loss: 0.2764 - mean_iou_all: 0.4785 - precision_tumor: 0.5875 - recall_tumor: 0.6468 - tumor_iou: 0.4433\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55674\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9863 - dice_coef_metric_tumor: 0.5955 - loss: 0.2764 - mean_iou_all: 0.4786 - precision_tumor: 0.5874 - recall_tumor: 0.6467 - tumor_iou: 0.4433 - val_acc: 0.9864 - val_dice_coef_metric_tumor: 0.5495 - val_loss: 0.3109 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5332 - val_recall_tumor: 0.6140 - val_tumor_iou: 0.3998 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 158 lên WandB.\n\n--- Epoch 159/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5911 - loss: 0.2773 - mean_iou_all: 0.4630 - precision_tumor: 0.6085 - recall_tumor: 0.6245 - tumor_iou: 0.4388\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55674\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9870 - dice_coef_metric_tumor: 0.5911 - loss: 0.2773 - mean_iou_all: 0.4630 - precision_tumor: 0.6084 - recall_tumor: 0.6245 - tumor_iou: 0.4387 - val_acc: 0.9877 - val_dice_coef_metric_tumor: 0.5301 - val_loss: 0.3226 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6222 - val_recall_tumor: 0.4973 - val_tumor_iou: 0.3867 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 159 lên WandB.\n\n--- Epoch 160/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5993 - loss: 0.2777 - mean_iou_all: 0.4590 - precision_tumor: 0.6148 - recall_tumor: 0.6352 - tumor_iou: 0.4456\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55674\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9868 - dice_coef_metric_tumor: 0.5993 - loss: 0.2776 - mean_iou_all: 0.4590 - precision_tumor: 0.6148 - recall_tumor: 0.6353 - tumor_iou: 0.4456 - val_acc: 0.9842 - val_dice_coef_metric_tumor: 0.5266 - val_loss: 0.3260 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4780 - val_recall_tumor: 0.6419 - val_tumor_iou: 0.3792 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 160 lên WandB.\n\n--- Epoch 161/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.6142 - loss: 0.2625 - mean_iou_all: 0.4684 - precision_tumor: 0.6261 - recall_tumor: 0.6438 - tumor_iou: 0.4608\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.55674\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9877 - dice_coef_metric_tumor: 0.6141 - loss: 0.2625 - mean_iou_all: 0.4684 - precision_tumor: 0.6260 - recall_tumor: 0.6438 - tumor_iou: 0.4607 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.5538 - val_loss: 0.3080 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6160 - val_recall_tumor: 0.5303 - val_tumor_iou: 0.4100 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 161 lên WandB.\n\n--- Epoch 162/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.6020 - loss: 0.2725 - mean_iou_all: 0.4717 - precision_tumor: 0.6077 - recall_tumor: 0.6461 - tumor_iou: 0.4486\nEpoch 1: val_dice_coef_metric_tumor improved from 0.55674 to 0.58246, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 926ms/step - acc: 0.9867 - dice_coef_metric_tumor: 0.6019 - loss: 0.2724 - mean_iou_all: 0.4717 - precision_tumor: 0.6077 - recall_tumor: 0.6460 - tumor_iou: 0.4486 - val_acc: 0.9870 - val_dice_coef_metric_tumor: 0.5825 - val_loss: 0.2913 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5562 - val_recall_tumor: 0.6491 - val_tumor_iou: 0.4345 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 162 lên WandB.\n\n--- Epoch 163/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.6115 - loss: 0.2654 - mean_iou_all: 0.4747 - precision_tumor: 0.6065 - recall_tumor: 0.6605 - tumor_iou: 0.4583\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9869 - dice_coef_metric_tumor: 0.6114 - loss: 0.2654 - mean_iou_all: 0.4747 - precision_tumor: 0.6065 - recall_tumor: 0.6604 - tumor_iou: 0.4582 - val_acc: 0.9802 - val_dice_coef_metric_tumor: 0.5067 - val_loss: 0.3398 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4273 - val_recall_tumor: 0.7023 - val_tumor_iou: 0.3570 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 163 lên WandB.\n\n--- Epoch 164/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6227 - loss: 0.2599 - mean_iou_all: 0.4789 - precision_tumor: 0.6426 - recall_tumor: 0.6393 - tumor_iou: 0.4691\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6226 - loss: 0.2599 - mean_iou_all: 0.4789 - precision_tumor: 0.6425 - recall_tumor: 0.6393 - tumor_iou: 0.4691 - val_acc: 0.9881 - val_dice_coef_metric_tumor: 0.5685 - val_loss: 0.2997 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6065 - val_recall_tumor: 0.5653 - val_tumor_iou: 0.4207 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 164 lên WandB.\n\n--- Epoch 165/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.6146 - loss: 0.2664 - mean_iou_all: 0.4706 - precision_tumor: 0.6331 - recall_tumor: 0.6511 - tumor_iou: 0.4607\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 915ms/step - acc: 0.9871 - dice_coef_metric_tumor: 0.6145 - loss: 0.2664 - mean_iou_all: 0.4706 - precision_tumor: 0.6330 - recall_tumor: 0.6510 - tumor_iou: 0.4607 - val_acc: 0.9864 - val_dice_coef_metric_tumor: 0.5581 - val_loss: 0.3063 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5306 - val_recall_tumor: 0.6374 - val_tumor_iou: 0.4068 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 165 lên WandB.\n\n--- Epoch 166/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.6252 - loss: 0.2604 - mean_iou_all: 0.4700 - precision_tumor: 0.6312 - recall_tumor: 0.6560 - tumor_iou: 0.4680\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.6251 - loss: 0.2605 - mean_iou_all: 0.4701 - precision_tumor: 0.6311 - recall_tumor: 0.6559 - tumor_iou: 0.4679 - val_acc: 0.9874 - val_dice_coef_metric_tumor: 0.5629 - val_loss: 0.3033 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5817 - val_recall_tumor: 0.5830 - val_tumor_iou: 0.4155 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 166 lên WandB.\n\n--- Epoch 167/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.6086 - loss: 0.2601 - mean_iou_all: 0.4788 - precision_tumor: 0.6184 - recall_tumor: 0.6604 - tumor_iou: 0.4560\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.6085 - loss: 0.2602 - mean_iou_all: 0.4788 - precision_tumor: 0.6184 - recall_tumor: 0.6603 - tumor_iou: 0.4559 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5307 - val_loss: 0.3222 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6740 - val_recall_tumor: 0.4663 - val_tumor_iou: 0.3866 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 167 lên WandB.\n\n--- Epoch 168/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.6176 - loss: 0.2568 - mean_iou_all: 0.4730 - precision_tumor: 0.6122 - recall_tumor: 0.6589 - tumor_iou: 0.4647\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.6176 - loss: 0.2568 - mean_iou_all: 0.4730 - precision_tumor: 0.6122 - recall_tumor: 0.6588 - tumor_iou: 0.4647 - val_acc: 0.9879 - val_dice_coef_metric_tumor: 0.5492 - val_loss: 0.3113 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5919 - val_recall_tumor: 0.5455 - val_tumor_iou: 0.4062 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 168 lên WandB.\n\n--- Epoch 169/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.6226 - loss: 0.2639 - mean_iou_all: 0.4665 - precision_tumor: 0.6369 - recall_tumor: 0.6459 - tumor_iou: 0.4670\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.6225 - loss: 0.2639 - mean_iou_all: 0.4664 - precision_tumor: 0.6368 - recall_tumor: 0.6459 - tumor_iou: 0.4669 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5593 - val_loss: 0.3058 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6293 - val_recall_tumor: 0.5294 - val_tumor_iou: 0.4131 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 169 lên WandB.\n\n--- Epoch 170/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6253 - loss: 0.2594 - mean_iou_all: 0.4776 - precision_tumor: 0.6396 - recall_tumor: 0.6565 - tumor_iou: 0.4736\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6252 - loss: 0.2594 - mean_iou_all: 0.4776 - precision_tumor: 0.6395 - recall_tumor: 0.6564 - tumor_iou: 0.4735 - val_acc: 0.9872 - val_dice_coef_metric_tumor: 0.5662 - val_loss: 0.3019 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5735 - val_recall_tumor: 0.5998 - val_tumor_iou: 0.4128 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 170 lên WandB.\n\n--- Epoch 171/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.6200 - loss: 0.2612 - mean_iou_all: 0.4731 - precision_tumor: 0.6399 - recall_tumor: 0.6458 - tumor_iou: 0.4671\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.6199 - loss: 0.2613 - mean_iou_all: 0.4731 - precision_tumor: 0.6398 - recall_tumor: 0.6459 - tumor_iou: 0.4670 - val_acc: 0.9845 - val_dice_coef_metric_tumor: 0.5593 - val_loss: 0.3070 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5040 - val_recall_tumor: 0.6888 - val_tumor_iou: 0.4096 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 171 lên WandB.\n\n--- Epoch 172/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9874 - dice_coef_metric_tumor: 0.6250 - loss: 0.2567 - mean_iou_all: 0.4862 - precision_tumor: 0.6125 - recall_tumor: 0.6746 - tumor_iou: 0.4732\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9874 - dice_coef_metric_tumor: 0.6248 - loss: 0.2567 - mean_iou_all: 0.4862 - precision_tumor: 0.6125 - recall_tumor: 0.6745 - tumor_iou: 0.4731 - val_acc: 0.9779 - val_dice_coef_metric_tumor: 0.4900 - val_loss: 0.3512 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.3860 - val_recall_tumor: 0.7696 - val_tumor_iou: 0.3428 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 172 lên WandB.\n\n--- Epoch 173/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.6043 - loss: 0.2661 - mean_iou_all: 0.4796 - precision_tumor: 0.5995 - recall_tumor: 0.6633 - tumor_iou: 0.4548\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9872 - dice_coef_metric_tumor: 0.6042 - loss: 0.2661 - mean_iou_all: 0.4796 - precision_tumor: 0.5995 - recall_tumor: 0.6632 - tumor_iou: 0.4548 - val_acc: 0.9865 - val_dice_coef_metric_tumor: 0.5191 - val_loss: 0.3307 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5581 - val_recall_tumor: 0.5241 - val_tumor_iou: 0.3739 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 173 lên WandB.\n\n--- Epoch 174/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5986 - loss: 0.2806 - mean_iou_all: 0.4830 - precision_tumor: 0.6020 - recall_tumor: 0.6522 - tumor_iou: 0.4424\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9859 - dice_coef_metric_tumor: 0.5986 - loss: 0.2806 - mean_iou_all: 0.4830 - precision_tumor: 0.6020 - recall_tumor: 0.6522 - tumor_iou: 0.4424 - val_acc: 0.9862 - val_dice_coef_metric_tumor: 0.5448 - val_loss: 0.3151 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5319 - val_recall_tumor: 0.5929 - val_tumor_iou: 0.3955 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 174 lên WandB.\n\n--- Epoch 175/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6281 - loss: 0.2559 - mean_iou_all: 0.4797 - precision_tumor: 0.6432 - recall_tumor: 0.6567 - tumor_iou: 0.4751\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6280 - loss: 0.2559 - mean_iou_all: 0.4797 - precision_tumor: 0.6432 - recall_tumor: 0.6567 - tumor_iou: 0.4750 - val_acc: 0.9879 - val_dice_coef_metric_tumor: 0.5062 - val_loss: 0.3379 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6163 - val_recall_tumor: 0.4579 - val_tumor_iou: 0.3666 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 175 lên WandB.\n\n--- Epoch 176/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6452 - loss: 0.2453 - mean_iou_all: 0.4795 - precision_tumor: 0.6567 - recall_tumor: 0.6737 - tumor_iou: 0.4906\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 921ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6450 - loss: 0.2453 - mean_iou_all: 0.4795 - precision_tumor: 0.6566 - recall_tumor: 0.6736 - tumor_iou: 0.4905 - val_acc: 0.9881 - val_dice_coef_metric_tumor: 0.4923 - val_loss: 0.3476 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6801 - val_recall_tumor: 0.4085 - val_tumor_iou: 0.3505 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 176 lên WandB.\n\n--- Epoch 177/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.6337 - loss: 0.2598 - mean_iou_all: 0.4774 - precision_tumor: 0.6472 - recall_tumor: 0.6668 - tumor_iou: 0.4808\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9876 - dice_coef_metric_tumor: 0.6337 - loss: 0.2598 - mean_iou_all: 0.4774 - precision_tumor: 0.6472 - recall_tumor: 0.6667 - tumor_iou: 0.4807 - val_acc: 0.9882 - val_dice_coef_metric_tumor: 0.5415 - val_loss: 0.3165 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6402 - val_recall_tumor: 0.5062 - val_tumor_iou: 0.3972 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 177 lên WandB.\n\n--- Epoch 178/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6332 - loss: 0.2519 - mean_iou_all: 0.4830 - precision_tumor: 0.6414 - recall_tumor: 0.6633 - tumor_iou: 0.4790\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6331 - loss: 0.2519 - mean_iou_all: 0.4830 - precision_tumor: 0.6414 - recall_tumor: 0.6632 - tumor_iou: 0.4790 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5116 - val_loss: 0.3346 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7431 - val_recall_tumor: 0.4241 - val_tumor_iou: 0.3704 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 178 lên WandB.\n\n--- Epoch 179/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6291 - loss: 0.2545 - mean_iou_all: 0.4773 - precision_tumor: 0.6480 - recall_tumor: 0.6560 - tumor_iou: 0.4759\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6290 - loss: 0.2545 - mean_iou_all: 0.4772 - precision_tumor: 0.6479 - recall_tumor: 0.6559 - tumor_iou: 0.4758 - val_acc: 0.9881 - val_dice_coef_metric_tumor: 0.5805 - val_loss: 0.2933 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5921 - val_recall_tumor: 0.6051 - val_tumor_iou: 0.4316 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 179 lên WandB.\n\n--- Epoch 180/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.6189 - loss: 0.2593 - mean_iou_all: 0.4677 - precision_tumor: 0.6330 - recall_tumor: 0.6493 - tumor_iou: 0.4663\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.6189 - loss: 0.2593 - mean_iou_all: 0.4677 - precision_tumor: 0.6330 - recall_tumor: 0.6493 - tumor_iou: 0.4663 - val_acc: 0.9873 - val_dice_coef_metric_tumor: 0.5594 - val_loss: 0.3063 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5489 - val_recall_tumor: 0.6111 - val_tumor_iou: 0.4103 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 180 lên WandB.\n\n--- Epoch 181/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6177 - loss: 0.2540 - mean_iou_all: 0.4735 - precision_tumor: 0.6340 - recall_tumor: 0.6466 - tumor_iou: 0.4679\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6177 - loss: 0.2540 - mean_iou_all: 0.4735 - precision_tumor: 0.6340 - recall_tumor: 0.6466 - tumor_iou: 0.4679 - val_acc: 0.9882 - val_dice_coef_metric_tumor: 0.5616 - val_loss: 0.3050 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5949 - val_recall_tumor: 0.5711 - val_tumor_iou: 0.4148 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 181 lên WandB.\n\n--- Epoch 182/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6334 - loss: 0.2563 - mean_iou_all: 0.4785 - precision_tumor: 0.6520 - recall_tumor: 0.6540 - tumor_iou: 0.4797\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6333 - loss: 0.2562 - mean_iou_all: 0.4785 - precision_tumor: 0.6519 - recall_tumor: 0.6539 - tumor_iou: 0.4797 - val_acc: 0.9882 - val_dice_coef_metric_tumor: 0.5681 - val_loss: 0.3010 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5833 - val_recall_tumor: 0.5876 - val_tumor_iou: 0.4219 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 182 lên WandB.\n\n--- Epoch 183/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.6320 - loss: 0.2577 - mean_iou_all: 0.4646 - precision_tumor: 0.6296 - recall_tumor: 0.6713 - tumor_iou: 0.4779\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 913ms/step - acc: 0.9875 - dice_coef_metric_tumor: 0.6320 - loss: 0.2577 - mean_iou_all: 0.4645 - precision_tumor: 0.6296 - recall_tumor: 0.6712 - tumor_iou: 0.4778 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5295 - val_loss: 0.3244 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6764 - val_recall_tumor: 0.4608 - val_tumor_iou: 0.3837 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 183 lên WandB.\n\n--- Epoch 184/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6403 - loss: 0.2502 - mean_iou_all: 0.4800 - precision_tumor: 0.6524 - recall_tumor: 0.6681 - tumor_iou: 0.4852\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6403 - loss: 0.2502 - mean_iou_all: 0.4800 - precision_tumor: 0.6524 - recall_tumor: 0.6681 - tumor_iou: 0.4852 - val_acc: 0.9869 - val_dice_coef_metric_tumor: 0.5787 - val_loss: 0.2949 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5449 - val_recall_tumor: 0.6539 - val_tumor_iou: 0.4305 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 184 lên WandB.\n\n--- Epoch 185/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6300 - loss: 0.2561 - mean_iou_all: 0.4821 - precision_tumor: 0.6385 - recall_tumor: 0.6662 - tumor_iou: 0.4796\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6299 - loss: 0.2561 - mean_iou_all: 0.4820 - precision_tumor: 0.6385 - recall_tumor: 0.6661 - tumor_iou: 0.4795 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5724 - val_loss: 0.2982 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6606 - val_recall_tumor: 0.5320 - val_tumor_iou: 0.4259 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 185 lên WandB.\n\n--- Epoch 186/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6474 - loss: 0.2472 - mean_iou_all: 0.4685 - precision_tumor: 0.6593 - recall_tumor: 0.6721 - tumor_iou: 0.4921\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6474 - loss: 0.2472 - mean_iou_all: 0.4684 - precision_tumor: 0.6592 - recall_tumor: 0.6721 - tumor_iou: 0.4921 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5319 - val_loss: 0.3228 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6338 - val_recall_tumor: 0.5002 - val_tumor_iou: 0.3945 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 186 lên WandB.\n\n--- Epoch 187/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.6328 - loss: 0.2574 - mean_iou_all: 0.4656 - precision_tumor: 0.6440 - recall_tumor: 0.6624 - tumor_iou: 0.4774\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9880 - dice_coef_metric_tumor: 0.6327 - loss: 0.2573 - mean_iou_all: 0.4655 - precision_tumor: 0.6439 - recall_tumor: 0.6624 - tumor_iou: 0.4774 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5541 - val_loss: 0.3099 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7322 - val_recall_tumor: 0.4726 - val_tumor_iou: 0.4075 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 187 lên WandB.\n\n--- Epoch 188/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6580 - loss: 0.2392 - mean_iou_all: 0.4732 - precision_tumor: 0.6779 - recall_tumor: 0.6796 - tumor_iou: 0.5069\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58246\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6579 - loss: 0.2392 - mean_iou_all: 0.4732 - precision_tumor: 0.6778 - recall_tumor: 0.6795 - tumor_iou: 0.5068 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.5697 - val_loss: 0.3003 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6357 - val_recall_tumor: 0.5469 - val_tumor_iou: 0.4235 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 188 lên WandB.\n\n--- Epoch 189/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6440 - loss: 0.2472 - mean_iou_all: 0.4725 - precision_tumor: 0.6625 - recall_tumor: 0.6626 - tumor_iou: 0.4910\nEpoch 1: val_dice_coef_metric_tumor improved from 0.58246 to 0.58880, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 926ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6440 - loss: 0.2472 - mean_iou_all: 0.4724 - precision_tumor: 0.6624 - recall_tumor: 0.6626 - tumor_iou: 0.4909 - val_acc: 0.9887 - val_dice_coef_metric_tumor: 0.5888 - val_loss: 0.2884 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6038 - val_recall_tumor: 0.6060 - val_tumor_iou: 0.4432 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 189 lên WandB.\n\n--- Epoch 190/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6186 - loss: 0.2556 - mean_iou_all: 0.4691 - precision_tumor: 0.6192 - recall_tumor: 0.6683 - tumor_iou: 0.4685\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58880\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6186 - loss: 0.2556 - mean_iou_all: 0.4691 - precision_tumor: 0.6192 - recall_tumor: 0.6682 - tumor_iou: 0.4685 - val_acc: 0.9878 - val_dice_coef_metric_tumor: 0.5849 - val_loss: 0.2915 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5963 - val_recall_tumor: 0.6071 - val_tumor_iou: 0.4368 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 190 lên WandB.\n\n--- Epoch 191/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6408 - loss: 0.2433 - mean_iou_all: 0.4700 - precision_tumor: 0.6469 - recall_tumor: 0.6664 - tumor_iou: 0.4917\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58880\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6407 - loss: 0.2433 - mean_iou_all: 0.4699 - precision_tumor: 0.6469 - recall_tumor: 0.6663 - tumor_iou: 0.4917 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.5811 - val_loss: 0.2938 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5558 - val_recall_tumor: 0.6429 - val_tumor_iou: 0.4330 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 191 lên WandB.\n\n--- Epoch 192/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6376 - loss: 0.2534 - mean_iou_all: 0.4735 - precision_tumor: 0.6548 - recall_tumor: 0.6666 - tumor_iou: 0.4867\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58880\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6375 - loss: 0.2534 - mean_iou_all: 0.4734 - precision_tumor: 0.6546 - recall_tumor: 0.6665 - tumor_iou: 0.4866 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5184 - val_loss: 0.3317 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7122 - val_recall_tumor: 0.4359 - val_tumor_iou: 0.3717 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 192 lên WandB.\n\n--- Epoch 193/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6525 - loss: 0.2469 - mean_iou_all: 0.4543 - precision_tumor: 0.6621 - recall_tumor: 0.6767 - tumor_iou: 0.4993\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58880\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6525 - loss: 0.2469 - mean_iou_all: 0.4542 - precision_tumor: 0.6621 - recall_tumor: 0.6766 - tumor_iou: 0.4993 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5823 - val_loss: 0.2928 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5981 - val_recall_tumor: 0.5952 - val_tumor_iou: 0.4425 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 193 lên WandB.\n\n--- Epoch 194/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6385 - loss: 0.2479 - mean_iou_all: 0.4569 - precision_tumor: 0.6483 - recall_tumor: 0.6660 - tumor_iou: 0.4882\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58880\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6385 - loss: 0.2479 - mean_iou_all: 0.4568 - precision_tumor: 0.6482 - recall_tumor: 0.6659 - tumor_iou: 0.4881 - val_acc: 0.9873 - val_dice_coef_metric_tumor: 0.5784 - val_loss: 0.2957 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5488 - val_recall_tumor: 0.6536 - val_tumor_iou: 0.4313 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 194 lên WandB.\n\n--- Epoch 195/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6400 - loss: 0.2493 - mean_iou_all: 0.4706 - precision_tumor: 0.6580 - recall_tumor: 0.6626 - tumor_iou: 0.4878\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58880\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6399 - loss: 0.2493 - mean_iou_all: 0.4706 - precision_tumor: 0.6580 - recall_tumor: 0.6626 - tumor_iou: 0.4877 - val_acc: 0.9890 - val_dice_coef_metric_tumor: 0.5780 - val_loss: 0.2955 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6260 - val_recall_tumor: 0.5673 - val_tumor_iou: 0.4327 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 195 lên WandB.\n\n--- Epoch 196/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6357 - loss: 0.2531 - mean_iou_all: 0.4663 - precision_tumor: 0.6470 - recall_tumor: 0.6686 - tumor_iou: 0.4839\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58880\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6356 - loss: 0.2531 - mean_iou_all: 0.4662 - precision_tumor: 0.6470 - recall_tumor: 0.6686 - tumor_iou: 0.4838 - val_acc: 0.9846 - val_dice_coef_metric_tumor: 0.5419 - val_loss: 0.3189 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4935 - val_recall_tumor: 0.6621 - val_tumor_iou: 0.3920 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 196 lên WandB.\n\n--- Epoch 197/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6257 - loss: 0.2582 - mean_iou_all: 0.4792 - precision_tumor: 0.6343 - recall_tumor: 0.6653 - tumor_iou: 0.4734\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58880\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9879 - dice_coef_metric_tumor: 0.6256 - loss: 0.2582 - mean_iou_all: 0.4792 - precision_tumor: 0.6343 - recall_tumor: 0.6652 - tumor_iou: 0.4734 - val_acc: 0.9899 - val_dice_coef_metric_tumor: 0.5578 - val_loss: 0.3078 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7099 - val_recall_tumor: 0.4805 - val_tumor_iou: 0.4145 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 197 lên WandB.\n\n--- Epoch 198/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6368 - loss: 0.2526 - mean_iou_all: 0.4809 - precision_tumor: 0.6397 - recall_tumor: 0.6688 - tumor_iou: 0.4851\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58880\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9881 - dice_coef_metric_tumor: 0.6368 - loss: 0.2526 - mean_iou_all: 0.4808 - precision_tumor: 0.6398 - recall_tumor: 0.6688 - tumor_iou: 0.4851 - val_acc: 0.9879 - val_dice_coef_metric_tumor: 0.5289 - val_loss: 0.3262 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6262 - val_recall_tumor: 0.4893 - val_tumor_iou: 0.3885 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 198 lên WandB.\n\n--- Epoch 199/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6531 - loss: 0.2477 - mean_iou_all: 0.4684 - precision_tumor: 0.6685 - recall_tumor: 0.6821 - tumor_iou: 0.5002\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.58880\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6530 - loss: 0.2476 - mean_iou_all: 0.4683 - precision_tumor: 0.6685 - recall_tumor: 0.6820 - tumor_iou: 0.5002 - val_acc: 0.9879 - val_dice_coef_metric_tumor: 0.5475 - val_loss: 0.3144 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6007 - val_recall_tumor: 0.5430 - val_tumor_iou: 0.4041 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 199 lên WandB.\n\n--- Epoch 200/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6527 - loss: 0.2416 - mean_iou_all: 0.4757 - precision_tumor: 0.6665 - recall_tumor: 0.6741 - tumor_iou: 0.5027\nEpoch 1: val_dice_coef_metric_tumor improved from 0.58880 to 0.59232, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 926ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6527 - loss: 0.2416 - mean_iou_all: 0.4757 - precision_tumor: 0.6665 - recall_tumor: 0.6741 - tumor_iou: 0.5026 - val_acc: 0.9887 - val_dice_coef_metric_tumor: 0.5923 - val_loss: 0.2870 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6177 - val_recall_tumor: 0.6017 - val_tumor_iou: 0.4456 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 200 lên WandB.\n\n--- Epoch 201/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6481 - loss: 0.2431 - mean_iou_all: 0.4721 - precision_tumor: 0.6617 - recall_tumor: 0.6740 - tumor_iou: 0.4971\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6480 - loss: 0.2431 - mean_iou_all: 0.4720 - precision_tumor: 0.6616 - recall_tumor: 0.6739 - tumor_iou: 0.4970 - val_acc: 0.9896 - val_dice_coef_metric_tumor: 0.5770 - val_loss: 0.2961 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6645 - val_recall_tumor: 0.5381 - val_tumor_iou: 0.4349 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 201 lên WandB.\n\n--- Epoch 202/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6629 - loss: 0.2345 - mean_iou_all: 0.4593 - precision_tumor: 0.6740 - recall_tumor: 0.6898 - tumor_iou: 0.5143\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6629 - loss: 0.2345 - mean_iou_all: 0.4591 - precision_tumor: 0.6740 - recall_tumor: 0.6897 - tumor_iou: 0.5142 - val_acc: 0.9888 - val_dice_coef_metric_tumor: 0.5820 - val_loss: 0.2934 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5991 - val_recall_tumor: 0.5885 - val_tumor_iou: 0.4383 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 202 lên WandB.\n\n--- Epoch 203/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6404 - loss: 0.2513 - mean_iou_all: 0.4596 - precision_tumor: 0.6588 - recall_tumor: 0.6585 - tumor_iou: 0.4864\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6403 - loss: 0.2513 - mean_iou_all: 0.4595 - precision_tumor: 0.6587 - recall_tumor: 0.6585 - tumor_iou: 0.4863 - val_acc: 0.9817 - val_dice_coef_metric_tumor: 0.5328 - val_loss: 0.3260 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.4461 - val_recall_tumor: 0.7161 - val_tumor_iou: 0.3853 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 203 lên WandB.\n\n--- Epoch 204/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6427 - loss: 0.2463 - mean_iou_all: 0.4670 - precision_tumor: 0.6434 - recall_tumor: 0.6796 - tumor_iou: 0.4895\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9885 - dice_coef_metric_tumor: 0.6427 - loss: 0.2463 - mean_iou_all: 0.4669 - precision_tumor: 0.6434 - recall_tumor: 0.6795 - tumor_iou: 0.4895 - val_acc: 0.9888 - val_dice_coef_metric_tumor: 0.5631 - val_loss: 0.3054 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6520 - val_recall_tumor: 0.5185 - val_tumor_iou: 0.4182 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 204 lên WandB.\n\n--- Epoch 205/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6485 - loss: 0.2472 - mean_iou_all: 0.4742 - precision_tumor: 0.6602 - recall_tumor: 0.6763 - tumor_iou: 0.4954\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9887 - dice_coef_metric_tumor: 0.6483 - loss: 0.2472 - mean_iou_all: 0.4741 - precision_tumor: 0.6601 - recall_tumor: 0.6763 - tumor_iou: 0.4953 - val_acc: 0.9875 - val_dice_coef_metric_tumor: 0.5583 - val_loss: 0.3086 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5807 - val_recall_tumor: 0.5756 - val_tumor_iou: 0.4075 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 205 lên WandB.\n\n--- Epoch 206/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.6240 - loss: 0.2612 - mean_iou_all: 0.4786 - precision_tumor: 0.6298 - recall_tumor: 0.6661 - tumor_iou: 0.4730\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9878 - dice_coef_metric_tumor: 0.6239 - loss: 0.2611 - mean_iou_all: 0.4785 - precision_tumor: 0.6298 - recall_tumor: 0.6661 - tumor_iou: 0.4730 - val_acc: 0.9869 - val_dice_coef_metric_tumor: 0.5722 - val_loss: 0.3004 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5549 - val_recall_tumor: 0.6403 - val_tumor_iou: 0.4272 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 206 lên WandB.\n\n--- Epoch 207/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6565 - loss: 0.2429 - mean_iou_all: 0.4765 - precision_tumor: 0.6699 - recall_tumor: 0.6734 - tumor_iou: 0.5041\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6565 - loss: 0.2429 - mean_iou_all: 0.4764 - precision_tumor: 0.6699 - recall_tumor: 0.6734 - tumor_iou: 0.5040 - val_acc: 0.9898 - val_dice_coef_metric_tumor: 0.5695 - val_loss: 0.3010 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7321 - val_recall_tumor: 0.4942 - val_tumor_iou: 0.4236 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 207 lên WandB.\n\n--- Epoch 208/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6530 - loss: 0.2403 - mean_iou_all: 0.4650 - precision_tumor: 0.6705 - recall_tumor: 0.6757 - tumor_iou: 0.5024\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6529 - loss: 0.2404 - mean_iou_all: 0.4649 - precision_tumor: 0.6704 - recall_tumor: 0.6756 - tumor_iou: 0.5023 - val_acc: 0.9888 - val_dice_coef_metric_tumor: 0.5850 - val_loss: 0.2921 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6043 - val_recall_tumor: 0.5940 - val_tumor_iou: 0.4411 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 208 lên WandB.\n\n--- Epoch 209/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6397 - loss: 0.2458 - mean_iou_all: 0.4712 - precision_tumor: 0.6455 - recall_tumor: 0.6841 - tumor_iou: 0.4911\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6396 - loss: 0.2458 - mean_iou_all: 0.4711 - precision_tumor: 0.6455 - recall_tumor: 0.6841 - tumor_iou: 0.4910 - val_acc: 0.9882 - val_dice_coef_metric_tumor: 0.5793 - val_loss: 0.2961 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6304 - val_recall_tumor: 0.5668 - val_tumor_iou: 0.4310 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 209 lên WandB.\n\n--- Epoch 210/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6512 - loss: 0.2436 - mean_iou_all: 0.4668 - precision_tumor: 0.6686 - recall_tumor: 0.6717 - tumor_iou: 0.5002\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6512 - loss: 0.2436 - mean_iou_all: 0.4666 - precision_tumor: 0.6686 - recall_tumor: 0.6717 - tumor_iou: 0.5001 - val_acc: 0.9880 - val_dice_coef_metric_tumor: 0.5698 - val_loss: 0.3020 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5865 - val_recall_tumor: 0.5920 - val_tumor_iou: 0.4269 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 210 lên WandB.\n\n--- Epoch 211/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6333 - loss: 0.2535 - mean_iou_all: 0.4809 - precision_tumor: 0.6466 - recall_tumor: 0.6666 - tumor_iou: 0.4823\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9882 - dice_coef_metric_tumor: 0.6332 - loss: 0.2535 - mean_iou_all: 0.4809 - precision_tumor: 0.6465 - recall_tumor: 0.6665 - tumor_iou: 0.4822 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5906 - val_loss: 0.2889 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6154 - val_recall_tumor: 0.6030 - val_tumor_iou: 0.4420 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 211 lên WandB.\n\n--- Epoch 212/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6607 - loss: 0.2424 - mean_iou_all: 0.4787 - precision_tumor: 0.6847 - recall_tumor: 0.6724 - tumor_iou: 0.5092\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6607 - loss: 0.2423 - mean_iou_all: 0.4787 - precision_tumor: 0.6847 - recall_tumor: 0.6725 - tumor_iou: 0.5092 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.5870 - val_loss: 0.2919 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6140 - val_recall_tumor: 0.5979 - val_tumor_iou: 0.4347 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 212 lên WandB.\n\n--- Epoch 213/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6390 - loss: 0.2474 - mean_iou_all: 0.4750 - precision_tumor: 0.6531 - recall_tumor: 0.6731 - tumor_iou: 0.4885\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6389 - loss: 0.2474 - mean_iou_all: 0.4748 - precision_tumor: 0.6530 - recall_tumor: 0.6730 - tumor_iou: 0.4885 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5502 - val_loss: 0.3138 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6688 - val_recall_tumor: 0.4978 - val_tumor_iou: 0.4065 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 213 lên WandB.\n\n--- Epoch 214/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6615 - loss: 0.2406 - mean_iou_all: 0.4658 - precision_tumor: 0.6709 - recall_tumor: 0.6919 - tumor_iou: 0.5095\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 922ms/step - acc: 0.9886 - dice_coef_metric_tumor: 0.6615 - loss: 0.2406 - mean_iou_all: 0.4657 - precision_tumor: 0.6709 - recall_tumor: 0.6918 - tumor_iou: 0.5095 - val_acc: 0.9886 - val_dice_coef_metric_tumor: 0.5898 - val_loss: 0.2897 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6093 - val_recall_tumor: 0.6020 - val_tumor_iou: 0.4440 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 214 lên WandB.\n\n--- Epoch 215/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9883 - dice_coef_metric_tumor: 0.6614 - loss: 0.2474 - mean_iou_all: 0.4579 - precision_tumor: 0.6823 - recall_tumor: 0.6918 - tumor_iou: 0.5083\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9884 - dice_coef_metric_tumor: 0.6613 - loss: 0.2473 - mean_iou_all: 0.4578 - precision_tumor: 0.6823 - recall_tumor: 0.6918 - tumor_iou: 0.5083 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5786 - val_loss: 0.2964 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5948 - val_recall_tumor: 0.5982 - val_tumor_iou: 0.4347 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 215 lên WandB.\n\n--- Epoch 216/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6326 - loss: 0.2487 - mean_iou_all: 0.4733 - precision_tumor: 0.6392 - recall_tumor: 0.6594 - tumor_iou: 0.4844\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6326 - loss: 0.2486 - mean_iou_all: 0.4731 - precision_tumor: 0.6393 - recall_tumor: 0.6594 - tumor_iou: 0.4844 - val_acc: 0.9869 - val_dice_coef_metric_tumor: 0.5451 - val_loss: 0.3175 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5944 - val_recall_tumor: 0.5466 - val_tumor_iou: 0.3992 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 216 lên WandB.\n\n--- Epoch 217/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6676 - loss: 0.2363 - mean_iou_all: 0.4721 - precision_tumor: 0.6846 - recall_tumor: 0.6861 - tumor_iou: 0.5167\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6675 - loss: 0.2363 - mean_iou_all: 0.4720 - precision_tumor: 0.6846 - recall_tumor: 0.6860 - tumor_iou: 0.5166 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5796 - val_loss: 0.2959 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6491 - val_recall_tumor: 0.5468 - val_tumor_iou: 0.4332 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 217 lên WandB.\n\n--- Epoch 218/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6508 - loss: 0.2420 - mean_iou_all: 0.4736 - precision_tumor: 0.6716 - recall_tumor: 0.6690 - tumor_iou: 0.4988\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6507 - loss: 0.2420 - mean_iou_all: 0.4735 - precision_tumor: 0.6716 - recall_tumor: 0.6690 - tumor_iou: 0.4988 - val_acc: 0.9888 - val_dice_coef_metric_tumor: 0.5629 - val_loss: 0.3066 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6212 - val_recall_tumor: 0.5516 - val_tumor_iou: 0.4205 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 218 lên WandB.\n\n--- Epoch 219/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6424 - loss: 0.2496 - mean_iou_all: 0.4736 - precision_tumor: 0.6615 - recall_tumor: 0.6580 - tumor_iou: 0.4920\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9888 - dice_coef_metric_tumor: 0.6424 - loss: 0.2495 - mean_iou_all: 0.4735 - precision_tumor: 0.6615 - recall_tumor: 0.6581 - tumor_iou: 0.4920 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.5766 - val_loss: 0.2981 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6431 - val_recall_tumor: 0.5559 - val_tumor_iou: 0.4337 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 219 lên WandB.\n\n--- Epoch 220/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6561 - loss: 0.2429 - mean_iou_all: 0.4605 - precision_tumor: 0.6742 - recall_tumor: 0.6856 - tumor_iou: 0.5049\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.59232\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6560 - loss: 0.2429 - mean_iou_all: 0.4604 - precision_tumor: 0.6741 - recall_tumor: 0.6856 - tumor_iou: 0.5048 - val_acc: 0.9884 - val_dice_coef_metric_tumor: 0.5903 - val_loss: 0.2898 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6062 - val_recall_tumor: 0.6071 - val_tumor_iou: 0.4452 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 220 lên WandB.\n\n--- Epoch 221/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6590 - loss: 0.2399 - mean_iou_all: 0.4651 - precision_tumor: 0.6712 - recall_tumor: 0.6760 - tumor_iou: 0.5064\nEpoch 1: val_dice_coef_metric_tumor improved from 0.59232 to 0.60718, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 928ms/step - acc: 0.9893 - dice_coef_metric_tumor: 0.6590 - loss: 0.2399 - mean_iou_all: 0.4649 - precision_tumor: 0.6712 - recall_tumor: 0.6760 - tumor_iou: 0.5064 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.6072 - val_loss: 0.2791 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6177 - val_recall_tumor: 0.6225 - val_tumor_iou: 0.4600 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 221 lên WandB.\n\n--- Epoch 222/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9899 - dice_coef_metric_tumor: 0.6590 - loss: 0.2346 - mean_iou_all: 0.4565 - precision_tumor: 0.6738 - recall_tumor: 0.6775 - tumor_iou: 0.5074\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60718\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9899 - dice_coef_metric_tumor: 0.6590 - loss: 0.2346 - mean_iou_all: 0.4563 - precision_tumor: 0.6737 - recall_tumor: 0.6775 - tumor_iou: 0.5074 - val_acc: 0.9865 - val_dice_coef_metric_tumor: 0.5651 - val_loss: 0.3060 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5392 - val_recall_tumor: 0.6383 - val_tumor_iou: 0.4174 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 222 lên WandB.\n\n--- Epoch 223/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6609 - loss: 0.2370 - mean_iou_all: 0.4697 - precision_tumor: 0.6675 - recall_tumor: 0.6924 - tumor_iou: 0.5141\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60718\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6608 - loss: 0.2370 - mean_iou_all: 0.4696 - precision_tumor: 0.6675 - recall_tumor: 0.6924 - tumor_iou: 0.5140 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.5852 - val_loss: 0.2929 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6614 - val_recall_tumor: 0.5517 - val_tumor_iou: 0.4376 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 223 lên WandB.\n\n--- Epoch 224/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6538 - loss: 0.2451 - mean_iou_all: 0.4641 - precision_tumor: 0.6709 - recall_tumor: 0.6731 - tumor_iou: 0.5044\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60718\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9890 - dice_coef_metric_tumor: 0.6537 - loss: 0.2451 - mean_iou_all: 0.4640 - precision_tumor: 0.6708 - recall_tumor: 0.6731 - tumor_iou: 0.5043 - val_acc: 0.9894 - val_dice_coef_metric_tumor: 0.5504 - val_loss: 0.3145 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6787 - val_recall_tumor: 0.4855 - val_tumor_iou: 0.4084 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 224 lên WandB.\n\n--- Epoch 225/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6573 - loss: 0.2409 - mean_iou_all: 0.4736 - precision_tumor: 0.6677 - recall_tumor: 0.6828 - tumor_iou: 0.5029\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60718\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6573 - loss: 0.2409 - mean_iou_all: 0.4735 - precision_tumor: 0.6677 - recall_tumor: 0.6828 - tumor_iou: 0.5029 - val_acc: 0.9856 - val_dice_coef_metric_tumor: 0.5360 - val_loss: 0.3240 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5345 - val_recall_tumor: 0.5901 - val_tumor_iou: 0.3882 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 225 lên WandB.\n\n--- Epoch 226/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6658 - loss: 0.2349 - mean_iou_all: 0.4734 - precision_tumor: 0.6808 - recall_tumor: 0.6834 - tumor_iou: 0.5175\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60718\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6657 - loss: 0.2349 - mean_iou_all: 0.4733 - precision_tumor: 0.6807 - recall_tumor: 0.6833 - tumor_iou: 0.5174 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5668 - val_loss: 0.3040 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6450 - val_recall_tumor: 0.5474 - val_tumor_iou: 0.4280 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 226 lên WandB.\n\n--- Epoch 227/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9899 - dice_coef_metric_tumor: 0.6816 - loss: 0.2296 - mean_iou_all: 0.4690 - precision_tumor: 0.7105 - recall_tumor: 0.6900 - tumor_iou: 0.5282\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60718\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 922ms/step - acc: 0.9899 - dice_coef_metric_tumor: 0.6815 - loss: 0.2296 - mean_iou_all: 0.4689 - precision_tumor: 0.7104 - recall_tumor: 0.6899 - tumor_iou: 0.5281 - val_acc: 0.9894 - val_dice_coef_metric_tumor: 0.5800 - val_loss: 0.2967 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6553 - val_recall_tumor: 0.5451 - val_tumor_iou: 0.4353 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 227 lên WandB.\n\n--- Epoch 228/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6802 - loss: 0.2326 - mean_iou_all: 0.4523 - precision_tumor: 0.7078 - recall_tumor: 0.6903 - tumor_iou: 0.5283\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60718\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6801 - loss: 0.2326 - mean_iou_all: 0.4520 - precision_tumor: 0.7077 - recall_tumor: 0.6903 - tumor_iou: 0.5282 - val_acc: 0.9896 - val_dice_coef_metric_tumor: 0.5777 - val_loss: 0.2978 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6736 - val_recall_tumor: 0.5356 - val_tumor_iou: 0.4351 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 228 lên WandB.\n\n--- Epoch 229/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6840 - loss: 0.2297 - mean_iou_all: 0.4485 - precision_tumor: 0.6993 - recall_tumor: 0.6992 - tumor_iou: 0.5346\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60718\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6839 - loss: 0.2297 - mean_iou_all: 0.4483 - precision_tumor: 0.6992 - recall_tumor: 0.6991 - tumor_iou: 0.5345 - val_acc: 0.9890 - val_dice_coef_metric_tumor: 0.5957 - val_loss: 0.2869 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6249 - val_recall_tumor: 0.6023 - val_tumor_iou: 0.4498 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 229 lên WandB.\n\n--- Epoch 230/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6492 - loss: 0.2425 - mean_iou_all: 0.4590 - precision_tumor: 0.6775 - recall_tumor: 0.6706 - tumor_iou: 0.4993\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60718\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6492 - loss: 0.2425 - mean_iou_all: 0.4587 - precision_tumor: 0.6774 - recall_tumor: 0.6706 - tumor_iou: 0.4993 - val_acc: 0.9885 - val_dice_coef_metric_tumor: 0.5839 - val_loss: 0.2942 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5968 - val_recall_tumor: 0.6075 - val_tumor_iou: 0.4385 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 230 lên WandB.\n\n--- Epoch 231/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9902 - dice_coef_metric_tumor: 0.6774 - loss: 0.2276 - mean_iou_all: 0.4441 - precision_tumor: 0.7033 - recall_tumor: 0.6890 - tumor_iou: 0.5298\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60718\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9902 - dice_coef_metric_tumor: 0.6773 - loss: 0.2276 - mean_iou_all: 0.4438 - precision_tumor: 0.7034 - recall_tumor: 0.6889 - tumor_iou: 0.5297 - val_acc: 0.9880 - val_dice_coef_metric_tumor: 0.5715 - val_loss: 0.3021 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5753 - val_recall_tumor: 0.5997 - val_tumor_iou: 0.4233 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 231 lên WandB.\n\n--- Epoch 232/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6671 - loss: 0.2385 - mean_iou_all: 0.4650 - precision_tumor: 0.6775 - recall_tumor: 0.6918 - tumor_iou: 0.5143\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60718\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9891 - dice_coef_metric_tumor: 0.6671 - loss: 0.2385 - mean_iou_all: 0.4647 - precision_tumor: 0.6775 - recall_tumor: 0.6917 - tumor_iou: 0.5143 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.5396 - val_loss: 0.3214 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7035 - val_recall_tumor: 0.4597 - val_tumor_iou: 0.3965 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 232 lên WandB.\n\n--- Epoch 233/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9900 - dice_coef_metric_tumor: 0.6796 - loss: 0.2313 - mean_iou_all: 0.4560 - precision_tumor: 0.7089 - recall_tumor: 0.6868 - tumor_iou: 0.5307\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60718\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9900 - dice_coef_metric_tumor: 0.6796 - loss: 0.2313 - mean_iou_all: 0.4557 - precision_tumor: 0.7088 - recall_tumor: 0.6868 - tumor_iou: 0.5306 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5701 - val_loss: 0.3031 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6600 - val_recall_tumor: 0.5362 - val_tumor_iou: 0.4249 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 233 lên WandB.\n\n--- Epoch 234/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9907 - dice_coef_metric_tumor: 0.6958 - loss: 0.2183 - mean_iou_all: 0.4477 - precision_tumor: 0.7205 - recall_tumor: 0.7041 - tumor_iou: 0.5493\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60718\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 921ms/step - acc: 0.9907 - dice_coef_metric_tumor: 0.6957 - loss: 0.2183 - mean_iou_all: 0.4476 - precision_tumor: 0.7204 - recall_tumor: 0.7041 - tumor_iou: 0.5492 - val_acc: 0.9901 - val_dice_coef_metric_tumor: 0.5867 - val_loss: 0.2923 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7211 - val_recall_tumor: 0.5198 - val_tumor_iou: 0.4424 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 234 lên WandB.\n\n--- Epoch 235/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6685 - loss: 0.2346 - mean_iou_all: 0.4691 - precision_tumor: 0.6818 - recall_tumor: 0.7012 - tumor_iou: 0.5198\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60718\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6684 - loss: 0.2346 - mean_iou_all: 0.4690 - precision_tumor: 0.6817 - recall_tumor: 0.7012 - tumor_iou: 0.5197 - val_acc: 0.9896 - val_dice_coef_metric_tumor: 0.5564 - val_loss: 0.3112 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7287 - val_recall_tumor: 0.4716 - val_tumor_iou: 0.4070 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 235 lên WandB.\n\n--- Epoch 236/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9900 - dice_coef_metric_tumor: 0.6749 - loss: 0.2307 - mean_iou_all: 0.4685 - precision_tumor: 0.6978 - recall_tumor: 0.6878 - tumor_iou: 0.5232\nEpoch 1: val_dice_coef_metric_tumor improved from 0.60718 to 0.60864, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 924ms/step - acc: 0.9900 - dice_coef_metric_tumor: 0.6748 - loss: 0.2307 - mean_iou_all: 0.4683 - precision_tumor: 0.6978 - recall_tumor: 0.6878 - tumor_iou: 0.5232 - val_acc: 0.9887 - val_dice_coef_metric_tumor: 0.6086 - val_loss: 0.2793 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5911 - val_recall_tumor: 0.6568 - val_tumor_iou: 0.4609 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 236 lên WandB.\n\n--- Epoch 237/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6617 - loss: 0.2431 - mean_iou_all: 0.4613 - precision_tumor: 0.6721 - recall_tumor: 0.6903 - tumor_iou: 0.5084\nEpoch 1: val_dice_coef_metric_tumor improved from 0.60864 to 0.60889, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 926ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6616 - loss: 0.2431 - mean_iou_all: 0.4611 - precision_tumor: 0.6721 - recall_tumor: 0.6902 - tumor_iou: 0.5084 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.6089 - val_loss: 0.2792 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6039 - val_recall_tumor: 0.6446 - val_tumor_iou: 0.4613 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 237 lên WandB.\n\n--- Epoch 238/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9901 - dice_coef_metric_tumor: 0.6811 - loss: 0.2276 - mean_iou_all: 0.4622 - precision_tumor: 0.7009 - recall_tumor: 0.6932 - tumor_iou: 0.5320\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9901 - dice_coef_metric_tumor: 0.6810 - loss: 0.2276 - mean_iou_all: 0.4620 - precision_tumor: 0.7008 - recall_tumor: 0.6931 - tumor_iou: 0.5319 - val_acc: 0.9876 - val_dice_coef_metric_tumor: 0.5442 - val_loss: 0.3193 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6249 - val_recall_tumor: 0.5104 - val_tumor_iou: 0.3941 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 238 lên WandB.\n\n--- Epoch 239/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6758 - loss: 0.2362 - mean_iou_all: 0.4744 - precision_tumor: 0.6797 - recall_tumor: 0.7001 - tumor_iou: 0.5264\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9892 - dice_coef_metric_tumor: 0.6758 - loss: 0.2361 - mean_iou_all: 0.4743 - precision_tumor: 0.6798 - recall_tumor: 0.7001 - tumor_iou: 0.5264 - val_acc: 0.9877 - val_dice_coef_metric_tumor: 0.5787 - val_loss: 0.2986 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5943 - val_recall_tumor: 0.5969 - val_tumor_iou: 0.4337 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 239 lên WandB.\n\n--- Epoch 240/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6706 - loss: 0.2421 - mean_iou_all: 0.4717 - precision_tumor: 0.6822 - recall_tumor: 0.6917 - tumor_iou: 0.5202\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9889 - dice_coef_metric_tumor: 0.6706 - loss: 0.2420 - mean_iou_all: 0.4715 - precision_tumor: 0.6822 - recall_tumor: 0.6916 - tumor_iou: 0.5201 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.5846 - val_loss: 0.2944 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5993 - val_recall_tumor: 0.6002 - val_tumor_iou: 0.4396 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 240 lên WandB.\n\n--- Epoch 241/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6807 - loss: 0.2325 - mean_iou_all: 0.4789 - precision_tumor: 0.7004 - recall_tumor: 0.6907 - tumor_iou: 0.5299\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6807 - loss: 0.2325 - mean_iou_all: 0.4788 - precision_tumor: 0.7004 - recall_tumor: 0.6906 - tumor_iou: 0.5298 - val_acc: 0.9887 - val_dice_coef_metric_tumor: 0.5879 - val_loss: 0.2925 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6020 - val_recall_tumor: 0.6011 - val_tumor_iou: 0.4403 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 241 lên WandB.\n\n--- Epoch 242/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6702 - loss: 0.2331 - mean_iou_all: 0.4698 - precision_tumor: 0.6915 - recall_tumor: 0.6824 - tumor_iou: 0.5234\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9898 - dice_coef_metric_tumor: 0.6701 - loss: 0.2331 - mean_iou_all: 0.4696 - precision_tumor: 0.6914 - recall_tumor: 0.6824 - tumor_iou: 0.5233 - val_acc: 0.9890 - val_dice_coef_metric_tumor: 0.5893 - val_loss: 0.2913 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6022 - val_recall_tumor: 0.6051 - val_tumor_iou: 0.4450 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 242 lên WandB.\n\n--- Epoch 243/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6752 - loss: 0.2323 - mean_iou_all: 0.4672 - precision_tumor: 0.6887 - recall_tumor: 0.6987 - tumor_iou: 0.5263\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6752 - loss: 0.2323 - mean_iou_all: 0.4671 - precision_tumor: 0.6886 - recall_tumor: 0.6987 - tumor_iou: 0.5262 - val_acc: 0.9890 - val_dice_coef_metric_tumor: 0.5296 - val_loss: 0.3287 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7419 - val_recall_tumor: 0.4354 - val_tumor_iou: 0.3823 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 243 lên WandB.\n\n--- Epoch 244/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6621 - loss: 0.2398 - mean_iou_all: 0.4707 - precision_tumor: 0.6856 - recall_tumor: 0.6697 - tumor_iou: 0.5100\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6621 - loss: 0.2398 - mean_iou_all: 0.4706 - precision_tumor: 0.6855 - recall_tumor: 0.6697 - tumor_iou: 0.5100 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.6052 - val_loss: 0.2816 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5952 - val_recall_tumor: 0.6571 - val_tumor_iou: 0.4595 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 244 lên WandB.\n\n--- Epoch 245/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9899 - dice_coef_metric_tumor: 0.6734 - loss: 0.2287 - mean_iou_all: 0.4601 - precision_tumor: 0.6802 - recall_tumor: 0.7048 - tumor_iou: 0.5263\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9899 - dice_coef_metric_tumor: 0.6733 - loss: 0.2287 - mean_iou_all: 0.4599 - precision_tumor: 0.6801 - recall_tumor: 0.7047 - tumor_iou: 0.5262 - val_acc: 0.9889 - val_dice_coef_metric_tumor: 0.6042 - val_loss: 0.2827 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5964 - val_recall_tumor: 0.6410 - val_tumor_iou: 0.4579 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 245 lên WandB.\n\n--- Epoch 246/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6697 - loss: 0.2335 - mean_iou_all: 0.4504 - precision_tumor: 0.6946 - recall_tumor: 0.6903 - tumor_iou: 0.5203\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6696 - loss: 0.2334 - mean_iou_all: 0.4502 - precision_tumor: 0.6946 - recall_tumor: 0.6903 - tumor_iou: 0.5202 - val_acc: 0.9887 - val_dice_coef_metric_tumor: 0.5908 - val_loss: 0.2909 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6266 - val_recall_tumor: 0.5946 - val_tumor_iou: 0.4442 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 246 lên WandB.\n\n--- Epoch 247/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.6994 - loss: 0.2216 - mean_iou_all: 0.4551 - precision_tumor: 0.7257 - recall_tumor: 0.7041 - tumor_iou: 0.5513\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.6993 - loss: 0.2216 - mean_iou_all: 0.4549 - precision_tumor: 0.7255 - recall_tumor: 0.7041 - tumor_iou: 0.5512 - val_acc: 0.9887 - val_dice_coef_metric_tumor: 0.5915 - val_loss: 0.2904 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.5987 - val_recall_tumor: 0.6119 - val_tumor_iou: 0.4444 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 247 lên WandB.\n\n--- Epoch 248/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6716 - loss: 0.2348 - mean_iou_all: 0.4784 - precision_tumor: 0.6824 - recall_tumor: 0.6906 - tumor_iou: 0.5217\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6716 - loss: 0.2348 - mean_iou_all: 0.4783 - precision_tumor: 0.6824 - recall_tumor: 0.6906 - tumor_iou: 0.5217 - val_acc: 0.9899 - val_dice_coef_metric_tumor: 0.6019 - val_loss: 0.2842 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6990 - val_recall_tumor: 0.5498 - val_tumor_iou: 0.4536 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 248 lên WandB.\n\n--- Epoch 249/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6720 - loss: 0.2379 - mean_iou_all: 0.4781 - precision_tumor: 0.6883 - recall_tumor: 0.6908 - tumor_iou: 0.5211\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9894 - dice_coef_metric_tumor: 0.6720 - loss: 0.2378 - mean_iou_all: 0.4779 - precision_tumor: 0.6883 - recall_tumor: 0.6908 - tumor_iou: 0.5211 - val_acc: 0.9890 - val_dice_coef_metric_tumor: 0.5893 - val_loss: 0.2919 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6185 - val_recall_tumor: 0.5929 - val_tumor_iou: 0.4451 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 249 lên WandB.\n\n--- Epoch 250/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9903 - dice_coef_metric_tumor: 0.6879 - loss: 0.2220 - mean_iou_all: 0.4591 - precision_tumor: 0.6981 - recall_tumor: 0.7099 - tumor_iou: 0.5392\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 920ms/step - acc: 0.9903 - dice_coef_metric_tumor: 0.6878 - loss: 0.2220 - mean_iou_all: 0.4589 - precision_tumor: 0.6981 - recall_tumor: 0.7098 - tumor_iou: 0.5392 - val_acc: 0.9905 - val_dice_coef_metric_tumor: 0.5963 - val_loss: 0.2873 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7347 - val_recall_tumor: 0.5294 - val_tumor_iou: 0.4510 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 250 lên WandB.\n\n--- Epoch 251/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - acc: 0.9909 - dice_coef_metric_tumor: 0.7045 - loss: 0.2135 - mean_iou_all: 0.4785 - precision_tumor: 0.7272 - recall_tumor: 0.7138 - tumor_iou: 0.5575\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9909 - dice_coef_metric_tumor: 0.7044 - loss: 0.2135 - mean_iou_all: 0.4784 - precision_tumor: 0.7271 - recall_tumor: 0.7138 - tumor_iou: 0.5575 - val_acc: 0.9899 - val_dice_coef_metric_tumor: 0.5719 - val_loss: 0.3028 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7681 - val_recall_tumor: 0.4771 - val_tumor_iou: 0.4237 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 251 lên WandB.\n\n--- Epoch 252/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6767 - loss: 0.2356 - mean_iou_all: 0.4673 - precision_tumor: 0.7073 - recall_tumor: 0.6864 - tumor_iou: 0.5275\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6766 - loss: 0.2355 - mean_iou_all: 0.4672 - precision_tumor: 0.7072 - recall_tumor: 0.6865 - tumor_iou: 0.5275 - val_acc: 0.9891 - val_dice_coef_metric_tumor: 0.5869 - val_loss: 0.2937 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6544 - val_recall_tumor: 0.5558 - val_tumor_iou: 0.4404 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 252 lên WandB.\n\n--- Epoch 253/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9901 - dice_coef_metric_tumor: 0.6852 - loss: 0.2253 - mean_iou_all: 0.4709 - precision_tumor: 0.7012 - recall_tumor: 0.6991 - tumor_iou: 0.5365\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9901 - dice_coef_metric_tumor: 0.6851 - loss: 0.2252 - mean_iou_all: 0.4707 - precision_tumor: 0.7012 - recall_tumor: 0.6991 - tumor_iou: 0.5365 - val_acc: 0.9900 - val_dice_coef_metric_tumor: 0.5767 - val_loss: 0.3002 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7427 - val_recall_tumor: 0.4947 - val_tumor_iou: 0.4292 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 253 lên WandB.\n\n--- Epoch 254/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9908 - dice_coef_metric_tumor: 0.7022 - loss: 0.2167 - mean_iou_all: 0.4695 - precision_tumor: 0.7218 - recall_tumor: 0.7071 - tumor_iou: 0.5577\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9908 - dice_coef_metric_tumor: 0.7021 - loss: 0.2167 - mean_iou_all: 0.4694 - precision_tumor: 0.7216 - recall_tumor: 0.7070 - tumor_iou: 0.5576 - val_acc: 0.9897 - val_dice_coef_metric_tumor: 0.6007 - val_loss: 0.2852 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6757 - val_recall_tumor: 0.5631 - val_tumor_iou: 0.4531 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 254 lên WandB.\n\n--- Epoch 255/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - acc: 0.9901 - dice_coef_metric_tumor: 0.6773 - loss: 0.2288 - mean_iou_all: 0.4706 - precision_tumor: 0.6951 - recall_tumor: 0.6945 - tumor_iou: 0.5321\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 921ms/step - acc: 0.9901 - dice_coef_metric_tumor: 0.6772 - loss: 0.2288 - mean_iou_all: 0.4705 - precision_tumor: 0.6951 - recall_tumor: 0.6945 - tumor_iou: 0.5321 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5957 - val_loss: 0.2883 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6501 - val_recall_tumor: 0.5801 - val_tumor_iou: 0.4491 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 255 lên WandB.\n\n--- Epoch 256/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.6917 - loss: 0.2237 - mean_iou_all: 0.4682 - precision_tumor: 0.7145 - recall_tumor: 0.6975 - tumor_iou: 0.5430\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 919ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.6916 - loss: 0.2237 - mean_iou_all: 0.4680 - precision_tumor: 0.7145 - recall_tumor: 0.6975 - tumor_iou: 0.5430 - val_acc: 0.9890 - val_dice_coef_metric_tumor: 0.5784 - val_loss: 0.2994 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6604 - val_recall_tumor: 0.5518 - val_tumor_iou: 0.4280 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 256 lên WandB.\n\n--- Epoch 257/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6718 - loss: 0.2331 - mean_iou_all: 0.4521 - precision_tumor: 0.6761 - recall_tumor: 0.7056 - tumor_iou: 0.5222\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9895 - dice_coef_metric_tumor: 0.6717 - loss: 0.2332 - mean_iou_all: 0.4520 - precision_tumor: 0.6760 - recall_tumor: 0.7055 - tumor_iou: 0.5221 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.5969 - val_loss: 0.2881 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6527 - val_recall_tumor: 0.5795 - val_tumor_iou: 0.4515 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 257 lên WandB.\n\n--- Epoch 258/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6840 - loss: 0.2299 - mean_iou_all: 0.4625 - precision_tumor: 0.6912 - recall_tumor: 0.7064 - tumor_iou: 0.5350\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.60889\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9897 - dice_coef_metric_tumor: 0.6840 - loss: 0.2299 - mean_iou_all: 0.4623 - precision_tumor: 0.6913 - recall_tumor: 0.7065 - tumor_iou: 0.5350 - val_acc: 0.9898 - val_dice_coef_metric_tumor: 0.6059 - val_loss: 0.2824 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6571 - val_recall_tumor: 0.5896 - val_tumor_iou: 0.4592 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 258 lên WandB.\n\n--- Epoch 259/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6724 - loss: 0.2358 - mean_iou_all: 0.4772 - precision_tumor: 0.6928 - recall_tumor: 0.6914 - tumor_iou: 0.5225\nEpoch 1: val_dice_coef_metric_tumor improved from 0.60889 to 0.61903, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 924ms/step - acc: 0.9896 - dice_coef_metric_tumor: 0.6723 - loss: 0.2358 - mean_iou_all: 0.4771 - precision_tumor: 0.6928 - recall_tumor: 0.6914 - tumor_iou: 0.5225 - val_acc: 0.9901 - val_dice_coef_metric_tumor: 0.6190 - val_loss: 0.2741 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6864 - val_recall_tumor: 0.5903 - val_tumor_iou: 0.4685 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 259 lên WandB.\n\n--- Epoch 260/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9906 - dice_coef_metric_tumor: 0.6917 - loss: 0.2225 - mean_iou_all: 0.4787 - precision_tumor: 0.7186 - recall_tumor: 0.7031 - tumor_iou: 0.5438\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.61903\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9906 - dice_coef_metric_tumor: 0.6917 - loss: 0.2225 - mean_iou_all: 0.4786 - precision_tumor: 0.7185 - recall_tumor: 0.7031 - tumor_iou: 0.5438 - val_acc: 0.9900 - val_dice_coef_metric_tumor: 0.6108 - val_loss: 0.2792 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7062 - val_recall_tumor: 0.5661 - val_tumor_iou: 0.4608 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 260 lên WandB.\n\n--- Epoch 261/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9906 - dice_coef_metric_tumor: 0.6940 - loss: 0.2204 - mean_iou_all: 0.4606 - precision_tumor: 0.7158 - recall_tumor: 0.6999 - tumor_iou: 0.5458\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.61903\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9906 - dice_coef_metric_tumor: 0.6940 - loss: 0.2204 - mean_iou_all: 0.4605 - precision_tumor: 0.7158 - recall_tumor: 0.7000 - tumor_iou: 0.5458 - val_acc: 0.9900 - val_dice_coef_metric_tumor: 0.6008 - val_loss: 0.2862 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7138 - val_recall_tumor: 0.5408 - val_tumor_iou: 0.4507 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 261 lên WandB.\n\n--- Epoch 262/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815ms/step - acc: 0.9901 - dice_coef_metric_tumor: 0.6873 - loss: 0.2258 - mean_iou_all: 0.4768 - precision_tumor: 0.6978 - recall_tumor: 0.7128 - tumor_iou: 0.5405\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.61903\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 915ms/step - acc: 0.9901 - dice_coef_metric_tumor: 0.6872 - loss: 0.2258 - mean_iou_all: 0.4767 - precision_tumor: 0.6977 - recall_tumor: 0.7128 - tumor_iou: 0.5404 - val_acc: 0.9894 - val_dice_coef_metric_tumor: 0.6159 - val_loss: 0.2765 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6230 - val_recall_tumor: 0.6368 - val_tumor_iou: 0.4701 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 262 lên WandB.\n\n--- Epoch 263/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.6927 - loss: 0.2237 - mean_iou_all: 0.4817 - precision_tumor: 0.7153 - recall_tumor: 0.6976 - tumor_iou: 0.5456\nEpoch 1: val_dice_coef_metric_tumor improved from 0.61903 to 0.62286, saving model to unet_model_unet_model_combined_dice0.6_focal_attnFalse_02062025_093045.h5\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 925ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.6926 - loss: 0.2237 - mean_iou_all: 0.4816 - precision_tumor: 0.7152 - recall_tumor: 0.6976 - tumor_iou: 0.5455 - val_acc: 0.9897 - val_dice_coef_metric_tumor: 0.6229 - val_loss: 0.2722 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6580 - val_recall_tumor: 0.6156 - val_tumor_iou: 0.4763 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 263 lên WandB.\n\n--- Epoch 264/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9900 - dice_coef_metric_tumor: 0.6955 - loss: 0.2229 - mean_iou_all: 0.4808 - precision_tumor: 0.7076 - recall_tumor: 0.7167 - tumor_iou: 0.5489\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.62286\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 920ms/step - acc: 0.9900 - dice_coef_metric_tumor: 0.6954 - loss: 0.2229 - mean_iou_all: 0.4807 - precision_tumor: 0.7075 - recall_tumor: 0.7167 - tumor_iou: 0.5489 - val_acc: 0.9898 - val_dice_coef_metric_tumor: 0.6146 - val_loss: 0.2770 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6715 - val_recall_tumor: 0.5905 - val_tumor_iou: 0.4663 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 264 lên WandB.\n\n--- Epoch 265/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.7003 - loss: 0.2192 - mean_iou_all: 0.4789 - precision_tumor: 0.7129 - recall_tumor: 0.7168 - tumor_iou: 0.5527\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.62286\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 915ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.7002 - loss: 0.2192 - mean_iou_all: 0.4787 - precision_tumor: 0.7129 - recall_tumor: 0.7168 - tumor_iou: 0.5526 - val_acc: 0.9897 - val_dice_coef_metric_tumor: 0.5945 - val_loss: 0.2894 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6933 - val_recall_tumor: 0.5440 - val_tumor_iou: 0.4471 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 265 lên WandB.\n\n--- Epoch 266/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9906 - dice_coef_metric_tumor: 0.6963 - loss: 0.2199 - mean_iou_all: 0.4657 - precision_tumor: 0.7176 - recall_tumor: 0.7058 - tumor_iou: 0.5475\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.62286\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9906 - dice_coef_metric_tumor: 0.6962 - loss: 0.2199 - mean_iou_all: 0.4655 - precision_tumor: 0.7176 - recall_tumor: 0.7058 - tumor_iou: 0.5474 - val_acc: 0.9893 - val_dice_coef_metric_tumor: 0.6109 - val_loss: 0.2795 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6284 - val_recall_tumor: 0.6178 - val_tumor_iou: 0.4627 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 266 lên WandB.\n\n--- Epoch 267/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.6994 - loss: 0.2209 - mean_iou_all: 0.4635 - precision_tumor: 0.7191 - recall_tumor: 0.7105 - tumor_iou: 0.5529\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.62286\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.6993 - loss: 0.2209 - mean_iou_all: 0.4632 - precision_tumor: 0.7190 - recall_tumor: 0.7105 - tumor_iou: 0.5529 - val_acc: 0.9898 - val_dice_coef_metric_tumor: 0.5481 - val_loss: 0.3182 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7816 - val_recall_tumor: 0.4426 - val_tumor_iou: 0.3993 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 267 lên WandB.\n\n--- Epoch 268/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9907 - dice_coef_metric_tumor: 0.7033 - loss: 0.2179 - mean_iou_all: 0.4667 - precision_tumor: 0.7268 - recall_tumor: 0.7057 - tumor_iou: 0.5565\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.62286\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9907 - dice_coef_metric_tumor: 0.7032 - loss: 0.2179 - mean_iou_all: 0.4666 - precision_tumor: 0.7268 - recall_tumor: 0.7057 - tumor_iou: 0.5565 - val_acc: 0.9888 - val_dice_coef_metric_tumor: 0.5942 - val_loss: 0.2901 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6439 - val_recall_tumor: 0.5806 - val_tumor_iou: 0.4447 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 268 lên WandB.\n\n--- Epoch 269/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9905 - dice_coef_metric_tumor: 0.6912 - loss: 0.2230 - mean_iou_all: 0.4714 - precision_tumor: 0.7163 - recall_tumor: 0.7044 - tumor_iou: 0.5474\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.62286\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 918ms/step - acc: 0.9905 - dice_coef_metric_tumor: 0.6912 - loss: 0.2230 - mean_iou_all: 0.4712 - precision_tumor: 0.7163 - recall_tumor: 0.7044 - tumor_iou: 0.5474 - val_acc: 0.9901 - val_dice_coef_metric_tumor: 0.5945 - val_loss: 0.2892 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7090 - val_recall_tumor: 0.5369 - val_tumor_iou: 0.4488 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 269 lên WandB.\n\n--- Epoch 270/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9907 - dice_coef_metric_tumor: 0.6988 - loss: 0.2175 - mean_iou_all: 0.4629 - precision_tumor: 0.7156 - recall_tumor: 0.7130 - tumor_iou: 0.5546\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.62286\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9907 - dice_coef_metric_tumor: 0.6987 - loss: 0.2175 - mean_iou_all: 0.4626 - precision_tumor: 0.7155 - recall_tumor: 0.7129 - tumor_iou: 0.5545 - val_acc: 0.9892 - val_dice_coef_metric_tumor: 0.5840 - val_loss: 0.2969 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6639 - val_recall_tumor: 0.5472 - val_tumor_iou: 0.4346 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 270 lên WandB.\n\n--- Epoch 271/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9902 - dice_coef_metric_tumor: 0.6834 - loss: 0.2245 - mean_iou_all: 0.4683 - precision_tumor: 0.6959 - recall_tumor: 0.7113 - tumor_iou: 0.5354\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.62286\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9902 - dice_coef_metric_tumor: 0.6834 - loss: 0.2245 - mean_iou_all: 0.4681 - precision_tumor: 0.6959 - recall_tumor: 0.7112 - tumor_iou: 0.5354 - val_acc: 0.9901 - val_dice_coef_metric_tumor: 0.5886 - val_loss: 0.2932 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7224 - val_recall_tumor: 0.5254 - val_tumor_iou: 0.4403 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 271 lên WandB.\n\n--- Epoch 272/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.6817 - loss: 0.2249 - mean_iou_all: 0.4538 - precision_tumor: 0.6965 - recall_tumor: 0.7048 - tumor_iou: 0.5381\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.62286\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.6816 - loss: 0.2249 - mean_iou_all: 0.4535 - precision_tumor: 0.6964 - recall_tumor: 0.7048 - tumor_iou: 0.5380 - val_acc: 0.9897 - val_dice_coef_metric_tumor: 0.5689 - val_loss: 0.3054 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6837 - val_recall_tumor: 0.5161 - val_tumor_iou: 0.4244 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 272 lên WandB.\n\n--- Epoch 273/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9907 - dice_coef_metric_tumor: 0.7113 - loss: 0.2145 - mean_iou_all: 0.4716 - precision_tumor: 0.7284 - recall_tumor: 0.7266 - tumor_iou: 0.5654\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.62286\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 916ms/step - acc: 0.9907 - dice_coef_metric_tumor: 0.7113 - loss: 0.2145 - mean_iou_all: 0.4714 - precision_tumor: 0.7283 - recall_tumor: 0.7265 - tumor_iou: 0.5654 - val_acc: 0.9897 - val_dice_coef_metric_tumor: 0.6125 - val_loss: 0.2788 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6584 - val_recall_tumor: 0.6023 - val_tumor_iou: 0.4672 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 273 lên WandB.\n\n--- Epoch 274/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - acc: 0.9907 - dice_coef_metric_tumor: 0.6992 - loss: 0.2193 - mean_iou_all: 0.4674 - precision_tumor: 0.7253 - recall_tumor: 0.7077 - tumor_iou: 0.5520\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.62286\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9907 - dice_coef_metric_tumor: 0.6991 - loss: 0.2193 - mean_iou_all: 0.4672 - precision_tumor: 0.7252 - recall_tumor: 0.7077 - tumor_iou: 0.5520 - val_acc: 0.9901 - val_dice_coef_metric_tumor: 0.6055 - val_loss: 0.2832 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6947 - val_recall_tumor: 0.5623 - val_tumor_iou: 0.4566 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 274 lên WandB.\n\n--- Epoch 275/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - acc: 0.9906 - dice_coef_metric_tumor: 0.6998 - loss: 0.2181 - mean_iou_all: 0.4476 - precision_tumor: 0.7101 - recall_tumor: 0.7186 - tumor_iou: 0.5526\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.62286\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 914ms/step - acc: 0.9906 - dice_coef_metric_tumor: 0.6998 - loss: 0.2181 - mean_iou_all: 0.4474 - precision_tumor: 0.7101 - recall_tumor: 0.7185 - tumor_iou: 0.5526 - val_acc: 0.9896 - val_dice_coef_metric_tumor: 0.6079 - val_loss: 0.2818 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.6341 - val_recall_tumor: 0.6140 - val_tumor_iou: 0.4593 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 275 lên WandB.\n\n--- Epoch 276/300 ---\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.6963 - loss: 0.2219 - mean_iou_all: 0.4526 - precision_tumor: 0.7130 - recall_tumor: 0.7093 - tumor_iou: 0.5483\nEpoch 1: val_dice_coef_metric_tumor did not improve from 0.62286\n\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 917ms/step - acc: 0.9904 - dice_coef_metric_tumor: 0.6963 - loss: 0.2219 - mean_iou_all: 0.4523 - precision_tumor: 0.7129 - recall_tumor: 0.7093 - tumor_iou: 0.5483 - val_acc: 0.9902 - val_dice_coef_metric_tumor: 0.5973 - val_loss: 0.2885 - val_mean_iou_all: 0.5000 - val_precision_tumor: 0.7441 - val_recall_tumor: 0.5193 - val_tumor_iou: 0.4500 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\nĐã log metrics cho epoch 276 lên WandB.\n\n--- Epoch 277/300 ---\n\u001b[1m166/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 817ms/step - acc: 0.9911 - dice_coef_metric_tumor: 0.7151 - loss: 0.2118 - mean_iou_all: 0.4291 - precision_tumor: 0.7434 - recall_tumor: 0.7155 - tumor_iou: 0.5666","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"   ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}